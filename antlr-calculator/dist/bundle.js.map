{"version":3,"sources":["webpack:///dist/bundle.js","webpack:///webpack/bootstrap 942a5966cbc125448730","webpack:///./Calculator.ts","webpack:///./FormulaVisitor.ts","webpack:///./GeneratedAntlr/index.js","webpack:///./GeneratedAntlr/CalculatorLexer.js","webpack:///./~/antlr4/index.js","webpack:///./~/antlr4/atn/index.js","webpack:///./~/antlr4/atn/ATN.js","webpack:///./~/antlr4/LL1Analyzer.js","webpack:///./~/antlr4/Utils.js","webpack:///./~/antlr4/Token.js","webpack:///./~/antlr4/atn/ATNConfig.js","webpack:///./~/antlr4/atn/ATNState.js","webpack:///./~/antlr4/atn/SemanticContext.js","webpack:///./~/antlr4/IntervalSet.js","webpack:///./~/antlr4/atn/Transition.js","webpack:///./~/antlr4/PredictionContext.js","webpack:///./~/antlr4/RuleContext.js","webpack:///./~/antlr4/tree/Tree.js","webpack:///./~/antlr4/tree/Trees.js","webpack:///./~/antlr4/ParserRuleContext.js","webpack:///./~/antlr4/atn/ATNDeserializer.js","webpack:///./~/antlr4/atn/ATNType.js","webpack:///./~/antlr4/atn/ATNDeserializationOptions.js","webpack:///./~/antlr4/atn/LexerAction.js","webpack:///./~/antlr4/atn/LexerATNSimulator.js","webpack:///./~/antlr4/Lexer.js","webpack:///./~/antlr4/Recognizer.js","webpack:///./~/antlr4/error/ErrorListener.js","webpack:///./~/antlr4/CommonTokenFactory.js","webpack:///./~/antlr4/error/Errors.js","webpack:///./~/antlr4/atn/ATNSimulator.js","webpack:///./~/antlr4/dfa/DFAState.js","webpack:///./~/antlr4/atn/ATNConfigSet.js","webpack:///./~/antlr4/atn/LexerActionExecutor.js","webpack:///./~/antlr4/atn/ParserATNSimulator.js","webpack:///./~/antlr4/atn/PredictionMode.js","webpack:///./~/antlr4/dfa/index.js","webpack:///./~/antlr4/dfa/DFA.js","webpack:///./~/antlr4/dfa/DFASerializer.js","webpack:///./~/antlr4/tree/index.js","webpack:///./~/antlr4/error/index.js","webpack:///./~/antlr4/error/DiagnosticErrorListener.js","webpack:///./~/antlr4/error/ErrorStrategy.js","webpack:///./~/antlr4/InputStream.js","webpack:///./~/antlr4/FileStream.js","webpack:///./~/antlr4/CommonTokenStream.js","webpack:///./~/antlr4/BufferedTokenStream.js","webpack:///./~/antlr4/Parser.js","webpack:///./GeneratedAntlr/CalculatorParser.js","webpack:///./GeneratedAntlr/CalculatorVisitor.js","webpack:///./CalculationResult.ts","webpack:///./FormulaErrorListener.ts"],"names":["antlrCalc","modules","__webpack_require__","moduleId","installedModules","exports","module","id","loaded","call","m","c","p","__WEBPACK_AMD_DEFINE_ARRAY__","__WEBPACK_AMD_DEFINE_RESULT__","require","FormulaVisitor_1","CalculationResult_1","FormulaErrorListener_1","antlr4_1","GeneratedAntlr_1","Calculator","calculate","formula","result","CalculationResult","match","isValid","inputStream","InputStream","lexer","CalculatorLexer","commonTokenStream","CommonTokenStream","parser","CalculatorParser","errorListener","FormulaErrorListener","_listeners","visitor","FormulaVisitor","parseTree","calculator","visitorResult","visitCalculator","isNaN","NaN","errorPosition","errorLocation","errorMessage","apply","undefined","__extends","this","d","b","__","constructor","hasOwnProperty","prototype","Object","create","_super","arguments","context","expression","accept","visitExpression","visitTan","Math","tan","visitCosh","cosh","visitSqRoot","nthRoot","pow","visitNegExponent","visitExponent","visitArctan2","atan2","visitMulDiv","op","text","divisor","visitArcsin","asin","visitArccot","PI","atan","visitArccos","acos","visitEuler","E","visitArctan","visitParenthesis","visitAbs","abs","visitNumber","Number","getText","replace","visitSinh","sinh","visitRound","round","visitTrunc","trunc","visitPi","visitTanh","tanh","visitFloor","floor","visitLn","log","visitMod","visitLog","log10","visitAddSub","visitCos","cos","visitDeg","visitSqrt","sqrt","visitCot","visitWhole","visitUnary","visitUnaryPlus","visitRad","visitSqr","visitSin","sin","visitEex","visitPow","visitCeil","ceil","visitExp","visitRoundk","CalculatorVisitor","input","antlr4","Lexer","_interp","atn","LexerATNSimulator","decisionsToDFA","PredictionContextCache","serializedATN","join","ATNDeserializer","deserialize","decisionToState","map","ds","index","dfa","DFA","EOF","Token","T__0","T__1","T__2","T__3","T__4","T__5","T__6","T__7","T__8","NUMBER","FLOAT","DIGIT","MOD","WHOLE","MUL","DIV","ADD","SUB","EXPONENT","NEGEXPONENT","EULER","SQRT","SQR","FLOOR","CEIL","ABS","ROUNDK","ROUND","TRUNC","SIN","COS","TAN","COT","SINH","COSH","TANH","ARCSIN","ARCCOS","ARCTAN","ARCTAN2","ARCCOT","EXP","LN","EEX","LOG","RAD","DEG","WS","COM","INVALID","modeNames","literalNames","symbolicNames","ruleNames","grammarFileName","tree","error","CommonToken","FileStream","Parser","pc","ParserRuleContext","Interval","Utils","ATN","ParserATNSimulator","PredictionMode","grammarType","maxTokenType","states","ruleToStartState","ruleToStopState","modeNameToStartState","ruleToTokenType","lexerActions","modeToStartState","LL1Analyzer","IntervalSet","nextTokensInContext","s","ctx","anal","LOOK","nextTokensNoContext","nextTokenWithinRule","readOnly","nextTokens","addState","state","stateNumber","length","push","removeState","defineDecisionState","decision","getDecisionState","getExpectedTokens","following","contains","EPSILON","expected","addSet","removeOne","invokingState","rt","transitions","followState","parentCtx","addOne","INVALID_ALT_NUMBER","Set","BitSet","ATNConfig","RuleStopState","RuleTransition","NotSetTransition","WildcardTransition","AbstractPredicateTransition","predictionContextFromRuleContext","PredictionContext","SingletonPredictionContext","HIT_PRED","INVALID_TYPE","getDecisionLookahead","count","look","alt","lookBusy","seeThruPreds","_LOOK","transition","target","EMPTY","stopState","r","lookContext","calledRuleStack","addEOF","add","isEmpty","i","returnState","getReturnState","removed","ruleIndex","remove","getParent","j","t","newContext","isEpsilon","addRange","MIN_USER_TOKEN_TYPE","set","label","complement","arrayToString","a","standardEqualsFunction","equals","standardHashFunction","hashString","hashFunction","equalsFunction","data","AltDict","DoubleDict","escapeWhitespace","escapeSpaces","String","hashCode","hash","character","charCodeAt","defineProperty","get","values","value","key","l","indexOf","concat","toString","or","bits","keys","minValue","min","other","put","o","isArray","entity","titleCase","str","txt","charAt","toUpperCase","substr","source","type","channel","start","stop","tokenIndex","line","column","_text","EMPTY_SOURCE","DEFAULT_CHANNEL","HIDDEN_CHANNEL","getTokenSource","getInputStream","clone","n","size","checkParams","params","isCfg","semanticContext","reachesIntoOuterContext","props","precedenceFilterSuppressed","config","checkContext","SemanticContext","NONE","LexerATNConfig","lexerActionExecutor","passedThroughNonGreedyDecision","checkNonGreedyDecision","DecisionState","shortHashString","nonGreedy","ATNState","INVALID_STATE_NUMBER","stateType","epsilonOnlyTransitions","BasicState","BASIC","BlockStartState","endState","BasicBlockStartState","BLOCK_START","BlockEndState","BLOCK_END","startState","RULE_STOP","RuleStartState","RULE_START","isPrecedenceRule","PlusLoopbackState","PLUS_LOOP_BACK","PlusBlockStartState","PLUS_BLOCK_START","loopBackState","StarBlockStartState","STAR_BLOCK_START","StarLoopbackState","STAR_LOOP_BACK","StarLoopEntryState","STAR_LOOP_ENTRY","precedenceRuleDecision","LoopEndState","LOOP_END","TokensStartState","TOKEN_START","serializationNames","isNonGreedyExitState","addTransition","trans","splice","Predicate","predIndex","isCtxDependent","PrecedencePredicate","precedence","AND","operands","opnds","precedencePredicates","filterPrecedencePredicates","reduced","OR","sort","compareTo","evaluate","outerContext","evalPrecedence","andContext","orContext","localctx","sempred","precpred","differs","evaluated","slice","intervals","item","first","v","addInterval","h","k","max","reduce","intervalslength","pop","removeRange","len","x","elemsAreChar","toTokenString","toCharString","toIndexString","names","fromCharCode","elementName","Transition","AtomTransition","label_","makeLabel","serializationType","ATOM","ruleStart","RULE","EpsilonTransition","outermostPrecedenceReturn","RangeTransition","RANGE","PredicateTransition","PREDICATE","ActionTransition","actionIndex","ACTION","SetTransition","SET","NOT_SET","WILDCARD","PrecedencePredicateTransition","PRECEDENCE","serializationTypes","matches","symbol","minVocabSymbol","maxVocabSymbol","getPredicate","cachedHashString","calculateHashString","parent","calculateEmptyHashString","cache","EmptyPredictionContext","EMPTY_RETURN_STATE","ArrayPredictionContext","parents","returnStates","RuleContext","merge","rootIsWildcard","mergeCache","mergeSingletons","mergeArrays","previous","rootMerge","mergeRoot","spc","singleParent","payloads","apc","a_","mergedReturnStates","mergedParents","a_parent","b_parent","payload","bothDollars","ax_ax","mergedParent","M","combineCommonParents","uniqueParents","q","getCachedPredictionContext","contextCache","visited","existing","changed","updated","globalNodeCount","hasEmptyPath","contructor","up","RuleNode","INVALID_INTERVAL","depth","getSourceInterval","getRuleContext","getPayload","getChildCount","children","child","getAltNumber","setAltNumber","altNumber","getChild","visitChildren","Trees","toStringTree","recog","ri","ruleName","Tree","SyntaxTree","ParseTree","TerminalNode","ErrorNode","ParseTreeVisitor","ParseTreeListener","TerminalNodeImpl","ErrorNodeImpl","token","ParseTreeWalker","visit","self","visitAtom","visitTerminal","node","visitErrorNode","name","funcName","enterEveryRule","exitEveryRule","getSymbol","isErrorNode","walk","listener","errorNode","enterRule","exitRule","DEFAULT","getNodeText","res","getChildren","list","getAncestors","ancestors","findAllTokenNodes","ttype","findAllNodes","findAllRuleNodes","findTokens","nodes","_findAllNodes","descendants","invokingStateNumber","exception","InterpreterRuleContext","copyFrom","addChild","removeLastChild","addTokenNode","addErrorNode","badToken","getToken","getTokens","tokens","getTypedRuleContext","ctxType","getTypedRuleContexts","contexts","initArray","tmp","options","ATNDeserializationOptions","defaultOptions","deserializationOptions","stateFactories","actionFactories","createByteToHex","bth","ATNType","ATNStates","Transitions","LexerActions","LexerActionType","LexerSkipAction","LexerChannelAction","LexerCustomAction","LexerMoreAction","LexerTypeAction","LexerPushModeAction","LexerPopModeAction","LexerModeAction","BASE_SERIALIZED_UUID","SUPPORTED_UUIDS","SERIALIZED_VERSION","SERIALIZED_UUID","isFeatureSupported","feature","actualUuid","idx1","idx2","reset","checkVersion","checkUUID","readATN","readStates","readRules","readModes","sets","readSets","readEdges","readDecisions","readLexerActions","markPrecedenceDecisions","verifyATN","generateRuleBypassTransitions","PARSER","adjust","temp","split","pos","version","readInt","uuid","readUUID","pair","loopBackStateNumbers","endStateNumbers","nstates","stype","stateFactory","loopBackStateNumber","endStateNumber","numNonGreedyStates","numPrecedenceStates","nrules","LEXER","tokenType","nmodes","iset","containsEof","i1","i2","nedges","src","trg","arg1","arg2","arg3","edgeFactory","srcState","ndecisions","decState","actionType","data1","data2","lexerAction","lexerActionFactory","generateRuleBypassTransition","idx","bypassStart","bypassStop","excludeTransition","stateIsEndStateFor","matchState","maybeLoopEndState","checkCondition","condition","message","readInt32","low","high","readLong","byteToHex","bb","int","sf","af","CHANNEL","CUSTOM","MODE","MORE","INSTANCE","POP_MODE","PUSH_MODE","SKIP","TYPE","LexerAction","action","isPositionDependent","mode","LexerIndexedCustomAction","offset","execute","skip","pushMode","popMode","more","_channel","resetSimState","sim","dfaState","SimState","decisionToDFA","sharedContextCache","ATNSimulator","startIndex","DEFAULT_MODE","prevAccept","DFAState","OrderedATNConfigSet","ATNConfigSet","LexerActionExecutor","LexerNoViableAltException","debug","dfa_debug","MIN_DFA_EDGE","MAX_DFA_EDGE","match_calls","copyState","simulator","mark","s0","matchATN","execATN","release","console","old_mode","s0_closure","computeStartState","suppressEdge","hasSemanticContext","next","addDFAState","predict","toLexerString","ds0","configs","isAcceptState","captureSimState","LA","getExistingTargetState","computeTargetState","ERROR","consume","failOrAccept","edges","reach","getReachableConfigSet","items","addDFAEdge","prediction","closure","skipAlt","cfg","currentAltReachedAcceptState","getTokenName","getReachableTarget","fixOffsetBeforeMatch","treatEofAsEpsilon","charPos","seek","initialContext","speculative","getRuleNames","getEpsilonTarget","evaluatePredicate","append","savedcolumn","savedLine","marker","settings","from_","tk","to","cfgs","proposed","firstConfigWithRuleStopState","newState","setReadonly","getDFA","curChar","tt","Recognizer","_input","_factory","CommonTokenFactory","_tokenFactorySourcePair","_token","_tokenStartCharIndex","_tokenStartLine","_tokenStartColumn","_hitEOF","_type","_modeStack","_mode","DEFAULT_TOKEN_CHANNEL","HIDDEN","MIN_CHAR_VALUE","MAX_CHAR_VALUE","nextToken","tokenStartMarker","emitEOF","continueOuter","e","notifyListeners","recover","emit","sourceName","emitToken","getCharIndex","cpos","lpos","eof","getAllTokens","msg","getErrorDisplay","getErrorListenerDispatch","syntaxError","getErrorDisplayForChar","getCharErrorDisplay","re","ConsoleErrorListener","_stateNumber","ProxyErrorListener","tokenTypeMapCache","ruleIndexMapCache","toolVersion","runtimeVersion","addErrorListener","removeErrorListeners","getTokenTypeMap","tokenNames","getTokenNames","getRuleIndexMap","getTokenType","tokenName","getErrorHeader","getOffendingToken","getTokenErrorDisplay","ErrorListener","delegates","recognizer","offendingSymbol","reportAmbiguity","stopIndex","exact","ambigAlts","reportAttemptingFullContext","conflictingAlts","reportContextSensitivity","TokenFactory","copyText","createThin","RecognitionException","Error","captureStackTrace","stack","offendingToken","offendingState","deadEndConfigs","NoViableAltException","startToken","_ctx","getCurrentToken","InputMismatchException","FailedPredicateException","predicate","formatMessage","predicateIndex","ParseCancellationException","getCachedContext","PredPrediction","pred","requiresFullContext","predicates","getAltSet","alts","hashATNConfig","equalATNConfigs","fullCtx","configLookup","uniqueAlt","dipsIntoOuterContext","merged","getStates","getPredicates","preds","optimizeConfigs","interpreter","addAll","coll","hashConfigs","containsFast","clear","_hashString","updatedLexerActions","requiresSeek","numActions","predictionMode","LL","_startIndex","_outerContext","_dfa","debug_list_atn_decisions","retry_debug","adaptivePredict","getLookaheadName","LT","precedenceDfa","getPrecedenceStartState","getPrecedence","atnStartState","setPrecedenceDfa","applyPrecedenceFilter","setPrecedenceStartState","previousD","D","noViableAlt","getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule","SLL","conflictIndex","evalSemanticContext","execATNWithFullContext","computeReachSet","predictedAlt","getUniqueAlt","altSubSets","getConflictingAltSubsets","allSubsetsConflict","getConflictingAlts","hasSLLConflictTerminatingPrediction","predicateDFAState","decisionState","nalts","altsToCollectPredsFrom","getConflictingAltsOrUniqueAlt","altToPred","getPredsForAmbigAlts","getPredicatePredictions","foundExactAmbig","resolvesToJustOneViableAlt","LL_EXACT_AMBIG_DETECTION","allSubsetsEqual","getSingleViableAlt","intermediate","skippedStopStates","closureBusy","removeAllConfigsNotInRuleStopState","hasConfigInRuleStopState","lookToEndOfRule","allConfigsInRuleStopStates","endOfRuleState","statesFromAlt1","configSet","updatedContext","nPredAlts","pairs","containsPredicate","splitAccordingToSemanticValidity","semValidConfigs","semInvalidConfigs","getAltThatFinishedDecisionEntryRule","succeeded","failed","predicateEvaluationResult","predPredictions","complete","predictions","collectPredicates","initialDepth","closureCheckingStopState","parms","getRuleName","closure_","continueCollecting","newDepth","inContext","ruleTransition","precedenceTransition","predTransition","actionTransition","pt","getRuleInvocationStack","currentPosition","predSucceeds","newSemCtx","altsets","getAlts","dumpDeadEndConfigs","nvae","decs","getDeadEndConfigs","neg","interval","getTokenStream","dup","hasConflictingAltSet","hasStateAssociatedWithOneAlt","hasNonConflictingAltSet","all","configToAlts","getStateToAltMap","minAlt","DFASerializer","LexerDFASerializer","DFAStatesSet","_states","precedenceState","sortedStates","serializer","buf","getStateString","getEdgeLabel","baseStateStr","DiagnosticErrorListener","BailErrorStrategy","exactOnly","getDecisionDescription","notifyErrorListeners","reportedAlts","ErrorStrategy","DefaultErrorStrategy","errorRecoveryMode","lastErrorIndex","lastErrorStates","Errors","recoverInline","sync","inErrorRecoveryMode","reportError","endErrorCondition","beginErrorCondition","reportMatch","reportNoViableAlternative","reportInputMismatch","reportFailedPredicate","getMessage","followSet","getErrorRecoverySet","consumeUntil","la","isExpectedToken","singleTokenDeletion","reportUnwantedToken","expecting","whatFollowsLoopIterationOrRule","escapeWSAndQuote","reportMissingToken","matchedSymbol","singleTokenInsertion","getMissingSymbol","currentSymbolType","currentState","expectingAtLL2","nextTokenType","tokenText","currentSymbol","expectedTokenType","current","lookback","getTokenFactory","recoverSet","follow","_loadString","stream","_index","strdata","_size","fileName","fs","readFileSync","isNodeJs","window","importScripts","BufferedTokenStream","adjustSeekIndex","nextTokenOnChannel","LB","previousTokenOnChannel","lazyInit","getNumberOfOnChannelTokens","fill","TokenStream","tokenSource","fetchedEOF","skipEofCheck","fetched","fetch","types","subset","setup","setTokenSource","getHiddenTokensToRight","nextOnChannel","filterForChannel","getHiddenTokensToLeft","prevOnChannel","left","right","hidden","getSourceName","TraceListener","_errHandler","_precedenceStack","buildParseTrees","_tracer","_parseListeners","_syntaxErrors","setInputStream","bypassAltsAtnCache","setTrace","matchWildcard","_buildParseTrees","getParseListeners","addParseListener","removeParseListener","removeParseListeners","triggerEnterRuleEvent","triggerExitRuleEvent","reverse","setTokenFactory","factory","getATNWithBypassAlts","serializedAtn","getSerializedATN","compileParseTreePattern","pattern","patternRuleIndex","ParseTreePatternMatcher","compile","setTokenStream","err","hasListener","addContextToParseTree","enterOuterAlt","altNum","enterRecursionRule","pushNewRecursionContext","unrollRecursionContexts","retCtx","getInvokingContext","getExpectedTokensWithinCurrentRule","getRuleIndex","getDFAStrings","dumpDFA","seenOne","printer","println","print","trace","CalculatorContext","RULE_calculator","ExpressionContext","RULE_expression","TanContext","CoshContext","SqRootContext","NegExponentContext","ExponentContext","Arctan2Context","MulDivContext","ArcsinContext","UnaryPlusContext","ArccotContext","ArccosContext","EulerContext","ArctanContext","ParenthesisContext","AbsContext","NumberContext","SinhContext","RoundContext","TruncContext","PiContext","TanhContext","FloorContext","LnContext","ModContext","LogContext","AddSubContext","CosContext","DegContext","SqrtContext","CotContext","WholeContext","UnaryContext","RadContext","SqrContext","SinContext","EexContext","PowContext","CeilContext","ExpContext","RoundkContext","CompileUnitContext","RULE_compileUnit","compileUnit","la_","_p","_parentctx","_parentState","_prevctx","_startState","_la","_alt","visitCompileUnit","expression_sempred","_isValid","_errorLocation","enumerable","configurable","_errorMessage"],"mappings":"AAAA,GAAIA,WACK,SAAUC,GCGnB,QAAAC,GAAAC,GAGA,GAAAC,EAAAD,GACA,MAAAC,GAAAD,GAAAE,OAGA,IAAAC,GAAAF,EAAAD,IACAE,WACAE,GAAAJ,EACAK,QAAA,EAUA,OANAP,GAAAE,GAAAM,KAAAH,EAAAD,QAAAC,IAAAD,QAAAH,GAGAI,EAAAE,QAAA,EAGAF,EAAAD,QAvBA,GAAAD,KAqCA,OATAF,GAAAQ,EAAAT,EAGAC,EAAAS,EAAAP,EAGAF,EAAAU,EAAA,GAGAV,EAAA,KDOM,SAASI,EAAQD,EAASH,GAE/B,GAAIW,GAA8BC,CAAgCD,IAAgCX,EAAqBG,EAASH,EAAoB,GAAIA,EAAoB,IAAKA,EAAoB,IAAKA,EAAoB,GAAIA,EAAoB,IAAKY,EAAgC,SAAUC,EAASV,EAASW,EAAkBC,EAAqBC,EAAwBC,EAAUC,GAC5X,YEtCL,IAAAC,GAAA,mBAAAA,MAiCA,MAhCkBA,GAAAC,UAAd,SAAwBC,GACpB,GAAIC,GAAS,GAAIP,GAAAQ,iBACjB,IAAgB,OAAZF,GAA+C,OAA3BA,EAAQG,MAAM,SAGlC,MAFAF,GAAOA,OAAS,EAChBA,EAAOG,SAAU,EACVH,CAEX,IAAII,GAAc,GAAIT,GAAAU,YAAYN,GAC9BO,EAAQ,GAAIV,GAAAW,gBAAgBH,GAC5BI,EAAoB,GAAIb,GAAAc,kBAAkBH,GAC1CI,EAAS,GAAId,GAAAe,iBAAiBH,GAC9BI,EAAgB,GAAIlB,GAAAmB,oBACxBH,GAAOI,YAAcF,EACrB,IAAIG,GAAU,GAAIvB,GAAAwB,eACdC,EAAYP,EAAOQ,YACvB,IAAIN,EAAcT,QAAS,CACvB,GAAIgB,GAAgBJ,EAAQK,gBAAgBH,EAQ5C,OAPII,OAAMF,IACNnB,EAAOG,SAAU,EACjBH,EAAOA,OAASsB,MAEhBtB,EAAOG,SAAU,EACjBH,EAAOA,OAASmB,GAEbnB,EAMX,MAJAA,GAAOG,SAAU,EACjBH,EAAOuB,cAAgBX,EAAcY,cACrCxB,EAAOyB,aAAeb,EAAca,aACpCzB,EAAOA,OAASsB,IACTtB,GAEfH,IAjCahB,GAAAgB,WAAUA,GF8EpB6B,MAAM7C,EAASQ,KAAiEsC,SAAlCrC,IAAgDR,EAAOD,QAAUS,KAK5G,SAASR,EAAQD,EAASH,GAE/B,GAAIW,GAA8BC,EAAkCsC,EAAaC,MAAQA,KAAKD,WAAc,SAAUE,EAAGC,GAErH,QAASC,KAAOH,KAAKI,YAAcH,EADnC,IAAK,GAAI1C,KAAK2C,GAAOA,EAAEG,eAAe9C,KAAI0C,EAAE1C,GAAK2C,EAAE3C,GAEnD0C,GAAEK,UAAkB,OAANJ,EAAaK,OAAOC,OAAON,IAAMC,EAAGG,UAAYJ,EAAEI,UAAW,GAAIH,IAEjF3C,IAAgCX,EAAqBG,EAASH,EAAoB,IAAKY,EAAgC,SAAUC,EAASV,EAASe,GACjJ,YGjGL,IAAAoB,GAAA,SAAAsB,GAAA,QAAAtB,KAAoCsB,EAAAZ,MAAAG,KAAAU,WAuQpC,MAvQoCX,GAAAZ,EAAAsB,GAGzBtB,EAAAmB,UAAAf,gBAAP,SAAuBoB,GACnB,MAAOA,GAAQC,WAAW,GAAGC,OAAOb,OAGjCb,EAAAmB,UAAAQ,gBAAP,SAAuBH,GACnB,MAAOA,GAAQE,OAAOb,OAInBb,EAAAmB,UAAAS,SAAP,SAAgBJ,GACZ,MAAOK,MAAKC,IAAIjB,KAAKc,gBAAgBH,EAAQC,WAAW,MAKrDzB,EAAAmB,UAAAY,UAAP,SAAiBP,GACb,MAAOK,MAAKG,KAAKnB,KAAKc,gBAAgBH,EAAQC,WAAW,MAKtDzB,EAAAmB,UAAAc,YAAP,SAAmBT,GACf,GAAIU,GAAUrB,KAAKc,gBAAgBH,EAAQC,WAAW,GACtD,OAAgB,KAAZS,EACO5B,IAEJuB,KAAKM,IAAItB,KAAKc,gBAAgBH,EAAQC,WAAW,IAAK,EAAIS,IAK9DlC,EAAAmB,UAAAiB,iBAAP,SAAwBZ,GACpB,MAAOX,MAAKc,gBAAgBH,EAAQC,WAAW,IAAMI,KAAKM,IAAI,MAAStB,KAAKc,gBAAgBH,EAAQC,WAAW,MAK5GzB,EAAAmB,UAAAkB,cAAP,SAAqBb,GACjB,MAAOX,MAAKc,gBAAgBH,EAAQC,WAAW,IAAMI,KAAKM,IAAI,GAAItB,KAAKc,gBAAgBH,EAAQC,WAAW,MAKvGzB,EAAAmB,UAAAmB,aAAP,SAAoBd,GAChB,MAAOK,MAAKU,MAAM1B,KAAKc,gBAAgBH,EAAQC,WAAW,IAAKZ,KAAKc,gBAAgBH,EAAQC,WAAW,MAKpGzB,EAAAmB,UAAAqB,YAAP,SAAmBhB,GACf,GAAwB,MAApBA,EAAQiB,GAAGC,KACX,MAAO7B,MAAKc,gBAAgBH,EAAQC,WAAW,IAAMZ,KAAKc,gBAAgBH,EAAQC,WAAW,GAE7F,IAAIkB,GAAU9B,KAAKc,gBAAgBH,EAAQC,WAAW,GACtD,OAAgB,KAAZkB,EACO9B,KAAKc,gBAAgBH,EAAQC,WAAW,IAAMkB,EAElDrC,KAMRN,EAAAmB,UAAAyB,YAAP,SAAmBpB,GACf,MAAOK,MAAKgB,KAAKhC,KAAKc,gBAAgBH,EAAQC,WAAW,MAKtDzB,EAAAmB,UAAA2B,YAAP,SAAmBtB,GACf,MAAiB,GAAVK,KAAKkB,GAAWlB,KAAKmB,KAAKnC,KAAKc,gBAAgBH,EAAQC,WAAW,MAKtEzB,EAAAmB,UAAA8B,YAAP,SAAmBzB,GACf,MAAOK,MAAKqB,KAAKrC,KAAKc,gBAAgBH,EAAQC,WAAW,MAKtDzB,EAAAmB,UAAAgC,WAAP,SAAkB3B,GACd,MAAOK,MAAKuB,GAKTpD,EAAAmB,UAAAkC,YAAP,SAAmB7B,GACf,MAAOK,MAAKmB,KAAKnC,KAAKc,gBAAgBH,EAAQC,WAAW,MAKtDzB,EAAAmB,UAAAmC,iBAAP,SAAwB9B,GACpB,MAAOX,MAAKc,gBAAgBH,EAAQC,WAAW,KAK5CzB,EAAAmB,UAAAoC,SAAP,SAAgB/B,GACZ,MAAOK,MAAK2B,IAAI3C,KAAKc,gBAAgBH,EAAQC,WAAW,MAKrDzB,EAAAmB,UAAAsC,YAAP,SAAmBjC,GACf,MAAOkC,QAAOlC,EAAQmC,UAAUC,QAAQ,IAAK,OAK1C5D,EAAAmB,UAAA0C,UAAP,SAAiBrC,GACb,MAAOK,MAAKiC,KAAKjD,KAAKc,gBAAgBH,EAAQC,WAAW,MAKtDzB,EAAAmB,UAAA4C,WAAP,SAAkBvC,GACd,MAAOK,MAAKmC,MAAMnD,KAAKc,gBAAgBH,EAAQC,WAAW,MAKvDzB,EAAAmB,UAAA8C,WAAP,SAAkBzC,GACd,MAAOK,MAAKqC,MAAMrD,KAAKc,gBAAgBH,EAAQC,WAAW,MAKvDzB,EAAAmB,UAAAgD,QAAP,SAAe3C,GACX,MAAOK,MAAKkB,IAKT/C,EAAAmB,UAAAiD,UAAP,SAAiB5C,GACb,MAAOK,MAAKwC,KAAKxD,KAAKc,gBAAgBH,EAAQC,WAAW,MAKtDzB,EAAAmB,UAAAmD,WAAP,SAAkB9C,GACd,MAAOK,MAAK0C,MAAM1D,KAAKc,gBAAgBH,EAAQC,WAAW,MAKvDzB,EAAAmB,UAAAqD,QAAP,SAAehD,GACX,MAAOK,MAAK4C,IAAI5D,KAAKc,gBAAgBH,EAAQC,WAAW,MAKrDzB,EAAAmB,UAAAuD,SAAP,SAAgBlD,GACZ,MAAOX,MAAKc,gBAAgBH,EAAQC,WAAW,IAAMZ,KAAKc,gBAAgBH,EAAQC,WAAW,KAK1FzB,EAAAmB,UAAAwD,SAAP,SAAgBnD,GACZ,MAAOK,MAAK+C,MAAM/D,KAAKc,gBAAgBH,EAAQC,WAAW,MAKvDzB,EAAAmB,UAAA0D,YAAP,SAAmBrD,GACf,MAA2B,MAApBA,EAAQiB,GAAGC,KACX7B,KAAKc,gBAAgBH,EAAQC,WAAW,IAAMZ,KAAKc,gBAAgBH,EAAQC,WAAW,IACtFZ,KAAKc,gBAAgBH,EAAQC,WAAW,IAAMZ,KAAKc,gBAAgBH,EAAQC,WAAW,KAK1FzB,EAAAmB,UAAA2D,SAAP,SAAgBtD,GACZ,MAAOK,MAAKkD,IAAIlE,KAAKc,gBAAgBH,EAAQC,WAAW,MAKrDzB,EAAAmB,UAAA6D,SAAP,SAAgBxD,GACZ,MAAqD,KAA9CX,KAAKc,gBAAgBH,EAAQC,WAAW,IAAYI,KAAKkB,IAK7D/C,EAAAmB,UAAA8D,UAAP,SAAiBzD,GACb,MAAOK,MAAKqD,KAAKrE,KAAKc,gBAAgBH,EAAQC,WAAW,MAKtDzB,EAAAmB,UAAAgE,SAAP,SAAgB3D,GACZ,MAAO,GAAIK,KAAKC,IAAIjB,KAAKc,gBAAgBH,EAAQC,WAAW,MAKzDzB,EAAAmB,UAAAiE,WAAP,SAAkB5D,GACd,MAAOK,MAAKqC,MAAMrD,KAAKc,gBAAgBH,EAAQC,WAAW,IAAMZ,KAAKc,gBAAgBH,EAAQC,WAAW,MAKrGzB,EAAAmB,UAAAkE,WAAP,SAAkB7D,GACd,SAAYX,KAAKc,gBAAgBH,EAAQC,WAAW,KAIjDzB,EAAAmB,UAAAmE,eAAP,SAAsB9D,GAClB,MAAOX,MAAKc,gBAAgBH,EAAQC,WAAW,KAK5CzB,EAAAmB,UAAAoE,SAAP,SAAgB/D,GACZ,MAAOX,MAAKc,gBAAgBH,EAAQC,WAAW,IAAMI,KAAKkB,GAAK,KAK5D/C,EAAAmB,UAAAqE,SAAP,SAAgBhE,GACZ,MAAOX,MAAKc,gBAAgBH,EAAQC,WAAW,IAAMZ,KAAKc,gBAAgBH,EAAQC,WAAW,KAK1FzB,EAAAmB,UAAAsE,SAAP,SAAgBjE,GACZ,MAAOK,MAAK6D,IAAI7E,KAAKc,gBAAgBH,EAAQC,WAAW,MAKrDzB,EAAAmB,UAAAwE,SAAP,SAAgBnE,GACZ,MAAOK,MAAKM,IAAI,GAAItB,KAAKc,gBAAgBH,EAAQC,WAAW,MAKzDzB,EAAAmB,UAAAyE,SAAP,SAAgBpE,GACZ,MAAOK,MAAKM,IAAItB,KAAKc,gBAAgBH,EAAQC,WAAW,IAAKZ,KAAKc,gBAAgBH,EAAQC,WAAW,MAKlGzB,EAAAmB,UAAA0E,UAAP,SAAiBrE,GACb,MAAOK,MAAKiE,KAAKjF,KAAKc,gBAAgBH,EAAQC,WAAW,MAKtDzB,EAAAmB,UAAA4E,SAAP,SAAgBvE,GACZ,MAAOK,MAAKM,IAAIN,KAAKuB,EAAGvC,KAAKc,gBAAgBH,EAAQC,WAAW,MAK7DzB,EAAAmB,UAAA6E,YAAP,SAAmBxE,GACf,MAAOK,MAAKmC,MAAMnD,KAAKc,gBAAgBH,EAAQC,WAAW,IAAMI,KAAKM,IAAI,GAAItB,KAAKc,gBAAgBH,EAAQC,WAAW,MACjHI,KAAKM,IAAI,GAAItB,KAAKc,gBAAgBH,EAAQC,WAAW,MAEjEzB,GAvQoCpB,EAAAqH,kBAAvBpI,GAAAmC,eAAcA,GH2UxBU,MAAM7C,EAASQ,KAAiEsC,SAAlCrC,IAAgDR,EAAOD,QAAUS,KAK5G,SAASR,EAAQD,EAASH,GIpVhCG,EAAA0B,gBAAA7B,EAAA,GAAA6B,gBACA1B,EAAA8B,iBAAAjC,EAAA,IAAAiC,iBACA9B,EAAAoI,kBAAAvI,EAAA,IAAAuI,mBJ0VM,SAASnI,EAAQD,EAASH,GKjHhC,QAAA6B,GAAA2G,GAGA,MAFAC,GAAAC,MAAAnI,KAAA4C,KAAAqF,GACArF,KAAAwF,QAAA,GAAAF,GAAAG,IAAAC,kBAAA1F,KAAAyF,EAAAE,EAAA,GAAAL,GAAAM,wBACA5F,KA5OA,GAAAsF,GAAAzI,EAAA,GAGAgJ,GAAA,YACA,oBACA,qBACA,qCACA,4BACA,qBACA,oBACA,qBACA,oBACA,4BACA,qCACA,sCACA,+BACA,eACA,gBACA,6BACA,iCACA,kCACA,kCACA,iCACA,gBACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,sBACA,sBACA,uBACA,qBACA,uBACA,uBACA,uBACA,uBACA,uBACA,uBACA,4BACA,4BACA,4BACA,oBACA,6BACA,oBACA,uBACA,sDACA,uBACA,4BACA,8BACA,6BACA,4BACA,8BACA,qBACA,eACA,mBACA,gBACA,eACA,eACA,eACA,eACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,kBACA,qBACA,iBACA,eACA,eACA,eACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,gBACA,iBACA,gBACA,gBACA,gBACA,oBACA,oBACA,oBACA,sBACA,mBACA,oBACA,oBACA,eACA,kBACA,eACA,eACA,eACA,eACA,gBACA,eACA,gBACA,gBACA,eACA,eACA,gBACA,gBACA,eACA,eACA,eACA,gBACA,gBACA,kBACA,gBACA,oBACA,eACA,gBACA,iBACA,gBACA,oBACA,mBACA,oBACA,gBACA,mBACA,0BACA,iBACA,uBACA,oBACA,kBACA,oBACA,iBACA,qBACA,iBACA,qBACA,mBACA,oBACA,kBACA,mBACA,kBACA,mBACA,oBACA,kBACA,iBACA,uBACA,iBACA,qBACA,iBACA,mBACA,kBACA,iBACA,qBACA,kBACA,iBACA,uBACA,iBACA,kBACA,iBACA,qBACA,qBACA,iBACA,oBACA,kBACA,sBACA,oBACA,kBACA,mBACA,oBACA,kBACA,kBACA,iBACA,qBACA,kBACA,iBACA,oBACA,oBACA,iBACA,qBACA,kBACA,oBACA,mBACA,kBACA,iBACA,oBACA,gBACA,kBACA,gBACA,qBACA,eACA,gBACA,kBACA,eACA,eACA,eACA,gBACA,kBACA,eACA,eACA,eACA,kBACA,eACA,eACA,eACA,eACA,eACA,iBACA,eAAAC,KAAA,IAGAL,GAAA,GAAAH,GAAAG,IAAAM,iBAAAC,YAAAH,GAEAF,EAAAF,EAAAQ,gBAAAC,IAAA,SAAAC,EAAAC,GAAmE,UAAAd,GAAAe,IAAAC,IAAAH,EAAAC,IAQnE1H,GAAA4B,UAAAC,OAAAC,OAAA8E,EAAAC,MAAAjF,WACA5B,EAAA4B,UAAAF,YAAA1B,EAEAA,EAAA6H,IAAAjB,EAAAkB,MAAAD,IACA7H,EAAA+H,KAAA,EACA/H,EAAAgI,KAAA,EACAhI,EAAAiI,KAAA,EACAjI,EAAAkI,KAAA,EACAlI,EAAAmI,KAAA,EACAnI,EAAAoI,KAAA,EACApI,EAAAqI,KAAA,EACArI,EAAAsI,KAAA,EACAtI,EAAAuI,KAAA,EACAvI,EAAAwI,OAAA,GACAxI,EAAAyI,MAAA,GACAzI,EAAA0I,MAAA,GACA1I,EAAA2I,IAAA,GACA3I,EAAA4I,MAAA,GACA5I,EAAA6I,IAAA,GACA7I,EAAA8I,IAAA,GACA9I,EAAA+I,IAAA,GACA/I,EAAAgJ,IAAA,GACAhJ,EAAAwD,GAAA,GACAxD,EAAAiJ,SAAA,GACAjJ,EAAAkJ,YAAA,GACAlJ,EAAAmJ,MAAA,GACAnJ,EAAAoJ,KAAA,GACApJ,EAAAqJ,IAAA,GACArJ,EAAAsJ,MAAA,GACAtJ,EAAAuJ,KAAA,GACAvJ,EAAAwJ,IAAA,GACAxJ,EAAAyJ,OAAA,GACAzJ,EAAA0J,MAAA,GACA1J,EAAA2J,MAAA,GACA3J,EAAA4J,IAAA,GACA5J,EAAA6J,IAAA,GACA7J,EAAA8J,IAAA,GACA9J,EAAA+J,IAAA,GACA/J,EAAAgK,KAAA,GACAhK,EAAAiK,KAAA,GACAjK,EAAAkK,KAAA,GACAlK,EAAAmK,OAAA,GACAnK,EAAAoK,OAAA,GACApK,EAAAqK,OAAA,GACArK,EAAAsK,QAAA,GACAtK,EAAAuK,OAAA,GACAvK,EAAAwK,IAAA,GACAxK,EAAAyK,GAAA,GACAzK,EAAA0K,IAAA,GACA1K,EAAA2K,IAAA,GACA3K,EAAA4K,IAAA,GACA5K,EAAA6K,IAAA,GACA7K,EAAA8K,GAAA,GACA9K,EAAA+K,IAAA,GACA/K,EAAAgL,QAAA,GAGAhL,EAAAiL,WAAA,gBAEAjL,EAAAkL,cAAA,iBAAiD,mBACjD,oCACA,iCACA,OAEAlL,EAAAmL,eAAA,mCACA,wCACA,sCACA,sCACA,kCACA,qCACA,iCACA,qCACA,sCACA,4BAEAnL,EAAAoL,WAAA,0CACA,sCACA,wCACA,4CACA,2CACA,wCACA,uCACA,uCACA,6CACA,WAEApL,EAAAqL,gBAAA,gBAIA/M,EAAA0B,mBLoWM,SAASzB,EAAQD,EAASH,GM/qBhCG,EAAAyI,IAAA5I,EAAA,GACAG,EAAAqJ,IAAAxJ,EAAA,IACAG,EAAAgN,KAAAnN,EAAA,IACAG,EAAAiN,MAAApN,EAAA,IACAG,EAAAwJ,MAAA3J,EAAA,GAAA2J,MACAxJ,EAAAkN,YAAArN,EAAA,GAAAqN,YACAlN,EAAAwB,YAAA3B,EAAA,IAAA2B,YACAxB,EAAAmN,WAAAtN,EAAA,IAAAsN,WACAnN,EAAA4B,kBAAA/B,EAAA,IAAA+B,kBACA5B,EAAAuI,MAAA1I,EAAA,IAAA0I,MACAvI,EAAAoN,OAAAvN,EAAA,IAAAuN,MACA,IAAAC,GAAAxN,EAAA,GACAG,GAAA4I,uBAAAyE,EAAAzE,uBACA5I,EAAAsN,kBAAAzN,EAAA,IAAAyN,kBACAtN,EAAAuN,SAAA1N,EAAA,IAAA0N,SACAvN,EAAAwN,MAAA3N,EAAA,INsrBM,SAASI,EAAQD,EAASH,GOrsBhCG,EAAAyN,IAAA5N,EAAA,GAAA4N,IACAzN,EAAA+I,gBAAAlJ,EAAA,IAAAkJ,gBACA/I,EAAA0I,kBAAA7I,EAAA,IAAA6I,kBACA1I,EAAA0N,mBAAA7N,EAAA,IAAA6N,mBACA1N,EAAA2N,eAAA9N,EAAA,IAAA8N,gBP2sBM,SAAS1N,EAAQD,EAASH,GQ/qBhC,QAAA4N,GAAAG,EAAAC,GA4BA,MAxBA7K,MAAA4K,cAEA5K,KAAA6K,eACA7K,KAAA8K,UAIA9K,KAAAiG,mBAEAjG,KAAA+K,oBAEA/K,KAAAgL,gBAAA,KACAhL,KAAAiL,wBAMAjL,KAAAkL,gBAAA,KAGAlL,KAAAmL,aAAA,KACAnL,KAAAoL,oBAEApL,KA/BA,GAAAqL,GAAAxO,EAAA,GAAAwO,YACAC,EAAAzO,EAAA,IAAAyO,WAqCAb,GAAAnK,UAAAiL,oBAAA,SAAAC,EAAAC,GACA,GAAAC,GAAA,GAAAL,GAAArL,KACA,OAAA0L,GAAAC,KAAAH,EAAA,KAAAC,IAMAhB,EAAAnK,UAAAsL,oBAAA,SAAAJ,GACA,cAAAA,EAAAK,oBACAL,EAAAK,qBAEAL,EAAAK,oBAAA7L,KAAAuL,oBAAAC,EAAA,MACAA,EAAAK,oBAAAC,UAAA,EACAN,EAAAK,sBAGApB,EAAAnK,UAAAyL,WAAA,SAAAP,EAAAC,GACA,MAAA3L,UAAA2L,EACAzL,KAAA4L,oBAAAJ,GAEAxL,KAAAuL,oBAAAC,EAAAC,IAIAhB,EAAAnK,UAAA0L,SAAA,SAAAC,GACA,OAAAA,IACAA,EAAAxG,IAAAzF,KACAiM,EAAAC,YAAAlM,KAAA8K,OAAAqB,QAEAnM,KAAA8K,OAAAsB,KAAAH,IAGAxB,EAAAnK,UAAA+L,YAAA,SAAAJ,GACAjM,KAAA8K,OAAAmB,EAAAC,aAAA,MAGAzB,EAAAnK,UAAAgM,oBAAA,SAAAd,GAGA,MAFAxL,MAAAiG,gBAAAmG,KAAAZ,GACAA,EAAAe,SAAAvM,KAAAiG,gBAAAkG,OAAA,EACAX,EAAAe,UAGA9B,EAAAnK,UAAAkM,iBAAA,SAAAD,GACA,WAAAvM,KAAAiG,gBAAAkG,OACA,KAEAnM,KAAAiG,gBAAAsG,GAqBA,IAAA/F,GAAA3J,EAAA,GAAA2J,KAEAiE,GAAAnK,UAAAmM,kBAAA,SAAAP,EAAAT,GACA,GAAAS,EAAA,GAAAA,GAAAlM,KAAA8K,OAAAqB,OACA,4BAEA,IAAAX,GAAAxL,KAAA8K,OAAAoB,GACAQ,EAAA1M,KAAA+L,WAAAP,EACA,KAAAkB,EAAAC,SAAAnG,EAAAoG,SACA,MAAAF,EAEA,IAAAG,GAAA,GAAAvB,EAGA,KAFAuB,EAAAC,OAAAJ,GACAG,EAAAE,UAAAvG,EAAAoG,SACA,OAAAnB,KAAAuB,eAAA,GAAAN,EAAAC,SAAAnG,EAAAoG,UAAA,CACA,GAAAI,GAAAhN,KAAA8K,OAAAW,EAAAuB,eACAC,EAAAD,EAAAE,YAAA,EACAR,GAAA1M,KAAA+L,WAAAkB,EAAAE,aACAN,EAAAC,OAAAJ,GACAG,EAAAE,UAAAvG,EAAAoG,SACAnB,IAAA2B,UAKA,MAHAV,GAAAC,SAAAnG,EAAAoG,UACAC,EAAAQ,OAAA7G,EAAAD,KAEAsG,GAGApC,EAAA6C,mBAAA,EAEAtQ,EAAAyN,ORqtBM,SAASxN,EAAQD,EAASH,GS10BhC,QAAAwO,GAAA5F,GACAzF,KAAAyF,MAlBA,GAAA8H,GAAA1Q,EAAA,GAAA0Q,IACAC,EAAA3Q,EAAA,GAAA2Q,OACAhH,EAAA3J,EAAA,GAAA2J,MACAiH,EAAA5Q,EAAA,IAAA4Q,UAEAnC,GADAzO,EAAA,IAAA0N,SACA1N,EAAA,IAAAyO,aACAoC,EAAA7Q,EAAA,IAAA6Q,cACAC,EAAA9Q,EAAA,IAAA8Q,eACAC,EAAA/Q,EAAA,IAAA+Q,iBACAC,EAAAhR,EAAA,IAAAgR,mBACAC,EAAAjR,EAAA,IAAAiR,4BAEAzD,EAAAxN,EAAA,IACAkR,EAAA1D,EAAA0D,iCACAC,EAAA3D,EAAA2D,kBACAC,EAAA5D,EAAA4D,0BASA5C,GAAA6C,SAAA1H,EAAA2H,aAaA9C,EAAA/K,UAAA8N,qBAAA,SAAA5C,GACA,UAAAA,EACA,WAIA,QAFA6C,GAAA7C,EAAA0B,YAAAf,OACAmC,KACAC,EAAA,EAAkBA,EAAAF,EAAYE,IAAA,CAC9BD,EAAAC,GAAA,GAAAjD,EACA,IAAAkD,GAAA,GAAAjB,GACAkB,GAAA,CACAzO,MAAA0O,MAAAlD,EAAAmD,WAAAJ,GAAAK,OAAA,KAAAZ,EAAAa,MACAP,EAAAC,GAAAC,EAAA,GAAAhB,GAAAiB,GAAA,IAGA,IAAAH,EAAAC,GAAApC,QAAAmC,EAAAC,GAAA5B,SAAAtB,EAAA6C,aACAI,EAAAC,GAAA,MAGA,MAAAD,IAqBAjD,EAAA/K,UAAAqL,KAAA,SAAAH,EAAAsD,EAAArD,GACA,GAAAsD,GAAA,GAAAzD,GACAmD,GAAA,CACAhD,MAAA,IACA,IAAAuD,GAAA,OAAAvD,EAAAsC,EAAAvC,EAAA/F,IAAAgG,GAAA,IAEA,OADAzL,MAAA0O,MAAAlD,EAAAsD,EAAAE,EAAAD,EAAA,GAAAxB,GAAA,GAAAC,GAAAiB,GAAA,GACAM,GAiCA1D,EAAA/K,UAAAoO,MAAA,SAAAlD,EAAAsD,EAAArD,EAAA6C,EAAAE,EAAAS,EAAAR,EAAAS,GACA,GAAA5R,GAAA,GAAAmQ,IAA2BxB,MAAAT,EAAA+C,IAAA,EAAA5N,QAAA8K,GAA6B,KACxD,KAAA+C,EAAA7B,SAAArP,GAAA,CAIA,GADAkR,EAAAW,IAAA7R,GACAkO,IAAAsD,EAAA,CACA,UAAArD,EAEA,WADA6C,GAAAjB,OAAA7G,EAAAoG,QAES,IAAAnB,EAAA2D,WAAAF,EAET,WADAZ,GAAAjB,OAAA7G,EAAAD,KAIA,GAAAiF,YAAAkC,GAAA,CACA,UAAAjC,EAEA,WADA6C,GAAAjB,OAAA7G,EAAAoG,QAES,IAAAnB,EAAA2D,WAAAF,EAET,WADAZ,GAAAjB,OAAA7G,EAAAD,IAGA,IAAAkF,IAAAuC,EAAAa,MAAA,CAEA,OAAAQ,GAAA,EAAwBA,EAAA5D,EAAAU,OAAckD,IAAA,CACtC,GAAAC,GAAAtP,KAAAyF,IAAAqF,OAAAW,EAAA8D,eAAAF,IACAG,EAAAP,EAAAtC,SAAA2C,EAAAG,UACA,KACAR,EAAAS,OAAAJ,EAAAG,WACAzP,KAAA0O,MAAAY,EAAAR,EAAArD,EAAAkE,UAAAN,GAAAf,EAAAE,EAAAS,EAAAR,EAAAS,GACiB,QACjBM,GACAP,EAAAE,IAAAG,EAAAG,YAIA,QAGA,OAAAG,GAAA,EAAgBA,EAAApE,EAAA0B,YAAAf,OAAwByD,IAAA,CACxC,GAAAC,GAAArE,EAAA0B,YAAA0C,EACA,IAAAC,EAAAzP,cAAAuN,EAAA,CACA,GAAAsB,EAAAtC,SAAAkD,EAAAjB,OAAAa,WACA,QAEA,IAAAK,GAAA7B,EAAAzN,OAAAiL,EAAAoE,EAAA1C,YAAAjB,YACA,KACA+C,EAAAE,IAAAU,EAAAjB,OAAAa,WACAzP,KAAA0O,MAAAmB,EAAAjB,OAAAE,EAAAgB,EAAAxB,EAAAE,EAAAS,EAAAR,EAAAS,GACa,QACbD,EAAAS,OAAAG,EAAAjB,OAAAa,gBAES,IAAAI,YAAA/B,GACTW,EACAzO,KAAA0O,MAAAmB,EAAAjB,OAAAE,EAAArD,EAAA6C,EAAAE,EAAAS,EAAAR,EAAAS,GAEAZ,EAAAjB,OAAAhC,EAAA6C,cAES,IAAA2B,EAAAE,UACT/P,KAAA0O,MAAAmB,EAAAjB,OAAAE,EAAArD,EAAA6C,EAAAE,EAAAS,EAAAR,EAAAS,OACS,IAAAW,EAAAzP,cAAAyN,EACTS,EAAA0B,SAAAxJ,EAAAyJ,oBAAAjQ,KAAAyF,IAAAoF,kBACS,CACT,GAAAqF,GAAAL,EAAAM,KACA,QAAAD,IACAL,YAAAjC,KACAsC,IAAAE,WAAA5J,EAAAyJ,oBAAAjQ,KAAAyF,IAAAoF,eAEAyD,EAAAxB,OAAAoD,QAMAlT,EAAAqO,eTk4BM,SAASpO,EAAQD,GU/lCvB,QAAAqT,GAAAC,GACA,UAAAA,EAAAxK,KAAA,UAgBA,QAAAyK,GAAAD,EAAApQ,GACA,MAAAoQ,GAAAE,OAAAtQ,GAGA,QAAAuQ,GAAAH,GACA,MAAAA,GAAAI,aAGA,QAAAnD,GAAAoD,EAAAC,GAIA,MAHA5Q,MAAA6Q,QACA7Q,KAAA2Q,gBAAAF,EACAzQ,KAAA4Q,kBAAAL,EACAvQ,KAyDA,QAAAwN,KAEA,MADAxN,MAAA6Q,QACA7Q,KAiDA,QAAA8Q,KAEA,MADA9Q,MAAA6Q,QACA7Q,KAyBA,QAAA+Q,KACA,MAAA/Q,MAkBA,QAAAgR,GAAAxF,EAAAyF,GAOA,MANAzF,KAAAzI,QAAA,YACAyI,IAAAzI,QAAA,YACAyI,IAAAzI,QAAA,YACAkO,IACAzF,IAAAzI,QAAA,UAEAyI,EA1LA0F,OAAA5Q,UAAA6Q,SAAA,SAAA3F,GACA,GAAA4F,GAAA,CACA,QAAApR,KAAAmM,OACA,MAAAiF,EAEA,QAAA/B,GAAA,EAAgBA,EAAArP,KAAAmM,OAAiBkD,IAAA,CACjC,GAAAgC,GAAArR,KAAAsR,WAAAjC,EACA+B,OAAA,GAAAA,EAAAC,EACAD,KAEA,MAAAA,IAkBA7Q,OAAAgR,eAAAhE,EAAAjN,UAAA,UACAkR,IAAA,WACA,MAAAxR,MAAAyR,SAAAtF,UAIAoB,EAAAjN,UAAA6O,IAAA,SAAAuC,GACA,GAAAN,GAAApR,KAAA2Q,aAAAe,GACAC,EAAA,QAAAP,EAAAD,UACA,IAAAQ,IAAA3R,MAAA6Q,KAAA,CACA,GAAAxB,GACAoC,EAAAzR,KAAA6Q,KAAAc,EACA,KAAAtC,EAAA,EAAUA,EAAAoC,EAAAtF,OAAgBkD,IAC1B,GAAArP,KAAA4Q,eAAAc,EAAAD,EAAApC,IACA,MAAAoC,GAAApC,EAIA,OADAoC,GAAArF,KAAAsF,GACAA,EAGA,MADA1R,MAAA6Q,KAAAc,IAAAD,GACAA,GAIAnE,EAAAjN,UAAAqM,SAAA,SAAA+E,GACA,GAAAN,GAAApR,KAAA2Q,aAAAe,GACAC,EAAAP,EAAAD,UACA,IAAAQ,IAAA3R,MAAA6Q,KAAA,CACA,GAAAxB,GACAoC,EAAAzR,KAAA6Q,KAAAc,EACA,KAAAtC,EAAA,EAAUA,EAAAoC,EAAAtF,OAAgBkD,IAC1B,GAAArP,KAAA4Q,eAAAc,EAAAD,EAAApC,IACA,SAIA,UAGA9B,EAAAjN,UAAAmR,OAAA,WACA,GAAAG,KACA,QAAAD,KAAA3R,MAAA6Q,KACA,IAAAc,EAAAE,QAAA,WACAD,IAAAE,OAAA9R,KAAA6Q,KAAAc,IAGA,OAAAC,IAGArE,EAAAjN,UAAAyR,SAAA,WACA,MAAA1B,GAAArQ,KAAAyR,WAQAjE,EAAAlN,UAAA6O,IAAA,SAAAuC,GACA1R,KAAA6Q,KAAAa,IAAA,GAGAlE,EAAAlN,UAAA0R,GAAA,SAAA9B,GACA,GAAA+B,GAAAjS,IACAO,QAAA2R,KAAAhC,EAAAW,MAAA3K,IAAA,SAAAqI,GAA2C0D,EAAA9C,IAAAZ,MAG3Cf,EAAAlN,UAAAoP,OAAA,SAAAgC,SACA1R,MAAA6Q,KAAAa,IAGAlE,EAAAlN,UAAAqM,SAAA,SAAA+E,GACA,MAAA1R,MAAA6Q,KAAAa,MAAA,GAGAlE,EAAAlN,UAAAmR,OAAA,WACA,MAAAlR,QAAA2R,KAAAlS,KAAA6Q,OAGArD,EAAAlN,UAAA6R,SAAA,WACA,MAAAnR,MAAAoR,IAAAvS,MAAA,KAAAG,KAAAyR,WAGAjE,EAAAlN,UAAAoQ,WAAA,WACA,MAAA1Q,MAAAyR,SAAAM,YAGAvE,EAAAlN,UAAAkQ,OAAA,SAAA6B,GACA,MAAAA,aAAA7E,IAGAxN,KAAA0Q,eAAA2B,EAAA3B,cAGAnQ,OAAAgR,eAAA/D,EAAAlN,UAAA,UACAkR,IAAA,WACA,MAAAxR,MAAAyR,SAAAtF,UAIAqB,EAAAlN,UAAAyR,SAAA,WACA,UAAU/R,KAAAyR,SAAA3L,KAAA,WAQVgL,EAAAxQ,UAAAkR,IAAA,SAAAG,GAEA,MADAA,GAAA,KAAAA,EACAA,IAAA3R,MAAA6Q,KACA7Q,KAAA6Q,KAAAc,GAEA,MAIAb,EAAAxQ,UAAAgS,IAAA,SAAAX,EAAAD,GACAC,EAAA,KAAAA,EACA3R,KAAA6Q,KAAAc,GAAAD,GAGAZ,EAAAxQ,UAAAmR,OAAA,WACA,GAAAZ,GAAA7Q,KAAA6Q,KACAqB,EAAA3R,OAAA2R,KAAAlS,KAAA6Q,KACA,OAAAqB,GAAAhM,IAAA,SAAAyL,GACA,MAAAd,GAAAc,MAQAZ,EAAAzQ,UAAAkR,IAAA,SAAAlB,EAAApQ,GACA,GAAAD,GAAAD,KAAAsQ,IAAA,IACA,eAAArQ,EAAA,KAAAA,EAAAC,IAAA,MAGA6Q,EAAAzQ,UAAA4P,IAAA,SAAAI,EAAApQ,EAAAqS,GACA,GAAAtS,GAAAD,KAAAsQ,IAAA,IACA,QAAArQ,IACAA,KACAD,KAAAsQ,GAAArQ,GAEAA,EAAAC,GAAAqS,GAcAvV,EAAAwV,QAAA,SAAAC,GACA,yBAAAlS,OAAAD,UAAAyR,SAAA3U,KAAAqV,IAGAzV,EAAA0V,UAAA,SAAAC,GACA,MAAAA,GAAA5P,QAAA,kBAAA6P,GAA4C,MAAAA,GAAAC,OAAA,GAAAC,cAAAF,EAAAG,OAAA,MAG5C/V,EAAAuQ,MACAvQ,EAAAwQ,SACAxQ,EAAA8T,UACA9T,EAAA+T,aACA/T,EAAAgU,mBACAhU,EAAAqT,iBVsmCM,SAASpT,EAAQD,GWlxCvB,QAAAwJ,KAUA,MATAxG,MAAAgT,OAAA,KACAhT,KAAAiT,KAAA,KACAjT,KAAAkT,QAAA,KACAlT,KAAAmT,MAAA,KACAnT,KAAAoT,KAAA,KACApT,KAAAqT,WAAA,KACArT,KAAAsT,KAAA,KACAtT,KAAAuT,OAAA,KACAvT,KAAAwT,MAAA,KACAxT,KAiDA,QAAAkK,GAAA8I,EAAAC,EAAAC,EAAAC,EAAAC,GAcA,MAbA5M,GAAApJ,KAAA4C,MACAA,KAAAgT,OAAAlT,SAAAkT,IAAA9I,EAAAuJ,aACAzT,KAAAiT,KAAAnT,SAAAmT,IAAA,KACAjT,KAAAkT,QAAApT,SAAAoT,IAAA1M,EAAAkN,gBACA1T,KAAAmT,MAAArT,SAAAqT,OACAnT,KAAAoT,KAAAtT,SAAAsT,OACApT,KAAAqT,cACA,OAAArT,KAAAgT,OAAA,IACAhT,KAAAsT,KAAAN,EAAA,GAAAM,KACAtT,KAAAuT,OAAAP,EAAA,GAAAO,QAEAvT,KAAAuT,UAEAvT,KA5DAwG,EAAA2H,aAAA,EAIA3H,EAAAoG,WAEApG,EAAAyJ,oBAAA,EAEAzJ,EAAAD,OAMAC,EAAAkN,gBAAA,EAKAlN,EAAAmN,eAAA,EAUApT,OAAAgR,eAAA/K,EAAAlG,UAAA,QACAkR,IAAA,WACA,MAAAxR,MAAAwT,OAEAtD,IAAA,SAAArO,GACA7B,KAAAwT,MAAA3R,KAIA2E,EAAAlG,UAAAsT,eAAA,WACA,MAAA5T,MAAAgT,OAAA,IAGAxM,EAAAlG,UAAAuT,eAAA,WACA,MAAA7T,MAAAgT,OAAA,IAoBA9I,EAAA5J,UAAAC,OAAAC,OAAAgG,EAAAlG,WACA4J,EAAA5J,UAAAF,YAAA8J,EAIAA,EAAAuJ,cAAA,WAcAvJ,EAAA5J,UAAAwT,MAAA,WACA,GAAAjE,GAAA,GAAA3F,GAAAlK,KAAAgT,OAAAhT,KAAAiT,KAAAjT,KAAAkT,QAAAlT,KAAAmT,MACAnT,KAAAoT,KAKA,OAJAvD,GAAAwD,WAAArT,KAAAqT,WACAxD,EAAAyD,KAAAtT,KAAAsT,KACAzD,EAAA0D,OAAAvT,KAAAuT,OACA1D,EAAAhO,KAAA7B,KAAA6B,KACAgO,GAGAtP,OAAAgR,eAAArH,EAAA5J,UAAA,QACAkR,IAAA,WACA,UAAAxR,KAAAwT,MACA,MAAAxT,MAAAwT,KAEA,IAAAnO,GAAArF,KAAA6T,gBACA,WAAAxO,EACA,WAEA,IAAA0O,GAAA1O,EAAA2O,IACA,OAAAhU,MAAAmT,MAAAY,GAAA/T,KAAAoT,KAAAW,EACA1O,EAAAvC,QAAA9C,KAAAmT,MAAAnT,KAAAoT,MAEA,SAGAlD,IAAA,SAAArO,GACA7B,KAAAwT,MAAA3R,KAIAqI,EAAA5J,UAAAyR,SAAA,WACA,GAAAa,GAAA5S,KAAA6B,IAMA,OAJA+Q,GADA,OAAAA,EACAA,EAAA7P,QAAA,aAAAA,QAAA,aAAAA,QAAA,aAEA,YAEA,KAAA/C,KAAAqT,WAAA,IAAArT,KAAAmT,MAAA,IAAAnT,KAAAoT,KAAA,KACAR,EAAA,MAAA5S,KAAAiT,KAAA,KACAjT,KAAAkT,QAAA,cAAAlT,KAAAkT,QAAA,QACAlT,KAAAsT,KAAA,IAAAtT,KAAAuT,OAAA,KAGAvW,EAAAwJ,QACAxJ,EAAAkN,eX2zCM,SAASjN,EAAQD,EAASH,GY/7ChC,QAAAoX,GAAAC,EAAAC,GACA,UAAAD,EAAA,CACA,GAAA/V,IAAgB8N,MAAA,KAAAsC,IAAA,KAAA5N,QAAA,KAAAyT,gBAAA,KAIhB,OAHAD,KACAhW,EAAAkW,wBAAA,GAEAlW,EAEA,GAAAmW,KASA,OARAA,GAAArI,MAAAiI,EAAAjI,OAAA,KACAqI,EAAA/F,IAAAzO,SAAAoU,EAAA3F,IAAA,KAAA2F,EAAA3F,IACA+F,EAAA3T,QAAAuT,EAAAvT,SAAA,KACA2T,EAAAF,gBAAAF,EAAAE,iBAAA,KACAD,IACAG,EAAAD,wBAAAH,EAAAG,yBAAA,EACAC,EAAAC,2BAAAL,EAAAK,6BAAA,GAEAD,EAIA,QAAA7G,GAAAyG,EAAAM,GAyBA,MAxBAxU,MAAAyU,aAAAP,EAAAM,GACAN,EAAAD,EAAAC,GACAM,EAAAP,EAAAO,GAAA,GAEAxU,KAAAiM,MAAA,OAAAiI,EAAAjI,MAAAiI,EAAAjI,MAAAuI,EAAAvI,MAEAjM,KAAAuO,IAAA,OAAA2F,EAAA3F,IAAA2F,EAAA3F,IAAAiG,EAAAjG,IAIAvO,KAAAW,QAAA,OAAAuT,EAAAvT,QAAAuT,EAAAvT,QAAA6T,EAAA7T,QACAX,KAAAoU,gBAAA,OAAAF,EAAAE,gBAAAF,EAAAE,gBACA,OAAAI,EAAAJ,gBAAAI,EAAAJ,gBAAAM,EAAAC,KAUA3U,KAAAqU,wBAAAG,EAAAH,wBACArU,KAAAuU,2BAAAC,EAAAD,2BACAvU,KAkDA,QAAA4U,GAAAV,EAAAM,GACA/G,EAAArQ,KAAA4C,KAAAkU,EAAAM,EAGA,IAAAK,GAAAX,EAAAW,qBAAA,IAGA,OAFA7U,MAAA6U,wBAAA,OAAAL,IAAAK,oBAAA,MACA7U,KAAA8U,+BAAA,OAAAN,GAAAxU,KAAA+U,uBAAAP,EAAAxU,KAAAiM,OACAjM,KA1GA,GAAAgV,GAAAnY,EAAA,IAAAmY,cACAN,EAAA7X,EAAA,IAAA6X,eAmDAjH,GAAAnN,UAAAmU,aAAA,SAAAP,EAAAM,GACA,OAAAN,EAAAvT,SAAAb,SAAAoU,EAAAvT,SACA,OAAA6T,GAAA,OAAAA,EAAA7T,SAAAb,SAAA0U,EAAA7T,UACAX,KAAAW,QAAA,OAQA8M,EAAAnN,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEKA,YAAA5E,KAGLzN,KAAAiM,MAAAC,cAAAmG,EAAApG,MAAAC,aACAlM,KAAAuO,MAAA8D,EAAA9D,MACA,OAAAvO,KAAAW,QAAA,OAAA0R,EAAA1R,QAAAX,KAAAW,QAAA6P,OAAA6B,EAAA1R,WACAX,KAAAoU,gBAAA5D,OAAA6B,EAAA+B,kBACApU,KAAAuU,6BAAAlC,EAAAkC,6BAIA9G,EAAAnN,UAAA2U,gBAAA,WACA,SAAAjV,KAAAiM,MAAAC,YAAA,IAAAlM,KAAAuO,IAAA,IAAAvO,KAAAoU,iBAGA3G,EAAAnN,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAiM,MAAAC,YAAA,IAAAlM,KAAAuO,IAAA,KACA,OAAAvO,KAAAW,QAAA,GAAAX,KAAAW,QAAA+P,cACA,IAAA1Q,KAAAoU,gBAAA1D,cAGAjD,EAAAnN,UAAAyR,SAAA,WACA,UAAA/R,KAAAiM,MAAA,IAAAjM,KAAAuO,KACA,OAAAvO,KAAAW,QAAA,KAAAX,KAAAW,QAAAoR,WAAA,SACA/R,KAAAoU,kBAAAM,EAAAC,KACA,IAAA3U,KAAAoU,gBAAArC,WACA,KACA/R,KAAAqU,wBAAA,EACA,OAAArU,KAAAqU,wBACA,SAcAO,EAAAtU,UAAAC,OAAAC,OAAAiN,EAAAnN,WACAsU,EAAAtU,UAAAF,YAAAwU,EAEAA,EAAAtU,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAiM,MAAAC,YAAAlM,KAAAuO,IAAAvO,KAAAW,QACAX,KAAAoU,iBAAApU,KAAA8U,+BAAA,KACA9U,KAAA6U,qBAGAD,EAAAtU,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEKA,YAAAuC,KAEA5U,KAAA8U,iCAAAzC,EAAAyC,mCAEA9U,KAAA6U,qBACL7U,KAAA6U,oBAAArE,OAAA6B,EAAAwC,sBACAxC,EAAAwC,sBAGApH,EAAAnN,UAAAkQ,OAAApT,KAAA4C,KAAAqS,MAIAuC,EAAAtU,UAAAyU,uBAAA,SAAA/B,EAAApE,GACA,MAAAoE,GAAA8B,gCACAlG,YAAAoG,IAAApG,EAAAsG,WAGAlY,EAAAyQ,YACAzQ,EAAA4X,kBZ++CM,SAAS3X,EAAQD,GarkDvB,QAAAmY,KAWA,MATAnV,MAAAyF,IAAA,KACAzF,KAAAkM,YAAAiJ,EAAAC,qBACApV,KAAAqV,UAAA,KACArV,KAAAyP,UAAA,EACAzP,KAAAsV,wBAAA,EAEAtV,KAAAkN,eAEAlN,KAAA6L,oBAAA,KACA7L,KAoEA,QAAAuV,KAGA,MAFAJ,GAAA/X,KAAA4C,MACAA,KAAAqV,UAAAF,EAAAK,MACAxV,KAOA,QAAAgV,KAIA,MAHAG,GAAA/X,KAAA4C,MACAA,KAAAuM,YACAvM,KAAAkV,WAAA,EACAlV,KAQA,QAAAyV,KAGA,MAFAT,GAAA5X,KAAA4C,MACAA,KAAA0V,SAAA,KACA1V,KAOA,QAAA2V,KAGA,MAFAF,GAAArY,KAAA4C,MACAA,KAAAqV,UAAAF,EAAAS,YACA5V,KAQA,QAAA6V,KAIA,MAHAV,GAAA/X,KAAA4C,MACAA,KAAAqV,UAAAF,EAAAW,UACA9V,KAAA+V,WAAA,KACA/V,KAYA,QAAA0N,KAGA,MAFAyH,GAAA/X,KAAA4C,MACAA,KAAAqV,UAAAF,EAAAa,UACAhW,KAMA,QAAAiW,KAKA,MAJAd,GAAA/X,KAAA4C,MACAA,KAAAqV,UAAAF,EAAAe,WACAlW,KAAA8O,UAAA,KACA9O,KAAAmW,kBAAA,EACAnW,KASA,QAAAoW,KAGA,MAFApB,GAAA5X,KAAA4C,MACAA,KAAAqV,UAAAF,EAAAkB,eACArW,KAYA,QAAAsW,KAIA,MAHAb,GAAArY,KAAA4C,MACAA,KAAAqV,UAAAF,EAAAoB,iBACAvW,KAAAwW,cAAA,KACAxW,KAOA,QAAAyW,KAGA,MAFAhB,GAAArY,KAAA4C,MACAA,KAAAqV,UAAAF,EAAAuB,iBACA1W,KAOA,QAAA2W,KAGA,MAFAxB,GAAA/X,KAAA4C,MACAA,KAAAqV,UAAAF,EAAAyB,eACA5W,KAOA,QAAA6W,KAMA,MALA7B,GAAA5X,KAAA4C,MACAA,KAAAqV,UAAAF,EAAA2B,gBACA9W,KAAAwW,cAAA,KAEAxW,KAAA+W,uBAAA,KACA/W,KAQA,QAAAgX,KAIA,MAHA7B,GAAA/X,KAAA4C,MACAA,KAAAqV,UAAAF,EAAA8B,SACAjX,KAAAwW,cAAA,KACAxW,KAQA,QAAAkX,KAGA,MAFAlC,GAAA5X,KAAA4C,MACAA,KAAAqV,UAAAF,EAAAgC,YACAnX,KA7NAmV,EAAAhH,aAAA,EACAgH,EAAAK,MAAA,EACAL,EAAAe,WAAA,EACAf,EAAAS,YAAA,EACAT,EAAAoB,iBAAA,EACApB,EAAAuB,iBAAA,EACAvB,EAAAgC,YAAA,EACAhC,EAAAa,UAAA,EACAb,EAAAW,UAAA,EACAX,EAAAyB,eAAA,EACAzB,EAAA2B,gBAAA,GACA3B,EAAAkB,eAAA,GACAlB,EAAA8B,SAAA,GAEA9B,EAAAiC,oBACA,UACA,QACA,aACA,cACA,mBACA,mBACA,cACA,YACA,YACA,iBACA,kBACA,iBACA,YAEAjC,EAAAC,wBAEAD,EAAA7U,UAAAyR,SAAA,WACA,MAAA/R,MAAAkM,aAGAiJ,EAAA7U,UAAAkQ,OAAA,SAAA6B,GACA,MAAAA,aAAA8C,IACAnV,KAAAkM,cAAAmG,EAAAnG,aAMAiJ,EAAA7U,UAAA+W,qBAAA,WACA,UAIAlC,EAAA7U,UAAAgX,cAAA,SAAAC,EAAAnR,GACAtG,SAAAsG,IACAA,MAEA,IAAApG,KAAAkN,YAAAf,OACAnM,KAAAsV,uBAAAiC,EAAAxH,UACK/P,KAAAsV,yBAAAiC,EAAAxH,YACL/P,KAAAsV,wBAAA,GAEAlP,OACApG,KAAAkN,YAAAd,KAAAmL,GAEAvX,KAAAkN,YAAAsK,OAAApR,EAAA,EAAAmR,IAUAhC,EAAAjV,UAAAC,OAAAC,OAAA2U,EAAA7U,WACAiV,EAAAjV,UAAAF,YAAAmV,EAUAP,EAAA1U,UAAAC,OAAAC,OAAA2U,EAAA7U,WACA0U,EAAA1U,UAAAF,YAAA4U,EAUAS,EAAAnV,UAAAC,OAAAC,OAAAwU,EAAA1U,WACAmV,EAAAnV,UAAAF,YAAAqV,EASAE,EAAArV,UAAAC,OAAAC,OAAAiV,EAAAnV,WACAqV,EAAArV,UAAAF,YAAAuV,EAWAE,EAAAvV,UAAAC,OAAAC,OAAA2U,EAAA7U,WACAuV,EAAAvV,UAAAF,YAAAyV,EAcAnI,EAAApN,UAAAC,OAAAC,OAAA2U,EAAA7U,WACAoN,EAAApN,UAAAF,YAAAsN,EAUAuI,EAAA3V,UAAAC,OAAAC,OAAA2U,EAAA7U,WACA2V,EAAA3V,UAAAF,YAAA6V,EAWAG,EAAA9V,UAAAC,OAAAC,OAAAwU,EAAA1U,WACA8V,EAAA9V,UAAAF,YAAAgW,EAeAE,EAAAhW,UAAAC,OAAAC,OAAAiV,EAAAnV,WACAgW,EAAAhW,UAAAF,YAAAkW,EASAG,EAAAnW,UAAAC,OAAAC,OAAAiV,EAAAnV,WACAmW,EAAAnW,UAAAF,YAAAqW,EASAE,EAAArW,UAAAC,OAAAC,OAAA2U,EAAA7U,WACAqW,EAAArW,UAAAF,YAAAuW,EAYAE,EAAAvW,UAAAC,OAAAC,OAAAwU,EAAA1U,WACAuW,EAAAvW,UAAAF,YAAAyW,EAWAG,EAAA1W,UAAAC,OAAAC,OAAA2U,EAAA7U,WACA0W,EAAA1W,UAAAF,YAAA4W,EAUAE,EAAA5W,UAAAC,OAAAC,OAAAwU,EAAA1U,WACA4W,EAAA5W,UAAAF,YAAA8W,EAEAla,EAAAmY,WACAnY,EAAAuY,aACAvY,EAAAgY,gBACAhY,EAAAyY,kBACAzY,EAAA6Y,gBACA7Y,EAAAga,eACAha,EAAAiZ,iBACAjZ,EAAA0Q,gBACA1Q,EAAAka,mBACAla,EAAAoZ,oBACApZ,EAAA2Z,oBACA3Z,EAAA6Z,qBACA7Z,EAAAsZ,sBACAtZ,EAAAyZ,sBACAzZ,EAAA2Y,wBbyqDM,SAAS1Y,EAAQD,EAASH,Gc79DhC,QAAA6X,KACA,MAAA1U,MAyEA,QAAAyX,GAAAhI,EAAAiI,EAAAC,GAKA,MAJAjD,GAAAtX,KAAA4C,MACAA,KAAAyP,UAAA3P,SAAA2P,OACAzP,KAAA0X,UAAA5X,SAAA4X,OACA1X,KAAA2X,eAAA7X,SAAA6X,KACA3X,KAqCA,QAAA4X,GAAAC,GACAnD,EAAAtX,KAAA4C,MACAA,KAAA6X,WAAA/X,SAAA+X,EAAA,EAAAA,EAwDA,QAAAC,GAAAxH,EAAApQ,GACAwU,EAAAtX,KAAA4C,KACA,IAAA+X,GAAA,GAAAxK,EACA+C,aAAAwH,GACAxH,EAAA0H,MAAA9R,IAAA,SAAAqM,GACAwF,EAAA5I,IAAAoD,KAGAwF,EAAA5I,IAAAmB,GAEApQ,YAAA4X,GACA5X,EAAA8X,MAAA9R,IAAA,SAAAqM,GACAwF,EAAA5I,IAAAoD,KAGAwF,EAAA5I,IAAAjP,EAEA,IAAA+X,GAAAL,EAAAM,2BAAAH,EACA,IAAAE,EAAA9L,OAAA,GAEA,GAAAgM,GAAA,IACAF,GAAA/R,IAAA,SAAA3I,IACA,OAAA4a,GAAA5a,EAAAsa,WAAAM,EAAAN,cACAM,EAAA5a,KAGAwa,EAAA5I,IAAAgJ,GAGA,MADAnY,MAAAgY,MAAAD,EAAAtG,SACAzR,KA4EA,QAAAoY,GAAA9H,EAAApQ,GACAwU,EAAAtX,KAAA4C,KACA,IAAA+X,GAAA,GAAAxK,EACA+C,aAAA8H,GACA9H,EAAA0H,MAAA9R,IAAA,SAAAqM,GACAwF,EAAA5I,IAAAoD,KAGAwF,EAAA5I,IAAAmB,GAEApQ,YAAAkY,GACAlY,EAAA8X,MAAA9R,IAAA,SAAAqM,GACAwF,EAAA5I,IAAAoD,KAGAwF,EAAA5I,IAAAjP,EAGA,IAAA+X,GAAAL,EAAAM,2BAAAH,EACA,IAAAE,EAAA9L,OAAA,GAEA,GAAAX,GAAAyM,EAAAI,KAAA,SAAA/H,EAAApQ,GACA,MAAAoQ,GAAAgI,UAAApY,KAEAiY,EAAA3M,IAAAW,OAAA,EACA4L,GAAA5I,IAAAgJ,GAGA,MADAnY,MAAAgY,MAAAD,EAAAtG,SACAzR,KArTA,GAAAuN,GAAA1Q,EAAA,GAAA0Q,GAkBAmH,GAAApU,UAAAiY,SAAA,SAAA1Z,EAAA2Z,KAqBA9D,EAAApU,UAAAmY,eAAA,SAAA5Z,EAAA2Z,GACA,MAAAxY,OAGA0U,EAAAgE,WAAA,SAAApI,EAAApQ,GACA,UAAAoQ,OAAAoE,EAAAC,KACA,MAAAzU,EAEA,WAAAA,OAAAwU,EAAAC,KACA,MAAArE,EAEA,IAAAnS,GAAA,GAAA2Z,GAAAxH,EAAApQ,EACA,YAAA/B,EAAA6Z,MAAA7L,OACAhO,EAAA6Z,MAAA,GAEA7Z,GAIAuW,EAAAiE,UAAA,SAAArI,EAAApQ,GACA,UAAAoQ,EACA,MAAApQ,EAEA,WAAAA,EACA,MAAAoQ,EAEA,IAAAA,IAAAoE,EAAAC,MAAAzU,IAAAwU,EAAAC,KACA,MAAAD,GAAAC,IAEA,IAAAxW,GAAA,GAAAia,GAAA9H,EAAApQ,EACA,YAAA/B,EAAA6Z,MAAA7L,OACAhO,EAAA6Z,MAAA,GAEA7Z,GAYAsZ,EAAAnX,UAAAC,OAAAC,OAAAkU,EAAApU,WACAmX,EAAAnX,UAAAF,YAAAqX,EAKA/C,EAAAC,KAAA,GAAA8C,GAGAA,EAAAnX,UAAAiY,SAAA,SAAA1Z,EAAA2Z,GACA,GAAAI,GAAA5Y,KAAA2X,eAAAa,EAAA,IACA,OAAA3Z,GAAAga,QAAAD,EAAA5Y,KAAAyP,UAAAzP,KAAA0X,YAGAD,EAAAnX,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAyP,UAAA,IAAAzP,KAAA0X,UAAA,IAAA1X,KAAA2X,gBAGAF,EAAAnX,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEEA,YAAAoF,KAGFzX,KAAAyP,YAAA4C,EAAA5C,WACAzP,KAAA0X,YAAArF,EAAAqF,WACA1X,KAAA2X,iBAAAtF,EAAAsF,iBAIAF,EAAAnX,UAAAyR,SAAA,WACA,UAAU/R,KAAAyP,UAAA,IAAAzP,KAAA0X,UAAA,MAQVE,EAAAtX,UAAAC,OAAAC,OAAAkU,EAAApU,WACAsX,EAAAtX,UAAAF,YAAAwX,EAEAA,EAAAtX,UAAAiY,SAAA,SAAA1Z,EAAA2Z,GACA,MAAA3Z,GAAAia,SAAAN,EAAAxY,KAAA6X,aAGAD,EAAAtX,UAAAmY,eAAA,SAAA5Z,EAAA2Z,GACA,MAAA3Z,GAAAia,SAAAN,EAAAxY,KAAA6X,YACAnD,EAAAC,KAEA,MAIAiD,EAAAtX,UAAAgY,UAAA,SAAAjG,GACA,MAAArS,MAAA6X,WAAAxF,EAAAwF,YAGAD,EAAAtX,UAAAoQ,WAAA,WACA,YAGAkH,EAAAtX,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEEA,YAAAuF,IAGF5X,KAAA6X,aAAAxF,EAAAwF,YAIAD,EAAAtX,UAAAyR,SAAA,WACA,UAAU/R,KAAA6X,WAAA,YAKVD,EAAAM,2BAAA,SAAAhI,GACA,GAAA/R,KAMA,OALA+R,GAAAuB,SAAAvL,IAAA,SAAAvF,GACAA,YAAAiX,IACAzZ,EAAAiO,KAAAzL,KAGAxC,GAuCA2Z,EAAAxX,UAAAC,OAAAC,OAAAkU,EAAApU,WACAwX,EAAAxX,UAAAF,YAAA0X,EAEAA,EAAAxX,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEEA,YAAAyF,IAGF9X,KAAAgY,QAAA3F,EAAA2F,OAIAF,EAAAxX,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAgY,MAAA,QASAF,EAAAxX,UAAAiY,SAAA,SAAA1Z,EAAA2Z,GACA,OAAAnJ,GAAA,EAAgBA,EAAArP,KAAAgY,MAAA7L,OAAuBkD,IACvC,IAAArP,KAAAgY,MAAA3I,GAAAkJ,SAAA1Z,EAAA2Z,GACA,QAGA,WAGAV,EAAAxX,UAAAmY,eAAA,SAAA5Z,EAAA2Z,GAGA,OAFAO,IAAA,EACAhB,KACA1I,EAAA,EAAgBA,EAAArP,KAAAgY,MAAA7L,OAAuBkD,IAAA,CACvC,GAAA1O,GAAAX,KAAAgY,MAAA3I,GACA2J,EAAArY,EAAA8X,eAAA5Z,EAAA2Z,EAEA,IADAO,GAAAC,IAAArY,EACA,OAAAqY,EAEA,WACGA,KAAAtE,EAAAC,MAEHoD,EAAA3L,KAAA4M,GAGA,IAAAD,EACA,MAAA/Y,KAEA,QAAA+X,EAAA5L,OAEA,MAAAuI,GAAAC,IAEA,IAAAxW,GAAA,IAIA,OAHA4Z,GAAA7R,IAAA,SAAAqM,GACApU,EAAA,OAAAA,EAAAoU,EAAAmC,EAAAgE,WAAAva,EAAAoU,KAEApU,GAGA2Z,EAAAxX,UAAAyR,SAAA,WACA,GAAAvG,GAAA,EAIA,OAHAxL,MAAAgY,MAAA9R,IAAA,SAAAqM,GACA/G,GAAA,MAAA+G,EAAAR,aAEAvG,EAAAW,OAAA,EAAAX,EAAAyN,MAAA,GAAAzN,GAsCA4M,EAAA9X,UAAAC,OAAAC,OAAAkU,EAAApU,WACA8X,EAAA9X,UAAAF,YAAAgY,EAEAA,EAAA9X,UAAAF,YAAA,SAAAiS,GACA,MAAArS,QAAAqS,GAEEA,YAAA+F,IAGFpY,KAAAgY,QAAA3F,EAAA2F,OAIAI,EAAA9X,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAgY,MAAA,OAOAI,EAAA9X,UAAAiY,SAAA,SAAA1Z,EAAA2Z,GACA,OAAAnJ,GAAA,EAAgBA,EAAArP,KAAAgY,MAAA7L,OAAuBkD,IACvC,GAAArP,KAAAgY,MAAA3I,GAAAkJ,SAAA1Z,EAAA2Z,GACA,QAGA,WAGAJ,EAAA9X,UAAAmY,eAAA,SAAA5Z,EAAA2Z,GAGA,OAFAO,IAAA,EACAhB,KACA1I,EAAA,EAAgBA,EAAArP,KAAAgY,MAAA7L,OAAuBkD,IAAA,CACvC,GAAA1O,GAAAX,KAAAgY,MAAA3I,GACA2J,EAAArY,EAAA8X,eAAA5Z,EAAA2Z,EAEA,IADAO,GAAAC,IAAArY,EACAqY,IAAAtE,EAAAC,KAEA,MAAAD,GAAAC,IACG,QAAAqE,GAEHjB,EAAA3L,KAAA4M,GAGA,IAAAD,EACA,MAAA/Y,KAEA,QAAA+X,EAAA5L,OAEA,WAEA,IAAAhO,GAAA,IAIA,OAHA4Z,GAAA7R,IAAA,SAAAqM,GACA,cAAApU,EAAAoU,EAAAmC,EAAAiE,UAAAxa,EAAAoU,KAEApU,GAGAia,EAAA9X,UAAAyR,SAAA,WACA,GAAAvG,GAAA,EAIA,OAHAxL,MAAAgY,MAAA9R,IAAA,SAAAqM,GACA/G,GAAA,MAAA+G,EAAAR,aAEAvG,EAAAW,OAAA,EAAAX,EAAAyN,MAAA,GAAAzN,GAGAxO,EAAA0X,kBACA1X,EAAA4a,sBACA5a,EAAAya,ad6gEM,SAASxa,EAAQD,EAASH,Ge56EhC,QAAA0N,GAAA4I,EAAAC,GAGA,MAFApT,MAAAmT,QACAnT,KAAAoT,OACApT,KAsBA,QAAAsL,KACAtL,KAAAkZ,UAAA,KACAlZ,KAAA8L,UAAA,EA9BA,GAAAtF,GAAA3J,EAAA,GAAA2J,KASA+D,GAAAjK,UAAAqM,SAAA,SAAAwM,GACA,MAAAA,IAAAnZ,KAAAmT,OAAAgG,EAAAnZ,KAAAoT,MAGA7I,EAAAjK,UAAAyR,SAAA,WACA,MAAA/R,MAAAmT,QAAAnT,KAAAoT,KAAA,EACApT,KAAAmT,MAAApB,WAEA/R,KAAAmT,MAAApB,WAAA,MAAA/R,KAAAoT,KAAA,GAAArB,YAKAxR,OAAAgR,eAAAhH,EAAAjK,UAAA,UACAkR,IAAA,WACA,MAAAxR,MAAAoT,KAAApT,KAAAmT,SASA7H,EAAAhL,UAAA8Y,MAAA,SAAAC,GACA,cAAArZ,KAAAkZ,WAAA,IAAAlZ,KAAAkZ,UAAA/M,OACA3F,EAAA2H,aAEAnO,KAAAkZ,UAAA,GAAA/F,OAIA7H,EAAAhL,UAAA+M,OAAA,SAAAgM,GACArZ,KAAAsZ,YAAA,GAAA/O,GAAA8O,IAAA,KAGA/N,EAAAhL,UAAA0P,SAAA,SAAA4B,EAAA2H,GACAvZ,KAAAsZ,YAAA,GAAA/O,GAAAqH,EAAA2H,EAAA,KAGAjO,EAAAhL,UAAAgZ,YAAA,SAAAD,GACA,UAAArZ,KAAAkZ,UACAlZ,KAAAkZ,aACAlZ,KAAAkZ,UAAA9M,KAAAiN,OACE,CAEF,OAAAG,GAAA,EAAiBA,EAAAxZ,KAAAkZ,UAAA/M,OAA2BqN,IAAA,CAC5C,GAAAnK,GAAArP,KAAAkZ,UAAAM,EAEA,IAAAH,EAAAjG,KAAA/D,EAAA8D,MAEA,WADAnT,MAAAkZ,UAAA1B,OAAAgC,EAAA,EAAAH,EAIA,IAAAA,EAAAjG,OAAA/D,EAAA8D,MAEA,YADAnT,KAAAkZ,UAAAM,GAAArG,MAAAkG,EAAAlG,MAIA,IAAAkG,EAAAlG,OAAA9D,EAAA+D,KAGA,MAFApT,MAAAkZ,UAAAM,GAAA,GAAAjP,GAAAvJ,KAAAoR,IAAA/C,EAAA8D,MAAAkG,EAAAlG,OAAAnS,KAAAyY,IAAApK,EAAA+D,KAAAiG,EAAAjG;IACApT,MAAA0Z,OAAAF,GAKAxZ,KAAAkZ,UAAA9M,KAAAiN,KAIA/N,EAAAhL,UAAAwM,OAAA,SAAAuF,GACA,UAAAA,EAAA6G,UACA,OAAAM,GAAA,EAAiBA,EAAAnH,EAAA6G,UAAA/M,OAA4BqN,IAAA,CAC7C,GAAAnK,GAAAgD,EAAA6G,UAAAM,EACAxZ,MAAAsZ,YAAA,GAAA/O,GAAA8E,EAAA8D,MAAA9D,EAAA+D,OAGA,MAAApT,OAGAsL,EAAAhL,UAAAoZ,OAAA,SAAAF,GAEA,GAAAA,EAAAxZ,KAAA2Z,gBAAA,GACA,GAAA/H,GAAA5R,KAAAkZ,UAAAM,GACAzK,EAAA/O,KAAAkZ,UAAAM,EAAA,EAEA5H,GAAAwB,MAAArE,EAAAqE,MACApT,KAAAkZ,UAAAU,IAAAJ,EAAA,GACAxZ,KAAA0Z,OAAAF,IACG5H,EAAAwB,MAAArE,EAAAoE,QACHnT,KAAAkZ,UAAAM,GAAA,GAAAjP,GAAAqH,EAAAuB,MAAApE,EAAAqE,MACApT,KAAAkZ,UAAAU,IAAAJ,EAAA,MAKAlO,EAAAhL,UAAA8P,WAAA,SAAA+C,EAAAC,GACA,GAAAjV,GAAA,GAAAmN,EACAnN,GAAAmb,YAAA,GAAA/O,GAAA4I,EAAAC,EAAA,GACA,QAAA/D,GAAA,EAAgBA,EAAArP,KAAAkZ,UAAA/M,OAAyBkD,IACzClR,EAAA0b,YAAA7Z,KAAAkZ,UAAA7J,GAEA,OAAAlR,IAGAmN,EAAAhL,UAAAqM,SAAA,SAAAwM,GACA,UAAAnZ,KAAAkZ,UACA,QAEA,QAAAM,GAAA,EAAiBA,EAAAxZ,KAAAkZ,UAAA/M,OAA2BqN,IAC5C,GAAAxZ,KAAAkZ,UAAAM,GAAA7M,SAAAwM,GACA,QAGA,WAIA5Y,OAAAgR,eAAAjG,EAAAhL,UAAA,UACAkR,IAAA,WACA,GAAAsI,GAAA,CAEA,OADA9Z,MAAAkZ,UAAAhT,IAAA,SAAAmJ,GAAkCyK,GAAAzK,EAAAlD,SAClC2N,KAIAxO,EAAAhL,UAAAuZ,YAAA,SAAAR,GACA,GAAAA,EAAAlG,QAAAkG,EAAAjG,KAAA,EACApT,KAAA+M,UAAAsM,EAAAlG,WACK,WAAAnT,KAAAkZ,UAEL,OADAM,GAAA,EACAzF,EAAA,EAAoBA,EAAA/T,KAAAkZ,UAAA/M,OAAyB4H,IAAA,CAC7C,GAAA1E,GAAArP,KAAAkZ,UAAAM,EAEA,IAAAH,EAAAjG,MAAA/D,EAAA8D,MACA,MAGA,IAAAkG,EAAAlG,MAAA9D,EAAA8D,OAAAkG,EAAAjG,KAAA/D,EAAA+D,KAAA,CACApT,KAAAkZ,UAAAM,GAAA,GAAAjP,GAAA8E,EAAA8D,MAAAkG,EAAAlG,MACA,IAAA4G,GAAA,GAAAxP,GAAA8O,EAAAjG,KAAA/D,EAAA+D,KAEA,YADApT,MAAAkZ,UAAA1B,OAAAgC,EAAA,EAAAO,GAIAV,EAAAlG,OAAA9D,EAAA8D,OAAAkG,EAAAjG,MAAA/D,EAAA+D,MACApT,KAAAkZ,UAAA1B,OAAAgC,EAAA,GACAA,GAAA,GAGAH,EAAAlG,MAAA9D,EAAA+D,KACApT,KAAAkZ,UAAAM,GAAA,GAAAjP,GAAA8E,EAAA8D,MAAAkG,EAAAlG,OAGAkG,EAAAjG,KAAA/D,EAAA+D,OACApT,KAAAkZ,UAAAM,GAAA,GAAAjP,GAAA8O,EAAAjG,KAAA/D,EAAA+D,OAEAoG,GAAA,IAKAlO,EAAAhL,UAAAyM,UAAA,SAAAsM,GACA,UAAArZ,KAAAkZ,UACA,OAAAM,GAAA,EAAiBA,EAAAxZ,KAAAkZ,UAAA/M,OAA2BqN,IAAA,CAC5C,GAAAnK,GAAArP,KAAAkZ,UAAAM,EAEA,IAAAH,EAAAhK,EAAA8D,MACA,MAGA,IAAAkG,IAAAhK,EAAA8D,OAAAkG,IAAAhK,EAAA+D,KAAA,EAEA,WADApT,MAAAkZ,UAAA1B,OAAAgC,EAAA,EAIA,IAAAH,IAAAhK,EAAA8D,MAEA,YADAnT,KAAAkZ,UAAAM,GAAA,GAAAjP,GAAA8E,EAAA8D,MAAA,EAAA9D,EAAA+D,MAIA,IAAAiG,IAAAhK,EAAA+D,KAAA,EAEA,YADApT,KAAAkZ,UAAAM,GAAA,GAAAjP,GAAA8E,EAAA8D,MAAA9D,EAAA+D,KAAA,GAIA,IAAAiG,EAAAhK,EAAA+D,KAAA,GACA,GAAA2G,GAAA,GAAAxP,GAAA8E,EAAA8D,MAAAkG,EAGA,OAFAhK,GAAA8D,MAAAkG,EAAA,MACArZ,MAAAkZ,UAAA1B,OAAAgC,EAAA,EAAAO,MAOAzO,EAAAhL,UAAAyR,SAAA,SAAAnI,EAAAC,EAAAmQ,GAIA,MAHApQ,MAAA,KACAC,KAAA,KACAmQ,MAAA,EACA,OAAAha,KAAAkZ,UACA,KACE,OAAAtP,GAAA,OAAAC,EACF7J,KAAAia,cAAArQ,EAAAC,GACEmQ,EACFha,KAAAka,eAEAla,KAAAma,iBAIA7O,EAAAhL,UAAA4Z,aAAA,WAEA,OADAE,MACA/K,EAAA,EAAgBA,EAAArP,KAAAkZ,UAAA/M,OAA2BkD,IAAA,CAC3C,GAAAgK,GAAArZ,KAAAkZ,UAAA7J,EACAgK,GAAAjG,OAAAiG,EAAAlG,MAAA,EACAkG,EAAAlG,QAAA3M,EAAAD,IACA6T,EAAAhO,KAAA,SAEAgO,EAAAhO,KAAA,IAAA8E,OAAAmJ,aAAAhB,EAAAlG,OAAA,KAGAiH,EAAAhO,KAAA,IAAA8E,OAAAmJ,aAAAhB,EAAAlG,OAAA,OAAAjC,OAAAmJ,aAAAhB,EAAAjG,KAAA,QAGA,MAAAgH,GAAAjO,OAAA,EACA,IAAWiO,EAAAtU,KAAA,UAEXsU,EAAA,IAKA9O,EAAAhL,UAAA6Z,cAAA,WAEA,OADAC,MACA/K,EAAA,EAAgBA,EAAArP,KAAAkZ,UAAA/M,OAA2BkD,IAAA,CAC3C,GAAAgK,GAAArZ,KAAAkZ,UAAA7J,EACAgK,GAAAjG,OAAAiG,EAAAlG,MAAA,EACAkG,EAAAlG,QAAA3M,EAAAD,IACA6T,EAAAhO,KAAA,SAEAgO,EAAAhO,KAAAiN,EAAAlG,MAAApB,YAGAqI,EAAAhO,KAAAiN,EAAAlG,MAAApB,WAAA,MAAAsH,EAAAjG,KAAA,GAAArB,YAGA,MAAAqI,GAAAjO,OAAA,EACA,IAAWiO,EAAAtU,KAAA,UAEXsU,EAAA,IAKA9O,EAAAhL,UAAA2Z,cAAA,SAAArQ,EAAAC,GAEA,OADAuQ,MACA/K,EAAA,EAAgBA,EAAArP,KAAAkZ,UAAA/M,OAA2BkD,IAE3C,OADAgK,GAAArZ,KAAAkZ,UAAA7J,GACAO,EAAAyJ,EAAAlG,MAAuBvD,EAAAyJ,EAAAjG,KAAYxD,IACnCwK,EAAAhO,KAAApM,KAAAsa,YAAA1Q,EAAAC,EAAA+F,GAGA,OAAAwK,GAAAjO,OAAA,EACA,IAAWiO,EAAAtU,KAAA,UAEXsU,EAAA,IAIA9O,EAAAhL,UAAAga,YAAA,SAAA1Q,EAAAC,EAAAyG,GACA,MAAAA,KAAA9J,EAAAD,IACA,QACE+J,IAAA9J,EAAAoG,QACF,YAEAhD,EAAA0G,IAAAzG,EAAAyG,IAIAtT,EAAAuN,WACAvN,EAAAsO,efw7EM,SAASrO,EAAQD,EAASH,GgB5qFhC,QAAA0d,GAAA3L,GAEA,GAAA9O,SAAA8O,GAAA,OAAAA,EACA,6BAMA,OAJA5O,MAAA4O,SAEA5O,KAAA+P,WAAA,EACA/P,KAAAmQ,MAAA,KACAnQ,KA2CA,QAAAwa,GAAA5L,EAAAuB,GAKA,MAJAoK,GAAAnd,KAAA4C,KAAA4O,GACA5O,KAAAya,OAAAtK,EACAnQ,KAAAmQ,MAAAnQ,KAAA0a,YACA1a,KAAA2a,kBAAAJ,EAAAK,KACA5a,KAoBA,QAAA2N,GAAAkN,EAAApL,EAAAoI,EAAA1K,GAOA,MANAoN,GAAAnd,KAAA4C,KAAA6a,GACA7a,KAAAyP,YACAzP,KAAA6X,aACA7X,KAAAmN,cACAnN,KAAA2a,kBAAAJ,EAAAO,KACA9a,KAAA+P,WAAA,EACA/P,KAWA,QAAA+a,GAAAnM,EAAAoM,GAKA,MAJAT,GAAAnd,KAAA4C,KAAA4O,GACA5O,KAAA2a,kBAAAJ,EAAA3N,QACA5M,KAAA+P,WAAA,EACA/P,KAAAgb,4BACAhb,KAcA,QAAAib,GAAArM,EAAAuE,EAAAC,GAMA,MALAmH,GAAAnd,KAAA4C,KAAA4O,GACA5O,KAAA2a,kBAAAJ,EAAAW,MACAlb,KAAAmT,QACAnT,KAAAoT,OACApT,KAAAmQ,MAAAnQ,KAAA0a,YACA1a,KAoBA,QAAA8N,GAAAc,GAEA,MADA2L,GAAAnd,KAAA4C,KAAA4O,GACA5O,KAMA,QAAAmb,GAAAvM,EAAAa,EAAAiI,EAAAC,GAOA,MANA7J,GAAA1Q,KAAA4C,KAAA4O,GACA5O,KAAA2a,kBAAAJ,EAAAa,UACApb,KAAAyP,YACAzP,KAAA0X,YACA1X,KAAA2X,iBACA3X,KAAA+P,WAAA,EACA/P,KAkBA,QAAAqb,GAAAzM,EAAAa,EAAA6L,EAAA3D,GAOA,MANA4C,GAAAnd,KAAA4C,KAAA4O,GACA5O,KAAA2a,kBAAAJ,EAAAgB,OACAvb,KAAAyP,YACAzP,KAAAsb,YAAAxb,SAAAwb,OACAtb,KAAA2X,eAAA7X,SAAA6X,KACA3X,KAAA+P,WAAA,EACA/P,KAiBA,QAAAwb,GAAA5M,EAAAsB,GASA,MARAqK,GAAAnd,KAAA4C,KAAA4O,GACA5O,KAAA2a,kBAAAJ,EAAAkB,IACA3b,SAAAoQ,GAAA,OAAAA,EACAlQ,KAAAmQ,MAAAD,GAEAlQ,KAAAmQ,MAAA,GAAA7E,GACAtL,KAAAmQ,MAAA9C,OAAA7G,EAAA2H,eAEAnO,KAeA,QAAA4N,GAAAgB,EAAAsB,GAGA,MAFAsL,GAAApe,KAAA4C,KAAA4O,EAAAsB,GACAlQ,KAAA2a,kBAAAJ,EAAAmB,QACA1b,KAeA,QAAA6N,GAAAe,GAGA,MAFA2L,GAAAnd,KAAA4C,KAAA4O,GACA5O,KAAA2a,kBAAAJ,EAAAoB,SACA3b,KAeA,QAAA4b,GAAAhN,EAAAiJ,GAKA,MAJA/J,GAAA1Q,KAAA4C,KAAA4O,GACA5O,KAAA2a,kBAAAJ,EAAAsB,WACA7b,KAAA6X,aACA7X,KAAA+P,WAAA,EACA/P,KA5QA,GAAAwG,GAAA3J,EAAA,GAAA2J,MAEA8E,GADAzO,EAAA,IAAA0N,SACA1N,EAAA,IAAAyO,aACAmM,EAAA5a,EAAA,IAAA4a,UACAG,EAAA/a,EAAA,IAAA+a,mBAcA2C,GAAA3N,QAAA,EACA2N,EAAAW,MAAA,EACAX,EAAAO,KAAA,EACAP,EAAAa,UAAA,EACAb,EAAAK,KAAA,EACAL,EAAAgB,OAAA,EACAhB,EAAAkB,IAAA,EACAlB,EAAAmB,QAAA,EACAnB,EAAAoB,SAAA,EACApB,EAAAsB,WAAA,GAEAtB,EAAAnD,oBACA,UACA,UACA,QACA,OACA,YACA,OACA,SACA,MACA,UACA,WACA,cAGAmD,EAAAuB,oBACAf,kBAAAR,EAAA3N,QACAqO,gBAAAV,EAAAW,MACAvN,eAAA4M,EAAAO,KACAK,oBAAAZ,EAAAa,UACAZ,eAAAD,EAAAK,KACAS,iBAAAd,EAAAgB,OACAC,cAAAjB,EAAAkB,IACA7N,iBAAA2M,EAAAmB,QACA7N,mBAAA0M,EAAAoB,SACAC,8BAAArB,EAAAsB,YAaArB,EAAAla,UAAAC,OAAAC,OAAA+Z,EAAAja,WACAka,EAAAla,UAAAF,YAAAoa,EAEAA,EAAAla,UAAAoa,UAAA,WACA,GAAAlP,GAAA,GAAAF,EAEA,OADAE,GAAA6B,OAAArN,KAAAya,QACAjP,GAGAgP,EAAAla,UAAAyb,QAAA,SAAAC,EAAAC,EAAAC,GACA,MAAAlc,MAAAya,SAAAuB,GAGAxB,EAAAla,UAAAyR,SAAA,WACA,MAAA/R,MAAAya,QAaA9M,EAAArN,UAAAC,OAAAC,OAAA+Z,EAAAja,WACAqN,EAAArN,UAAAF,YAAAuN,EAEAA,EAAArN,UAAAyb,QAAA,SAAAC,EAAAC,EAAAC,GACA,UAYAnB,EAAAza,UAAAC,OAAAC,OAAA+Z,EAAAja,WACAya,EAAAza,UAAAF,YAAA2a,EAEAA,EAAAza,UAAAyb,QAAA,SAAAC,EAAAC,EAAAC,GACA,UAGAnB,EAAAza,UAAAyR,SAAA,WACA,iBAYAkJ,EAAA3a,UAAAC,OAAAC,OAAA+Z,EAAAja,WACA2a,EAAA3a,UAAAF,YAAA6a,EAEAA,EAAA3a,UAAAoa,UAAA,WACA,GAAAlP,GAAA,GAAAF,EAEA,OADAE,GAAAwE,SAAAhQ,KAAAmT,MAAAnT,KAAAoT,MACA5H,GAGAyP,EAAA3a,UAAAyb,QAAA,SAAAC,EAAAC,EAAAC,GACA,MAAAF,IAAAhc,KAAAmT,OAAA6I,GAAAhc,KAAAoT,MAGA6H,EAAA3a,UAAAyR,SAAA,WACA,UAAAb,OAAAmJ,aAAAra,KAAAmT,OAAA,OAAAjC,OAAAmJ,aAAAra,KAAAoT,MAAA,KAQAtF,EAAAxN,UAAAC,OAAAC,OAAA+Z,EAAAja,WACAwN,EAAAxN,UAAAF,YAAA0N,EAYAqN,EAAA7a,UAAAC,OAAAC,OAAAsN,EAAAxN,WACA6a,EAAA7a,UAAAF,YAAA+a,EAEAA,EAAA7a,UAAAyb,QAAA,SAAAC,EAAAC,EAAAC,GACA,UAGAf,EAAA7a,UAAA6b,aAAA,WACA,UAAA1E,GAAAzX,KAAAyP,UAAAzP,KAAA0X,UAAA1X,KAAA2X,iBAGAwD,EAAA7a,UAAAyR,SAAA,WACA,cAAA/R,KAAAyP,UAAA,IAAAzP,KAAA0X,WAaA2D,EAAA/a,UAAAC,OAAAC,OAAA+Z,EAAAja,WACA+a,EAAA/a,UAAAF,YAAAib,EAGAA,EAAA/a,UAAAyb,QAAA,SAAAC,EAAAC,EAAAC,GACA,UAGAb,EAAA/a,UAAAyR,SAAA,WACA,gBAAA/R,KAAAyP,UAAA,IAAAzP,KAAAsb,aAiBAE,EAAAlb,UAAAC,OAAAC,OAAA+Z,EAAAja,WACAkb,EAAAlb,UAAAF,YAAAob,EAEAA,EAAAlb,UAAAyb,QAAA,SAAAC,EAAAC,EAAAC,GACA,MAAAlc,MAAAmQ,MAAAxD,SAAAqP,IAIAR,EAAAlb,UAAAyR,SAAA,WACA,MAAA/R,MAAAmQ,MAAA4B,YASAnE,EAAAtN,UAAAC,OAAAC,OAAAgb,EAAAlb,WACAsN,EAAAtN,UAAAF,YAAAwN,EAEAA,EAAAtN,UAAAyb,QAAA,SAAAC,EAAAC,EAAAC,GACA,MAAAF,IAAAC,GAAAD,GAAAE,IACAV,EAAAlb,UAAAyb,QAAA3e,KAAA4C,KAAAgc,EAAAC,EAAAC,IAGAtO,EAAAtN,UAAAyR,SAAA,WACA,UAAAyJ,EAAAlb,UAAAyR,SAAA3U,KAAA4C,OASA6N,EAAAvN,UAAAC,OAAAC,OAAA+Z,EAAAja,WACAuN,EAAAvN,UAAAF,YAAAyN,EAGAA,EAAAvN,UAAAyb,QAAA,SAAAC,EAAAC,EAAAC,GACA,MAAAF,IAAAC,GAAAD,GAAAE,GAGArO,EAAAvN,UAAAyR,SAAA,WACA,WAWA6J,EAAAtb,UAAAC,OAAAC,OAAAsN,EAAAxN,WACAsb,EAAAtb,UAAAF,YAAAwb,EAEAA,EAAAtb,UAAAyb,QAAA,SAAAC,EAAAC,EAAAC,GACA,UAGAN,EAAAtb,UAAA6b,aAAA,WACA,UAAAvE,GAAA5X,KAAA6X,aAGA+D,EAAAtb,UAAAyR,SAAA,WACA,MAAA/R,MAAA6X,WAAA,UAGA7a,EAAAud,aACAvd,EAAAwd,iBACAxd,EAAAwe,gBACAxe,EAAA4Q,mBACA5Q,EAAA2Q,iBACA3Q,EAAAqe,mBACAre,EAAA+d,oBACA/d,EAAAie,kBACAje,EAAA6Q,qBACA7Q,EAAAme,sBACAne,EAAA4e,gCACA5e,EAAA8Q,+BhBkuFM,SAAS7Q,EAAQD,EAASH,GiBphGhC,QAAAmR,GAAAoO,GACApc,KAAAoc,mBAuDA,QAAAC,GAAAC,EAAAhN,GACA,SAAAgN,EAAAhN,EAGA,QAAAiN,KACA,SAOA,QAAA3W,KAEA,MADA5F,MAAAwc,SACAxc,KA6BA,QAAAiO,GAAAqO,EAAAhN,GACA,GAAAoB,GAAA,OAAA4L,EAAAD,EAAAC,EAAAhN,GACAiN,GACAvO,GAAA5Q,KAAA4C,KAAA0Q,GACA1Q,KAAAoN,UAAAkP,EACAtc,KAAAsP,cA+DA,QAAAmN,KAEA,MADAxO,GAAA7Q,KAAA4C,KAAA,KAAAgO,EAAA0O,oBACA1c,KA4BA,QAAA2c,GAAAC,EAAAC,GAKA,GAAAzL,GAAAiL,EAAAO,EAAAC,EAIA,OAHA7O,GAAA5Q,KAAA4C,KAAAoR,GACApR,KAAA4c,UACA5c,KAAA6c,eACA7c,KAkEA,QAAA+N,GAAAtI,EAAA+S,GAMA,GALA1Y,SAAA0Y,GAAA,OAAAA,IACAA,EAAAsE,EAAAjO,OAIA,OAAA2J,EAAApL,WAAAoL,IAAAsE,EAAAjO,MACA,MAAAb,GAAAa,KAGA,IAAAyN,GAAAvO,EAAAtI,EAAA+S,EAAApL,WACAnB,EAAAxG,EAAAqF,OAAA0N,EAAAxL,eACA2B,EAAA1C,EAAAiB,YAAA,EACA,OAAAe,GAAAzN,OAAA8b,EAAA3N,EAAAxB,YAAAjB,aAcA,QAAA6Q,GAAAzM,EAAApQ,EAAA8c,EAAAC,GAEA,GAAA3M,IAAApQ,EACA,MAAAoQ,EAEA,IAAAA,YAAArC,IAAA/N,YAAA+N,GACA,MAAAiP,GAAA5M,EAAApQ,EAAA8c,EAAAC,EAIA,IAAAD,EAAA,CACA,GAAA1M,YAAAmM,GACA,MAAAnM,EAEA,IAAApQ,YAAAuc,GACA,MAAAvc,GAUA,MANAoQ,aAAArC,KACAqC,EAAA,GAAAqM,IAAArM,EAAAX,cAAAW,EAAAhB,eAEApP,YAAA+N,KACA/N,EAAA,GAAAyc,IAAAzc,EAAAyP,cAAAzP,EAAAoP,eAEA6N,EAAA7M,EAAApQ,EAAA8c,EAAAC,GAkCA,QAAAC,GAAA5M,EAAApQ,EAAA8c,EAAAC,GACA,UAAAA,EAAA,CACA,GAAAG,GAAAH,EAAAzL,IAAAlB,EAAApQ,EACA,WAAAkd,EACA,MAAAA,EAGA,IADAA,EAAAH,EAAAzL,IAAAtR,EAAAoQ,GACA,OAAA8M,EACA,MAAAA,GAIA,GAAAC,GAAAC,EAAAhN,EAAApQ,EAAA8c,EACA,WAAAK,EAIA,MAHA,QAAAJ,GACAA,EAAA/M,IAAAI,EAAApQ,EAAAmd,GAEAA,CAEA,IAAA/M,EAAAhB,cAAApP,EAAAoP,YAAA,CACA,GAAAgN,GAAAS,EAAAzM,EAAAlD,UAAAlN,EAAAkN,UAAA4P,EAAAC,EAGA,IAAAX,IAAAhM,EAAAlD,UACA,MAAAkD,EAEA,IAAAgM,IAAApc,EAAAkN,UACA,MAAAlN,EAMA,IAAAqd,GAAAtP,EAAAzN,OAAA8b,EAAAhM,EAAAhB,YAIA,OAHA,QAAA2N,GACAA,EAAA/M,IAAAI,EAAApQ,EAAAqd,GAEAA,EAGA,GAAAC,GAAA,IAMA,KALAlN,IAAApQ,GAAA,OAAAoQ,EAAAlD,WAAAkD,EAAAlD,YAAAlN,EAAAkN,aAGAoQ,EAAAlN,EAAAlD,WAEA,OAAAoQ,EAAA,CAEA,GAAAC,IAAAnN,EAAAhB,YAAApP,EAAAoP,YACAgB,GAAAhB,YAAApP,EAAAoP,cACAmO,EAAA,GAAAvd,EAAAoP,YACAmO,EAAA,GAAAnN,EAAAhB,YAEA,IAAAsN,IAAAY,KACAE,EAAA,GAAAf,GAAAC,EAAAa,EAIA,OAHA,QAAAR,GACAA,EAAA/M,IAAAI,EAAApQ,EAAAwd,GAEAA,EAKA,GAAAD,IAAAnN,EAAAhB,YAAApP,EAAAoP,aACAsN,GAAAtM,EAAAlD,UAAAlN,EAAAkN,UACAkD,GAAAhB,YAAApP,EAAAoP,cACAmO,EAAA,GAAAvd,EAAAoP,YACAmO,EAAA,GAAAnN,EAAAhB,YACAsN,GAAA1c,EAAAkN,UAAAkD,EAAAlD,WAEA,IAAAuQ,GAAA,GAAAhB,GAAAC,EAAAa,EAIA,OAHA,QAAAR,GACAA,EAAA/M,IAAAI,EAAApQ,EAAAyd,GAEAA,EA0CA,QAAAL,GAAAhN,EAAApQ,EAAA8c,GACA,GAAAA,EAAA,CACA,GAAA1M,IAAAtC,EAAAa,MACA,MAAAb,GAAAa,KAEA,IAAA3O,IAAA8N,EAAAa,MACA,MAAAb,GAAAa,UAEE,CACF,GAAAyB,IAAAtC,EAAAa,OAAA3O,IAAA8N,EAAAa,MACA,MAAAb,GAAAa,KACG,IAAAyB,IAAAtC,EAAAa,MAAA,CACH,GAAA4O,IAAAvd,EAAAoP,YACAtB,EAAA0O,oBACAE,GAAA1c,EAAAkN,UAAA,KACA,WAAAuP,GAAAC,EAAAa,GACG,GAAAvd,IAAA8N,EAAAa,MAAA,CACH,GAAA4O,IAAAnN,EAAAhB,YAAAtB,EAAA0O,oBACAE,GAAAtM,EAAAlD,UAAA,KACA,WAAAuP,GAAAC,EAAAa,IAGA,YAuBA,QAAAN,GAAA7M,EAAApQ,EAAA8c,EAAAC,GACA,UAAAA,EAAA,CACA,GAAAG,GAAAH,EAAAzL,IAAAlB,EAAApQ,EACA,WAAAkd,EACA,MAAAA,EAGA,IADAA,EAAAH,EAAAzL,IAAAtR,EAAAoQ,GACA,OAAA8M,EACA,MAAAA,GAWA,IAPA,GAAA/N,GAAA,EACAO,EAAA,EACA4J,EAAA,EAEAoE,KACAC,KAEAxO,EAAAiB,EAAAuM,aAAA1Q,QAAAyD,EAAA1P,EAAA2c,aAAA1Q,QAAA,CACA,GAAA2R,GAAAxN,EAAAsM,QAAAvN,GACA0O,EAAA7d,EAAA0c,QAAAhN,EACA,IAAAU,EAAAuM,aAAAxN,KAAAnP,EAAA2c,aAAAjN,GAAA,CAEA,GAAAoO,GAAA1N,EAAAuM,aAAAxN,GAEA4O,EAAAD,IAAAhQ,EAAA0O,oBACA,OAAAoB,GAAA,OAAAC,EACAG,EAAA,OAAAJ,GAAA,OAAAC,GAAAD,IAAAC,CAGA,IAAAE,GAAAC,EACAL,EAAArE,GAAAsE,EACAF,EAAApE,GAAAwE,MACI,CACJ,GAAAG,GAAApB,EAAAe,EAAAC,EAAAf,EAAAC,EACAY,GAAArE,GAAA2E,EACAP,EAAApE,GAAAwE,EAEA3O,GAAA,EACAO,GAAA,MACGU,GAAAuM,aAAAxN,GAAAnP,EAAA2c,aAAAjN,IACHiO,EAAArE,GAAAsE,EACAF,EAAApE,GAAAlJ,EAAAuM,aAAAxN,GACAA,GAAA,IAEAwO,EAAArE,GAAAuE,EACAH,EAAApE,GAAAtZ,EAAA2c,aAAAjN,GACAA,GAAA,EAEA4J,IAAA,EAGA,GAAAnK,EAAAiB,EAAAuM,aAAA1Q,OACA,OAAA5O,GAAA8R,EAAiB9R,EAAA+S,EAAAuM,aAAA1Q,OAA2B5O,IAC5CsgB,EAAArE,GAAAlJ,EAAAsM,QAAArf,GACAqgB,EAAApE,GAAAlJ,EAAAuM,aAAAtf,GACAic,GAAA,MAGA,QAAAjc,GAAAqS,EAAiBrS,EAAA2C,EAAA2c,aAAA1Q,OAA2B5O,IAC5CsgB,EAAArE,GAAAtZ,EAAA0c,QAAArf,GACAqgB,EAAApE,GAAAtZ,EAAA2c,aAAAtf,GACAic,GAAA,CAIA,IAAAA,EAAAqE,EAAA1R,OAAA,CACA,OAAAqN,EAAA,CACA,GAAAmE,GAAA1P,EAAAzN,OAAAqd,EAAA,GACAD,EAAA,GAIA,OAHA,QAAAX,GACAA,EAAA/M,IAAAI,EAAApQ,EAAAyd,GAEAA,EAEAE,IAAA5E,MAAA,EAAAO,GACAoE,IAAA3E,MAAA,EAAAO,GAGA,GAAA4E,GAAA,GAAAzB,GAAAkB,EAAAD,EAIA,OAAAQ,KAAA9N,GACA,OAAA2M,GACAA,EAAA/M,IAAAI,EAAApQ,EAAAoQ,GAEAA,GAEA8N,IAAAle,GACA,OAAA+c,GACAA,EAAA/M,IAAAI,EAAApQ,KAEAA,IAEAme,EAAAR,GAEA,OAAAZ,GACAA,EAAA/M,IAAAI,EAAApQ,EAAAke,GAEAA,GAOA,QAAAC,GAAAzB,GAGA,OAFA0B,MAEA/gB,EAAA,EAAgBA,EAAAqf,EAAAzQ,OAAoB5O,IAAA,CACpC,GAAA+e,GAAAM,EAAArf,EACA+e,KAAAgC,KACAA,EAAAhC,MAGA,OAAAiC,GAAA,EAAgBA,EAAA3B,EAAAzQ,OAAoBoS,IACpC3B,EAAA2B,GAAAD,EAAA1B,EAAA2B,IAIA,QAAAC,GAAA7d,EAAA8d,EAAAC,GACA,GAAA/d,EAAAyO,UACA,MAAAzO,EAEA,IAAAge,GAAAD,EAAA/d,IAAA,IACA,WAAAge,EACA,MAAAA,EAGA,IADAA,EAAAF,EAAAjN,IAAA7Q,GACA,OAAAge,EAEA,MADAD,GAAA/d,GAAAge,EACAA,CAIA,QAFAC,IAAA,EACAhC,KACAvN,EAAA,EAAgBA,EAAAuN,EAAAzQ,OAAoBkD,IAAA,CACpC,GAAAiN,GAAAkC,EAAA7d,EAAAgP,UAAAN,GAAAoP,EAAAC,EACA,IAAAE,GAAAtC,IAAA3b,EAAAgP,UAAAN,GAAA,CACA,IAAAuP,EAAA,CACAhC,IACA,QAAAhN,GAAA,EAAmBA,EAAAjP,EAAAwL,OAAoByD,IACvCgN,EAAAhN,GAAAjP,EAAAgP,UAAAC,EAEAgP,IAAA,EAEAhC,EAAAvN,GAAAiN,GAGA,IAAAsC,EAGA,MAFAH,GAAAtP,IAAAxO,GACA+d,EAAA/d,KACAA,CAEA,IAAAke,GAAA,IAaA,OAXAA,GADA,IAAAjC,EAAAzQ,OACA6B,EAAAa,MACE,IAAA+N,EAAAzQ,OACF8B,EAAAzN,OAAAoc,EAAA,GAAAjc,EACA4O,eAAA,IAEA,GAAAoN,GAAAC,EAAAjc,EAAAkc,cAEA4B,EAAAtP,IAAA0P,GACAH,EAAAG,KACAH,EAAA/d,GAAAke,EAEAA,EAjrBA,GAAA/B,GAAAjgB,EAAA,IAAAigB,WASA9O,GAAAa,MAAA,KAMAb,EAAA0O,mBAAA,WAEA1O,EAAA8Q,gBAAA,EACA9Q,EAAA9Q,GAAA8Q,EAAA8Q,gBA4BA9Q,EAAA1N,UAAA8O,QAAA,WACA,MAAApP,QAAAgO,EAAAa,OAGAb,EAAA1N,UAAAye,aAAA,WACA,MAAA/e,MAAAuP,eAAAvP,KAAAmM,OAAA,KAAA6B,EAAA0O,oBAGA1O,EAAA1N,UAAAoQ,WAAA,WACA,MAAA1Q,MAAAoc,kBAwBAxW,EAAAtF,UAAA6O,IAAA,SAAA1D,GACA,GAAAA,IAAAuC,EAAAa,MACA,MAAAb,GAAAa,KAEA,IAAA8P,GAAA3e,KAAAwc,MAAA/Q,IAAA,IACA,eAAAkT,EACAA,GAEA3e,KAAAwc,MAAA/Q,KACAA,IAGA7F,EAAAtF,UAAAkR,IAAA,SAAA/F,GACA,MAAAzL,MAAAwc,MAAA/Q,IAAA,MAGAlL,OAAAgR,eAAA3L,EAAAtF,UAAA,UACAkR,IAAA,WACA,MAAAxR,MAAAwc,MAAArQ,UAYA8B,EAAA3N,UAAAC,OAAAC,OAAAwN,EAAA1N,WACA2N,EAAA3N,UAAA0e,WAAA/Q,EAEAA,EAAAzN,OAAA,SAAA8b,EAAAhN,GACA,MAAAA,KAAAtB,EAAA0O,oBAAA,OAAAJ,EAEAtO,EAAAa,MAEA,GAAAZ,GAAAqO,EAAAhN,IAIA/O,OAAAgR,eAAAtD,EAAA3N,UAAA,UACAkR,IAAA,WACA,YAIAvD,EAAA3N,UAAAqP,UAAA,SAAAvJ,GACA,MAAApG,MAAAoN,WAGAa,EAAA3N,UAAAiP,eAAA,SAAAnJ,GACA,MAAApG,MAAAsP,aAGArB,EAAA3N,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEEA,YAAApE,KAEAjO,KAAA0Q,eAAA2B,EAAA3B,eAGF1Q,KAAAsP,cAAA+C,EAAA/C,cAEA,MAAAtP,KAAAoN,UACA,MAAAiF,EAAAjF,UAEApN,KAAAoN,UAAAoD,OAAA6B,EAAAjF,eAIAa,EAAA3N,UAAAoQ,WAAA,WACA,MAAA1Q,MAAAoc,kBAGAnO,EAAA3N,UAAAyR,SAAA,WACA,GAAAkN,GAAA,OAAAjf,KAAAoN,UAAA,GAAApN,KAAAoN,UAAA2E,UACA,YAAAkN,EAAA9S,OACAnM,KAAAsP,cAAAtP,KAAA0c,mBACA,IAEA,GAAA1c,KAAAsP,YAGA,GAAAtP,KAAAsP,YAAA,IAAA2P,GASAxC,EAAAnc,UAAAC,OAAAC,OAAAyN,EAAA3N,WACAmc,EAAAnc,UAAAF,YAAAqc,EAEAA,EAAAnc,UAAA8O,QAAA,WACA,UAGAqN,EAAAnc,UAAAqP,UAAA,SAAAvJ,GACA,aAGAqW,EAAAnc,UAAAiP,eAAA,SAAAnJ,GACA,MAAApG,MAAAsP,aAGAmN,EAAAnc,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAGAoK,EAAAnc,UAAAyR,SAAA,WACA,WAGA/D,EAAAa,MAAA,GAAA4N,GAcAE,EAAArc,UAAAC,OAAAC,OAAAwN,EAAA1N,WACAqc,EAAArc,UAAAF,YAAAuc,EAEAA,EAAArc,UAAA8O,QAAA,WAGA,MAAApP,MAAA6c,aAAA,KAAA7O,EAAA0O,oBAGAnc,OAAAgR,eAAAoL,EAAArc,UAAA,UACAkR,IAAA,WACA,MAAAxR,MAAA6c,aAAA1Q,UAIAwQ,EAAArc,UAAAqP,UAAA,SAAAvJ,GACA,MAAApG,MAAA4c,QAAAxW,IAGAuW,EAAArc,UAAAiP,eAAA,SAAAnJ,GACA,MAAApG,MAAA6c,aAAAzW,IAGAuW,EAAArc,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEEA,YAAAsK,KAEA3c,KAAA0Q,aAAA2B,EAAA3B,eAGF1Q,KAAA6c,eAAAxK,EAAAwK,cACA7c,KAAA4c,UAAAvK,EAAAuK,WAIAD,EAAArc,UAAAyR,SAAA,WACA,GAAA/R,KAAAoP,UACA,UAGA,QADA5D,GAAA,IACA6D,EAAA,EAAiBA,EAAArP,KAAA6c,aAAA1Q,OAA8BkD,IAC/CA,EAAA,IACA7D,GAAA,MAEAxL,KAAA6c,aAAAxN,KAAArB,EAAA0O,oBAIAlR,GAAAxL,KAAA6c,aAAAxN,GACA,OAAArP,KAAA4c,QAAAvN,GACA7D,IAAA,IAAAxL,KAAA4c,QAAAvN,GAEA7D,GAAA,QAPAA,GAAA,GAUA,OAAAA,GAAA,KA8bAxO,EAAA+f,QACA/f,EAAAgR,oBACAhR,EAAA4I,yBACA5I,EAAAiR,6BACAjR,EAAA+Q,mCACA/Q,EAAAwhB,8BjB4jGM,SAASvhB,EAAQD,EAASH,GkBlvHhC,QAAAigB,GAAAR,EAAAtP,GAQA,MAPAkS,GAAA9hB,KAAA4C,MAEAA,KAAAoN,UAAAkP,GAAA,KAIAtc,KAAAgN,oBACAhN,KAZA,GAAAkf,GAAAriB,EAAA,IAAAqiB,SACAC,EAAAtiB,EAAA,IAAAsiB,iBACA7R,EAAAzQ,EAAA,GAAAyQ,kBAaAwP,GAAAxc,UAAAC,OAAAC,OAAA0e,EAAA5e,WACAwc,EAAAxc,UAAAF,YAAA0c,EAEAA,EAAAxc,UAAA8e,MAAA,WAGA,IAFA,GAAArL,GAAA,EACAxW,EAAAyC,KACA,OAAAzC,GACAA,IAAA6P,UACA2G,GAAA,CAEA,OAAAA,IAKA+I,EAAAxc,UAAA8O,QAAA,WACA,MAAApP,MAAAgN,oBAKA8P,EAAAxc,UAAA+e,kBAAA,WACA,MAAAF,IAGArC,EAAAxc,UAAAgf,eAAA,WACA,MAAAtf,OAGA8c,EAAAxc,UAAAif,WAAA,WACA,MAAAvf,OAUA8c,EAAAxc,UAAAwC,QAAA,WACA,WAAA9C,KAAAwf,gBACA,GAEAxf,KAAAyf,SAAAvZ,IAAA,SAAAwZ,GACA,MAAAA,GAAA5c,YACGgD,KAAA,KAUHgX,EAAAxc,UAAAqf,aAAA,WAAiD,MAAArS,IAOjDwP,EAAAxc,UAAAsf,aAAA,SAAAC,KAEA/C,EAAAxc,UAAAwf,SAAA,SAAAzQ,GACA,aAGAyN,EAAAxc,UAAAkf,cAAA,WACA,UAGA1C,EAAAxc,UAAAO,OAAA,SAAA3B,GACA,MAAAA,GAAA6gB,cAAA/f,OAIAhD,EAAA8f,aACA,IAAAkD,GAAAnjB,EAAA,IAAAmjB,KAOAlD,GAAAxc,UAAA2f,aAAA,SAAAnW,EAAAoW,GACA,MAAAF,GAAAC,aAAAjgB,KAAA8J,EAAAoW,IAGApD,EAAAxc,UAAAyR,SAAA,SAAAjI,EAAAsJ,GACAtJ,KAAA,KACAsJ,KAAA,IAGA,KAFA,GAAA7V,GAAAyC,KACAwL,EAAA,IACA,OAAAjO,OAAA6V,GAAA,CACA,UAAAtJ,EACAvM,EAAA6R,YACA5D,GAAAjO,EAAAyP,mBAEG,CACH,GAAAmT,GAAA5iB,EAAAkS,UACA2Q,EAAAD,GAAA,GAAAA,EAAArW,EAAAqC,OAAArC,EAAAqW,GACA,GAAAA,CACA3U,IAAA4U,EAEA,OAAA7iB,EAAA6P,WAAA,OAAAtD,GAAAvM,EAAA6P,UAAAgC,YACA5D,GAAA,KAEAjO,IAAA6P,UAGA,MADA5B,IAAA,MlBmzHM,SAASvO,EAAQD,EAASH,GmB57HhC,QAAAwjB,KACA,MAAArgB,MAGA,QAAAsgB,KAEA,MADAD,GAAAjjB,KAAA4C,MACAA,KAMA,QAAAugB,KAEA,MADAD,GAAAljB,KAAA4C,MACAA,KAMA,QAAAkf,KAEA,MADAqB,GAAAnjB,KAAA4C,MACAA,KAMA,QAAAwgB,KAEA,MADAD,GAAAnjB,KAAA4C,MACAA,KAMA,QAAAygB,KAEA,MADAD,GAAApjB,KAAA4C,MACAA,KAMA,QAAA0gB,KACA,MAAA1gB,MA8BA,QAAA2gB,KACA,MAAA3gB,MAeA,QAAA4gB,GAAA5E,GAIA,MAHAwE,GAAApjB,KAAA4C,MACAA,KAAAoN,UAAA,KACApN,KAAAgc,SACAhc,KAwDA,QAAA6gB,GAAAC,GAEA,MADAF,GAAAxjB,KAAA4C,KAAA8gB,GACA9gB,KAcA,QAAA+gB,KACA,MAAA/gB,MA9KA,GAAAwG,GAAA3J,EAAA,GAAA2J,MACA+D,EAAA1N,EAAA,IAAA0N,SACA4U,EAAA,GAAA5U,cACAC,EAAA3N,EAAA,EAYAyjB,GAAAhgB,UAAAC,OAAAC,OAAA6f,EAAA/f,WACAggB,EAAAhgB,UAAAF,YAAAkgB,EAOAC,EAAAjgB,UAAAC,OAAAC,OAAA8f,EAAAhgB,WACAigB,EAAAjgB,UAAAF,YAAAmgB,EAOArB,EAAA5e,UAAAC,OAAAC,OAAA+f,EAAAjgB,WACA4e,EAAA5e,UAAAF,YAAA8e,EAOAsB,EAAAlgB,UAAAC,OAAAC,OAAA+f,EAAAjgB,WACAkgB,EAAAlgB,UAAAF,YAAAogB,EAOAC,EAAAngB,UAAAC,OAAAC,OAAAggB,EAAAlgB,WACAmgB,EAAAngB,UAAAF,YAAAqgB,EAMAC,EAAApgB,UAAA0gB,MAAA,SAAAvV,GACA,GAAAjB,EAAAgI,QAAA/G,GAAA,CACA,GAAAwV,GAAAjhB,IACA,OAAAyL,GAAAvF,IAAA,SAAAwZ,GAAkC,MAAAwB,GAAAD,EAAAvB,KAElC,MAAAwB,GAAAlhB,KAAAyL,IAIAiV,EAAApgB,UAAA6gB,cAAA,SAAAC,KAGAV,EAAApgB,UAAA+gB,eAAA,SAAAD,IAIA,IAAAF,GAAA,SAAAhiB,EAAAuM,GACA,GAAA3L,SAAA2L,EAAA5M,OAAA,CAIA,GAAAyiB,GAAA7V,EAAA5M,OAAAiL,UAAA2B,EAAAgE,WACA8R,EAAA,QAAA/W,EAAAkI,UAAA4O,EAEA,OAAApiB,GAAAqiB,GAAA9V,IAOAkV,GAAArgB,UAAA6gB,cAAA,SAAAC,KAGAT,EAAArgB,UAAA+gB,eAAA,SAAAD,KAGAT,EAAArgB,UAAAkhB,eAAA,SAAAJ,KAGAT,EAAArgB,UAAAmhB,cAAA,SAAAL,KAUAR,EAAAtgB,UAAAC,OAAAC,OAAAggB,EAAAlgB,WACAsgB,EAAAtgB,UAAAF,YAAAwgB,EAEAA,EAAAtgB,UAAAwf,SAAA,SAAAzQ,GACA,aAGAuR,EAAAtgB,UAAAohB,UAAA,WACA,MAAA1hB,MAAAgc,QAGA4E,EAAAtgB,UAAAqP,UAAA,WACA,MAAA3P,MAAAoN,WAGAwT,EAAAtgB,UAAAif,WAAA,WACA,MAAAvf,MAAAgc,QAGA4E,EAAAtgB,UAAA+e,kBAAA,WACA,UAAArf,KAAAgc,OACA,MAAAmD,EAEA,IAAA9L,GAAArT,KAAAgc,OAAA3I,UACA,WAAA9I,GAAA8I,MAGAuN,EAAAtgB,UAAAkf,cAAA,WACA,UAGAoB,EAAAtgB,UAAAO,OAAA,SAAA3B,GACA,MAAAA,GAAAiiB,cAAAnhB,OAGA4gB,EAAAtgB,UAAAwC,QAAA,WACA,MAAA9C,MAAAgc,OAAAna,MAGA+e,EAAAtgB,UAAAyR,SAAA,WACA,MAAA/R,MAAAgc,OAAA/I,OAAAzM,EAAAD,IACA,QAEAvG,KAAAgc,OAAAna,MAeAgf,EAAAvgB,UAAAC,OAAAC,OAAAogB,EAAAtgB,WACAugB,EAAAvgB,UAAAF,YAAAygB,EAEAA,EAAAvgB,UAAAqhB,YAAA,WACA,UAGAd,EAAAvgB,UAAAO,OAAA,SAAA3B,GACA,MAAAA,GAAAmiB,eAAArhB,OAOA+gB,EAAAzgB,UAAAshB,KAAA,SAAAC,EAAAhS,GACA,GAAAiS,GAAAjS,YAAA4Q,IACA3gB,SAAA+P,EAAA8R,aAAA9R,EAAA8R,aACA,IAAAG,EACAD,EAAAR,eAAAxR,OACE,IAAAA,YAAA2Q,GACFqB,EAAAV,cAAAtR,OACE,CACF7P,KAAA+hB,UAAAF,EAAAhS,EACA,QAAAR,GAAA,EAAiBA,EAAAQ,EAAA2P,gBAAuBnQ,IAAA,CACxC,GAAAqQ,GAAA7P,EAAAiQ,SAAAzQ,EACArP,MAAA4hB,KAAAC,EAAAnC,GAEA1f,KAAAgiB,SAAAH,EAAAhS,KASAkR,EAAAzgB,UAAAyhB,UAAA,SAAAF,EAAA9S,GACA,GAAAtD,GAAAsD,EAAAuQ,gBACAuC,GAAAL,eAAA/V,GACAA,EAAAsW,UAAAF,IAGAd,EAAAzgB,UAAA0hB,SAAA,SAAAH,EAAA9S,GACA,GAAAtD,GAAAsD,EAAAuQ,gBACA7T,GAAAuW,SAAAH,GACAA,EAAAJ,cAAAhW,IAGAsV,EAAAkB,QAAA,GAAAlB,GAEA/jB,EAAAkiB,WACAliB,EAAAyjB,YACAzjB,EAAAwjB,eACAxjB,EAAA6jB,gBACA7jB,EAAA4jB,mBACA5jB,EAAA2jB,oBACA3jB,EAAA0jB,mBACA1jB,EAAA+jB,kBACA/jB,EAAAmiB,oBnB0+HM,SAASliB,EAAQD,EAASH,GoBhsIhC,QAAAmjB,MAXA,GAAAxV,GAAA3N,EAAA,GACA2J,EAAA3J,EAAA,GAAA2J,MAEAia,GADA5jB,EAAA,IAAAqiB,SACAriB,EAAA,IAAA4jB,WACAD,EAAA3jB,EAAA,IAAA2jB,aACAlW,EAAAzN,EAAA,IAAAyN,kBACAwS,EAAAjgB,EAAA,IAAAigB,YACAxP,EAAAzQ,EAAA,GAAAyQ,kBAUA0S,GAAAC,aAAA,SAAAjW,EAAAF,EAAAoW,GACApW,KAAA,KACAoW,KAAA,KACA,OAAAA,IACApW,EAAAoW,EAAApW,UAEA,IAAA0B,GAAAwU,EAAAkC,YAAAlY,EAAAF,EACA0B,GAAAhB,EAAAwG,iBAAAxF,GAAA,EACA,IAAAlO,GAAA0M,EAAAwV,eACA,QAAAliB,EACA,MAAAkO,EAEA,IAAA2W,GAAA,IAAA3W,EAAA,GACAlO,GAAA,IACAkO,EAAAwU,EAAAC,aAAAjW,EAAA8V,SAAA,GAAAhW,GACAqY,IAAArQ,OAAAtG,GAEA,QAAA6D,GAAA,EAAgBA,EAAA/R,EAAI+R,IACpB7D,EAAAwU,EAAAC,aAAAjW,EAAA8V,SAAAzQ,GAAAvF,GACAqY,IAAArQ,OAAA,IAAAtG,EAGA,OADA2W,KAAArQ,OAAA,MAIAkO,EAAAkC,YAAA,SAAArS,EAAA/F,EAAAoW,GAMA,GALApW,KAAA,KACAoW,KAAA,KACA,OAAAA,IACApW,EAAAoW,EAAApW,WAEA,OAAAA,EAAA,CACA,GAAA+F,YAAAiN,GAAA,CACA,GAAA+C,GAAAhQ,EAAA8P,cACA,OAAAE,IAAAvS,EACAxD,EAAA+F,EAAAJ,WAAA,IAAAoQ,EAEA/V,EAAA+F,EAAAJ,WACQ,GAAAI,YAAA4Q,GACR,MAAA5Q,GAAAkC,UACQ,IAAAlC,YAAA2Q,IACR,OAAA3Q,EAAAmM,OACA,MAAAnM,GAAAmM,OAAAna,KAKA,GAAAmc,GAAAnO,EAAA0P,YACA,OAAAvB,aAAAxX,GACAwX,EAAAnc,KAEAgO,EAAA0P,aAAAxN,YAKAiO,EAAAoC,YAAA,SAAAvS,GAEA,OADAwS,MACAhT,EAAA,EAAaA,EAAAQ,EAAA2P,gBAAoBnQ,IACjCgT,EAAAjW,KAAAyD,EAAAiQ,SAAAzQ,GAEA,OAAAgT,IAMArC,EAAAsC,aAAA,SAAAzS,GACA,GAAA0S,KAEA,KADA1S,IAAAF,YACA,OAAAE,GACA0S,GAAA1S,GAAAiC,OAAAyQ,GACA1S,IAAAF,WAEA,OAAA4S,IAGAvC,EAAAwC,kBAAA,SAAA3S,EAAA4S,GACA,MAAAzC,GAAA0C,aAAA7S,EAAA4S,GAAA,IAGAzC,EAAA2C,iBAAA,SAAA9S,EAAAJ,GACA,MAAAuQ,GAAA0C,aAAA7S,EAAAJ,GAAA,IAGAuQ,EAAA0C,aAAA,SAAA7S,EAAAzJ,EAAAwc,GACA,GAAAC,KAEA,OADA7C,GAAA8C,cAAAjT,EAAAzJ,EAAAwc,EAAAC,GACAA,GAGA7C,EAAA8C,cAAA,SAAAjT,EAAAzJ,EAAAwc,EAAAC,GAEAD,GAAA/S,YAAA2Q,GACA3Q,EAAAmM,OAAA/I,OAAA7M,GACAyc,EAAAzW,KAAAyD,IAEE+S,GAAA/S,YAAAvF,IACFuF,EAAAJ,YAAArJ,GACAyc,EAAAzW,KAAAyD,EAIA,QAAAR,GAAA,EAAaA,EAAAQ,EAAA2P,gBAAoBnQ,IACjC2Q,EAAA8C,cAAAjT,EAAAiQ,SAAAzQ,GAAAjJ,EAAAwc,EAAAC,IAIA7C,EAAA+C,YAAA,SAAAlT,GAEA,OADAgT,IAAAhT,GACAR,EAAA,EAAgBA,EAAAQ,EAAA2P,gBAAoBnQ,IACpCwT,IAAA/Q,OAAAkO,EAAA+C,YAAAlT,EAAAiQ,SAAAzQ,IAEA,OAAAwT,IAIA7lB,EAAAgjB,SpB+uIM,SAAS/iB,EAAQD,EAASH,GqBv1IhC,QAAAyN,GAAAgS,EAAA0G,GACA1G,KAAA,KACA0G,KAAA,KACAlG,EAAA1f,KAAA4C,KAAAsc,EAAA0G,GACAhjB,KAAAyP,aAOAzP,KAAAyf,SAAA,KACAzf,KAAAmT,MAAA,KACAnT,KAAAoT,KAAA,KAGApT,KAAAijB,UAAA,KAkJA,QAAAC,GAAA5G,EAAA0G,EAAAvT,GAGA,MAFAnF,GAAAlN,KAAAkf,EAAA0G,GACAhjB,KAAAyP,YACAzP,KA7KA,GAAA8c,GAAAjgB,EAAA,IAAAigB,YACAuD,EAAAxjB,EAAA,IACAsiB,EAAAkB,EAAAlB,iBACAqB,EAAAH,EAAAG,aACAI,EAAAP,EAAAO,iBACAC,EAAAR,EAAAQ,cACAtW,EAAA1N,EAAA,IAAA0N,QAqBAD,GAAAhK,UAAAC,OAAAC,OAAAsc,EAAAxc,WACAgK,EAAAhK,UAAAF,YAAAkK,EAGAA,EAAAhK,UAAA6iB,SAAA,SAAA1X,GAEAzL,KAAAoN,UAAA3B,EAAA2B,UACApN,KAAAgN,cAAAvB,EAAAuB,cACAhN,KAAAyf,SAAA,KACAzf,KAAAmT,MAAA1H,EAAA0H,MACAnT,KAAAoT,KAAA3H,EAAA2H,MAIA9I,EAAAhK,UAAAyhB,UAAA,SAAAF,KAGAvX,EAAAhK,UAAA0hB,SAAA,SAAAH,KAIAvX,EAAAhK,UAAA8iB,SAAA,SAAA1D,GAKA,MAJA,QAAA1f,KAAAyf,WACAzf,KAAAyf,aAEAzf,KAAAyf,SAAArT,KAAAsT,GACAA,GAOApV,EAAAhK,UAAA+iB,gBAAA,WACA,OAAArjB,KAAAyf,UACAzf,KAAAyf,SAAA7F,OAIAtP,EAAAhK,UAAAgjB,aAAA,SAAAxC,GACA,GAAAM,GAAA,GAAAR,GAAAE,EAGA,OAFA9gB,MAAAojB,SAAAhC,GACAA,EAAAhU,UAAApN,KACAohB,GAGA9W,EAAAhK,UAAAijB,aAAA,SAAAC,GACA,GAAApC,GAAA,GAAAP,GAAA2C,EAGA,OAFAxjB,MAAAojB,SAAAhC,GACAA,EAAAhU,UAAApN,KACAohB,GAGA9W,EAAAhK,UAAAwf,SAAA,SAAAzQ,EAAA4D,GAEA,GADAA,KAAA,KACA,OAAAA,EACA,MAAAjT,MAAAyf,SAAAtT,QAAAkD,EAAArP,KAAAyf,SAAApQ,GAAA,IAEA,QAAAO,GAAA,EAAcA,EAAA5P,KAAAyf,SAAAtT,OAAwByD,IAAA,CACtC,GAAA8P,GAAA1f,KAAAyf,SAAA7P,EACA,IAAA8P,YAAAzM,GAAA,CACA,OAAA5D,EACA,MAAAqQ,EAEArQ,IAAA,GAIA,aAKA/E,EAAAhK,UAAAmjB,SAAA,SAAAhB,EAAApT,GACA,OAAAO,GAAA,EAAaA,EAAA5P,KAAAyf,SAAAtT,OAAwByD,IAAA,CACrC,GAAA8P,GAAA1f,KAAAyf,SAAA7P,EACA,IAAA8P,YAAAc,IACAd,EAAA1D,OAAA/I,OAAAwP,EAAA,CACA,OAAApT,EACA,MAAAqQ,EAEArQ,IAAA,GAKA,aAGA/E,EAAAhK,UAAAojB,UAAA,SAAAjB,GACA,UAAAziB,KAAAyf,SACA,QAGA,QADAkE,MACA/T,EAAA,EAAcA,EAAA5P,KAAAyf,SAAAtT,OAAwByD,IAAA,CACtC,GAAA8P,GAAA1f,KAAAyf,SAAA7P,EACA8P,aAAAc,IACAd,EAAA1D,OAAA/I,OAAAwP,GACAkB,EAAAvX,KAAAsT,GAIA,MAAAiE,IAIArZ,EAAAhK,UAAAsjB,oBAAA,SAAAC,EAAAxU,GACA,MAAArP,MAAA8f,SAAAzQ,EAAAwU,IAGAvZ,EAAAhK,UAAAwjB,qBAAA,SAAAD,GACA,UAAA7jB,KAAAyf,SACA,QAGA,QADAsE,MACAnU,EAAA,EAAcA,EAAA5P,KAAAyf,SAAAtT,OAAwByD,IAAA,CACtC,GAAA8P,GAAA1f,KAAAyf,SAAA7P,EACA8P,aAAAmE,IACAE,EAAA3X,KAAAsT,GAGA,MAAAqE,IAIAzZ,EAAAhK,UAAAkf,cAAA,WACA,cAAAxf,KAAAyf,SACA,EAEAzf,KAAAyf,SAAAtT,QAIA7B,EAAAhK,UAAA+e,kBAAA,WACA,cAAArf,KAAAmT,OAAA,OAAAnT,KAAAoT,KACA+L,EAEA,GAAA5U,GAAAvK,KAAAmT,MAAAE,WAAArT,KAAAoT,KAAAC,aAIAyJ,EAAAjO,MAAA,GAAAvE,GAQA4Y,EAAA5iB,UAAAC,OAAAC,OAAA8J,EAAAhK,WACA4iB,EAAA5iB,UAAAF,YAAA8iB,EAEAlmB,EAAAsN,qBrBy5IM,SAASrN,EAAQD,EAASH,GsB1iJhC,QAAAmnB,GAAA7X,EAAAuF,GACA,GAAAuS,KAEA,OADAA,GAAA9X,EAAA,GAAAuF,EACAuS,EAAA/d,IAAA,SAAAmJ,GAA6B,MAAAqC,KAG7B,QAAA3L,GAAAme,GASA,MAPApkB,UAAAokB,GAAA,OAAAA,IACAA,EAAAC,EAAAC,gBAEApkB,KAAAqkB,uBAAAH,EACAlkB,KAAAskB,eAAA,KACAtkB,KAAAukB,gBAAA,KAEAvkB,KAkeA,QAAAwkB,KAEA,OADAC,MACApV,EAAA,EAAgBA,EAAA,IAASA,IACzBoV,EAAApV,MAAA,KAAA0C,SAAA,IAAAgB,OAAA,GAAAD,aAEA,OAAA2R,GA/iBA,GAAAje,GAAA3J,EAAA,GAAA2J,MACAiE,EAAA5N,EAAA,GAAA4N,IACAia,EAAA7nB,EAAA,IAAA6nB,QACAC,EAAA9nB,EAAA,IACAsY,EAAAwP,EAAAxP,SACAI,EAAAoP,EAAApP,WACAP,EAAA2P,EAAA3P,cACAS,EAAAkP,EAAAlP,gBACAI,EAAA8O,EAAA9O,cACAmB,EAAA2N,EAAA3N,aACAf,EAAA0O,EAAA1O,eACAvI,EAAAiX,EAAAjX,cACAwJ,EAAAyN,EAAAzN,iBACAd,EAAAuO,EAAAvO,kBACAO,EAAAgO,EAAAhO,kBACAE,EAAA8N,EAAA9N,mBACAP,EAAAqO,EAAArO,oBACAG,EAAAkO,EAAAlO,oBACAd,EAAAgP,EAAAhP,qBACAiP,EAAA/nB,EAAA,IACA0d,EAAAqK,EAAArK,WACAC,EAAAoK,EAAApK,eACAgB,EAAAoJ,EAAApJ,cACA5N,EAAAgX,EAAAhX,iBACAD,EAAAiX,EAAAjX,eACAsN,EAAA2J,EAAA3J,gBACAI,EAAAuJ,EAAAvJ,iBACAN,EAAA6J,EAAA7J,kBACAlN,EAAA+W,EAAA/W,mBACAsN,EAAAyJ,EAAAzJ,oBACAS,EAAAgJ,EAAAhJ,8BACAtQ,EAAAzO,EAAA,IAAAyO,YAEA6Y,GADAtnB,EAAA,IAAA0N,SACA1N,EAAA,IAAAsnB,2BACAU,EAAAhoB,EAAA,IACAioB,EAAAD,EAAAC,gBACAC,EAAAF,EAAAE,gBACAC,EAAAH,EAAAG,mBACAC,EAAAJ,EAAAI,kBACAC,EAAAL,EAAAK,gBACAC,EAAAN,EAAAM,gBACAC,EAAAP,EAAAO,oBACAC,EAAAR,EAAAQ,mBACAC,EAAAT,EAAAS,gBAGAC,EAAA,uCAIAC,GAAAD,GAEAE,EAAA,EAGAC,EAAAH,CAgCAxf,GAAAzF,UAAAqlB,mBAAA,SAAAC,EAAAC,GACA,GAAAC,GAAAN,EAAApf,MAAAwf,EACA,IAAAE,EAAA,EACA,QAEA,IAAAC,GAAAP,EAAApf,MAAAyf,EACA,OAAAE,IAAAD,GAGA/f,EAAAzF,UAAA0F,YAAA,SAAA6K,GACA7Q,KAAAgmB,MAAAnV,GACA7Q,KAAAimB,eACAjmB,KAAAkmB,WACA,IAAAzgB,GAAAzF,KAAAmmB,SACAnmB,MAAAomB,WAAA3gB,GACAzF,KAAAqmB,UAAA5gB,GACAzF,KAAAsmB,UAAA7gB,EACA,IAAA8gB,GAAAvmB,KAAAwmB,SAAA/gB,EAWA,OAVAzF,MAAAymB,UAAAhhB,EAAA8gB,GACAvmB,KAAA0mB,cAAAjhB,GACAzF,KAAA2mB,iBAAAlhB,GACAzF,KAAA4mB,wBAAAnhB,GACAzF,KAAA6mB,UAAAphB,GACAzF,KAAAqkB,uBAAAyC,+BAAArhB,EAAAmF,cAAA8Z,EAAAqC,SACA/mB,KAAA8mB,8BAAArhB,GAEAzF,KAAA6mB,UAAAphB,IAEAA,GAGAM,EAAAzF,UAAA0lB,MAAA,SAAAnV,GACA,GAAAmW,GAAA,SAAA1pB,GACA,GAAA+b,GAAA/b,EAAAgU,WAAA,EACA,OAAA+H,GAAA,EAAAA,EAAA,MAEA4N,EAAApW,EAAAqW,MAAA,IAAAhhB,IAAA8gB,EAEAC,GAAA,GAAApW,EAAAS,WAAA,GACAtR,KAAA6Q,KAAAoW,EACAjnB,KAAAmnB,IAAA,GAGAphB,EAAAzF,UAAA2lB,aAAA,WACA,GAAAmB,GAAApnB,KAAAqnB,SACA,IAAAD,IAAA3B,EACA,+CAAA2B,EAAA,cAAA3B,EAAA,MAIA1f,EAAAzF,UAAA4lB,UAAA,WACA,GAAAoB,GAAAtnB,KAAAunB,UACA,IAAA/B,EAAA3T,QAAAyV,GAAA,EACA,KACA5B,EAEA1lB,MAAAsnB,QAGAvhB,EAAAzF,UAAA6lB,QAAA,WACA,GAAAvb,GAAA5K,KAAAqnB,UACAxc,EAAA7K,KAAAqnB,SACA,WAAA5c,GAAAG,EAAAC,IAGA9E,EAAAzF,UAAA8lB,WAAA,SAAA3gB,GAKA,OAJAmK,GAAA4X,EAAAtb,EACAub,KACAC,KACAC,EAAA3nB,KAAAqnB,UACAhY,EAAA,EAAgBA,EAAAsY,EAAWtY,IAAA,CAC3B,GAAAuY,GAAA5nB,KAAAqnB,SAEA,IAAAO,IAAAzS,EAAAhH,aAAA,CAIA,GAAAsB,GAAAzP,KAAAqnB,SACA,SAAA5X,IACAA,KAEA,IAAAjE,GAAAxL,KAAA6nB,aAAAD,EAAAnY,EACA,IAAAmY,IAAAzS,EAAA8B,SAAA,CACA,GAAA6Q,GAAA9nB,KAAAqnB,SACAI,GAAArb,MAAAZ,EAAAsc,QACS,IAAAtc,YAAAiK,GAAA,CACT,GAAAsS,GAAA/nB,KAAAqnB,SACAK,GAAAtb,MAAAZ,EAAAuc,IAEAtiB,EAAAuG,SAAAR,OAfA/F,GAAAuG,SAAA,MAmBA,IAAA4D,EAAA,EAAaA,EAAA6X,EAAAtb,OAA+ByD,IAC5C4X,EAAAC,EAAA7X,GACA4X,EAAA,GAAAhR,cAAA/Q,EAAAqF,OAAA0c,EAAA,GAGA,KAAA5X,EAAA,EAAaA,EAAA8X,EAAAvb,OAA0ByD,IACvC4X,EAAAE,EAAA9X,GACA4X,EAAA,GAAA9R,SAAAjQ,EAAAqF,OAAA0c,EAAA,GAGA,IAAAQ,GAAAhoB,KAAAqnB,SACA,KAAAzX,EAAA,EAAaA,EAAAoY,EAAsBpY,IACnC1D,EAAAlM,KAAAqnB,UACA5hB,EAAAqF,OAAAoB,GAAAgJ,WAAA,CAGA,IAAA+S,GAAAjoB,KAAAqnB,SACA,KAAAzX,EAAA,EAAaA,EAAAqY,EAAuBrY,IACpC1D,EAAAlM,KAAAqnB,UACA5hB,EAAAqF,OAAAoB,GAAAiK,kBAAA,GAIApQ,EAAAzF,UAAA+lB,UAAA,SAAA5gB,GACA,GAAA4J,GACA6Y,EAAAloB,KAAAqnB,SAKA,KAJA5hB,EAAAmF,cAAA8Z,EAAAyD,QACA1iB,EAAAyF,gBAAA8Y,EAAAkE,EAAA,IAEAziB,EAAAsF,iBAAAiZ,EAAAkE,EAAA,GACA7Y,EAAA,EAAaA,EAAA6Y,EAAU7Y,IAAA,CACvB,GAAA7D,GAAAxL,KAAAqnB,UACAtR,EAAAtQ,EAAAqF,OAAAU,EAEA,IADA/F,EAAAsF,iBAAAsE,GAAA0G,EACAtQ,EAAAmF,cAAA8Z,EAAAyD,MAAA,CACA,GAAAC,GAAApoB,KAAAqnB,SACA,SAAAe,IACAA,EAAA5hB,EAAAD,KAEAd,EAAAyF,gBAAAmE,GAAA+Y,GAIA,IADA3iB,EAAAuF,gBAAAgZ,EAAAkE,EAAA,GACA7Y,EAAA,EAAaA,EAAA5J,EAAAqF,OAAAqB,OAAqBkD,IAAA,CAClC,GAAApD,GAAAxG,EAAAqF,OAAAuE,EACApD,aAAAyB,KAGAjI,EAAAuF,gBAAAiB,EAAAwD,WAAAxD,EACAxG,EAAAsF,iBAAAkB,EAAAwD,WAAAX,UAAA7C,KAIAlG,EAAAzF,UAAAgmB,UAAA,SAAA7gB,GAEA,OADA4iB,GAAAroB,KAAAqnB,UACAhY,EAAA,EAAiBA,EAAAgZ,EAAUhZ,IAAA,CAC3B,GAAA7D,GAAAxL,KAAAqnB,SACA5hB,GAAA2F,iBAAAgB,KAAA3G,EAAAqF,OAAAU,MAIAzF,EAAAzF,UAAAkmB,SAAA,SAAA/gB,GAGA,OAFA8gB,MACAlpB,EAAA2C,KAAAqnB,UACAhY,EAAA,EAAiBA,EAAAhS,EAAKgS,IAAA,CACtB,GAAAiZ,GAAA,GAAAhd,EACAib,GAAAna,KAAAkc,EACA,IAAAvU,GAAA/T,KAAAqnB,UACAkB,EAAAvoB,KAAAqnB,SACA,KAAAkB,GACAD,EAAAjb,UAEA,QAAAuC,GAAA,EAAqBA,EAAAmE,EAAKnE,IAAA,CAC1B,GAAA4Y,GAAAxoB,KAAAqnB,UACAoB,EAAAzoB,KAAAqnB,SACAiB,GAAAtY,SAAAwY,EAAAC,IAGA,MAAAlC,IAGAxgB,EAAAzF,UAAAmmB,UAAA,SAAAhhB,EAAA8gB,GACA,GAAAlX,GAAAO,EAAA3D,EAAAsL,EAAA3I,EACA8Z,EAAA1oB,KAAAqnB,SACA,KAAAhY,EAAA,EAAaA,EAAAqZ,EAAUrZ,IAAA,CACvB,GAAAsZ,GAAA3oB,KAAAqnB,UACAuB,EAAA5oB,KAAAqnB,UACA5E,EAAAziB,KAAAqnB,UACAwB,EAAA7oB,KAAAqnB,UACAyB,EAAA9oB,KAAAqnB,UACA0B,EAAA/oB,KAAAqnB,SACA9P,GAAAvX,KAAAgpB,YAAAvjB,EAAAgd,EAAAkG,EAAAC,EAAAC,EAAAC,EAAAC,EAAAxC,EACA,IAAA0C,GAAAxjB,EAAAqF,OAAA6d,EACAM,GAAA3R,cAAAC,GAGA,IAAAlI,EAAA,EAAaA,EAAA5J,EAAAqF,OAAAqB,OAAqBkD,IAElC,IADApD,EAAAxG,EAAAqF,OAAAuE,GACAO,EAAA,EAAiBA,EAAA3D,EAAAiB,YAAAf,OAA4ByD,IAAA,CAC7C,GAAAC,GAAA5D,EAAAiB,YAAA0C,EACA,IAAAC,YAAAlC,GAAA,CAGA,GAAAqN,KACAvV,GAAAsF,iBAAA8E,EAAAjB,OAAAa,WAAA0G,kBACA,IAAAtG,EAAAgI,aACAmD,EAAAnL,EAAAjB,OAAAa,WAIA8H,EAAA,GAAAwD,GAAAlL,EAAA1C,YAAA6N,GACAvV,EAAAuF,gBAAA6E,EAAAjB,OAAAa,WAAA6H,cAAAC,IAIA,IAAAlI,EAAA,EAAaA,EAAA5J,EAAAqF,OAAAqB,OAAqBkD,IAAA,CAElC,GADApD,EAAAxG,EAAAqF,OAAAuE,GACApD,YAAAwJ,GAAA,CAEA,UAAAxJ,EAAAyJ,SACA,mBAIA,WAAAzJ,EAAAyJ,SAAAK,WACA,mBAEA9J,GAAAyJ,SAAAK,WAAA9J,EAEA,GAAAA,YAAAmK,GACA,IAAAxG,EAAA,EAAqBA,EAAA3D,EAAAiB,YAAAf,OAA4ByD,IACjDhB,EAAA3C,EAAAiB,YAAA0C,GAAAhB,OACAA,YAAA0H,KACA1H,EAAA4H,cAAAvK,OAGS,IAAAA,YAAA0K,GACT,IAAA/G,EAAA,EAAqBA,EAAA3D,EAAAiB,YAAAf,OAA4ByD,IACjDhB,EAAA3C,EAAAiB,YAAA0C,GAAAhB,OACAA,YAAAiI,KACAjI,EAAA4H,cAAAvK,KAOAlG,EAAAzF,UAAAomB,cAAA,SAAAjhB,GAEA,OADAyjB,GAAAlpB,KAAAqnB,UACAhY,EAAA,EAAiBA,EAAA6Z,EAAc7Z,IAAA,CAC/B,GAAA7D,GAAAxL,KAAAqnB,UACA8B,EAAA1jB,EAAAqF,OAAAU,EACA/F,GAAAQ,gBAAAmG,KAAA+c,GACAA,EAAA5c,SAAA8C,IAIAtJ,EAAAzF,UAAAqmB,iBAAA,SAAAlhB,GACA,GAAAA,EAAAmF,cAAA8Z,EAAAyD,MAAA,CACA,GAAA9Z,GAAArO,KAAAqnB,SACA5hB,GAAA0F,aAAA6Y,EAAA3V,EAAA,KACA,QAAAgB,GAAA,EAAqBA,EAAAhB,EAASgB,IAAA,CAC9B,GAAA+Z,GAAAppB,KAAAqnB,UACAgC,EAAArpB,KAAAqnB,SACA,SAAAgC,IACAA,KAEA,IAAAC,GAAAtpB,KAAAqnB,SACA,SAAAiC,IACAA,KAEA,IAAAC,GAAAvpB,KAAAwpB,mBAAAJ,EAAAC,EAAAC,EACA7jB,GAAA0F,aAAAkE,GAAAka,KAKAxjB,EAAAzF,UAAAwmB,8BAAA,SAAArhB,GACA,GAAA4J,GACAhB,EAAA5I,EAAAsF,iBAAAoB,MACA,KAAAkD,EAAA,EAAYA,EAAAhB,EAASgB,IACrB5J,EAAAyF,gBAAAmE,GAAA5J,EAAAoF,aAAAwE,EAAA,CAEA,KAAAA,EAAA,EAAYA,EAAAhB,EAASgB,IACrBrP,KAAAypB,6BAAAhkB,EAAA4J,IAIAtJ,EAAAzF,UAAAmpB,6BAAA,SAAAhkB,EAAAikB,GACA,GAAAra,GAAApD,EACA0d,EAAA,GAAAhU,EACAgU,GAAAla,UAAAia,EACAjkB,EAAAuG,SAAA2d,EAEA,IAAAC,GAAA,GAAA/T,EACA+T,GAAAna,UAAAia,EACAjkB,EAAAuG,SAAA4d,GAEAD,EAAAjU,SAAAkU,EACAnkB,EAAA6G,oBAAAqd,GAEAC,EAAA7T,WAAA4T,CAEA,IAAAE,GAAA,KACAnU,EAAA,IAEA,IAAAjQ,EAAAsF,iBAAA2e,GAAAvT,iBAAA,CAGA,IADAT,EAAA,KACArG,EAAA,EAAgBA,EAAA5J,EAAAqF,OAAAqB,OAAqBkD,IAErC,GADApD,EAAAxG,EAAAqF,OAAAuE,GACArP,KAAA8pB,mBAAA7d,EAAAyd,GAAA,CACAhU,EAAAzJ,EACA4d,EAAA5d,EAAAuK,cAAAtJ,YAAA,EACA,OAGA,UAAA2c,EACA,gFAGAnU,GAAAjQ,EAAAuF,gBAAA0e,EAKA,KAAAra,EAAA,EAAYA,EAAA5J,EAAAqF,OAAAqB,OAAqBkD,IAAA,CACjCpD,EAAAxG,EAAAqF,OAAAuE,EACA,QAAAO,GAAA,EAAoBA,EAAA3D,EAAAiB,YAAAf,OAA4ByD,IAAA,CAChD,GAAAjB,GAAA1C,EAAAiB,YAAA0C,EACAjB,KAAAkb,GAGAlb,EAAAC,SAAA8G,IACA/G,EAAAC,OAAAgb,IASA,IAFA,GAAA7e,GAAAtF,EAAAsF,iBAAA2e,GACArb,EAAAtD,EAAAmC,YAAAf,OACAkC,EAAA,GACAsb,EAAArS,cAAAvM,EAAAmC,YAAAmB,EAAA,IACAtD,EAAAmC,YAAAnC,EAAAmC,YAAA+L,SAGAxT,GAAAsF,iBAAA2e,GAAApS,cAAA,GAAAyD,GAAA4O,IACAC,EAAAtS,cAAA,GAAAyD,GAAArF,GAEA,IAAAqU,GAAA,GAAAxU,EACA9P,GAAAuG,SAAA+d,GACAA,EAAAzS,cAAA,GAAAkD,GAAAoP,EAAAnkB,EAAAyF,gBAAAwe,KACAC,EAAArS,cAAA,GAAAyD,GAAAgP,KAGAhkB,EAAAzF,UAAAwpB,mBAAA,SAAA7d,EAAAyd,GACA,GAAAzd,EAAAwD,YAAAia,EACA,WAEA,MAAAzd,YAAA4K,IACA,WAEA,IAAAmT,GAAA/d,EAAAiB,YAAAjB,EAAAiB,YAAAf,OAAA,GAAAyC,MACA,OAAAob,aAAAhT,IAGAgT,EAAA1U,wBACA0U,EAAA9c,YAAA,GAAA0B,iBAAAlB,GACAzB,EAJA,MAiBAlG,EAAAzF,UAAAsmB,wBAAA,SAAAnhB,GACA,OAAA4J,GAAA,EAAaA,EAAA5J,EAAAqF,OAAAqB,OAAqBkD,IAAA,CAClC,GAAApD,GAAAxG,EAAAqF,OAAAuE,EACA,IAAApD,YAAA4K,IAOApR,EAAAsF,iBAAAkB,EAAAwD,WAAA0G,iBAAA,CACA,GAAA6T,GAAA/d,EAAAiB,YAAAjB,EAAAiB,YAAAf,OAAA,GAAAyC,MACAob,aAAAhT,IACAgT,EAAA1U,wBACA0U,EAAA9c,YAAA,GAAA0B,iBAAAlB,KACAzB,EAAA8K,wBAAA,MAOAhR,EAAAzF,UAAAumB,UAAA,SAAAphB,GACA,GAAAzF,KAAAqkB,uBAAAwC,UAIA,OAAAxX,GAAA,EAAaA,EAAA5J,EAAAqF,OAAAqB,OAAqBkD,IAAA,CAClC,GAAApD,GAAAxG,EAAAqF,OAAAuE,EACA,WAAApD,EAIA,GADAjM,KAAAiqB,eAAAhe,EAAAqJ,wBAAArJ,EAAAiB,YAAAf,QAAA,GACAF,YAAAqK,GACAtW,KAAAiqB,eAAA,OAAAhe,EAAAuK,mBACS,IAAAvK,YAAA4K,GAGT,GAFA7W,KAAAiqB,eAAA,OAAAhe,EAAAuK,eACAxW,KAAAiqB,eAAA,IAAAhe,EAAAiB,YAAAf,QACAF,EAAAiB,YAAA,GAAA0B,iBAAA6H,GACAzW,KAAAiqB,eAAAhe,EAAAiB,YAAA,GAAA0B,iBAAAoI,IACAhX,KAAAiqB,gBAAAhe,EAAAiJ,eACa,MAAAjJ,EAAAiB,YAAA,GAAA0B,iBAAAoI,IAIb,mBAHAhX,MAAAiqB,eAAAhe,EAAAiB,YAAA,GAAA0B,iBAAA6H,IACAzW,KAAAiqB,eAAAhe,EAAAiJ,eAISjJ,aAAA0K,IACT3W,KAAAiqB,eAAA,IAAAhe,EAAAiB,YAAAf,QACAnM,KAAAiqB,eAAAhe,EAAAiB,YAAA,GAAA0B,iBAAAiI,KACS5K,YAAA+K,GACThX,KAAAiqB,eAAA,OAAAhe,EAAAuK,eACSvK,YAAAgK,GACTjW,KAAAiqB,eAAA,OAAAhe,EAAA6C,WACS7C,YAAAwJ,GACTzV,KAAAiqB,eAAA,OAAAhe,EAAAyJ,UACSzJ,YAAA4J,GACT7V,KAAAiqB,eAAA,OAAAhe,EAAA8J,YACS9J,YAAA+I,GACThV,KAAAiqB,eAAAhe,EAAAiB,YAAAf,QAAA,GAAAF,EAAAM,UAAA,GAEAvM,KAAAiqB,eAAAhe,EAAAiB,YAAAf,QAAA,GAAAF,YAAAyB,MAKA3H,EAAAzF,UAAA2pB,eAAA,SAAAC,EAAAC,GACA,IAAAD,EAIA,KAHApqB,UAAAqqB,GAAA,OAAAA,IACAA,EAAA,gBAEA,GAIApkB,EAAAzF,UAAA+mB,QAAA,WACA,MAAArnB,MAAA6Q,KAAA7Q,KAAAmnB,QAGAphB,EAAAzF,UAAA8pB,UAAA,WACA,GAAAC,GAAArqB,KAAAqnB,UACAiD,EAAAtqB,KAAAqnB,SACA,OAAAgD,GAAAC,GAAA,IAGAvkB,EAAAzF,UAAAiqB,SAAA,WACA,GAAAF,GAAArqB,KAAAoqB,YACAE,EAAAtqB,KAAAoqB,WACA,mBAAAC,EAAAC,GAAA,GAWA,IAAAE,GAAAhG,GAEAze,GAAAzF,UAAAinB,SAAA,WAEA,OADAkD,MACApb,EAAA,EAAaA,GAAA,EAAKA,IAAA,CAClB,GAAAqb,GAAA1qB,KAAAqnB,SAEAoD,GAAA,EAAApb,EAAA,OAAAqb,EACAD,EAAA,EAAApb,GAAAqb,GAAA,MAEA,MAAAF,GAAAC,EAAA,IAAAD,EAAAC,EAAA,IACAD,EAAAC,EAAA,IAAAD,EAAAC,EAAA,QACAD,EAAAC,EAAA,IAAAD,EAAAC,EAAA,QACAD,EAAAC,EAAA,IAAAD,EAAAC,EAAA,QACAD,EAAAC,EAAA,IAAAD,EAAAC,EAAA,QACAD,EAAAC,EAAA,KAAAD,EAAAC,EAAA,KACAD,EAAAC,EAAA,KAAAD,EAAAC,EAAA,KACAD,EAAAC,EAAA,KAAAD,EAAAC,EAAA,MAGA1kB,EAAAzF,UAAA0oB,YAAA,SAAAvjB,EAAAwN,EAAA0V,EAAAC,EAAAC,EAAAC,EAAAC,EAAAxC,GACA,GAAA3X,GAAAnJ,EAAAqF,OAAA8d,EACA,QAAA3V,GACA,IAAAsH,GAAA3N,QACA,UAAAmO,GAAAnM,EACA,KAAA2L,GAAAW,MACA,WAAA6N,EAAA,GAAA9N,GAAArM,EAAApI,EAAAD,IAAAuiB,GAAA,GAAA7N,GAAArM,EAAAia,EAAAC,EACA,KAAAvO,GAAAO,KACA,UAAAnN,GAAAlI,EAAAqF,OAAA+d,GAAAC,EAAAC,EAAAna,EACA,KAAA2L,GAAAa,UACA,UAAAD,GAAAvM,EAAAia,EAAAC,EAAA,IAAAC,EACA,KAAAxO,GAAAsB,WACA,UAAAD,GAAAhN,EAAAia,EACA,KAAAtO,GAAAK,KACA,WAAAmO,EAAA,GAAAvO,GAAA5L,EAAApI,EAAAD,KAAA,GAAAiU,GAAA5L,EAAAia,EACA,KAAAtO,GAAAgB,OACA,UAAAF,GAAAzM,EAAAia,EAAAC,EAAA,IAAAC,EACA,KAAAxO,GAAAkB,IACA,UAAAD,GAAA5M,EAAA2X,EAAAsC,GACA,KAAAtO,GAAAmB,QACA,UAAA9N,GAAAgB,EAAA2X,EAAAsC,GACA,KAAAtO,GAAAoB,SACA,UAAA9N,GAAAe,EACA,SACA,uCAAAqE,EAAA,mBAIAlN,EAAAzF,UAAAunB,aAAA,SAAA5U,EAAAxD,GACA,UAAAzP,KAAAskB,eAAA,CACA,GAAAqG,KACAA,GAAAxV,EAAAhH,cAAA,KACAwc,EAAAxV,EAAAK,OAAA,WAAyC,UAAAD,IACzCoV,EAAAxV,EAAAe,YAAA,WAA8C,UAAAD,IAC9C0U,EAAAxV,EAAAS,aAAA,WAA+C,UAAAD,IAC/CgV,EAAAxV,EAAAoB,kBAAA,WAAoD,UAAAD,IACpDqU,EAAAxV,EAAAuB,kBAAA,WAAoD,UAAAD,IACpDkU,EAAAxV,EAAAgC,aAAA,WAA+C,UAAAD,IAC/CyT,EAAAxV,EAAAa,WAAA,WAA6C,UAAAtI,IAC7Cid,EAAAxV,EAAAW,WAAA,WAA6C,UAAAD,IAC7C8U,EAAAxV,EAAAyB,gBAAA,WAAkD,UAAAD,IAClDgU,EAAAxV,EAAA2B,iBAAA,WAAmD,UAAAD,IACnD8T,EAAAxV,EAAAkB,gBAAA,WAAkD,UAAAD,IAClDuU,EAAAxV,EAAA8B,UAAA,WAA4C,UAAAD,IAC5ChX,KAAAskB,eAAAqG,EAEA,GAAA1X,EAAAjT,KAAAskB,eAAAnY,QAAA,OAAAnM,KAAAskB,eAAArR,GACA,iCAAAA,EAAA,gBAEA,IAAAzH,GAAAxL,KAAAskB,eAAArR,IACA,WAAAzH,EAEA,MADAA,GAAAiE,YACAjE,GAKAzF,EAAAzF,UAAAkpB,mBAAA,SAAAvW,EAAAoW,EAAAC,GACA,UAAAtpB,KAAAukB,gBAAA;AACA,GAAAqG,KACAA,GAAA9F,EAAA+F,SAAA,SAAAxB,EAAAC,GAA8D,UAAAtE,GAAAqE,IAC9DuB,EAAA9F,EAAAgG,QAAA,SAAAzB,EAAAC,GAA6D,UAAArE,GAAAoE,EAAAC,IAC7DsB,EAAA9F,EAAAiG,MAAA,SAAA1B,EAAAC,GAA2D,UAAAhE,GAAA+D,IAC3DuB,EAAA9F,EAAAkG,MAAA,SAAA3B,EAAAC,GAA2D,MAAApE,GAAA+F,UAC3DL,EAAA9F,EAAAoG,UAAA,SAAA7B,EAAAC,GAA+D,MAAAjE,GAAA4F,UAC/DL,EAAA9F,EAAAqG,WAAA,SAAA9B,EAAAC,GAAgE,UAAAlE,GAAAiE,IAChEuB,EAAA9F,EAAAsG,MAAA,SAAA/B,EAAAC,GAA2D,MAAAvE,GAAAkG,UAC3DL,EAAA9F,EAAAuG,MAAA,SAAAhC,EAAAC,GAA2D,UAAAnE,GAAAkE,IAC3DrpB,KAAAukB,gBAAAqG,EAEA,GAAA3X,EAAAjT,KAAAukB,gBAAApY,QAAA,OAAAnM,KAAAukB,gBAAAtR,GACA,wCAAAA,EAAA,gBAEA,OAAAjT,MAAAukB,gBAAAtR,GAAAoW,EAAAC,IAKAtsB,EAAA+I,mBtBsoJM,SAAS9I,EAAQD,GuBvxKvB,QAAA0nB,MAIAA,EAAAyD,MAAA,EACAzD,EAAAqC,OAAA,EAEA/pB,EAAA0nB,WvB+zKM,SAASznB,EAAQD,GwBz0KvB,QAAAmnB,GAAAhB,GAQA,MAPArjB,UAAAqjB,IACAA,EAAA,MAEAnjB,KAAA8L,UAAA,EACA9L,KAAA6mB,UAAA,OAAA1D,KAAA0D,UACA7mB,KAAA8mB,8BAAA,OAAA3D,KAAA2D,8BAEA9mB,KAGAmkB,EAAAC,eAAA,GAAAD,GACAA,EAAAC,eAAAtY,UAAA,EAOA9O,EAAAmnB,6BxB62KM,SAASlnB,EAAQD,GyB93KvB,QAAA8nB,MAYA,QAAAwG,GAAAC,GAGA,MAFAvrB,MAAAopB,WAAAmC,EACAvrB,KAAAwrB,qBAAA,EACAxrB,KAkBA,QAAA+kB,KAEA,MADAuG,GAAAluB,KAAA4C,KAAA8kB,EAAAsG,MACAprB,KAmBA,QAAAmlB,GAAAlS,GAGA,MAFAqY,GAAAluB,KAAA4C,KAAA8kB,EAAAuG,MACArrB,KAAAiT,OACAjT,KA+BA,QAAAolB,GAAAqG,GAGA,MAFAH,GAAAluB,KAAA4C,KAAA8kB,EAAAqG,WACAnrB,KAAAyrB,OACAzrB,KAmCA,QAAAqlB,KAEA,MADAiG,GAAAluB,KAAA4C,KAAA8kB,EAAAoG,UACAlrB,KAqBA,QAAAklB,KAEA,MADAoG,GAAAluB,KAAA4C,KAAA8kB,EAAAkG,MACAhrB,KAoBA,QAAAslB,GAAAmG,GAGA,MAFAH,GAAAluB,KAAA4C,KAAA8kB,EAAAiG,MACA/qB,KAAAyrB,OACAzrB,KAgDA,QAAAilB,GAAAxV,EAAA6L,GAKA,MAJAgQ,GAAAluB,KAAA4C,KAAA8kB,EAAAgG,QACA9qB,KAAAyP,YACAzP,KAAAsb,cACAtb,KAAAwrB,qBAAA,EACAxrB,KA8BA,QAAAglB,GAAA9R,GAGA,MAFAoY,GAAAluB,KAAA4C,KAAA8kB,EAAA+F,SACA7qB,KAAAkT,UACAlT,KAkDA,QAAA0rB,GAAAC,EAAAJ,GAKA,MAJAD,GAAAluB,KAAA4C,KAAAurB,EAAAnC,YACAppB,KAAA2rB,SACA3rB,KAAAurB,SACAvrB,KAAAwrB,qBAAA,EACAxrB,KAxTA8kB,EAAA+F,QAAA,EACA/F,EAAAgG,OAAA,EACAhG,EAAAiG,KAAA,EACAjG,EAAAkG,KAAA,EACAlG,EAAAoG,SAAA,EACApG,EAAAqG,UAAA,EACArG,EAAAsG,KAAA,EACAtG,EAAAuG,KAAA,EAQAC,EAAAhrB,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAopB,YAGAkC,EAAAhrB,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAeA0S,EAAAzkB,UAAAC,OAAAC,OAAA8qB,EAAAhrB,WACAykB,EAAAzkB,UAAAF,YAAA2kB,EAGAA,EAAAkG,SAAA,GAAAlG,GAEAA,EAAAzkB,UAAAsrB,QAAA,SAAAntB,GACAA,EAAAotB,QAGA9G,EAAAzkB,UAAAyR,SAAA,WACA,cAWAoT,EAAA7kB,UAAAC,OAAAC,OAAA8qB,EAAAhrB,WACA6kB,EAAA7kB,UAAAF,YAAA+kB,EAEAA,EAAA7kB,UAAAsrB,QAAA,SAAAntB,GACAA,EAAAwU,KAAAjT,KAAAiT,MAGAkS,EAAA7kB,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAopB,WAAAppB,KAAAiT,MAIAkS,EAAA7kB,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEKA,YAAA8S,IAGLnlB,KAAAiT,OAAAZ,EAAAY,MAIAkS,EAAA7kB,UAAAyR,SAAA,WACA,cAAA/R,KAAAiT,KAAA,KAWAmS,EAAA9kB,UAAAC,OAAAC,OAAA8qB,EAAAhrB,WACA8kB,EAAA9kB,UAAAF,YAAAglB,EAIAA,EAAA9kB,UAAAsrB,QAAA,SAAAntB,GACAA,EAAAqtB,SAAA9rB,KAAAyrB,OAGArG,EAAA9kB,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAopB,WAAAppB,KAAAyrB,MAGArG,EAAA9kB,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEKA,YAAA+S,IAGLplB,KAAAyrB,OAAApZ,EAAAoZ,MAIArG,EAAA9kB,UAAAyR,SAAA,WACA,kBAAA/R,KAAAyrB,KAAA,KAaApG,EAAA/kB,UAAAC,OAAAC,OAAA8qB,EAAAhrB,WACA+kB,EAAA/kB,UAAAF,YAAAilB,EAEAA,EAAA4F,SAAA,GAAA5F,GAGAA,EAAA/kB,UAAAsrB,QAAA,SAAAntB,GACAA,EAAAstB,WAGA1G,EAAA/kB,UAAAyR,SAAA,WACA,iBAYAmT,EAAA5kB,UAAAC,OAAAC,OAAA8qB,EAAAhrB,WACA4kB,EAAA5kB,UAAAF,YAAA8kB,EAEAA,EAAA+F,SAAA,GAAA/F,GAGAA,EAAA5kB,UAAAsrB,QAAA,SAAAntB,GACAA,EAAAutB,QAGA9G,EAAA5kB,UAAAyR,SAAA,WACA,cAYAuT,EAAAhlB,UAAAC,OAAAC,OAAA8qB,EAAAhrB,WACAglB,EAAAhlB,UAAAF,YAAAklB,EAIAA,EAAAhlB,UAAAsrB,QAAA,SAAAntB,GACAA,EAAAgtB,KAAAzrB,KAAAyrB,OAGAnG,EAAAhlB,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAopB,WAAAppB,KAAAyrB,MAGAnG,EAAAhlB,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEKA,YAAAiT,IAGLtlB,KAAAyrB,OAAApZ,EAAAoZ,MAIAnG,EAAAhlB,UAAAyR,SAAA,WACA,cAAA/R,KAAAyrB,KAAA,KA6BAxG,EAAA3kB,UAAAC,OAAAC,OAAA8qB,EAAAhrB,WACA2kB,EAAA3kB,UAAAF,YAAA6kB,EAIAA,EAAA3kB,UAAAsrB,QAAA,SAAAntB,GACAA,EAAA8sB,OAAA,KAAAvrB,KAAAyP,UAAAzP,KAAAsb,cAGA2J,EAAA3kB,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAopB,WAAAppB,KAAAyP,UAAAzP,KAAAsb,aAGA2J,EAAA3kB,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEKA,YAAA4S,KAGLjlB,KAAAyP,YAAA4C,EAAA5C,WAAAzP,KAAAsb,cAAAjJ,EAAAiJ,cAcA0J,EAAA1kB,UAAAC,OAAAC,OAAA8qB,EAAAhrB,WACA0kB,EAAA1kB,UAAAF,YAAA4kB,EAIAA,EAAA1kB,UAAAsrB,QAAA,SAAAntB,GACAA,EAAAwtB,SAAAjsB,KAAAkT,SAGA8R,EAAA1kB,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAopB,WAAAppB,KAAAkT,SAGA8R,EAAA1kB,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEKA,YAAA2S,IAGLhlB,KAAAkT,UAAAb,EAAAa,SAIA8R,EAAA1kB,UAAAyR,SAAA,WACA,iBAAA/R,KAAAkT,QAAA,KA+BAwY,EAAAprB,UAAAC,OAAAC,OAAA8qB,EAAAhrB,WACAorB,EAAAprB,UAAAF,YAAAsrB,EAIAA,EAAAprB,UAAAsrB,QAAA,SAAAntB,GAEAuB,KAAAurB,OAAAK,QAAAntB,IAGAitB,EAAAprB,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAopB,WAAAppB,KAAA2rB,OAAA3rB,KAAAurB,QAGAG,EAAAprB,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEKA,YAAAqZ,KAGL1rB,KAAA2rB,SAAAtZ,EAAAsZ,QAAA3rB,KAAAurB,SAAAlZ,EAAAkZ,SAKAvuB,EAAA8nB,kBACA9nB,EAAA+nB,kBACA/nB,EAAAgoB,qBACAhoB,EAAAioB,oBACAjoB,EAAA0uB,2BACA1uB,EAAAkoB,kBACAloB,EAAAmoB,kBACAnoB,EAAAooB,sBACApoB,EAAAqoB,qBACAroB,EAAAsoB,mBzBm6KM,SAASroB,EAAQD,EAASH,G0BpuLhC,QAAAqvB,GAAAC,GACAA,EAAA/lB,SACA+lB,EAAA7Y,KAAA,EACA6Y,EAAA5Y,UACA4Y,EAAAC,SAAA,KAGA,QAAAC,KAEA,MADAH,GAAAlsB,MACAA,KAOA,QAAA0F,GAAAwa,EAAAza,EAAA6mB,EAAAC,GAmBA,MAlBAC,GAAApvB,KAAA4C,KAAAyF,EAAA8mB,GACAvsB,KAAAssB,gBACAtsB,KAAAkgB,QAKAlgB,KAAAysB,cAEAzsB,KAAAsT,KAAA,EAGAtT,KAAAuT,OAAA,EACAvT,KAAAyrB,KAAAlmB,EAAAmnB,aAGA1sB,KAAA2sB,WAAA,GAAAN,GAEArsB,KAlDA,GAAAwG,GAAA3J,EAAA,GAAA2J,MACAjB,EAAA1I,EAAA,IAAA0I,MACAkF,EAAA5N,EAAA,GAAA4N,IACA+hB,EAAA3vB,EAAA,IAAA2vB,aACAI,EAAA/vB,EAAA,IAAA+vB,SAEAC,GADAhwB,EAAA,IAAAiwB,aACAjwB,EAAA,IAAAgwB,qBACA7e,EAAAnR,EAAA,IAAAmR,kBACAC,EAAApR,EAAA,IAAAoR,2BACAP,EAAA7Q,EAAA,IAAA6Q,cACAkH,EAAA/X,EAAA,IAAA+X,eACA2F,EAAA1d,EAAA,IAAA0d,WACAwS,EAAAlwB,EAAA,IAAAkwB,oBACAC,EAAAnwB,EAAA,IAAAmwB,yBAcAX,GAAA/rB,UAAA0lB,MAAA,WACAkG,EAAAlsB,OAyBA0F,EAAApF,UAAAC,OAAAC,OAAAgsB,EAAAlsB,WACAoF,EAAApF,UAAAF,YAAAsF,EAEAA,EAAAunB,OAAA,EACAvnB,EAAAwnB,WAAA,EAEAxnB,EAAAynB,aAAA,EACAznB,EAAA0nB,aAAA,IAEA1nB,EAAA2nB,YAAA,EAEA3nB,EAAApF,UAAAgtB,UAAA,SAAAC,GACAvtB,KAAAuT,OAAAga,EAAAha,OACAvT,KAAAsT,KAAAia,EAAAja,KACAtT,KAAAyrB,KAAA8B,EAAA9B,KACAzrB,KAAAysB,WAAAc,EAAAd,YAGA/mB,EAAApF,UAAAjC,MAAA,SAAAgH,EAAAomB,GACAzrB,KAAAqtB,aAAA,EACArtB,KAAAyrB,MACA,IAAA+B,GAAAnoB,EAAAmoB,MACA,KACAxtB,KAAAysB,WAAApnB,EAAAe,MACApG,KAAA2sB,WAAA3G,OACA,IAAA3f,GAAArG,KAAAssB,cAAAb,EACA,eAAAplB,EAAAonB,GACAztB,KAAA0tB,SAAAroB,GAEArF,KAAA2tB,QAAAtoB,EAAAgB,EAAAonB,IAEE,QACFpoB,EAAAuoB,QAAAJ,KAIA9nB,EAAApF,UAAA0lB,MAAA,WACAhmB,KAAA2sB,WAAA3G,QACAhmB,KAAAysB,cACAzsB,KAAAsT,KAAA,EACAtT,KAAAuT,OAAA,EACAvT,KAAAyrB,KAAAlmB,EAAAmnB,cAGAhnB,EAAApF,UAAAotB,SAAA,SAAAroB,GACA,GAAA0Q,GAAA/V,KAAAyF,IAAA2F,iBAAApL,KAAAyrB,KAEAzrB,MAAAitB,OACAY,QAAAjqB,IAAA,iBAAA5D,KAAAyrB,KAAA,WAAA1V,EAEA,IAAA+X,GAAA9tB,KAAAyrB,KACAsC,EAAA/tB,KAAAguB,kBAAA3oB,EAAA0Q,GACAkY,EAAAF,EAAAG,kBACAH,GAAAG,oBAAA,CAEA,IAAAC,GAAAnuB,KAAAouB,YAAAL,EACAE,KACAjuB,KAAAssB,cAAAtsB,KAAAyrB,MAAAgC,GAAAU,EAGA,IAAAE,GAAAruB,KAAA2tB,QAAAtoB,EAAA8oB,EAKA,OAHAnuB,MAAAitB,OACAY,QAAAjqB,IAAA,uBAAA5D,KAAAssB,cAAAwB,GAAAQ,iBAEAD,GAGA3oB,EAAApF,UAAAqtB,QAAA,SAAAtoB,EAAAkpB,GACAvuB,KAAAitB,OACAY,QAAAjqB,IAAA,uBAAA2qB,EAAAC,SAEAD,EAAAE,eAEAzuB,KAAA0uB,gBAAA1uB,KAAA2sB,WAAAtnB,EAAAkpB,EAKA,KAHA,GAAA1e,GAAAxK,EAAAspB,GAAA,GACAnjB,EAAA+iB,IAEA,CACAvuB,KAAAitB,OACAY,QAAAjqB,IAAA,kCAAA4H,EAAAgjB,QAqBA,IAAA5f,GAAA5O,KAAA4uB,uBAAApjB,EAAAqE,EAMA,IAJA,OAAAjB,IACAA,EAAA5O,KAAA6uB,mBAAAxpB,EAAAmG,EAAAqE,IAGAjB,IAAA4d,EAAAsC,MACA,KASA,IAHAjf,IAAArJ,EAAAD,KACAvG,KAAA+uB,QAAA1pB,GAEAuJ,EAAA6f,gBACAzuB,KAAA0uB,gBAAA1uB,KAAA2sB,WAAAtnB,EAAAuJ,GACAiB,IAAArJ,EAAAD,KACA,KAGAsJ,GAAAxK,EAAAspB,GAAA,GACAnjB,EAAAoD,EAEA,MAAA5O,MAAAgvB,aAAAhvB,KAAA2sB,WAAAtnB,EAAAmG,EAAAgjB,QAAA3e,IAYAnK,EAAApF,UAAAsuB,uBAAA,SAAApjB,EAAAqE,GACA,UAAArE,EAAAyjB,OAAApf,EAAAnK,EAAAynB,cAAAtd,EAAAnK,EAAA0nB,aACA,WAGA,IAAAxe,GAAApD,EAAAyjB,MAAApf,EAAAnK,EAAAynB,aAOA,OANArtB,UAAA8O,IACAA,EAAA,MAEA5O,KAAAitB,OAAA,OAAAre,GACAif,QAAAjqB,IAAA,eAAA4H,EAAAU,YAAA,YAAA0C,EAAA1C,aAEA0C,GAaAlJ,EAAApF,UAAAuuB,mBAAA,SAAAxpB,EAAAmG,EAAAqE,GACA,GAAAqf,GAAA,GAAArC,EAKA,OAFA7sB,MAAAmvB,sBAAA9pB,EAAAmG,EAAAgjB,QAAAU,EAAArf,GAEA,IAAAqf,EAAAE,MAAAjjB,QACA+iB,EAAAhB,oBAGAluB,KAAAqvB,WAAA7jB,EAAAqE,EAAA2c,EAAAsC,OAGAtC,EAAAsC,OAGA9uB,KAAAqvB,WAAA7jB,EAAAqE,EAAA,KAAAqf,IAGAxpB,EAAApF,UAAA0uB,aAAA,SAAArC,EAAAtnB,EAAA6pB,EAAArf,GACA,UAAA7P,KAAA2sB,WAAAP,SAAA,CACA,GAAAvX,GAAA8X,EAAAP,SAAAvX,mBAGA,OAFA7U,MAAAa,OAAAwE,EAAAwP,EAAA7U,KAAAysB,WACAE,EAAAvmB,MAAAumB,EAAArZ,KAAAqZ,EAAApZ,QACAoZ,EAAAP,SAAAkD,WAGA,GAAAzf,IAAArJ,EAAAD,KAAAlB,EAAAe,QAAApG,KAAAysB,WACA,MAAAjmB,GAAAD,GAEA,UAAAymB,GAAAhtB,KAAAkgB,MAAA7a,EAAArF,KAAAysB,WAAAyC,IAOAxpB,EAAApF,UAAA6uB,sBAAA,SAAA9pB,EAAAkqB,EACAL,EAAArf,GAIA,OADA2f,GAAA/kB,EAAA6C,mBACA+B,EAAA,EAAgBA,EAAAkgB,EAAAH,MAAAjjB,OAA0BkD,IAAA,CAC1C,GAAAogB,GAAAF,EAAAH,MAAA/f,GACAqgB,EAAAD,EAAAlhB,MAAAihB,CACA,KAAAE,IAAAD,EAAA3a,+BAAA,CAGA9U,KAAAitB,OACAY,QAAAjqB,IAAA,qBAAA5D,KAAA2vB,aAAA9f,GAAA4f,EACA1d,SAAA/R,KAAAkgB,OAAA,GAEA,QAAAtQ,GAAA,EAAiBA,EAAA6f,EAAAxjB,MAAAiB,YAAAf,OAAkCyD,IAAA,CACnD,GAAA2H,GAAAkY,EAAAxjB,MAAAiB,YAAA0C,GACAhB,EAAA5O,KAAA4vB,mBAAArY,EAAA1H,EACA,WAAAjB,EAAA,CACA,GAAAiG,GAAA4a,EAAA5a,mBACA,QAAAA,IACAA,IAAAgb,qBAAAxqB,EAAAe,MAAApG,KAAAysB,YAEA,IAAAqD,GAAAjgB,IAAArJ,EAAAD,IACAiO,EAAA,GAAAI,IAAqC3I,MAAA2C,EAAAiG,uBAAsD4a,EAC3FzvB,MAAAuvB,QAAAlqB,EAAAmP,EAAA0a,EACAQ,GAAA,EAAAI,KAGAN,EAAAC,EAAAlhB,UAOA7I,EAAApF,UAAAO,OAAA,SAAAwE,EAAAwP,EACA4X,EAAArmB,EAAAkN,EAAAyc,GACA/vB,KAAAitB,OACAY,QAAAjqB,IAAA,cAAAiR,GAGAxP,EAAA2qB,KAAA5pB,GACApG,KAAAsT,OACAtT,KAAAuT,OAAAwc,EACA,OAAAlb,GAAA,OAAA7U,KAAAkgB,OACArL,EAAA+W,QAAA5rB,KAAAkgB,MAAA7a,EAAAonB,IAIA/mB,EAAApF,UAAAsvB,mBAAA,SAAArY,EAAA1H,GACA,MAAA0H,GAAAwE,QAAAlM,EAAA,SACA0H,EAAA3I,OAEA,MAIAlJ,EAAApF,UAAA0tB,kBAAA,SAAA3oB,EAAA9H,GAGA,OAFA0yB,GAAAjiB,EAAAa,MACA2f,EAAA,GAAA3B,GACAxd,EAAA,EAAgBA,EAAA9R,EAAA2P,YAAAf,OAA0BkD,IAAA,CAC1C,GAAAT,GAAArR,EAAA2P,YAAAmC,GAAAT,OACA6gB,EAAA,GAAA7a,IAAsC3I,MAAA2C,EAAAL,IAAAc,EAAA,EAAA1O,QAAAsvB,GAA8C,KACpFjwB,MAAAuvB,QAAAlqB,EAAAoqB,EAAAjB,GAAA,SAEA,MAAAA,IAWA9oB,EAAApF,UAAAivB,QAAA,SAAAlqB,EAAAmP,EAAAga,EACAkB,EAAAQ,EAAAJ,GACA,GAAAL,GAAA,IAIA,IAHAzvB,KAAAitB,OACAY,QAAAjqB,IAAA,WAAA4Q,EAAAzC,SAAA/R,KAAAkgB,OAAA,QAEA1L,EAAAvI,gBAAAyB,GAAA,CAQA,GAPA1N,KAAAitB,QACA,OAAAjtB,KAAAkgB,MACA2N,QAAAjqB,IAAA,+BAAA5D,KAAAkgB,MAAAiQ,eAAA3b,EAAAvI,MAAAwD,WAAA+E,GAEAqZ,QAAAjqB,IAAA,4BAAA4Q,IAGA,OAAAA,EAAA7T,SAAA6T,EAAA7T,QAAAoe,eAAA,CACA,UAAAvK,EAAA7T,SAAA6T,EAAA7T,QAAAyO,UAEA,MADAof,GAAArf,IAAAqF,IACA,CAEAga,GAAArf,IAAA,GAAAyF,IAAoC3I,MAAAuI,EAAAvI,MAAAtL,QAAAqN,EAAAa,OAAqD2F,IACzFkb,GAAA,EAGA,UAAAlb,EAAA7T,UAAA6T,EAAA7T,QAAAyO,UACA,OAAAC,GAAA,EAAkBA,EAAAmF,EAAA7T,QAAAwL,OAA2BkD,IAC7C,GAAAmF,EAAA7T,QAAA4O,eAAAF,KAAArB,EAAA0O,mBAAA,CACA,GAAA5M,GAAA0E,EAAA7T,QAAAgP,UAAAN,GACAC,EAAAtP,KAAAyF,IAAAqF,OAAA0J,EAAA7T,QAAA4O,eAAAF,GACAogB,GAAA,GAAA7a,IAA+B3I,MAAAqD,EAAA3O,QAAAmP,GAAwC0E,GACvEkb,EAAA1vB,KAAAuvB,QAAAlqB,EAAAoqB,EACAjB,EAAAkB,EAAAQ,EACAJ,GAIA,MAAAJ,GAGAlb,EAAAvI,MAAAqJ,wBACAoa,GAAAlb,EAAAM,gCACA0Z,EAAArf,IAAAqF,EAGA,QAAA5E,GAAA,EAAgBA,EAAA4E,EAAAvI,MAAAiB,YAAAf,OAAqCyD,IAAA,CACrD,GAAA2H,GAAA/C,EAAAvI,MAAAiB,YAAA0C,EACA6f,GAAAzvB,KAAAowB,iBAAA/qB,EAAAmP,EAAA+C,EAAAiX,EAAA0B,EAAAJ,GACA,OAAAL,IACAC,EAAA1vB,KAAAuvB,QAAAlqB,EAAAoqB,EAAAjB,EACAkB,EAAAQ,EAAAJ,IAGA,MAAAJ,IAIAhqB,EAAApF,UAAA8vB,iBAAA,SAAA/qB,EAAAmP,EAAA+C,EACAiX,EAAA0B,EAAAJ,GACA,GAAAL,GAAA,IACA,IAAAlY,EAAAoD,oBAAAJ,EAAAO,KAAA,CACA,GAAAhL,GAAA7B,EAAAzN,OAAAgU,EAAA7T,QAAA4W,EAAApK,YAAAjB,YACAujB,GAAA,GAAA7a,IAA6B3I,MAAAsL,EAAA3I,OAAAjO,QAAAmP,GAAwC0E,OACnE,IAAA+C,EAAAoD,oBAAAJ,EAAAsB,WACF,yDACE,IAAAtE,EAAAoD,oBAAAJ,EAAAa,UAmBFpb,KAAAitB,OACAY,QAAAjqB,IAAA,aAAA2T,EAAA9H,UAAA,IAAA8H,EAAAG,WAEA8W,EAAAN,oBAAA,EACAluB,KAAAqwB,kBAAAhrB,EAAAkS,EAAA9H,UAAA8H,EAAAG,UAAAwY,KACAT,EAAA,GAAA7a,IAA6B3I,MAAAsL,EAAA3I,QAAoB4F,QAE/C,IAAA+C,EAAAoD,oBAAAJ,EAAAgB,OACF,UAAA/G,EAAA7T,SAAA6T,EAAA7T,QAAAoe,eAAA,CAaA,GAAAlK,GAAAkY,EAAAuD,OAAA9b,EAAAK,oBACA7U,KAAAyF,IAAA0F,aAAAoM,EAAA+D,aACAmU,GAAA,GAAA7a,IAA6B3I,MAAAsL,EAAA3I,OAAAiG,uBAA8DL,OAG3Fib,GAAA,GAAA7a,IAA8B3I,MAAAsL,EAAA3I,QAAoB4F,OAEhD+C,GAAAoD,oBAAAJ,EAAA3N,QACF6iB,EAAA,GAAA7a,IAA4B3I,MAAAsL,EAAA3I,QAAoB4F,GAC9C+C,EAAAoD,oBAAAJ,EAAAK,MACFrD,EAAAoD,oBAAAJ,EAAAW,OACA3D,EAAAoD,oBAAAJ,EAAAkB,KACAqU,GACAvY,EAAAwE,QAAAvV,EAAAD,IAAA,WACAkpB,EAAA,GAAA7a,IAA+B3I,MAAAsL,EAAA3I,QAAqB4F,IAIpD,MAAAib,IAuBA/pB,EAAApF,UAAA+vB,kBAAA,SAAAhrB,EAAAoK,EACAiI,EAAAwY,GAEA,UAAAlwB,KAAAkgB,MACA,QAEA,KAAAgQ,EACA,MAAAlwB,MAAAkgB,MAAArH,QAAA,KAAApJ,EAAAiI,EAEA,IAAA6Y,GAAAvwB,KAAAuT,OACAid,EAAAxwB,KAAAsT,KACAlN,EAAAf,EAAAe,MACAqqB,EAAAprB,EAAAmoB,MACA,KAEA,MADAxtB,MAAA+uB,QAAA1pB,GACArF,KAAAkgB,MAAArH,QAAA,KAAApJ,EAAAiI,GACE,QACF1X,KAAAuT,OAAAgd,EACAvwB,KAAAsT,KAAAkd,EACAnrB,EAAA2qB,KAAA5pB,GACAf,EAAAuoB,QAAA6C,KAIA/qB,EAAApF,UAAAouB,gBAAA,SAAAgC,EAAArrB,EAAA+mB,GACAsE,EAAAtqB,MAAAf,EAAAe,MACAsqB,EAAApd,KAAAtT,KAAAsT,KACAod,EAAAnd,OAAAvT,KAAAuT,OACAmd,EAAAtE,YAGA1mB,EAAApF,UAAA+uB,WAAA,SAAAsB,EAAAC,EAAAC,EAAAC,GAOA,GANAhxB,SAAA+wB,IACAA,EAAA,MAEA/wB,SAAAgxB,IACAA,EAAA,MAEA,OAAAD,GAAA,OAAAC,EAAA,CAYA,GAAA7C,GAAA6C,EAAA5C,kBAKA,IAJA4C,EAAA5C,oBAAA,EAEA2C,EAAA7wB,KAAAouB,YAAA0C,GAEA7C,EACA,MAAA4C,GAIA,MAAAD,GAAAlrB,EAAAynB,cAAAyD,EAAAlrB,EAAA0nB,aAEAyD,GAEA7wB,KAAAitB,OACAY,QAAAjqB,IAAA,QAAA+sB,EAAA,OAAAE,EAAA,SAAAD,GAEA,OAAAD,EAAA1B,QAEA0B,EAAA1B,UAEA0B,EAAA1B,MAAA2B,EAAAlrB,EAAAynB,cAAA0D,EAEAA,IAOAnrB,EAAApF,UAAA8tB,YAAA,SAAAI,GAGA,OAFAuC,GAAA,GAAAnE,GAAA,KAAA4B,GACAwC,EAAA,KACA3hB,EAAA,EAAgBA,EAAAmf,EAAAY,MAAAjjB,OAA0BkD,IAAA,CAC1C,GAAAogB,GAAAjB,EAAAY,MAAA/f,EACA,IAAAogB,EAAAxjB,gBAAAyB,GAAA,CACAsjB,EAAAvB,CACA,QAGA,OAAAuB,IACAD,EAAAtC,eAAA,EACAsC,EAAAlc,oBAAAmc,EAAAnc,oBACAkc,EAAAzB,WAAAtvB,KAAAyF,IAAAyF,gBAAA8lB,EAAA/kB,MAAAwD,WAEA,IAAA2B,GAAA2f,EAAArgB,aACArK,EAAArG,KAAAssB,cAAAtsB,KAAAyrB,MACA9M,EAAAtY,EAAAyE,OAAAsG,IAAA,IACA,WAAAuN,EACA,MAAAA,EAEA,IAAAsS,GAAAF,CAKA,OAJAE,GAAA/kB,YAAA7F,EAAAyE,OAAAqB,OACAqiB,EAAA0C,aAAA,GACAD,EAAAzC,UACAnoB,EAAAyE,OAAAsG,GAAA6f,EACAA,GAGAvrB,EAAApF,UAAA6wB,OAAA,SAAA1F,GACA,MAAAzrB,MAAAssB,cAAAb,IAIA/lB,EAAApF,UAAAwC,QAAA,SAAAuC,GAEA,MAAAA,GAAAvC,QAAA9C,KAAAysB,WAAApnB,EAAAe,MAAA,IAGAV,EAAApF,UAAAyuB,QAAA,SAAA1pB,GACA,GAAA+rB,GAAA/rB,EAAAspB,GAAA,EACAyC,KAAA,KAAA9f,WAAA,IACAtR,KAAAsT,MAAA,EACAtT,KAAAuT,OAAA,GAEAvT,KAAAuT,QAAA,EAEAlO,EAAA0pB,WAGArpB,EAAApF,UAAAqvB,aAAA,SAAA0B,GACA,MAAAA,QACA,MAEA,IAAAngB,OAAAmJ,aAAAgX,GAAA,KAIAr0B,EAAA0I,qB1ByyLM,SAASzI,EAAQD,EAASH,G2Bh5MhC,QAAA0I,GAAAF,GA8CA,MA7CAisB,GAAAl0B,KAAA4C,MACAA,KAAAuxB,OAAAlsB,EACArF,KAAAwxB,SAAAC,EAAAxP,QACAjiB,KAAA0xB,yBAAA1xB,KAAAqF,GAEArF,KAAAwF,QAAA,KASAxF,KAAA2xB,OAAA,KAKA3xB,KAAA4xB,wBAGA5xB,KAAA6xB,mBAGA7xB,KAAA8xB,qBAIA9xB,KAAA+xB,SAAA,EAGA/xB,KAAAisB,SAAAzlB,EAAAkN,gBAGA1T,KAAAgyB,MAAAxrB,EAAA2H,aAEAnO,KAAAiyB,cACAjyB,KAAAkyB,MAAA3sB,EAAAmnB,aAKA1sB,KAAAwT,MAAA,KAEAxT,KAvDA,GAAAwG,GAAA3J,EAAA,GAAA2J,MACA8qB,EAAAz0B,EAAA,IAAAy0B,WACAG,EAAA50B,EAAA,IAAA40B,mBACAzE,EAAAnwB,EAAA,IAAAmwB,yBAuDAznB,GAAAjF,UAAAC,OAAAC,OAAA8wB,EAAAhxB,WACAiF,EAAAjF,UAAAF,YAAAmF,EAEAA,EAAAmnB,aAAA,EACAnnB,EAAAylB,QACAzlB,EAAA6lB,QAEA7lB,EAAA4sB,sBAAA3rB,EAAAkN,gBACAnO,EAAA6sB,OAAA5rB,EAAAmN,eACApO,EAAA8sB,eAAA,KACA9sB,EAAA+sB,eAAA,IAEA/sB,EAAAjF,UAAA0lB,MAAA,WAEA,OAAAhmB,KAAAuxB,QACAvxB,KAAAuxB,OAAAvB,KAAA,GAEAhwB,KAAA2xB,OAAA,KACA3xB,KAAAgyB,MAAAxrB,EAAA2H,aACAnO,KAAAisB,SAAAzlB,EAAAkN,gBACA1T,KAAA4xB,wBACA5xB,KAAA8xB,qBACA9xB,KAAA6xB,mBACA7xB,KAAAwT,MAAA,KAEAxT,KAAA+xB,SAAA,EACA/xB,KAAAkyB,MAAA3sB,EAAAmnB,aACA1sB,KAAAiyB,cAEAjyB,KAAAwF,QAAAwgB,SAIAzgB,EAAAjF,UAAAiyB,UAAA,WACA,UAAAvyB,KAAAuxB,OACA,kDAKA,IAAAiB,GAAAxyB,KAAAuxB,OAAA/D,MACA,KACA,QACA,GAAAxtB,KAAA+xB,QAEA,MADA/xB,MAAAyyB,UACAzyB,KAAA2xB,MAEA3xB,MAAA2xB,OAAA,KACA3xB,KAAAisB,SAAAzlB,EAAAkN,gBACA1T,KAAA4xB,qBAAA5xB,KAAAuxB,OAAAnrB,MACApG,KAAA8xB,kBAAA9xB,KAAAwF,QAAA+N,OACAvT,KAAA6xB,gBAAA7xB,KAAAwF,QAAA8N,KACAtT,KAAAwT,MAAA,IAEA,KADA,GAAAkf,IAAA,IACA,CACA1yB,KAAAgyB,MAAAxrB,EAAA2H,YACA,IAAAsU,GAAAld,EAAA6lB,IACA,KACA3I,EAAAziB,KAAAwF,QAAAnH,MAAA2B,KAAAuxB,OAAAvxB,KAAAkyB,OACK,MAAAS,GACL3yB,KAAA4yB,gBAAAD,GACA3yB,KAAA6yB,QAAAF,GAQA,GANA3yB,KAAAuxB,OAAA5C,GAAA,KAAAnoB,EAAAD,MACAvG,KAAA+xB,SAAA,GAEA/xB,KAAAgyB,QAAAxrB,EAAA2H,eACAnO,KAAAgyB,MAAAvP,GAEAziB,KAAAgyB,QAAAzsB,EAAA6lB,KAAA,CACAsH,GAAA,CACA,OAEA,GAAA1yB,KAAAgyB,QAAAzsB,EAAAylB,KACA,MAGA,IAAA0H,EAMA,MAHA,QAAA1yB,KAAA2xB,QACA3xB,KAAA8yB,OAEA9yB,KAAA2xB,QAEE,QAGF3xB,KAAAuxB,OAAA3D,QAAA4E,KAUAjtB,EAAAjF,UAAAurB,KAAA,WACA7rB,KAAAgyB,MAAAzsB,EAAA6lB,MAGA7lB,EAAAjF,UAAA0rB,KAAA,WACAhsB,KAAAgyB,MAAAzsB,EAAAylB,MAGAzlB,EAAAjF,UAAAmrB,KAAA,SAAApuB,GACA2C,KAAAkyB,MAAA70B,GAGAkI,EAAAjF,UAAAwrB,SAAA,SAAAzuB,GACA2C,KAAAwF,QAAAynB,OACAY,QAAAjqB,IAAA,YAAAvG,GAEA2C,KAAAiyB,WAAA7lB,KAAApM,KAAAkyB,OACAlyB,KAAAyrB,KAAApuB,IAGAkI,EAAAjF,UAAAyrB,QAAA,WACA,OAAA/rB,KAAAiyB,WAAA9lB,OACA,kBAMA,OAJAnM,MAAAwF,QAAAynB,OACAY,QAAAjqB,IAAA,mBAAA5D,KAAAiyB,WAAAhZ,MAAA,OAEAjZ,KAAAyrB,KAAAzrB,KAAAiyB,WAAArY,OACA5Z,KAAAkyB,OAIA3xB,OAAAgR,eAAAhM,EAAAjF,UAAA,eACAkR,IAAA,WACA,MAAAxR,MAAAuxB,QAEArhB,IAAA,SAAA7K,GACArF,KAAAuxB,OAAA,KACAvxB,KAAA0xB,yBAAA1xB,UAAAuxB,QACAvxB,KAAAgmB,QACAhmB,KAAAuxB,OAAAlsB,EACArF,KAAA0xB,yBAAA1xB,UAAAuxB,WAIAhxB,OAAAgR,eAAAhM,EAAAjF,UAAA,cACAkR,IAAA,WACA,MAAAxR,MAAAuxB,OAAAwB,cASAxtB,EAAAjF,UAAA0yB,UAAA,SAAAlS,GACA9gB,KAAA2xB,OAAA7Q,GASAvb,EAAAjF,UAAAwyB,KAAA,WACA,GAAAjjB,GAAA7P,KAAAwxB,SAAAhxB,OAAAR,KAAA0xB,wBAAA1xB,KAAAgyB,MACAhyB,KAAAwT,MAAAxT,KAAAisB,SAAAjsB,KAAA4xB,qBAAA5xB,KACAizB,eAAA,EAAAjzB,KAAA6xB,gBACA7xB,KAAA8xB,kBAEA,OADA9xB,MAAAgzB,UAAAnjB,GACAA,GAGAtK,EAAAjF,UAAAmyB,QAAA,WACA,GAAAS,GAAAlzB,KAAAuT,OACA4f,EAAAnzB,KAAAsT,KACA8f,EAAApzB,KAAAwxB,SAAAhxB,OAAAR,KAAA0xB,wBAAAlrB,EAAAD,IACA,KAAAC,EAAAkN,gBAAA1T,KAAAuxB,OAAAnrB,MACApG,KAAAuxB,OAAAnrB,MAAA,EAAA+sB,EAAAD,EAEA,OADAlzB,MAAAgzB,UAAAI,GACAA,GAGA7yB,OAAAgR,eAAAhM,EAAAjF,UAAA,QACAkR,IAAA,WACA,MAAAxR,MAAAiT,MAEA/C,IAAA,SAAA+C,GACAjT,KAAAgyB,MAAA/e,KAIA1S,OAAAgR,eAAAhM,EAAAjF,UAAA,QACAkR,IAAA,WACA,MAAAxR,MAAAwF,QAAA8N,MAEApD,IAAA,SAAAoD,GACAtT,KAAAwF,QAAA8N,UAIA/S,OAAAgR,eAAAhM,EAAAjF,UAAA,UACAkR,IAAA,WACA,MAAAxR,MAAAwF,QAAA+N,QAEArD,IAAA,SAAAqD,GACAvT,KAAAwF,QAAA+N,YAMAhO,EAAAjF,UAAA2yB,aAAA,WACA,MAAAjzB,MAAAuxB,OAAAnrB,OAKA7F,OAAAgR,eAAAhM,EAAAjF,UAAA,QACAkR,IAAA,WACA,cAAAxR,KAAAwT,MACAxT,KAAAwT,MAEAxT,KAAAwF,QAAA1C,QAAA9C,KAAAuxB,SAGArhB,IAAA,SAAArO,GACA7B,KAAAwT,MAAA3R,KAMA0D,EAAAjF,UAAA+yB,aAAA,WAGA,IAFA,GAAA1P,MACA9T,EAAA7P,KAAAuyB,YACA1iB,EAAAoD,OAAAzM,EAAAD,KACAod,EAAAvX,KAAAyD,GACAA,EAAA7P,KAAAuyB,WAEA,OAAA5O,IAGApe,EAAAjF,UAAAsyB,gBAAA,SAAAD,GACA,GAAAxf,GAAAnT,KAAA4xB,qBACAxe,EAAApT,KAAAuxB,OAAAnrB,MACAvE,EAAA7B,KAAAuxB,OAAAzuB,QAAAqQ,EAAAC,GACAkgB,EAAA,gCAAAtzB,KAAAuzB,gBAAA1xB,GAAA,IACAggB,EAAA7hB,KAAAwzB,0BACA3R,GAAA4R,YAAAzzB,KAAA,KAAAA,KAAA6xB,gBACA7xB,KAAA8xB,kBAAAwB,EAAAX,IAGAptB,EAAAjF,UAAAizB,gBAAA,SAAA/nB,GAEA,OADAvL,MACAoP,EAAA,EAAgBA,EAAA7D,EAAAW,OAAckD,IAC9BpP,EAAAmM,KAAAZ,EAAA6D,GAEA,OAAApP,GAAA6F,KAAA,KAGAP,EAAAjF,UAAAozB,uBAAA,SAAAp2B,GACA,MAAAA,GAAAgU,WAAA,KAAA9K,EAAAD,IACA,QACE,OAAAjJ,EACF,MACE,OAAAA,EACF,MACE,OAAAA,EACF,MAEAA,GAIAiI,EAAAjF,UAAAqzB,oBAAA,SAAAr2B,GACA,UAAA0C,KAAA0zB,uBAAAp2B,GAAA,KAQAiI,EAAAjF,UAAAuyB,QAAA,SAAAe,GACA5zB,KAAAuxB,OAAA5C,GAAA,KAAAnoB,EAAAD,MACAqtB,YAAA5G,GAEAhtB,KAAAwF,QAAAupB,QAAA/uB,KAAAuxB,QAGAvxB,KAAAuxB,OAAAxC,YAKA/xB,EAAAuI,S3Bo8MM,SAAStI,EAAQD,EAASH,G4BvyNhC,QAAAy0B,KAIA,MAHAtxB,MAAAf,YAAA40B,EAAA5I,UACAjrB,KAAAwF,QAAA,KACAxF,KAAA8zB,gBACA9zB,KARA,GAAAwG,GAAA3J,EAAA,GAAA2J,MACAqtB,EAAAh3B,EAAA,IAAAg3B,qBACAE,EAAAl3B,EAAA,IAAAk3B,kBASAzC,GAAA0C,qBACA1C,EAAA2C,qBAGA3C,EAAAhxB,UAAA2lB,aAAA,SAAAiO,GACA,GAAAC,GAAA,OACAA,KAAAD,GACArG,QAAAjqB,IAAA,uDAAAuwB,EAAA,KAAAD,IAIA5C,EAAAhxB,UAAA8zB,iBAAA,SAAAvS,GACA7hB,KAAAf,WAAAmN,KAAAyV,IAGAyP,EAAAhxB,UAAA+zB,qBAAA,WACAr0B,KAAAf,eAGAqyB,EAAAhxB,UAAAg0B,gBAAA,WACA,GAAAC,GAAAv0B,KAAAw0B,eACA,WAAAD,EACA,qEAEA,IAAAp2B,GAAA6B,KAAAg0B,kBAAAO,EAMA,OALAz0B,UAAA3B,IACAA,EAAAo2B,EAAA7a,OAAA,SAAAnH,EAAAiH,EAAAnK,GAAsDkD,EAAAiH,GAAAnK,IACtDlR,EAAAoI,IAAAC,EAAAD,IACAvG,KAAAg0B,kBAAAO,GAAAp2B,GAEAA,GAOAmzB,EAAAhxB,UAAAm0B,gBAAA,WACA,GAAA3qB,GAAA9J,KAAAmwB,cACA,WAAArmB,EACA,oEAEA,IAAA3L,GAAA6B,KAAAi0B,kBAAAnqB,EAKA,OAJAhK,UAAA3B,IACAA,EAAA2L,EAAA4P,OAAA,SAAAnH,EAAAiH,EAAAnK,GAAqDkD,EAAAiH,GAAAnK,IACrDrP,KAAAi0B,kBAAAnqB,GAAA3L,GAEAA,GAGAmzB,EAAAhxB,UAAAo0B,aAAA,SAAAC,GACA,GAAAlS,GAAAziB,KAAAs0B,kBAAAK,EACA,OAAA70B,UAAA2iB,EACAA,EAEAjc,EAAA2H,cAMAmjB,EAAAhxB,UAAAs0B,eAAA,SAAAjC,GACA,GAAArf,GAAAqf,EAAAkC,oBAAAvhB,KACAC,EAAAof,EAAAkC,oBAAAthB,MACA,eAAAD,EAAA,IAAAC,GAiBA+d,EAAAhxB,UAAAw0B,qBAAA,SAAAjlB,GACA,UAAAA,EACA,kBAEA,IAAArE,GAAAqE,EAAAhO,IASA,OARA,QAAA2J,IAEAA,EADAqE,EAAAoD,OAAAzM,EAAAD,IACA,QAEA,IAAAsJ,EAAAoD,KAAA,KAGAzH,IAAAzI,QAAA,YAAAA,QAAA,YAAAA,QAAA,YACA,IAAAyI,EAAA,KAGA8lB,EAAAhxB,UAAAkzB,yBAAA,WACA,UAAAO,GAAA/zB,KAAAf,aAKAqyB,EAAAhxB,UAAAuY,QAAA,SAAAD,EAAAnJ,EAAA6L,GACA,UAGAgW,EAAAhxB,UAAAwY,SAAA,SAAAF,EAAAf,GACA,UAUAtX,OAAAgR,eAAA+f,EAAAhxB,UAAA,SACAkR,IAAA,WACA,MAAAxR,MAAA8zB,cAEA5jB,IAAA,SAAAjE,GACAjM,KAAA8zB,aAAA7nB,KAKAjP,EAAAs0B,c5Bi1NM,SAASr0B,EAAQD,G6Bz9NvB,QAAA+3B,KACA,MAAA/0B,MAeA,QAAA6zB,KAEA,MADAkB,GAAA33B,KAAA4C,MACAA,KA2BA,QAAA+zB,GAAAiB,GAEA,GADAD,EAAA33B,KAAA4C,MACA,OAAAg1B,EACA,gBAGA,OADAh1B,MAAAg1B,YACAh1B,KA/CA+0B,EAAAz0B,UAAAmzB,YAAA,SAAAwB,EAAAC,EAAA5hB,EAAAC,EAAA+f,EAAAX,KAGAoC,EAAAz0B,UAAA60B,gBAAA,SAAAF,EAAA5uB,EAAAomB,EAAA2I,EAAAC,EAAAC,EAAA9G,KAGAuG,EAAAz0B,UAAAi1B,4BAAA,SAAAN,EAAA5uB,EAAAomB,EAAA2I,EAAAI,EAAAhH,KAGAuG,EAAAz0B,UAAAm1B,yBAAA,SAAAR,EAAA5uB,EAAAomB,EAAA2I,EAAA9F,EAAAd,KAQAqF,EAAAvzB,UAAAC,OAAAC,OAAAu0B,EAAAz0B,WACAuzB,EAAAvzB,UAAAF,YAAAyzB,EAKAA,EAAA5I,SAAA,GAAA4I,GAcAA,EAAAvzB,UAAAmzB,YAAA,SAAAwB,EAAAC,EAAA5hB,EAAAC,EAAA+f,EAAAX,GACA9E,QAAA5jB,MAAA,QAAAqJ,EAAA,IAAAC,EAAA,IAAA+f,IAYAS,EAAAzzB,UAAAC,OAAAC,OAAAu0B,EAAAz0B,WACAyzB,EAAAzzB,UAAAF,YAAA2zB,EAEAA,EAAAzzB,UAAAmzB,YAAA,SAAAwB,EAAAC,EAAA5hB,EAAAC,EAAA+f,EAAAX,GACA3yB,KAAAg1B,UAAA9uB,IAAA,SAAAjG,GAAoCA,EAAAwzB,YAAAwB,EAAAC,EAAA5hB,EAAAC,EAAA+f,EAAAX,MAGpCoB,EAAAzzB,UAAA60B,gBAAA,SAAAF,EAAA5uB,EAAAomB,EAAA2I,EAAAC,EAAAC,EAAA9G,GACAxuB,KAAAg1B,UAAA9uB,IAAA,SAAAjG,GAAoCA,EAAAk1B,gBAAAF,EAAA5uB,EAAAomB,EAAA2I,EAAAC,EAAAC,EAAA9G,MAGpCuF,EAAAzzB,UAAAi1B,4BAAA,SAAAN,EAAA5uB,EAAAomB,EAAA2I,EAAAI,EAAAhH,GACAxuB,KAAAg1B,UAAA9uB,IAAA,SAAAjG,GAAiCA,EAAAs1B,4BAAAN,EAAA5uB,EAAAomB,EAAA2I,EAAAI,EAAAhH,MAGjCuF,EAAAzzB,UAAAm1B,yBAAA,SAAAR,EAAA5uB,EAAAomB,EAAA2I,EAAA9F,EAAAd,GACAxuB,KAAAg1B,UAAA9uB,IAAA,SAAAjG,GAAiCA,EAAAw1B,yBAAAR,EAAA5uB,EAAAomB,EAAA2I,EAAA9F,EAAAd,MAGjCxxB,EAAA+3B,gBACA/3B,EAAA62B,uBACA72B,EAAA+2B,sB7BmgOM,SAAS92B,EAAQD,EAASH,G8B1kOhC,QAAA64B,KACA,MAAA11B,MAGA,QAAAyxB,GAAAkE,GAiBA,MAhBAD,GAAAt4B,KAAA4C,MAeAA,KAAA21B,SAAA71B,SAAA61B,KACA31B,KAvBA,GAAAkK,GAAArN,EAAA,GAAAqN,WA0BAunB,GAAAnxB,UAAAC,OAAAC,OAAAk1B,EAAAp1B,WACAmxB,EAAAnxB,UAAAF,YAAAqxB,EASAA,EAAAxP,QAAA,GAAAwP,GAEAA,EAAAnxB,UAAAE,OAAA,SAAAwS,EAAAC,EAAApR,EAAAqR,EAAAC,EAAAC,EAAAE,EAAAC,GACA,GAAA1D,GAAA,GAAA3F,GAAA8I,EAAAC,EAAAC,EAAAC,EAAAC,EAQA,OAPAvD,GAAAyD,OACAzD,EAAA0D,SACA,OAAA1R,EACAgO,EAAAhO,OACK7B,KAAA21B,UAAA,OAAA3iB,EAAA,KACLnD,EAAAhO,KAAAmR,EAAA,GAAAlQ,QAAAqQ,EAAAC,IAEAvD,GAGA4hB,EAAAnxB,UAAAs1B,WAAA,SAAA3iB,EAAApR,GACA,GAAAgO,GAAA,GAAA3F,GAAA,KAAA+I,EAEA,OADApD,GAAAhO,OACAgO,GAGA7S,EAAAy0B,sB9BunOM,SAASx0B,EAAQD,EAASH,G+B9qOhC,QAAAg5B,GAAA3hB,GAEA,GADA4hB,MAAA14B,KAAA4C,MACA81B,MAAAC,kBACAD,MAAAC,kBAAA/1B,KAAA61B,OAEA,KAAAC,QAAAE,MAmBA,MAjBAh2B,MAAAmqB,QAAAjW,EAAAiW,QACAnqB,KAAAi1B,WAAA/gB,EAAA+gB,WACAj1B,KAAAqF,MAAA6O,EAAA7O,MACArF,KAAAyL,IAAAyI,EAAAzI,IAIAzL,KAAAi2B,eAAA,KAMAj2B,KAAAk2B,kBACA,OAAAl2B,KAAAi1B,aACAj1B,KAAAk2B,eAAAl2B,KAAAi1B,WAAAhpB,OAEAjM,KA8BA,QAAAgtB,GAAAvuB,EAAA4G,EAAAonB,EAAA0J,GAIA,MAHAN,GAAAz4B,KAAA4C,MAAkCmqB,QAAA,GAAA8K,WAAAx2B,EAAA4G,QAAAoG,IAAA,OAClCzL,KAAAysB,aACAzsB,KAAAm2B,iBACAn2B,KAmBA,QAAAo2B,GAAAnB,EAAA5vB,EAAAgxB,EAAAJ,EAAAE,EAAA1qB,GACAA,KAAAwpB,EAAAqB,KACAL,KAAAhB,EAAAsB,kBACAF,KAAApB,EAAAsB,kBACAlxB,KAAA4vB,EAAAphB,iBACAgiB,EAAAz4B,KAAA4C,MAAkCmqB,QAAA,GAAA8K,aAAA5vB,QAAAoG,QAGlCzL,KAAAm2B,iBAKAn2B,KAAAq2B,aACAr2B,KAAAi2B,iBASA,QAAAO,GAAAvB,GACAY,EAAAz4B,KAAA4C,MAAkCmqB,QAAA,GAAA8K,aAAA5vB,MAAA4vB,EAAAphB,iBAAApI,IAAAwpB,EAAAqB,OAClCt2B,KAAAi2B,eAAAhB,EAAAsB,kBAWA,QAAAE,GAAAxB,EAAAyB,EAAAvM,GACA0L,EAAAz4B,KAAA4C,MAAkCmqB,QAAAnqB,KAAA22B,cAAAD,EAAAvM,GAAA,MAAA8K,aAClC5vB,MAAA4vB,EAAAphB,iBAAApI,IAAAwpB,EAAAqB,MACA,IAAA9qB,GAAAypB,EAAAzvB,QAAAC,IAAAqF,OAAAmqB,EAAAhpB,OACAsL,EAAA/L,EAAA0B,YAAA,EAUA,OATAqK,aAAA4D,IACAnb,KAAAyP,UAAA8H,EAAA9H,UACAzP,KAAA42B,eAAArf,EAAAG,YAEA1X,KAAAyP,UAAA,EACAzP,KAAA42B,eAAA,GAEA52B,KAAA02B,YACA12B,KAAAi2B,eAAAhB,EAAAsB,kBACAv2B,KAcA,QAAA62B,KAGA,MAFAf,OAAA14B,KAAA4C,MACA81B,MAAAC,kBAAA/1B,KAAA62B,GACA72B,KAlJA,GAAAmb,GAAAte,EAAA,IAAAse,mBA6BA0a,GAAAv1B,UAAAC,OAAAC,OAAAs1B,MAAAx1B,WACAu1B,EAAAv1B,UAAAF,YAAAy1B,EAcAA,EAAAv1B,UAAAmM,kBAAA,WACA,cAAAzM,KAAAi1B,WACAj1B,KAAAi1B,WAAAxvB,IAAAgH,kBAAAzM,KAAAk2B,eAAAl2B,KAAAyL,KAEA,MAIAoqB,EAAAv1B,UAAAyR,SAAA,WACA,MAAA/R,MAAAmqB,SAUA6C,EAAA1sB,UAAAC,OAAAC,OAAAq1B,EAAAv1B,WACA0sB,EAAA1sB,UAAAF,YAAA4sB,EAEAA,EAAA1sB,UAAAyR,SAAA,WACA,GAAAiK,GAAA,EAIA,OAHAhc,MAAAysB,YAAA,GAAAzsB,KAAAysB,WAAAzsB,KAAAqF,MAAA2O,OACAgI,EAAAhc,KAAAqF,MAAAvC,SAAA9C,KAAAysB,WAAAzsB,KAAAysB,cAEA,4BAAAzQ,GAyBAoa,EAAA91B,UAAAC,OAAAC,OAAAq1B,EAAAv1B,WACA81B,EAAA91B,UAAAF,YAAAg2B,EAUAI,EAAAl2B,UAAAC,OAAAC,OAAAq1B,EAAAv1B,WACAk2B,EAAAl2B,UAAAF,YAAAo2B,EAwBAC,EAAAn2B,UAAAC,OAAAC,OAAAq1B,EAAAv1B,WACAm2B,EAAAn2B,UAAAF,YAAAq2B,EAEAA,EAAAn2B,UAAAq2B,cAAA,SAAAD,EAAAvM,GACA,cAAAA,EACAA,EAEA,sBAAmCuM,EAAA,MAUnCG,EAAAv2B,UAAAC,OAAAC,OAAAs1B,MAAAx1B,WACAu2B,EAAAv2B,UAAAF,YAAAy2B,EAEA75B,EAAA64B,uBACA74B,EAAAo5B,uBACAp5B,EAAAgwB,4BACAhwB,EAAAw5B,yBACAx5B,EAAAy5B,4B/B0tOM,SAASx5B,EAAQD,EAASH,GgCt3OhC,QAAA2vB,GAAA/mB,EAAA8mB,GAwBA,MAFAvsB,MAAAyF,MACAzF,KAAAusB,qBACAvsB,KA5BA,GAAA4sB,GAAA/vB,EAAA,IAAA+vB,SACAE,EAAAjwB,EAAA,IAAAiwB,aACAtO,EAAA3hB,EAAA,IAAA2hB,0BA8BAgO,GAAAsC,MAAA,GAAAlC,GAAA,cAAAE,IAGAN,EAAAlsB,UAAAw2B,iBAAA,SAAAn2B,GACA,UAAAX,KAAAusB,mBACA,MAAA5rB,EAEA,IAAA+d,KACA,OAAAF,GAAA7d,EAAAX,KAAAusB,mBAAA7N,IAGA1hB,EAAAwvB,gBhCg6OM,SAASvvB,EAAQD,EAASH,GiCr8OhC,QAAAk6B,GAAAC,EAAAzoB,GAGA,MAFAvO,MAAAuO,MACAvO,KAAAg3B,OACAh3B,KAgCA,QAAA4sB,GAAA1gB,EAAAsiB,GAuCA,MAtCA,QAAAtiB,IACAA,MAEA,OAAAsiB,IACAA,EAAA,GAAA1B,IAEA9sB,KAAAkM,cACAlM,KAAAwuB,UAGAxuB,KAAAivB,MAAA,KACAjvB,KAAAyuB,eAAA,EAKAzuB,KAAAsvB,WAAA,EACAtvB,KAAA6U,oBAAA,KAKA7U,KAAAi3B,qBAAA,EAeAj3B,KAAAk3B,WAAA,KACAl3B,KAhFA,GAAA8sB,GAAAjwB,EAAA,IAAAiwB,aACAtiB,EAAA3N,EAAA,GACA0Q,EAAA/C,EAAA+C,GAUAwpB,GAAAz2B,UAAAyR,SAAA,WACA,UAAA/R,KAAAg3B,KAAA,KAAAh3B,KAAAuO,IAAA,KAwEAqe,EAAAtsB,UAAA62B,UAAA,WACA,GAAAC,GAAA,GAAA7pB,EACA,WAAAvN,KAAAwuB,QACA,OAAAnf,GAAA,EAAiBA,EAAArP,KAAAwuB,QAAAriB,OAAyBkD,IAAA,CAC1C,GAAA/R,GAAA0C,KAAAwuB,QAAAnf,EACA+nB,GAAAjoB,IAAA7R,EAAAiR,KAGA,WAAA6oB,EAAAjrB,OACA,KAEAirB,GAeAxK,EAAAtsB,UAAAkQ,OAAA,SAAA6B,GAEA,MAAArS,QAAAqS,GAEEA,YAAAua,IAGF5sB,KAAAwuB,QAAAhe,OAAA6B,EAAAmc,UAIA5B,EAAAtsB,UAAAyR,SAAA,WACA,SAAA/R,KAAAkM,YAAA,IAAAlM,KAAA0Q,cAGAkc,EAAAtsB,UAAAoQ,WAAA,WACA,SAAA1Q,KAAAwuB,SACAxuB,KAAAyuB,cACA,aAAAzuB,KAAAk3B,WACAl3B,KAAAk3B,WACAl3B,KAAAsvB,YACA,KAGAtyB,EAAA4vB,WACA5vB,EAAA+5B,kBjCi/OM,SAAS95B,EAAQD,EAASH,GkC9mPhC,QAAAw6B,GAAA/5B,GACA,MAAAA,GAAA2X,kBAGA,QAAAqiB,GAAAhnB,EAAApQ,GACA,MAAAoQ,KAAApQ,GAGA,OAAAoQ,GAAA,OAAApQ,IAGAoQ,EAAArE,MAAAC,cAAAhM,EAAA+L,MAAAC,aACAoE,EAAA/B,MAAArO,EAAAqO,KAAA+B,EAAA8D,gBAAA5D,OAAAtQ,EAAAkU,kBAIA,QAAA0Y,GAAAyK,GAwCA,MA5BAv3B,MAAAw3B,aAAA,GAAAjqB,GAAA8pB,EAAAC,GAIAt3B,KAAAu3B,QAAAz3B,SAAAy3B,KAMAv3B,KAAA8L,UAAA,EAEA9L,KAAAwuB,WAMAxuB,KAAAy3B,UAAA,EACAz3B,KAAAw1B,gBAAA,KAIAx1B,KAAAkuB,oBAAA,EACAluB,KAAA03B,sBAAA,EAEA13B,KAAAoc,iBAAA,KAEApc,KA4KA,QAAA6sB,KAGA,MAFAC,GAAA1vB,KAAA4C,MACAA,KAAAw3B,aAAA,GAAAjqB,GACAvN,KA7OA,GAAAyK,GAAA5N,EAAA,GAAA4N,IACAD,EAAA3N,EAAA,GACA0Q,EAAA/C,EAAA+C,IACAmH,EAAA7X,EAAA,IAAA6X,gBACAqI,EAAAlgB,EAAA,IAAAkgB,KAsEA+P,GAAAxsB,UAAA6O,IAAA,SAAAqF,EAAAyI,GAIA,GAHAnd,SAAAmd,IACAA,EAAA,MAEAjd,KAAA8L,SACA,2BAEA0I,GAAAJ,kBAAAM,EAAAC,OACA3U,KAAAkuB,oBAAA,GAEA1Z,EAAAH,wBAAA,IACArU,KAAA03B,sBAAA,EAEA,IAAA/Y,GAAA3e,KAAAw3B,aAAAroB,IAAAqF,EACA,IAAAmK,IAAAnK,EAGA,MAFAxU,MAAAoc,iBAAA,KACApc,KAAAwuB,QAAApiB,KAAAoI,IACA,CAGA,IAAAwI,IAAAhd,KAAAu3B,QACAI,EAAA5a,EAAA4B,EAAAhe,QAAA6T,EAAA7T,QAAAqc,EAAAC,EAUA,OANA0B,GAAAtK,wBAAArT,KAAAyY,IAAAkF,EAAAtK,wBAAAG,EAAAH,yBAEAG,EAAAD,6BACAoK,EAAApK,4BAAA,GAEAoK,EAAAhe,QAAAg3B,GACA,GAGA7K,EAAAxsB,UAAAs3B,UAAA,WAEA,OADA9sB,GAAA,GAAAyC,GACA8B,EAAA,EAAgBA,EAAArP,KAAAwuB,QAAAriB,OAAyBkD,IACzCvE,EAAAqE,IAAAnP,KAAAwuB,QAAAnf,GAAApD,MAEA,OAAAnB,IAGAgiB,EAAAxsB,UAAAu3B,cAAA,WAEA,OADAC,MACAzoB,EAAA,EAAgBA,EAAArP,KAAAwuB,QAAAriB,OAAyBkD,IAAA,CACzC,GAAA/R,GAAA0C,KAAAwuB,QAAAnf,GAAA+E,eACA9W,KAAAoX,EAAAC,MACAmjB,EAAA1rB,KAAA9O,EAAA8W,iBAGA,MAAA0jB,IAGAv3B,OAAAgR,eAAAub,EAAAxsB,UAAA,SACAkR,IAAA,WACA,MAAAxR,MAAAwuB,WAIA1B,EAAAxsB,UAAAy3B,gBAAA,SAAAC,GACA,GAAAh4B,KAAA8L,SACA,2BAEA,QAAA9L,KAAAw3B,aAAArrB,OAGA,OAAAkD,GAAA,EAAgBA,EAAArP,KAAAwuB,QAAAriB,OAAyBkD,IAAA,CACzC,GAAAmF,GAAAxU,KAAAwuB,QAAAnf,EACAmF,GAAA7T,QAAAq3B,EAAAlB,iBAAAtiB,EAAA7T,WAIAmsB,EAAAxsB,UAAA23B,OAAA,SAAAC,GACA,OAAA7oB,GAAA,EAAgBA,EAAA6oB,EAAA/rB,OAAiBkD,IACjCrP,KAAAmP,IAAA+oB,EAAA7oB,GAEA,WAGAyd,EAAAxsB,UAAAkQ,OAAA,SAAA6B,GACA,MAAArS,QAAAqS,GAEEA,YAAAya,KAGF,OAAA9sB,KAAAwuB,SAAAxuB,KAAAwuB,QAAAhe,OAAA6B,EAAAmc,UACAxuB,KAAAu3B,UAAAllB,EAAAklB,SACAv3B,KAAAy3B,YAAAplB,EAAAolB,WACAz3B,KAAAw1B,kBAAAnjB,EAAAmjB,iBACAx1B,KAAAkuB,qBAAA7b,EAAA6b,oBACAluB,KAAA03B,uBAAArlB,EAAAqlB,uBAGA5K,EAAAxsB,UAAAoQ,WAAA,WACA,MAAA1Q,MAAA8L,UACA,OAAA9L,KAAAoc,mBACApc,KAAAoc,iBAAApc,KAAAm4B,eAEAn4B,KAAAoc,kBAEApc,KAAAm4B,eAIArL,EAAAxsB,UAAA63B,YAAA,WACA,GAAA3sB,GAAA,EAIA,OAHAxL,MAAAwuB,QAAAtoB,IAAA,SAAA5I,GACAkO,GAAAlO,EAAAyU,aAEAvG,GAGAjL,OAAAgR,eAAAub,EAAAxsB,UAAA,UACAkR,IAAA,WACA,MAAAxR,MAAAwuB,QAAAriB,UAIA2gB,EAAAxsB,UAAA8O,QAAA,WACA,WAAApP,KAAAwuB,QAAAriB,QAGA2gB,EAAAxsB,UAAAqM,SAAA,SAAAwM,GACA,UAAAnZ,KAAAw3B,aACA,wDAEA,OAAAx3B,MAAAw3B,aAAA7qB,SAAAwM,IAGA2T,EAAAxsB,UAAA83B,aAAA,SAAAjf,GACA,UAAAnZ,KAAAw3B,aACA,wDAEA,OAAAx3B,MAAAw3B,aAAAY,aAAAjf,IAGA2T,EAAAxsB,UAAA+3B,MAAA,WACA,GAAAr4B,KAAA8L,SACA,2BAEA9L,MAAAwuB,WACAxuB,KAAAoc,iBAAA,KACApc,KAAAw3B,aAAA,GAAAjqB,IAGAuf,EAAAxsB,UAAA4wB,YAAA,SAAAplB,GACA9L,KAAA8L,WACAA,IACA9L,KAAAw3B,aAAA,OAIA1K,EAAAxsB,UAAAyR,SAAA,WACA,MAAAvH,GAAA6F,cAAArQ,KAAAwuB,UACAxuB,KAAAkuB,mBAAA,uBAAAluB,KAAAkuB,mBAAA,KACAluB,KAAAy3B,YAAAhtB,EAAA6C,mBAAA,cAAAtN,KAAAy3B,UAAA,KACA,OAAAz3B,KAAAw1B,gBAAA,oBAAAx1B,KAAAw1B,gBAAA,KACAx1B,KAAA03B,qBAAA,6BASA7K,EAAAvsB,UAAAC,OAAAC,OAAAssB,EAAAxsB,WACAusB,EAAAvsB,UAAAF,YAAAysB,EAEA7vB,EAAA8vB,eACA9vB,EAAA6vB,uBlC+pPM,SAAS5vB,EAAQD,EAASH,GmC/4PhC,QAAAkwB,GAAA5hB,GAMA,MALAnL,MAAAmL,aAAA,OAAAA,OAGAnL,KAAAs4B,YAAAntB,EAAA4G,WAEA/R,KARA,GAAA0rB,GAAA7uB,EAAA,IAAA6uB,wBAwBAqB,GAAAuD,OAAA,SAAAzb,EAAA0U,GACA,UAAA1U,EACA,UAAAkY,IAAAxD,GAEA,IAAApe,GAAA0J,EAAA1J,aAAA2G,QAAAyX,GACA,WAAAwD,GAAA5hB,IA+BA4hB,EAAAzsB,UAAAuvB,qBAAA,SAAAlE,GAEA,OADA4M,GAAA,KACAlpB,EAAA,EAAgBA,EAAArP,KAAAmL,aAAAgB,OAA8BkD,KAC9CrP,KAAAmL,aAAAkE,GAAAmc,qBACAxrB,KAAAmL,aAAAkE,YAAAqc,KACA,OAAA6M,IACAA,EAAAv4B,KAAAmL,aAAA2G,YAEAymB,EAAAlpB,GAAA,GAAAqc,GAAAC,EACA3rB,KAAAmL,aAAAkE,IAGA,eAAAkpB,EACAv4B,KAEA,GAAA+sB,GAAAwL,IAsBAxL,EAAAzsB,UAAAsrB,QAAA,SAAAntB,EAAA4G,EAAAonB,GACA,GAAA+L,IAAA,EACApD,EAAA/vB,EAAAe,KACA,KACA,OAAAiJ,GAAA,EAAiBA,EAAArP,KAAAmL,aAAAgB,OAA8BkD,IAAA,CAC/C,GAAAka,GAAAvpB,KAAAmL,aAAAkE,EACA,IAAAka,YAAAmC,GAAA,CACA,GAAAC,GAAApC,EAAAoC,MACAtmB,GAAA2qB,KAAAvD,EAAAd,GACApC,IAAAgC,OACAiN,EAAA/L,EAAAd,IAAAyJ,MACI7L,GAAAiC,sBACJnmB,EAAA2qB,KAAAoF,GACAoD,GAAA,EAEAjP,GAAAqC,QAAAntB,IAEE,QACF+5B,GACAnzB,EAAA2qB,KAAAoF,KAKArI,EAAAzsB,UAAAoQ,WAAA,WACA,MAAA1Q,MAAAs4B,aAGAvL,EAAAzsB,UAAAkQ,OAAA,SAAA6B,GACA,GAAArS,OAAAqS,EACA,QACE,IAAAA,YAAA0a,GAEA,IAAA/sB,KAAAs4B,aAAAjmB,EAAAimB,YACF,QACE,IAAAt4B,KAAAmL,aAAAgB,QAAAkG,EAAAlH,aAAAgB,OACF,QAGA,QADAssB,GAAAz4B,KAAAmL,aAAAgB,OACAud,EAAA,EAAmBA,EAAA+O,IAAkB/O,EACrC,IAAA1pB,KAAAmL,aAAAue,GAAAlZ,OAAA6B,EAAAlH,aAAAue,IACA,QAGA,UAZA,UAgBA1sB,EAAA+vB,uBnC87PM,SAAS9vB,EAAQD,EAASH,GoCp1PhC,QAAA6N,GAAA7L,EAAA4G,EAAA6mB,EAAAC,GAoBA,MAnBAC,GAAApvB,KAAA4C,KAAAyF,EAAA8mB,GACAvsB,KAAAnB,SACAmB,KAAAssB,gBAEAtsB,KAAA04B,eAAA/tB,EAAAguB,GAEA34B,KAAAuxB,OAAA,KACAvxB,KAAA44B,YAAA,EACA54B,KAAA64B,cAAA,KACA74B,KAAA84B,KAAA,KASA94B,KAAAid,WAAA,KACAjd,KAlDA,GAAAwK,GAAA3N,EAAA,GACA0Q,EAAA/C,EAAA+C,IACAC,EAAAhD,EAAAgD,OACAuD,EAAAvG,EAAAuG,WACAtG,EAAA5N,EAAA,GAAA4N,IACAgD,EAAA5Q,EAAA,IAAA4Q,UACAqf,EAAAjwB,EAAA,IAAAiwB,aACAtmB,EAAA3J,EAAA,GAAA2J,MACAomB,EAAA/vB,EAAA,IAAA+vB,SACAmK,EAAAl6B,EAAA,IAAAk6B,eACAvK,EAAA3vB,EAAA,IAAA2vB,aACA7hB,EAAA9N,EAAA,IAAA8N,eACAmS,EAAAjgB,EAAA,IAAAigB,YAEApI,GADA7X,EAAA,IAAAyN,kBACAzN,EAAA,IAAA6X,iBACAmC,EAAAha,EAAA,IAAAga,mBACAnJ,EAAA7Q,EAAA,IAAA6Q,cACAM,EAAAnR,EAAA,IAAAmR,kBACAzD,EAAA1N,EAAA,IAAA0N,SACAqa,EAAA/nB,EAAA,IACA0d,EAAAqK,EAAArK,WACAiB,EAAAoJ,EAAApJ,cACA5N,EAAAgX,EAAAhX,iBACAD,EAAAiX,EAAAjX,eACA0N,EAAAuJ,EAAAvJ,iBACA+a,EAAAv5B,EAAA,IAAAu5B,qBAEAnoB,EAAApR,EAAA,IAAAoR,2BACAF,EAAAlR,EAAA,IAAAkR,gCAyBArD,GAAApK,UAAAC,OAAAC,OAAAgsB,EAAAlsB,WACAoK,EAAApK,UAAAF,YAAAsK,EAEAA,EAAApK,UAAA2sB,OAAA,EACAviB,EAAApK,UAAAy4B,0BAAA,EACAruB,EAAApK,UAAA4sB,WAAA,EACAxiB,EAAApK,UAAA04B,aAAA,EAGAtuB,EAAApK,UAAA0lB,MAAA,aAGAtb,EAAApK,UAAA24B,gBAAA,SAAA5zB,EAAAkH,EAAAiM,IACAxY,KAAAitB,OAAAjtB,KAAA+4B,2BACAlL,QAAAjqB,IAAA,4BAAA2I,EACA,gBAAAvM,KAAAk5B,iBAAA7zB,GACA,SAAAA,EAAA8zB,GAAA,GAAA7lB,KAAA,IACAjO,EAAA8zB,GAAA,GAAA5lB,QAEAvT,KAAAuxB,OAAAlsB,EACArF,KAAA44B,YAAAvzB,EAAAe,MACApG,KAAA64B,cAAArgB,CAEA,IAAAnS,GAAArG,KAAAssB,cAAA/f,EACAvM,MAAA84B,KAAAzyB,CACA,IAAAhJ,GAAAgI,EAAAmoB,OACApnB,EAAAf,EAAAe,KAIA,KACA,GAAAqnB,EASA,IALAA,EAHApnB,EAAA+yB,cAGA/yB,EAAAgzB,wBAAAr5B,KAAAnB,OAAAy6B,iBAGAjzB,EAAAonB,GAEA,OAAAA,EAAA,CACA,OAAAjV,IACAA,EAAAsE,EAAAjO,QAEA7O,KAAAitB,OAAAjtB,KAAA+4B,2BACAlL,QAAAjqB,IAAA,uBAAAyC,EAAAkG,SACA,gBAAAvM,KAAAk5B,iBAAA7zB,GACA,kBAAAmT,EAAAzG,SAAA/R,KAAAnB,OAAAiL,aAOAzD,EAAA+yB,eAAA/yB,EAAAkzB,wBAAA1iB,IACAxQ,EAAAkzB,cAAAxiB,wBACA1Q,EAAAmzB,kBAAA,EAGA,IAAAjC,IAAA,EACAxJ,EAAA/tB,KAAAguB,kBAAA3nB,EAAAkzB,cAAAzc,EAAAjO,MAAA0oB,EAEAlxB,GAAA+yB,eAOArL,EAAA/tB,KAAAy5B,sBAAA1L,GACAN,EAAAztB,KAAAouB,YAAA/nB,EAAA,GAAAumB,GAAA,KAAAmB,IACA1nB,EAAAqzB,wBAAA15B,KAAAnB,OAAAy6B,gBAAA7L,KAEAA,EAAAztB,KAAAouB,YAAA/nB,EAAA,GAAAumB,GAAA,KAAAmB,IACA1nB,EAAAonB,MAGA,GAAAlf,GAAAvO,KAAA2tB,QAAAtnB,EAAAonB,EAAApoB,EAAAe,EAAAoS,EAIA,OAHAxY,MAAAitB,OACAY,QAAAjqB,IAAA,yBAAAyC,EAAA0L,SAAA/R,KAAAnB,OAAA+K,eAEA2E,EACK,QACLvO,KAAA84B,KAAA,KACA94B,KAAAid,WAAA,KACA5X,EAAA2qB,KAAA5pB,GACAf,EAAAuoB,QAAAvwB,KAiCAqN,EAAApK,UAAAqtB,QAAA,SAAAtnB,EAAAonB,EAAApoB,EAAAonB,EAAAjU,IACAxY,KAAAitB,OAAAjtB,KAAA+4B,2BACAlL,QAAAjqB,IAAA,oBAAAyC,EAAAkG,SACA,gBAAAvM,KAAAk5B,iBAAA7zB,GACA,SAAAA,EAAA8zB,GAAA,GAAA7lB,KAAA,IAAAjO,EAAA8zB,GAAA,GAAA5lB,OAEA,IAAAhF,GACAorB,EAAAlM,CAEAztB,MAAAitB,OACAY,QAAAjqB,IAAA,QAAA6pB,EAGA,KADA,GAAA5d,GAAAxK,EAAAspB,GAAA,KACA,CACA,GAAAiL,GAAA55B,KAAA4uB,uBAAA+K,EAAA9pB,EAIA,IAHA,OAAA+pB,IACAA,EAAA55B,KAAA6uB,mBAAAxoB,EAAAszB,EAAA9pB,IAEA+pB,IAAApN,EAAAsC,MAAA,CAUA,GAAA6D,GAAA3yB,KAAA65B,YAAAx0B,EAAAmT,EAAAmhB,EAAAnL,QAAA/B,EAGA,IAFApnB,EAAA2qB,KAAAvD,GACAle,EAAAvO,KAAA85B,wDAAAH,EAAAnL,QAAAhW,GACAjK,IAAA9D,EAAA6C,mBACA,MAAAiB,EAEA,MAAAokB,GAGA,GAAAiH,EAAA3C,qBAAAj3B,KAAA04B,iBAAA/tB,EAAAovB,IAAA,CAEA,GAAAvE,GAAA,IACA,WAAAoE,EAAA1C,WAAA,CACAl3B,KAAAitB,OACAY,QAAAjqB,IAAA,6CAEA,IAAAo2B,GAAA30B,EAAAe,KAKA,IAJA4zB,IAAAvN,GACApnB,EAAA2qB,KAAAvD,GAEA+I,EAAAx1B,KAAAi6B,oBAAAL,EAAA1C,WAAA1e,GAAA,GACA,IAAAgd,EAAArpB,OAIA,MAHAnM,MAAAitB,OACAY,QAAAjqB,IAAA,mBAEA4xB,EAAArjB,UAEA6nB,KAAAvN,GAGApnB,EAAA2qB,KAAAgK,GAGAh6B,KAAAktB,WACAW,QAAAjqB,IAAA,uBAAA4U,EAAA,OAAAohB,EAEA,IAAArC,IAAA,EACAxJ,EAAA/tB,KAAAguB,kBAAA3nB,EAAAkzB,cAAA/gB,EAAA+e,EAGA,OAFAv3B,MAAAu1B,4BAAAlvB,EAAAmvB,EAAAoE,EAAApL,QAAA/B,EAAApnB,EAAAe,OACAmI,EAAAvO,KAAAk6B,uBAAA7zB,EAAAuzB,EAAA7L,EAAA1oB,EAAAonB,EAAAjU,GAGA,GAAAohB,EAAAnL,cAAA,CACA,UAAAmL,EAAA1C,WACA,MAAA0C,GAAAtK,UAEA,IAAA8F,GAAA/vB,EAAAe,KACAf,GAAA2qB,KAAAvD,EACA,IAAA2K,GAAAp3B,KAAAi6B,oBAAAL,EAAA1C,WAAA1e,GAAA,EACA,QAAA4e,EAAAjrB,OACA,KAAAnM,MAAA65B,YAAAx0B,EAAAmT,EAAAohB,EAAApL,QAAA/B;AACa,WAAA2K,EAAAjrB,OACbirB,EAAAjlB,YAGAnS,KAAAm1B,gBAAA9uB,EAAAuzB,EAAAnN,EAAA2I,GAAA,EAAAgC,EAAAwC,EAAApL,SACA4I,EAAAjlB,YAGAwnB,EAAAC,EAEA/pB,IAAArJ,EAAAD,MACAlB,EAAA0pB,UACAlf,EAAAxK,EAAAspB,GAAA,MAeAjkB,EAAApK,UAAAsuB,uBAAA,SAAA+K,EAAA9pB,GACA,GAAAof,GAAA0K,EAAA1K,KACA,eAAAA,EACA,KAEAA,EAAApf,EAAA,UAeAnF,EAAApK,UAAAuuB,mBAAA,SAAAxoB,EAAAszB,EAAA9pB,GACA,GAAAqf,GAAAlvB,KAAAm6B,gBAAAR,EAAAnL,QAAA3e,GAAA,EACA,WAAAqf,EAEA,MADAlvB,MAAAqvB,WAAAhpB,EAAAszB,EAAA9pB,EAAA2c,EAAAsC,OACAtC,EAAAsC,KAGA,IAAA8K,GAAA,GAAAhN,GAAA,KAAAsC,GAEAkL,EAAAp6B,KAAAq6B,aAAAnL,EAEA,IAAAlvB,KAAAitB,MAAA,CACA,GAAAqN,GAAA3vB,EAAA4vB,yBAAArL,EACArB,SAAAjqB,IAAA,kBAAA4G,EAAA6F,cAAAiqB,GACA,cAAAX,EAAAnL,QACA,aAAAU,EACA,aAAAkL,EACA,wBACAzvB,EAAA6vB,mBAAAF,GAAA,qBACAt6B,KAAAy6B,mBAAAvL,IAuBA,MArBAkL,KAAA3vB,EAAA6C,oBAEAssB,EAAAnL,eAAA,EACAmL,EAAApL,QAAAiJ,UAAA2C,EACAR,EAAAtK,WAAA8K,GACKzvB,EAAA+vB,oCAAA16B,KAAA04B,eAAAxJ,KAEL0K,EAAApL,QAAAgH,gBAAAx1B,KAAAy6B,mBAAAvL,GACA0K,EAAA3C,qBAAA,EAEA2C,EAAAnL,eAAA,EACAmL,EAAAtK,WAAAsK,EAAApL,QAAAgH,gBAAArjB,YAEAynB,EAAAnL,eAAAmL,EAAApL,QAAAN,qBACAluB,KAAA26B,kBAAAf,EAAA55B,KAAAyF,IAAA+G,iBAAAnG,EAAAkG,WACA,OAAAqtB,EAAA1C,aACA0C,EAAAtK,WAAA7kB,EAAA6C,qBAIAssB,EAAA55B,KAAAqvB,WAAAhpB,EAAAszB,EAAA9pB,EAAA+pB,IAIAlvB,EAAApK,UAAAq6B,kBAAA,SAAAvO,EAAAwO,GAGA,GAAAC,GAAAD,EAAA1tB,YAAAf,OAGA2uB,EAAA96B,KAAA+6B,8BAAA3O,EAAAoC,SACAwM,EAAAh7B,KAAAi7B,qBAAAH,EAAA1O,EAAAoC,QAAAqM,EACA,QAAAG,GACA5O,EAAA8K,WAAAl3B,KAAAk7B,wBAAAJ,EAAAE,GACA5O,EAAAkD,WAAA7kB,EAAA6C,oBAKA8e,EAAAkD,WAAAwL,EAAA3oB,YAKAzH,EAAApK,UAAA45B,uBAAA,SAAA7zB,EAAAuzB,EACAnM,EACApoB,EACAonB,EACAjU,IACAxY,KAAAitB,OAAAjtB,KAAA+4B,2BACAlL,QAAAjqB,IAAA,0BAAA6pB,EAEA,IAAA8J,IAAA,EACA4D,GAAA,EACAjM,EAAA,KACA9R,EAAAqQ,CACApoB,GAAA2qB,KAAAvD,EAGA,KAFA,GAAA5c,GAAAxK,EAAAspB,GAAA,GACAyL,OACA,CAEA,GADAlL,EAAAlvB,KAAAm6B,gBAAA/c,EAAAvN,EAAA0nB,GACA,OAAArI,EAAA,CAUA,GAAAyD,GAAA3yB,KAAA65B,YAAAx0B,EAAAmT,EAAA4E,EAAAqP,EACApnB,GAAA2qB,KAAAvD,EACA,IAAAle,GAAAvO,KAAA85B,wDAAA1c,EAAA5E,EACA,IAAAjK,IAAA9D,EAAA6C,mBACA,MAAAiB,EAEA,MAAAokB,GAGA,GAAA2H,GAAA3vB,EAAA4vB,yBAAArL,EAQA,IAPAlvB,KAAAitB,OACAY,QAAAjqB,IAAA,iBAAA02B,EAAA,aACA3vB,EAAA0vB,aAAAC,GAAA,gCACA3vB,EAAAywB,2BAAAd,IAEApL,EAAAuI,UAAAz3B,KAAAq6B,aAAAnL,GAEAA,EAAAuI,YAAAhtB,EAAA6C,mBAAA,CACA8sB,EAAAlL,EAAAuI,SACA,OACS,GAAAz3B,KAAA04B,iBAAA/tB,EAAA0wB,0BAET,GADAjB,EAAAzvB,EAAAywB,2BAAAd,GACAF,IAAA3vB,EAAA6C,mBACA,UAKA,IAAA3C,EAAA6vB,mBAAAF,IAAA3vB,EAAA2wB,gBAAAhB,GAAA,CACAa,GAAA,EACAf,EAAAzvB,EAAA4wB,mBAAAjB,EACA,OAMAld,EAAA8R,EACArf,IAAArJ,EAAAD,MACAlB,EAAA0pB,UACAlf,EAAAxK,EAAAspB,GAAA,IAMA,MAAAO,GAAAuI,YAAAhtB,EAAA6C,oBACAtN,KAAAy1B,yBAAApvB,EAAA+zB,EAAAlL,EAAAzC,EAAApnB,EAAAe,OACAg0B,IA6BAp6B,KAAAm1B,gBAAA9uB,EAAAuzB,EAAAnN,EAAApnB,EAAAe,MAAA+0B,EAAA,KAAAjM,GAEAkL,IAGA1vB,EAAApK,UAAA65B,gBAAA,SAAA5K,EAAA1f,EAAA0nB,GACAv3B,KAAAitB,OACAY,QAAAjqB,IAAA,yCAAA2rB,GAEA,OAAAvvB,KAAAid,aACAjd,KAAAid,WAAA,GAAAlM,GAiBA,QAfAyqB,GAAA,GAAA1O,GAAAyK,GAYAkE,EAAA,KAGApsB,EAAA,EAAiBA,EAAAkgB,EAAAH,MAAAjjB,OAAwBkD,IAAA,CACzC,GAAA/R,GAAAiyB,EAAAH,MAAA/f,EAIA,IAHArP,KAAAitB,OACAY,QAAAjqB,IAAA,WAAA5D,KAAA2vB,aAAA9f,GAAA,OAAAvS,GAEAA,EAAA2O,gBAAAyB,IACA6pB,GAAA1nB,IAAArJ,EAAAD,OACA,OAAAk1B,IACAA,MAEAA,EAAArvB,KAAA9O,GACA0C,KAAAitB,OACAY,QAAAjqB,IAAA,SAAAtG,EAAA,8BAKA,QAAAsS,GAAA,EAAoBA,EAAAtS,EAAA2O,MAAAiB,YAAAf,OAA6ByD,IAAA,CACjD,GAAA2H,GAAAja,EAAA2O,MAAAiB,YAAA0C,GACAhB,EAAA5O,KAAA4vB,mBAAArY,EAAA1H,EACA,WAAAjB,EAAA,CACA,GAAA6gB,GAAA,GAAAhiB,IAAyCxB,MAAA2C,GAAatR,EACtDk+B,GAAArsB,IAAAsgB,EAAAzvB,KAAAid,YACAjd,KAAAitB,OACAY,QAAAjqB,IAAA,SAAA6rB,EAAA,sBAMA,GAAAP,GAAA,IA2BA,IAhBA,OAAAuM,GAAA5rB,IAAArJ,EAAAD,MACA,IAAAi1B,EAAApM,MAAAjjB,OAKA+iB,EAAAsM,EACSx7B,KAAAq6B,aAAAmB,KAAA/wB,EAAA6C,qBAGT4hB,EAAAsM,IAMA,OAAAtM,EAAA,CACAA,EAAA,GAAApC,GAAAyK,EAGA,QAFAmE,GAAA,GAAAnuB,GACAuiB,EAAAjgB,IAAArJ,EAAAD,IACAiT,EAAA,EAAqBA,EAAAgiB,EAAApM,MAAAjjB,OAA6BqN,IAClDxZ,KAAAuvB,QAAAiM,EAAApM,MAAA5V,GAAA0V,EAAAwM,GAAA,EAAAnE,EAAAzH,GA+BA,GA5BAjgB,IAAArJ,EAAAD,MAkBA2oB,EAAAlvB,KAAA27B,mCAAAzM,MAAAsM,MAUA,OAAAC,GAAAlE,GAAA5sB,EAAAixB,yBAAA1M,IACA,OAAAtd,GAAA,EAAqBA,EAAA6pB,EAAAtvB,OAA4ByF,IACjDsd,EAAA/f,IAAAssB,EAAA7pB,GAAA5R,KAAAid,WAGA,YAAAiS,EAAAE,MAAAjjB,OACA,KAEA+iB,GAuBAxkB,EAAApK,UAAAq7B,mCAAA,SAAAnN,EAAAqN,GACA,GAAAlxB,EAAAmxB,2BAAAtN,GACA,MAAAA,EAGA,QADArwB,GAAA,GAAA2uB,GAAA0B,EAAA+I,SACAloB,EAAA,EAAgBA,EAAAmf,EAAAY,MAAAjjB,OAAwBkD,IAAA,CACxC,GAAAmF,GAAAga,EAAAY,MAAA/f,EACA,IAAAmF,EAAAvI,gBAAAyB,GACAvP,EAAAgR,IAAAqF,EAAAxU,KAAAid,gBAGA,IAAA4e,GAAArnB,EAAAvI,MAAAqJ,uBAAA,CACA,GAAAvJ,GAAA/L,KAAAyF,IAAAsG,WAAAyI,EAAAvI,MACA,IAAAF,EAAAY,SAAAnG,EAAAoG,SAAA,CACA,GAAAmvB,GAAA/7B,KAAAyF,IAAAuF,gBAAAwJ,EAAAvI,MAAAwD,UACAtR,GAAAgR,IAAA,GAAA1B,IAA0CxB,MAAA8vB,GAAqBvnB,GAAAxU,KAAAid,cAI/D,MAAA9e,IAGAuM,EAAApK,UAAA0tB,kBAAA,SAAAzwB,EAAAkO,EAAA8rB,GAIA,OAFAtH,GAAAliB,EAAA/N,KAAAyF,IAAAgG,GACA+iB,EAAA,GAAA1B,GAAAyK,GACAloB,EAAA,EAAgBA,EAAA9R,EAAA2P,YAAAf,OAAuBkD,IAAA,CACvC,GAAAT,GAAArR,EAAA2P,YAAAmC,GAAAT,OACAtR,EAAA,GAAAmQ,IAA+BxB,MAAA2C,EAAAL,IAAAc,EAAA,EAAA1O,QAAAsvB,GAAgD,MAC/EyL,EAAA,GAAAnuB,EACAvN,MAAAuvB,QAAAjyB,EAAAkxB,EAAAkN,GAAA,EAAAnE,GAAA,GAEA,MAAA/I,IA2DA9jB,EAAApK,UAAAm5B,sBAAA,SAAAjL,GAIA,OAHAha,GACAwnB,KACAC,EAAA,GAAAnP,GAAA0B,EAAA+I,SACAloB,EAAA,EAAgBA,EAAAmf,EAAAY,MAAAjjB,OAAwBkD,IAGxC,GAFAmF,EAAAga,EAAAY,MAAA/f,GAEA,IAAAmF,EAAAjG,IAAA,CAGA,GAAA2tB,GAAA1nB,EAAAJ,gBAAAqE,eAAAzY,KAAAnB,OAAAmB,KAAA64B,cACA,QAAAqD,IAIAF,EAAAxnB,EAAAvI,MAAAC,aAAAsI,EAAA7T,QACAu7B,IAAA1nB,EAAAJ,gBACA6nB,EAAA9sB,IAAA,GAAA1B,IAAyC2G,gBAAA8nB,GAA+B1nB,GAAAxU,KAAAid,YAExEgf,EAAA9sB,IAAAqF,EAAAxU,KAAAid,aAGA,IAAA5N,EAAA,EAAYA,EAAAmf,EAAAY,MAAAjjB,OAAwBkD,IAEpC,GADAmF,EAAAga,EAAAY,MAAA/f,GACA,IAAAmF,EAAAjG,IAAA,CAOA,IAAAiG,EAAAD,2BAAA,CACA,GAAA5T,GAAAq7B,EAAAxnB,EAAAvI,MAAAC,cAAA,IACA,WAAAvL,KAAA6P,OAAAgE,EAAA7T,SAEA,SAGAs7B,EAAA9sB,IAAAqF,EAAAxU,KAAAid,YAEA,MAAAgf,IAGAvxB,EAAApK,UAAAsvB,mBAAA,SAAArY,EAAAkL,GACA,MAAAlL,GAAAwE,QAAA0G,EAAA,EAAAziB,KAAAyF,IAAAoF,cACA0M,EAAA3I,OAEA,MAIAlE,EAAApK,UAAA26B,qBAAA,SAAA3F,EAAA9G,EAAAqM,GAcA,OADAG,MACA3rB,EAAA,EAAgBA,EAAAmf,EAAAY,MAAAjjB,OAAuBkD,IAAA,CACvC,GAAA/R,GAAAkxB,EAAAY,MAAA/f,EACAimB,GAAA3oB,SAAArP,EAAAiR,OACAysB,EAAA19B,EAAAiR,KAAAmG,EAAAiE,UAAAqiB,EAAA19B,EAAAiR,MAAA,KAAAjR,EAAA8W,kBAGA,GAAA+nB,GAAA,CACA,KAAA9sB,EAAA,EAAcA,EAAAwrB,EAAA,EAAWxrB,IAAA,CACzB,GAAA2nB,GAAAgE,EAAA3rB,IAAA,IACA,QAAA2nB,EACAgE,EAAA3rB,GAAAqF,EAAAC,KACSqiB,IAAAtiB,EAAAC,OACTwnB,GAAA,GAUA,MANA,KAAAA,IACAnB,EAAA,MAEAh7B,KAAAitB,OACAY,QAAAjqB,IAAA,+BAAA4G,EAAA6F,cAAA2qB,IAEAA,GAGAtwB,EAAApK,UAAA46B,wBAAA,SAAA5F,EAAA0F,GAGA,OAFAoB,MACAC,GAAA,EACAhtB,EAAA,EAAiBA,EAAA2rB,EAAA7uB,OAAoBkD,IAAA,CACrC,GAAA2nB,GAAAgE,EAAA3rB,EAEA,QAAAimB,KAAA3oB,SAAA0C,IACA+sB,EAAAhwB,KAAA,GAAA2qB,GAAAC,EAAA3nB,IAEA2nB,IAAAtiB,EAAAC,OACA0nB,GAAA,GAGA,MAAAA,GAGAD,EAFA,MAmDA1xB,EAAApK,UAAAw5B,wDAAA,SAAAtL,EAAAhW,GACA,GAAAsY,GAAA9wB,KAAAs8B,iCAAA9N,EAAAhW,GACA+jB,EAAAzL,EAAA,GACA0L,EAAA1L,EAAA,GACAviB,EAAAvO,KAAAy8B,oCAAAF,EACA,OAAAhuB,KAAA9D,EAAA6C,mBACAiB,EAGAiuB,EAAApN,MAAAjjB,OAAA,IACAoC,EAAAvO,KAAAy8B,oCAAAD,GACAjuB,IAAA9D,EAAA6C,oBACAiB,EAGA9D,EAAA6C,oBAGA5C,EAAApK,UAAAm8B,oCAAA,SAAAjO,GAEA,OADA4I,MACA/nB,EAAA,EAAgBA,EAAAmf,EAAAY,MAAAjjB,OAAuBkD,IAAA,CACvC,GAAA/R,GAAAkxB,EAAAY,MAAA/f,IACA/R,EAAA+W,wBAAA,GAAA/W,EAAA2O,gBAAAyB,IAAApQ,EAAAqD,QAAAoe,iBACAqY,EAAAvlB,QAAAvU,EAAAiR,KAAA,GACA6oB,EAAAhrB,KAAA9O,EAAAiR,KAIA,WAAA6oB,EAAAjrB,OACA1B,EAAA6C,mBAEAtM,KAAAoR,IAAAvS,MAAA,KAAAu3B,IAYA1sB,EAAApK,UAAAg8B,iCAAA,SAAA9N,EAAAhW,GAGA,OAFAkkB,GAAA,GAAA5P,GAAA0B,EAAA+I,SACAoF,EAAA,GAAA7P,GAAA0B,EAAA+I,SACAloB,EAAA,EAAgBA,EAAAmf,EAAAY,MAAAjjB,OAAuBkD,IAAA,CACvC,GAAA/R,GAAAkxB,EAAAY,MAAA/f,EACA,IAAA/R,EAAA8W,kBAAAM,EAAAC,KAAA,CACA,GAAAioB,GAAAt/B,EAAA8W,gBAAAmE,SAAAvY,KAAAnB,OAAA2Z,EACAokB,GACAF,EAAAvtB,IAAA7R,GAEAq/B,EAAAxtB,IAAA7R,OAGAo/B,GAAAvtB,IAAA7R,GAGA,OAAAo/B,EAAAC,IASAjyB,EAAApK,UAAA25B,oBAAA,SAAA4C,EAAArkB,EAAAskB,GAEA,OADAC,GAAA,GAAAvvB,GACA6B,EAAA,EAAgBA,EAAAwtB,EAAA1wB,OAAyBkD,IAAA,CACzC,GAAAmY,GAAAqV,EAAAxtB,EACA,IAAAmY,EAAAwP,OAAAtiB,EAAAC,KAAA,CAOA,GAAAioB,GAAApV,EAAAwP,KAAAze,SAAAvY,KAAAnB,OAAA2Z,EAIA,KAHAxY,KAAAitB,OAAAjtB,KAAAktB,YACAW,QAAAjqB,IAAA,aAAA4jB,EAAA,IAAAoV,GAEAA,KACA58B,KAAAitB,OAAAjtB,KAAAktB,YACAW,QAAAjqB,IAAA,WAAA4jB,EAAAjZ,KAEAwuB,EAAA5tB,IAAAqY,EAAAjZ,MACAuuB,GACA,UAfA,IADAC,EAAA5tB,IAAAqY,EAAAjZ,MACAuuB,EACA,MAkBA,MAAAC,IAUAryB,EAAApK,UAAAivB,QAAA,SAAA/a,EAAAga,EAAAkN,EAAAsB,EAAAzF,EAAAzH,GACA,GAAAmN,GAAA,CACAj9B,MAAAk9B,yBAAA1oB,EAAAga,EAAAkN,EAAAsB,EACAzF,EAAA0F,EAAAnN,IAIAplB,EAAApK,UAAA48B,yBAAA,SAAA1oB,EAAAga,EAAAkN,EAAAsB,EAAAzF,EAAAnY,EAAA0Q,GACA,GAAA9vB,KAAAitB,QACAY,QAAAjqB,IAAA,WAAA4Q,EAAAzC,SAAA/R,KAAAnB,QAAA,QACAgvB,QAAAjqB,IAAA,WAAA4qB,EAAAzc,WAAA,KACAyC,EAAAH,wBAAA,IACA,cAGA,IAAAG,EAAAvI,gBAAAyB,GAAA,CAGA,IAAA8G,EAAA7T,QAAAyO,UAAA,CACA,OAAAC,GAAA,EAA2BA,EAAAmF,EAAA7T,QAAAwL,OAAyBkD,IACpD,GAAAmF,EAAA7T,QAAA4O,eAAAF,KAAArB,EAAA0O,mBAAA,CAcA,GAAApN,GAAAtP,KAAAyF,IAAAqF,OAAA0J,EAAA7T,QAAA4O,eAAAF,IACAS,EAAA0E,EAAA7T,QAAAgP,UAAAN,GACA8tB,GAA6BlxB,MAAAqD,EAAAf,IAAAiG,EAAAjG,IAAA5N,QAAAmP,EAAAsE,gBAAAI,EAAAJ,iBAC7B9W,EAAA,GAAAmQ,GAAA0vB,EAAA,KAIA7/B,GAAA+W,wBAAAG,EAAAH,wBACArU,KAAAk9B,yBAAA5/B,EAAAkxB,EAAAkN,EAAAsB,EAAAzF,EAAAnY,EAAA,EAAA0Q,OAtBA,CACA,GAAAyH,EAAA,CACA/I,EAAArf,IAAA,GAAA1B,IAAmDxB,MAAAuI,EAAAvI,MAAAtL,QAAAqN,EAAAa,OAAoD2F,GAAAxU,KAAAid,WACvG,UAGAjd,KAAAitB,OACAY,QAAAjqB,IAAA,oBAAA5D,KAAAo9B,YAAA5oB,EAAAvI,MAAAwD,YAEAzP,KAAAq9B,SAAA7oB,EAAAga,EAAAkN,EAAAsB,EACAzF,EAAAnY,EAAA0Q,GAcA,OACS,GAAAyH,EAGT,WADA/I,GAAArf,IAAAqF,EAAAxU,KAAAid,WAIAjd,MAAAitB,OACAY,QAAAjqB,IAAA,oBAAA5D,KAAAo9B,YAAA5oB,EAAAvI,MAAAwD,YAIAzP,KAAAq9B,SAAA7oB,EAAAga,EAAAkN,EAAAsB,EAAAzF,EAAAnY,EAAA0Q,IAIAplB,EAAApK,UAAA+8B,SAAA,SAAA7oB,EAAAga,EAAAkN,EAAAsB,EAAAzF,EAAAnY,EAAA0Q,GACA,GAAAvyB,GAAAiX,EAAAvI,KAEA1O,GAAA+X,wBACAkZ,EAAArf,IAAAqF,EAAAxU,KAAAid,WAIA,QAAA5N,GAAA,EAAkBA,EAAA9R,EAAA2P,YAAAf,OAAuBkD,IAAA,CACzC,GAAAQ,GAAAtS,EAAA2P,YAAAmC,GACAiuB,EAAAN,KAAAntB,YAAAwL,IACA/d,EAAA0C,KAAAowB,iBAAA5b,EAAA3E,EAAAytB,EAAA,IAAAle,EAAAmY,EAAAzH,EACA,WAAAxyB,EAAA,CACA,IAAAuS,EAAAE,WAAA2rB,EAAAvsB,IAAA7R,OAEA,QAEA,IAAAigC,GAAAne,CACA,IAAA5K,EAAAvI,gBAAAyB,GAAA,CAOA,GAAAguB,EAAAvsB,IAAA7R,OAEA,QAGA,QAAA0C,KAAA84B,MAAA94B,KAAA84B,KAAAM,eACAvpB,EAAAmL,4BAAAhb,KAAA84B,KAAAS,cAAA9pB,YACAnS,EAAAiX,4BAAA,GAIAjX,EAAA+W,yBAAA,EACAma,EAAAkJ,sBAAA,EACA6F,GAAA,EACAv9B,KAAAitB,OACAY,QAAAjqB,IAAA,wBAAAtG,OAEauS,aAAAlC,IAEb4vB,GAAA,IACAA,GAAA,EAGAv9B,MAAAk9B,yBAAA5/B,EAAAkxB,EAAAkN,EAAA4B,EAAA/F,EAAAgG,EAAAzN,MAKAplB,EAAApK,UAAA88B,YAAA,SAAAh3B,GACA,cAAApG,KAAAnB,QAAAuH,GAAA,EACApG,KAAAnB,OAAAiL,UAAA1D,GAEA,SAAAA,EAAA,KAIAsE,EAAApK,UAAA8vB,iBAAA,SAAA5b,EAAA3E,EAAAmtB,EAAAQ,EAAAjG,EAAAzH,GACA,OAAAjgB,EAAA8K,mBACA,IAAAJ,GAAAO,KACA,MAAA9a,MAAAy9B,eAAAjpB,EAAA3E,EACA,KAAA0K,GAAAsB,WACA,MAAA7b,MAAA09B,qBAAAlpB,EAAA3E,EAAAmtB,EAAAQ,EAAAjG,EACA,KAAAhd,GAAAa,UACA,MAAApb,MAAA29B,eAAAnpB,EAAA3E,EAAAmtB,EAAAQ,EAAAjG,EACA,KAAAhd,GAAAgB,OACA,MAAAvb,MAAA49B,iBAAAppB,EAAA3E,EACA,KAAA0K,GAAA3N,QACA,UAAAa,IAA8BxB,MAAA4D,EAAAjB,QAAe4F,EAC7C,KAAA+F,GAAAK,KACA,IAAAL,GAAAW,MACA,IAAAX,GAAAkB,IAGA,MAAAqU,IACAjgB,EAAAkM,QAAAvV,EAAAD,IAAA,KACA,GAAAkH,IAAsCxB,MAAA4D,EAAAjB,QAAgB4F,GAGtD,IACA,SACA,cAIA9J,EAAApK,UAAAs9B,iBAAA,SAAAppB,EAAA3E,GAIA,MAHA7P,MAAAitB,OACAY,QAAAjqB,IAAA,eAAAiM,EAAAJ,UAAA,IAAAI,EAAAyL,aAEA,GAAA7N,IAA0BxB,MAAA4D,EAAAjB,QAAe4F,IAGzC9J,EAAApK,UAAAo9B,qBAAA,SAAAlpB,EAAAqpB,EAAAb,EAAAQ,EAAAjG,GACAv3B,KAAAitB,QACAY,QAAAjqB,IAAA,2BAAAo5B,EAAA,KACAa,EAAAhmB,WAAA,4BACA,OAAA7X,KAAAnB,QACAgvB,QAAAjqB,IAAA,+BAAA4G,EAAA6F,cAAArQ,KAAAnB,OAAAi/B,2BAGA,IAAAxgC,GAAA,IACA,IAAA0/B,GAAAQ,EACA,GAAAjG,EAAA,CAKA,GAAAwG,GAAA/9B,KAAAuxB,OAAAnrB,KACApG,MAAAuxB,OAAAvB,KAAAhwB,KAAA44B,YACA,IAAAoF,GAAAH,EAAA1hB,eAAA5D,SAAAvY,KAAAnB,OAAAmB,KAAA64B,cACA74B,MAAAuxB,OAAAvB,KAAA+N,GACAC,IACA1gC,EAAA,GAAAmQ,IAAmCxB,MAAA4xB,EAAAjvB,QAAgB4F,QAGnDypB,WAAAvpB,EAAAgE,WAAAlE,EAAAJ,gBAAAypB,EAAA1hB,gBACA7e,EAAA,GAAAmQ,IAA+BxB,MAAA4xB,EAAAjvB,OAAAwF,gBAAA6pB,WAA2CzpB,OAG1ElX,GAAA,GAAAmQ,IAA2BxB,MAAA4xB,EAAAjvB,QAAgB4F,EAK3C,OAHAxU,MAAAitB,OACAY,QAAAjqB,IAAA,+BAAAtG,GAEAA,GAGAoN,EAAApK,UAAAq9B,eAAA,SAAAnpB,EAAAqpB,EAAAb,EAAAQ,EAAAjG,GACAv3B,KAAAitB,QACAY,QAAAjqB,IAAA,2BAAAo5B,EAAA,KAAAa,EAAApuB,UACA,IAAAouB,EAAAnmB,UAAA,mBAAAmmB,EAAAlmB,gBACA,OAAA3X,KAAAnB,QACAgvB,QAAAjqB,IAAA,+BAAA4G,EAAA6F,cAAArQ,KAAAnB,OAAAi/B,2BAGA,IAAAxgC,GAAA,IACA,IAAA0/B,IAAAa,EAAAlmB,gBAAA6lB,IAAAK,EAAAlmB,gBACA,GAAA4f,EAAA,CAKA,GAAAwG,GAAA/9B,KAAAuxB,OAAAnrB,KACApG,MAAAuxB,OAAAvB,KAAAhwB,KAAA44B,YACA,IAAAoF,GAAAH,EAAA1hB,eAAA5D,SAAAvY,KAAAnB,OAAAmB,KAAA64B,cACA74B,MAAAuxB,OAAAvB,KAAA+N,GACAC,IACA1gC,EAAA,GAAAmQ,IAAmCxB,MAAA4xB,EAAAjvB,QAAgB4F,QAE1C,CACT,GAAAypB,GAAAvpB,EAAAgE,WAAAlE,EAAAJ,gBAAAypB,EAAA1hB,eACA7e,GAAA,GAAAmQ,IAA+BxB,MAAA4xB,EAAAjvB,OAAAwF,gBAAA6pB,GAA2CzpB,OAG1ElX,GAAA,GAAAmQ,IAA2BxB,MAAA4xB,EAAAjvB,QAAgB4F,EAK3C,OAHAxU,MAAAitB,OACAY,QAAAjqB,IAAA,+BAAAtG,GAEAA,GAGAoN,EAAApK,UAAAm9B,eAAA,SAAAjpB,EAAA3E,GACA7P,KAAAitB,OACAY,QAAAjqB,IAAA,aAAA5D,KAAAo9B,YAAAvtB,EAAAjB,OAAAa,WAAA,SAAA+E,EAAA7T,QAEA,IAAA2O,GAAAO,EAAA1C,YACA2C,EAAA7B,EAAAzN,OAAAgU,EAAA7T,QAAA2O,EAAApD,YACA,WAAAuB,IAA0BxB,MAAA4D,EAAAjB,OAAAjO,QAAAmP,GAAmC0E,IAG7D9J,EAAApK,UAAAm6B,mBAAA,SAAAjM,GACA,GAAA0P,GAAAvzB,EAAA4vB,yBAAA/L,EACA,OAAA7jB,GAAAwzB,QAAAD,IAuCAxzB,EAAApK,UAAAy6B,8BAAA,SAAAvM,GACA,GAAAgH,GAAA,IAOA,OANAhH,GAAAiJ,YAAAhtB,EAAA6C,oBACAkoB,EAAA,GAAAhoB,GACAgoB,EAAArmB,IAAAqf,EAAAiJ,YAEAjC,EAAAhH,EAAAgH,gBAEAA,GAGA9qB,EAAApK,UAAAqvB,aAAA,SAAA9f,GACA,GAAAA,IAAArJ,EAAAD,IACA,WAEA,WAAAvG,KAAAnB,QAAA,OAAAmB,KAAAnB,OAAA+K,aAAA,CACA,KAAAiG,GAAA7P,KAAAnB,OAAA+K,aAAAuC,QAIA,MAAAnM,MAAAnB,OAAA+K,aAAAiG,GAAA,IAAAA,EAAA,GAHAge,SAAAjqB,IAAA,GAAAiM,EAAA,wBAAA7P,KAAAnB,OAAA+K,cACAikB,QAAAjqB,IAAA,GAAA5D,KAAAnB,OAAAgV,iBAAA6P,aAKA,SAAA7T,GAGAnF,EAAApK,UAAA44B,iBAAA,SAAA7zB,GACA,MAAArF,MAAA2vB,aAAAtqB,EAAAspB,GAAA,KAOAjkB,EAAApK,UAAA89B,mBAAA,SAAAC,GACAxQ,QAAAjqB,IAAA,qBAEA,QADA06B,GAAAD,EAAAE,oBACAlvB,EAAA,EAAgBA,EAAAivB,EAAAnyB,OAAekD,IAAA,CAC/B,GAAA/R,GAAAghC,EAAAjvB,GACAkI,EAAA,UACA,IAAAja,EAAA2O,MAAAiB,YAAAf,OAAA,GACA,GAAA0D,GAAAvS,EAAA2O,MAAAiB,YAAA,EACA,IAAA2C,YAAA2K,gBACAjD,EAAA,QAAAvX,KAAA2vB,aAAA9f,EAAAM,WACa,IAAAN,YAAA2L,GAAA,CACb,GAAAgjB,GAAA3uB,YAAAjC,EACA2J,IAAAinB,EAAA,eAAA3uB,EAAAK,KAGA2d,QAAA5jB,MAAA3M,EAAAyU,SAAA/R,KAAAnB,QAAA,OAAA0Y,KAIA7M,EAAApK,UAAAu5B,YAAA,SAAAx0B,EAAAmT,EAAAgW,EAAA/B,GACA,UAAA2J,GAAAp2B,KAAAnB,OAAAwG,IAAAmM,IAAAib,GAAApnB,EAAA8zB,GAAA,GAAA3K,EAAAhW,IAGA9N,EAAApK,UAAA+5B,aAAA,SAAA7L,GAEA,OADAjgB,GAAA9D,EAAA6C,mBACA+B,EAAA,EAAgBA,EAAAmf,EAAAY,MAAAjjB,OAAuBkD,IAAA,CACvC,GAAA/R,GAAAkxB,EAAAY,MAAA/f,EACA,IAAAd,IAAA9D,EAAA6C,mBACAiB,EAAAjR,EAAAiR,QACS,IAAAjR,EAAAiR,QACT,MAAA9D,GAAA6C,mBAGA,MAAAiB,IAuBA7D,EAAApK,UAAA+uB,WAAA,SAAAhpB,EAAAsqB,EAAA9gB,EAAAghB,GAIA,GAHA7wB,KAAAitB,OACAY,QAAAjqB,IAAA,QAAA+sB,EAAA,OAAAE,EAAA,SAAA7wB,KAAA2vB,aAAA9f,IAEA,OAAAghB,EACA,WAGA,IADAA,EAAA7wB,KAAAouB,YAAA/nB,EAAAwqB,GACA,OAAAF,GAAA9gB,QAAA7P,KAAAyF,IAAAoF,aACA,MAAAgmB,EAOA,IALA,OAAAF,EAAA1B,QACA0B,EAAA1B,UAEA0B,EAAA1B,MAAApf,EAAA,GAAAghB,EAEA7wB,KAAAitB,MAAA,CACA,GAAA7S,GAAA,OAAApa,KAAAnB,OAAA,KAAAmB,KAAAnB,OAAA+K,YACAikB,SAAAjqB,IAAA,SAAAyC,EAAA0L,SAAAqI,IAEA,MAAAyW,IAiBAnmB,EAAApK,UAAA8tB,YAAA,SAAA/nB,EAAAuzB,GACA,GAAAA,GAAApN,EAAAsC,MACA,MAAA8K,EAEA,IAAAxoB,GAAAwoB,EAAAlpB,aACAiO,EAAAtY,EAAAyE,OAAAsG,IAAA,IACA,eAAAuN,EACAA,GAEAib,EAAA1tB,YAAA7F,EAAAyE,OAAAqB,OACAytB,EAAApL,QAAA1iB,WACA8tB,EAAApL,QAAAuJ,gBAAA/3B,MACA45B,EAAApL,QAAA0C,aAAA,IAEA7qB,EAAAyE,OAAAsG,GAAAwoB,EACA55B,KAAAitB,OACAY,QAAAjqB,IAAA,yBAAAg2B,GAEAA,IAGAlvB,EAAApK,UAAAi1B,4BAAA,SAAAlvB,EAAAmvB,EAAAhH,EAAA/B,EAAA2I,GACA,GAAAp1B,KAAAitB,OAAAjtB,KAAAg5B,YAAA,CACA,GAAAyF,GAAA,GAAAl0B,GAAAkiB,EAAA2I,EAAA,EACAvH,SAAAjqB,IAAA,wCAAAyC,EAAAkG,SAAA,IAAAiiB,EACA,WAAAxuB,KAAAnB,OAAA6/B,iBAAA57B,QAAA27B,IAEA,OAAAz+B,KAAAnB,QACAmB,KAAAnB,OAAA20B,2BAAA+B,4BAAAv1B,KAAAnB,OAAAwH,EAAAomB,EAAA2I,EAAAI,EAAAhH,IAIA9jB,EAAApK,UAAAm1B,yBAAA,SAAApvB,EAAAipB,EAAAd,EAAA/B,EAAA2I,GACA,GAAAp1B,KAAAitB,OAAAjtB,KAAAg5B,YAAA,CACA,GAAAyF,GAAA,GAAAl0B,GAAAkiB,EAAA2I,EAAA,EACAvH,SAAAjqB,IAAA,qCAAAyC,EAAAkG,SAAA,IAAAiiB,EACA,WAAAxuB,KAAAnB,OAAA6/B,iBAAA57B,QAAA27B,IAEA,OAAAz+B,KAAAnB,QACAmB,KAAAnB,OAAA20B,2BAAAiC,yBAAAz1B,KAAAnB,OAAAwH,EAAAomB,EAAA2I,EAAA9F,EAAAd,IAKA9jB,EAAApK,UAAA60B,gBAAA,SAAA9uB,EAAAuzB,EAAAnN,EAAA2I,EACAC,EAAAC,EAAA9G,GACA,GAAAxuB,KAAAitB,OAAAjtB,KAAAg5B,YAAA,CACA,GAAAyF,GAAA,GAAAl0B,GAAAkiB,EAAA2I,EAAA,EACAvH,SAAAjqB,IAAA,mBAAA0xB,EAAA,IAAA9G,EACA,WAAAxuB,KAAAnB,OAAA6/B,iBAAA57B,QAAA27B,IAEA,OAAAz+B,KAAAnB,QACAmB,KAAAnB,OAAA20B,2BAAA2B,gBAAAn1B,KAAAnB,OAAAwH,EAAAomB,EAAA2I,EAAAC,EAAAC,EAAA9G,IAIAxxB,EAAA0N,sBpC2nQM,SAASzN,EAAQD,EAASH,GqCpuThC,QAAA8N,KACA,MAAA3K,MAVA,GACAwN,IADA3Q,EAAA,GAAA0Q,IACA1Q,EAAA,GAAA2Q,QACAsD,EAAAjU,EAAA,GAAAiU,QACArG,EAAA5N,EAAA,GAAA4N,IACAiD,EAAA7Q,EAAA,IAAA6Q,cACAof,EAAAjwB,EAAA,IAAAiwB,aACArf,EAAA5Q,EAAA,IAAA4Q,UACAiH,EAAA7X,EAAA,IAAA6X,eA2BA/J,GAAAovB,IAAA,EAmBApvB,EAAAguB,GAAA,EAkBAhuB,EAAA0wB,yBAAA,EA+FA1wB,EAAA+vB,oCAAA,SAAAjP,EAAA+C,GAMA,GAAA7jB,EAAAmxB,2BAAAtN,GACA,QAGA,IAAA/C,IAAA9gB,EAAAovB,KAIAvL,EAAAN,mBAAA,CAGA,OADAyQ,GAAA,GAAA7R,GACAzd,EAAA,EAAwBA,EAAAmf,EAAAY,MAAAjjB,OAAuBkD,IAAA,CAC/C,GAAA/R,GAAAkxB,EAAAY,MAAA/f,EACA/R,GAAA,GAAAmQ,IAAmC2G,gBAAAM,EAAAC,MAAqCrX,GACxEqhC,EAAAxvB,IAAA7R,GAEAkxB,EAAAmQ,EAKA,GAAAT,GAAAvzB,EAAA4vB,yBAAA/L,EACA,OAAA7jB,GAAAi0B,qBAAAV,KAAAvzB,EAAAk0B,6BAAArQ,IAWA7jB,EAAAixB,yBAAA,SAAApN,GACA,OAAAnf,GAAA,EAAaA,EAAAmf,EAAAY,MAAAjjB,OAAuBkD,IAAA,CACpC,GAAA/R,GAAAkxB,EAAAY,MAAA/f,EACA,IAAA/R,EAAA2O,gBAAAyB,GACA,SAGA,UAWA/C,EAAAmxB,2BAAA,SAAAtN,GACA,OAAAnf,GAAA,EAAaA,EAAAmf,EAAAY,MAAAjjB,OAAuBkD,IAAA,CACpC,GAAA/R,GAAAkxB,EAAAY,MAAA/f,EACA,MAAA/R,EAAA2O,gBAAAyB,IACA,SAGA,UAgJA/C,EAAAywB,2BAAA,SAAA8C,GACA,MAAAvzB,GAAA4wB,mBAAA2C,IAWAvzB,EAAA6vB,mBAAA,SAAA0D,GACA,OAAAvzB,EAAAm0B,wBAAAZ,IAUAvzB,EAAAm0B,wBAAA,SAAAZ,GACA,OAAA7uB,GAAA,EAAaA,EAAA6uB,EAAA/xB,OAAiBkD,IAAA,CAC9B,GAAA+nB,GAAA8G,EAAA7uB,EACA,QAAA+nB,EAAAjrB,OACA,SAGA,UAWAxB,EAAAi0B,qBAAA,SAAAV,GACA,OAAA7uB,GAAA,EAAaA,EAAA6uB,EAAA/xB,OAAiBkD,IAAA,CAC9B,GAAA+nB,GAAA8G,EAAA7uB,EACA,IAAA+nB,EAAAjrB,OAAA,EACA,SAGA,UAUAxB,EAAA2wB,gBAAA,SAAA4C,GAEA,OADA9kB,GAAA,KACA/J,EAAA,EAAaA,EAAA6uB,EAAA/xB,OAAiBkD,IAAA,CAC9B,GAAA+nB,GAAA8G,EAAA7uB,EACA,WAAA+J,EACAA,EAAAge,MACS,IAAAA,IAAAhe,EACT,SAGA,UAUAzO,EAAA0vB,aAAA,SAAA6D,GACA,GAAAa,GAAAp0B,EAAAwzB,QAAAD,EACA,YAAAa,EAAA5yB,OACA4yB,EAAA5sB,WAEA1H,EAAA6C,oBAWA3C,EAAAwzB,QAAA,SAAAD,GACA,GAAAa,GAAA,GAAAvxB,EAEA,OADA0wB,GAAAh4B,IAAA,SAAAkxB,GAAiC2H,EAAA/sB,GAAAolB,KACjC2H,GAYAp0B,EAAA4vB,yBAAA,SAAA/L,GAEA,OADAwQ,MACA3vB,EAAA,EAAaA,EAAAmf,EAAAY,MAAAjjB,OAAuBkD,IAAA,CACpC,GAAA/R,GAAAkxB,EAAAY,MAAA/f,GACAsC,EAAA,OAAArU,EAAA2O,MAAAC,YAAA,IAAA5O,EAAAqD,QACAy2B,EAAA4H,EAAArtB,IAAA,IACA,QAAAylB,IACAA,EAAA,GAAA5pB,GACAwxB,EAAArtB,GAAAylB,GAEAA,EAAAjoB,IAAA7R,EAAAiR,KAEA,GAAAkD,KACA,QAAA+H,KAAAwlB,GACA,IAAAxlB,EAAA3H,QAAA,SAGAJ,EAAArF,KAAA4yB,EAAAxlB,GAEA,OAAA/H,IAWA9G,EAAAs0B,iBAAA,SAAAzQ,GACA,GAAAnxB,GAAA,GAAAyT,EASA,OARA0d,GAAAY,MAAAlpB,IAAA,SAAA5I,GACA,GAAA85B,GAAA/5B,EAAAmU,IAAAlU,EAAA2O,MACA,QAAAmrB,IACAA,EAAA,GAAA5pB,GACAnQ,EAAAiV,IAAAhV,EAAA2O,MAAAmrB,IAEAA,EAAAjoB,IAAA7R,EAAAiR,OAEAlR,GAGAsN,EAAAk0B,6BAAA,SAAArQ,GAEA,OADA/c,GAAA9G,EAAAs0B,iBAAAzQ,GAAA/c,SACApC,EAAA,EAAgBA,EAAAoC,EAAAtF,OAAgBkD,IAChC,OAAAoC,EAAApC,GAAAlD,OACA,QAGA,WAGAxB,EAAA4wB,mBAAA,SAAA2C,GAEA,OADA//B,GAAA,KACAkR,EAAA,EAAaA,EAAA6uB,EAAA/xB,OAAiBkD,IAAA,CAC9B,GAAA+nB,GAAA8G,EAAA7uB,GACA6vB,EAAA9H,EAAAjlB,UACA,WAAAhU,EACAA,EAAA+gC,MACS,IAAA/gC,IAAA+gC,EACT,MAAAz0B,GAAA6C,mBAGA,MAAAnP,IAGAnB,EAAA2N,kBrCuxTM,SAAS1N,EAAQD,EAASH,GsCh2UhCG,EAAAsJ,IAAAzJ,EAAA,IAAAyJ,IACAtJ,EAAAmiC,cAAAtiC,EAAA,IAAAsiC,cACAniC,EAAAoiC,mBAAAviC,EAAA,IAAAuiC,mBACApiC,EAAA+5B,eAAAl6B,EAAA,IAAAk6B,gBtCu2UM,SAAS95B,EAAQD,EAASH,GuCv0UhC,QAAAwiC,KACA,MAAAr/B,MASA,QAAAsG,GAAAizB,EAAAhtB,GAeA,MAdAzM,UAAAyM,IACAA,EAAA,GAGAvM,KAAAu5B,gBACAv5B,KAAAuM,WAGAvM,KAAAs/B,QAAA,GAAAD,GACAr/B,KAAAytB,GAAA,KAIAztB,KAAAo5B,eAAA,EACAp5B,KA9BA,GAAA4sB,GAAA/vB,EAAA,IAAA+vB,SACAE,EAAAjwB,EAAA,IAAAiwB,aACAqS,EAAAtiC,EAAA,IAAAsiC,cACAC,EAAAviC,EAAA,IAAAuiC,kBAMA7+B,QAAAgR,eAAA8tB,EAAA/+B,UAAA,UACAkR,IAAA,WACA,MAAAjR,QAAA2R,KAAAlS,MAAAmM,UA+BA7F,EAAAhG,UAAA+4B,wBAAA,SAAAxhB,GACA,IAAA7X,KAAA,cACA,iEAGA,OAAA6X,GAAA,GAAAA,GAAA7X,KAAAytB,GAAAwB,MAAA9iB,OACA,KAEAnM,KAAAytB,GAAAwB,MAAApX,IAAA,MAYAvR,EAAAhG,UAAAo5B,wBAAA,SAAA7hB,EAAA9B,GACA,IAAA/V,KAAA,cACA,iEAEA6X,GAAA,IAOA7X,KAAAytB,GAAAwB,MAAApX,GAAA9B,IAoBAzP,EAAAhG,UAAAk5B,iBAAA,SAAAJ,GACA,GAAAp5B,KAAAo5B,kBAAA,CAEA,GADAp5B,KAAAs/B,QAAA,GAAAD,GACAjG,EAAA,CACA,GAAAmG,GAAA,GAAA3S,GAAA,GAAAE,GACAyS,GAAAtQ,SACAsQ,EAAA9Q,eAAA,EACA8Q,EAAAtI,qBAAA,EACAj3B,KAAAytB,GAAA8R,MAEAv/B,MAAAytB,GAAA,IAEAztB,MAAAo5B,kBAIA74B,OAAAgR,eAAAjL,EAAAhG,UAAA,UACAkR,IAAA,WACA,MAAAxR,MAAAs/B,WAKAh5B,EAAAhG,UAAAk/B,aAAA,WAIA,OAFAttB,GAAA3R,OAAA2R,KAAAlS,KAAAs/B,SACAjd,KACAhT,EAAA,EAAaA,EAAA6C,EAAA/F,OAAckD,IAC3BgT,EAAAjW,KAAApM,KAAAs/B,QAAAptB,EAAA7C,IAEA,OAAAgT,GAAAhK,KAAA,SAAA/H,EAAApQ,GACA,MAAAoQ,GAAApE,YAAAhM,EAAAgM,eAIA5F,EAAAhG,UAAAyR,SAAA,SAAAnI,EAAAC,GAGA,GAFAD,KAAA,KACAC,KAAA,KACA,OAAA7J,KAAAytB,GACA,QAEA,IAAAgS,GAAA,GAAAN,GAAAn/B,KAAA4J,EAAAC,EACA,OAAA41B,GAAA1tB,YAGAzL,EAAAhG,UAAAguB,cAAA,WACA,UAAAtuB,KAAAytB,GACA,QAEA,IAAAgS,GAAA,GAAAL,GAAAp/B,KACA,OAAAy/B,GAAA1tB,YAGA/U,EAAAsJ,OvCi3UM,SAASrJ,EAAQD,GwCjgVvB,QAAAmiC,GAAA94B,EAAAuD,EAAAC,GAIA,MAHA7J,MAAAqG,MACArG,KAAA4J,mBACA5J,KAAA6J,oBACA7J,KAoDA,QAAAo/B,GAAA/4B,GAEA,MADA84B,GAAA/hC,KAAA4C,KAAAqG,EAAA,MACArG,KAnDAm/B,EAAA7+B,UAAAyR,SAAA,WACA,UAAA/R,KAAAqG,IAAAonB,GACA,WAIA,QAFAiS,GAAA,GACA50B,EAAA9K,KAAAqG,IAAAm5B,eACAnwB,EAAA,EAAeA,EAAAvE,EAAAqB,OAAgBkD,IAAA,CAC/B,GAAA7D,GAAAV,EAAAuE,EACA,WAAA7D,EAAAyjB,MAEA,OADAlb,GAAAvI,EAAAyjB,MAAA9iB,OACAyD,EAAA,EAAwBA,EAAAmE,EAAInE,IAAA,CAC5B,GAAAC,GAAArE,EAAAyjB,MAAArf,IAAA,IACA,QAAAC,GAAA,aAAAA,EAAA3D,cACAwzB,IAAA5tB,OAAA9R,KAAA2/B,eAAAn0B,IACAk0B,IAAA5tB,OAAA,KACA4tB,IAAA5tB,OAAA9R,KAAA4/B,aAAAhwB,IACA8vB,IAAA5tB,OAAA,MACA4tB,IAAA5tB,OAAA9R,KAAA2/B,eAAA9vB,IACA6vB,IAAA5tB,OAAA,QAKA,WAAA4tB,EAAAvzB,OAAA,KAAAuzB,GAGAP,EAAA7+B,UAAAs/B,aAAA,SAAAvwB,GACA,WAAAA,EACA,MACK,OAAArP,KAAA4J,cAAA,OAAA5J,KAAA6J,cACL7J,KAAA4J,aAAAyF,EAAA,IAAArP,KAAA6J,cAAAwF,EAAA,GAEA6B,OAAAmJ,aAAAhL,EAAA,IAIA8vB,EAAA7+B,UAAAq/B,eAAA,SAAAn0B,GACA,GAAAq0B,IAAAr0B,EAAAijB,cAAA,YAAAjjB,EAAAU,aAAAV,EAAAyrB,oBAAA,OACA,OAAAzrB,GAAAijB,cACA,OAAAjjB,EAAA0rB,WACA2I,EAAA,KAAAr0B,EAAA0rB,WAAAnlB,WAEA8tB,EAAA,KAAAr0B,EAAA8jB,WAAAvd,WAGA8tB,GASAT,EAAA9+B,UAAAC,OAAAC,OAAA2+B,EAAA7+B,WACA8+B,EAAA9+B,UAAAF,YAAAg/B,EAEAA,EAAA9+B,UAAAs/B,aAAA,SAAAvwB,GACA,UAAA6B,OAAAmJ,aAAAhL,GAAA,KAGArS,EAAAmiC,gBACAniC,EAAAoiC,sBxCyiVM,SAASniC,EAAQD,EAASH,GyC9oVhC,GAAAwjB,GAAAxjB,EAAA,GACAG,GAAAgjB,MAAAnjB,EAAA,IAAAmjB,MACAhjB,EAAAkiB,SAAAmB,EAAAnB,SACAliB,EAAA2jB,kBAAAN,EAAAM,kBACA3jB,EAAA0jB,iBAAAL,EAAAK,iBACA1jB,EAAA+jB,gBAAAV,EAAAU,iBzCqpVM,SAAS9jB,EAAQD,EAASH,G0C1pVhCG,EAAA64B,qBAAAh5B,EAAA,IAAAg5B,qBACA74B,EAAAo5B,qBAAAv5B,EAAA,IAAAu5B,qBACAp5B,EAAAgwB,0BAAAnwB,EAAA,IAAAmwB,0BACAhwB,EAAAw5B,uBAAA35B,EAAA,IAAA25B,uBACAx5B,EAAAy5B,yBAAA55B,EAAA,IAAA45B,yBACAz5B,EAAA8iC,wBAAAjjC,EAAA,IAAAijC,wBACA9iC,EAAA+iC,kBAAAljC,EAAA,IAAAkjC,kBACA/iC,EAAA+3B,cAAAl4B,EAAA,IAAAk4B,e1CgqVM,SAAS93B,EAAQD,EAASH,G2CjnVhC,QAAAijC,GAAAE,GAKA,MAJAjL,GAAA33B,KAAA4C,MACAggC,MAAA,EAEAhgC,KAAAggC,YACAhgC,KATA,GAAAwN,GAAA3Q,EAAA,GAAA2Q,OACAunB,EAAAl4B,EAAA,IAAAk4B,cACAxqB,EAAA1N,EAAA,IAAA0N,QAUAu1B,GAAAx/B,UAAAC,OAAAC,OAAAu0B,EAAAz0B,WACAw/B,EAAAx/B,UAAAF,YAAA0/B,EAEAA,EAAAx/B,UAAA60B,gBAAA,SAAAF,EAAA5uB,EACAomB,EAAA2I,EAAAC,EAAAC,EAAA9G,GACA,IAAAxuB,KAAAggC,WAAA3K,EAAA,CAGA,GAAA/B,GAAA,qBACAtzB,KAAAigC,uBAAAhL,EAAA5uB,GACA,eACArG,KAAAy6B,mBAAAnF,EAAA9G,GACA,YACAyG,EAAAyJ,iBAAA57B,QAAA,GAAAyH,GAAAkiB,EAAA2I,IAAA,GACAH,GAAAiL,qBAAA5M,KAGAwM,EAAAx/B,UAAAi1B,4BAAA,SACAN,EAAA5uB,EAAAomB,EAAA2I,EAAAI,EAAAhH,GACA,GAAA8E,GAAA,iCACAtzB,KAAAigC,uBAAAhL,EAAA5uB,GACA,YACA4uB,EAAAyJ,iBAAA57B,QAAA,GAAAyH,GAAAkiB,EAAA2I,IAAA,GACAH,GAAAiL,qBAAA5M,IAGAwM,EAAAx/B,UAAAm1B,yBAAA,SACAR,EAAA5uB,EAAAomB,EAAA2I,EAAA9F,EAAAd,GACA,GAAA8E,GAAA,8BACAtzB,KAAAigC,uBAAAhL,EAAA5uB,GACA,YACA4uB,EAAAyJ,iBAAA57B,QAAA,GAAAyH,GAAAkiB,EAAA2I,IAAA,GACAH,GAAAiL,qBAAA5M,IAGAwM,EAAAx/B,UAAA2/B,uBAAA,SAAAhL,EAAA5uB,GACA,GAAAkG,GAAAlG,EAAAkG,SACAkD,EAAApJ,EAAAkzB,cAAA9pB,UAEA3F,EAAAmrB,EAAAnrB,SACA,IAAA2F,EAAA,GAAAA,GAAA3F,EAAAqC,OACA,SAAAI,CAEA,IAAA6T,GAAAtW,EAAA2F,IAAA,IACA,eAAA2Q,GAAA,IAAAA,EAAAjU,OACA,GAAAI,EAEA,GAAAA,EAAA,KAAA6T,EAAA,KAcA0f,EAAAx/B,UAAAm6B,mBAAA,SAAA0F,EAAA3R,GACA,UAAA2R,EACA,MAAAA,EAGA,QADAhiC,GAAA,GAAAqP,GACA6B,EAAA,EAAgBA,EAAAmf,EAAAY,MAAAjjB,OAA0BkD,IAC1ClR,EAAAgR,IAAAqf,EAAAY,MAAA/f,GAAAd,IAEA,WAAUpQ,EAAAsT,SAAA3L,KAAA,WAGV9I,EAAA8iC,2B3C6qVM,SAAS7iC,EAAQD,EAASH,G4C1wVhC,QAAAujC,MA2BA,QAAAC,KAkBA,MAjBAD,GAAAhjC,KAAA4C,MAOAA,KAAAsgC,mBAAA,EAQAtgC,KAAAugC,kBACAvgC,KAAAwgC,gBAAA,KACAxgC,KAqpBA,QAAA+/B,KAEA,MADAM,GAAAjjC,KAAA4C,MACAA,KA9sBA,GAAAwG,GAAA3J,EAAA,GAAA2J,MACAi6B,EAAA5jC,EAAA,IACAu5B,EAAAqK,EAAArK,qBACAI,EAAAiK,EAAAjK,uBACAC,EAAAgK,EAAAhK,yBACAI,EAAA4J,EAAA5J,2BACA1hB,EAAAtY,EAAA,IAAAsY,SACA5K,EAAA1N,EAAA,IAAA0N,SACAe,EAAAzO,EAAA,IAAAyO,WAMA80B,GAAA9/B,UAAA0lB,MAAA,SAAAiP,KAGAmL,EAAA9/B,UAAAogC,cAAA,SAAAzL,KAGAmL,EAAA9/B,UAAAuyB,QAAA,SAAAoC,EAAAtC,KAGAyN,EAAA9/B,UAAAqgC,KAAA,SAAA1L,KAGAmL,EAAA9/B,UAAAsgC,oBAAA,SAAA3L,KAGAmL,EAAA9/B,UAAAugC,YAAA,SAAA5L,KA6BAoL,EAAA//B,UAAAC,OAAAC,OAAA4/B,EAAA9/B,WACA+/B,EAAA//B,UAAAF,YAAAigC,EAIAA,EAAA//B,UAAA0lB,MAAA,SAAAiP,GACAj1B,KAAA8gC,kBAAA7L,IASAoL,EAAA//B,UAAAygC,oBAAA,SAAA9L,GACAj1B,KAAAsgC,mBAAA,GAGAD,EAAA//B,UAAAsgC,oBAAA,SAAA3L,GACA,MAAAj1B,MAAAsgC,mBASAD,EAAA//B,UAAAwgC,kBAAA,SAAA7L,GACAj1B,KAAAsgC,mBAAA,EACAtgC,KAAAwgC,gBAAA,KACAxgC,KAAAugC,mBAQAF,EAAA//B,UAAA0gC,YAAA,SAAA/L,GACAj1B,KAAA8gC,kBAAA7L,IAsBAoL,EAAA//B,UAAAugC,YAAA,SAAA5L,EAAAtC,GAGA3yB,KAAA4gC,oBAAA3L,KAGAj1B,KAAA+gC,oBAAA9L,GACAtC,YAAAyD,GACAp2B,KAAAihC,0BAAAhM,EAAAtC,GACKA,YAAA6D,GACLx2B,KAAAkhC,oBAAAjM,EAAAtC,GACKA,YAAA8D,GACLz2B,KAAAmhC,sBAAAlM,EAAAtC,IAEA9E,QAAAjqB,IAAA,mCAAA+uB,EAAAvyB,YAAAkhB,MACAuM,QAAAjqB,IAAA+uB,EAAAqD,OACAf,EAAAiL,qBAAAvN,EAAAkC,oBAAAlC,EAAAyO,aAAAzO,MAUA0N,EAAA//B,UAAAuyB,QAAA,SAAAoC,EAAAtC,GACA3yB,KAAAugC,iBAAAtL,EAAAphB,iBAAAzN,OACA,OAAApG,KAAAwgC,iBAAAxgC,KAAAwgC,gBAAA3uB,QAAAojB,EAAAhpB,QAAA,GAKAgpB,EAAAlG,UAEA/uB,KAAAugC,eAAAtL,EAAA1D,OAAAnrB,MACA,OAAApG,KAAAwgC,kBACAxgC,KAAAwgC,oBAEAxgC,KAAAwgC,gBAAAp0B,KAAA6oB,EAAAhpB,MACA,IAAAo1B,GAAArhC,KAAAshC,oBAAArM,EACAj1B,MAAAuhC,aAAAtM,EAAAoM,IAgDAhB,EAAA//B,UAAAqgC,KAAA,SAAA1L,GAEA,IAAAj1B,KAAA4gC,oBAAA3L,GAAA,CAGA,GAAAzpB,GAAAypB,EAAAzvB,QAAAC,IAAAqF,OAAAmqB,EAAAhpB,OACAu1B,EAAAvM,EAAAyJ,iBAAA/P,GAAA,EAEA,IAAA6S,IAAAh7B,EAAAD,MAAA0uB,EAAAxvB,IAAAsG,WAAAP,GAAAmB,SAAA60B,KAIAvM,EAAAwM,gBAAAD,GAGA,OAAAh2B,EAAA6J,WACA,IAAAF,GAAAS,YACA,IAAAT,GAAAuB,iBACA,IAAAvB,GAAAoB,iBACA,IAAApB,GAAA2B,gBAEA,UAAA9W,KAAA0hC,oBAAAzM,GACA,MAEA,UAAAuB,GAAAvB,EAGA,KAAA9f,GAAAkB,eACA,IAAAlB,GAAAyB,eACA5W,KAAA2hC,oBAAA1M,EACA,IAAA2M,GAAA,GAAAt2B,EACAs2B,GAAA90B,OAAAmoB,EAAAxoB,oBACA,IAAAo1B,GAAAD,EAAA90B,OAAA9M,KAAAshC,oBAAArM,GACAj1B,MAAAuhC,aAAAtM,EAAA4M,MAeAxB,EAAA//B,UAAA2gC,0BAAA,SAAAhM,EAAAtC,GACA,GACAttB,GADAse,EAAAsR,EAAAyJ,gBAIAr5B,GAFA,OAAAse,EACAgP,EAAA0D,WAAApjB,OAAAzM,EAAAD,IACA,QAEAod,EAAA7gB,QAAA,GAAAyH,GAAAooB,EAAA0D,WAAA1D,EAAAsD,iBAGA,iBAEA,IAAA3C,GAAA,kCAAAtzB,KAAA8hC,iBAAAz8B,EACA4vB,GAAAiL,qBAAA5M,EAAAX,EAAAsD,eAAAtD,IAYA0N,EAAA//B,UAAA4gC,oBAAA,SAAAjM,EAAAtC,GACA,GAAAW,GAAA,oBAAAtzB,KAAA80B,qBAAAnC,EAAAsD,gBACA,cAAAtD,EAAAlmB,oBAAAsF,SAAAkjB,EAAArrB,aAAAqrB,EAAAprB,cACAorB,GAAAiL,qBAAA5M,EAAAX,EAAAsD,eAAAtD,IAYA0N,EAAA//B,UAAA6gC,sBAAA,SAAAlM,EAAAtC,GACA,GAAAvS,GAAA6U,EAAAnrB,UAAAmrB,EAAAqB,KAAA7mB,WACA6jB,EAAA,QAAAlT,EAAA,IAAAuS,EAAAxI,OACA8K,GAAAiL,qBAAA5M,EAAAX,EAAAsD,eAAAtD,IAoBA0N,EAAA//B,UAAAqhC,oBAAA,SAAA1M,GACA,IAAAj1B,KAAA4gC,oBAAA3L,GAAA,CAGAj1B,KAAA+gC,oBAAA9L,EACA,IAAAplB,GAAAolB,EAAAsB,kBACA5B,EAAA30B,KAAA80B,qBAAAjlB,GACA+xB,EAAA5hC,KAAAyM,kBAAAwoB,GACA3B,EAAA,oBAAAqB,EAAA,cACAiN,EAAA7vB,SAAAkjB,EAAArrB,aAAAqrB,EAAAprB,cACAorB,GAAAiL,qBAAA5M,EAAAzjB,EAAA,QAkBAwwB,EAAA//B,UAAAyhC,mBAAA,SAAA9M,GACA,IAAAj1B,KAAA4gC,oBAAA3L,GAAA,CAGAj1B,KAAA+gC,oBAAA9L,EACA,IAAAplB,GAAAolB,EAAAsB,kBACAqL,EAAA5hC,KAAAyM,kBAAAwoB,GACA3B,EAAA,WAAAsO,EAAA7vB,SAAAkjB,EAAArrB,aAAAqrB,EAAAprB,eACA,OAAA7J,KAAA80B,qBAAAjlB,EACAolB,GAAAiL,qBAAA5M,EAAAzjB,EAAA,QAoDAwwB,EAAA//B,UAAAogC,cAAA,SAAAzL,GAEA,GAAA+M,GAAAhiC,KAAA0hC,oBAAAzM,EACA,WAAA+M,EAIA,MADA/M,GAAAlG,UACAiT,CAGA,IAAAhiC,KAAAiiC,qBAAAhN,GACA,MAAAj1B,MAAAkiC,iBAAAjN,EAGA,UAAAuB,GAAAvB,IAoBAoL,EAAA//B,UAAA2hC,qBAAA,SAAAhN,GACA,GAAAkN,GAAAlN,EAAAyJ,iBAAA/P,GAAA,GAIAlpB,EAAAwvB,EAAAzvB,QAAAC,IACA28B,EAAA38B,EAAAqF,OAAAmqB,EAAAhpB,OACAkiB,EAAAiU,EAAAl1B,YAAA,GAAA0B,OACAyzB,EAAA58B,EAAAsG,WAAAoiB,EAAA8G,EAAAqB,KACA,SAAA+L,EAAA11B,SAAAw1B,KACAniC,KAAA+hC,mBAAA9M,IACA,IAwBAoL,EAAA//B,UAAAohC,oBAAA,SAAAzM,GACA,GAAAqN,GAAArN,EAAAyJ,iBAAA/P,GAAA,GACAiT,EAAA5hC,KAAAyM,kBAAAwoB,EACA,IAAA2M,EAAAj1B,SAAA21B,GAAA,CACAtiC,KAAA2hC,oBAAA1M,GAKAA,EAAAlG,SAEA,IAAAiT,GAAA/M,EAAAsB,iBAEA,OADAv2B,MAAAghC,YAAA/L,GACA+M,EAEA,aAuBA3B,EAAA//B,UAAA4hC,iBAAA,SAAAjN,GACA,GAGAsN,GAHAC,EAAAvN,EAAAsB,kBACAqL,EAAA5hC,KAAAyM,kBAAAwoB,GACAwN,EAAAb,EAAAxoB,OAGAmpB,GADAE,IAAAj8B,EAAAD,IACA,gBAEA,YAAA0uB,EAAArrB,aAAA64B,GAAA,GAEA,IAAAC,GAAAF,EACAG,EAAA1N,EAAAyJ,iBAAAvF,MAIA,OAHAuJ,GAAAzvB,OAAAzM,EAAAD,KAAA,OAAAo8B,IACAD,EAAAC,GAEA1N,EAAA2N,kBAAApiC,OAAAkiC,EAAA1vB,OACAyvB,EAAAF,EAAA/7B,EAAAkN,sBACAgvB,EAAApvB,KAAAovB,EAAAnvB,SAGA8sB,EAAA//B,UAAAmM,kBAAA,SAAAwoB,GACA,MAAAA,GAAAxoB,qBAWA4zB,EAAA//B,UAAAw0B,qBAAA,SAAAjlB,GACA,UAAAA,EACA,kBAEA,IAAArE,GAAAqE,EAAAhO,IAQA,OAPA,QAAA2J,IAEAA,EADAqE,EAAAoD,OAAAzM,EAAAD,IACA,QAEA,IAAAsJ,EAAAoD,KAAA,KAGAjT,KAAA8hC,iBAAAt2B,IAGA60B,EAAA//B,UAAAwhC,iBAAA,SAAAt2B,GAIA,MAHAA,KAAAzI,QAAA,aACAyI,IAAAzI,QAAA,aACAyI,IAAAzI,QAAA,aACA,IAAAyI,EAAA,KA+FA60B,EAAA//B,UAAAghC,oBAAA,SAAArM,GAIA,IAHA,GAAAxvB,GAAAwvB,EAAAzvB,QAAAC,IACAgG,EAAAwpB,EAAAqB,KACAuM,EAAA,GAAAv3B,GACA,OAAAG,KAAAuB,eAAA,IAEA,GAAAA,GAAAvH,EAAAqF,OAAAW,EAAAuB,eACAC,EAAAD,EAAAE,YAAA,GACA41B,EAAAr9B,EAAAsG,WAAAkB,EAAAE,YACA01B,GAAA/1B,OAAAg2B,GACAr3B,IAAA2B,UAGA,MADAy1B,GAAA91B,UAAAvG,EAAAoG,SACAi2B,GAIAxC,EAAA//B,UAAAihC,aAAA,SAAAtM,EAAA/kB,GAEA,IADA,GAAAuS,GAAAwS,EAAAyJ,iBAAA/P,GAAA,GACAlM,IAAAjc,EAAAD,MAAA2J,EAAAvD,SAAA8V,IACAwS,EAAAlG,UACAtM,EAAAwS,EAAAyJ,iBAAA/P,GAAA,IAqCAoR,EAAAz/B,UAAAC,OAAAC,OAAA6/B,EAAA//B,WACAy/B,EAAAz/B,UAAAF,YAAA2/B,EAOAA,EAAAz/B,UAAAuyB,QAAA,SAAAoC,EAAAtC,GAEA,IADA,GAAAhyB,GAAAs0B,EAAAqB,KACA,OAAA31B,GACAA,EAAAsiB,UAAA0P,EACAhyB,IAAAyM,SAEA,UAAAypB,GAAAlE,IAMAoN,EAAAz/B,UAAAogC,cAAA,SAAAzL,GACAj1B,KAAA6yB,QAAAoC,EAAA,GAAAuB,GAAAvB,KAIA8K,EAAAz/B,UAAAqgC,KAAA,SAAA1L,KAIAj4B,EAAA+iC,oBACA/iC,EAAAqjC,wB5CyzVM,SAASpjC,EAAQD,EAASH,G6CpiXhC,QAAAkmC,GAAAC,GACAA,EAAAC,OAAA,EACAD,EAAAnyB,OACA,QAAAxB,GAAA,EAAgBA,EAAA2zB,EAAAE,QAAA/2B,OAA2BkD,IAC3C2zB,EAAAnyB,KAAAzE,KAAA42B,EAAAE,QAAA5xB,WAAAjC,GAEA2zB,GAAAG,MAAAH,EAAAnyB,KAAA1E,OAGA,QAAA3N,GAAAqS,GAIA,MAHA7Q,MAAAshB,KAAA,UACAthB,KAAAkjC,QAAAryB,EACAkyB,EAAA/iC,MACAA,KAjBA,GAAAwG,GAAA3J,EAAA,GAAA2J,KAoBAjG,QAAAgR,eAAA/S,EAAA8B,UAAA,SACAkR,IAAA,WACA,MAAAxR,MAAAijC,UAIA1iC,OAAAgR,eAAA/S,EAAA8B,UAAA,QACAkR,IAAA,WACA,MAAAxR,MAAAmjC,SAQA3kC,EAAA8B,UAAA0lB,MAAA,WACAhmB,KAAAijC,OAAA,GAGAzkC,EAAA8B,UAAAyuB,QAAA,WACA,GAAA/uB,KAAAijC,QAAAjjC,KAAAmjC,MAEA,yBAEAnjC,MAAAijC,QAAA,GAGAzkC,EAAA8B,UAAAquB,GAAA,SAAAhD,GACA,OAAAA,EACA,QAEAA,GAAA,IACAA,GAAA,EAEA,IAAAxE,GAAAnnB,KAAAijC,OAAAtX,EAAA,CACA,OAAAxE,GAAA,GAAAA,GAAAnnB,KAAAmjC,MACA38B,EAAAD,IAEAvG,KAAA6Q,KAAAsW,IAGA3oB,EAAA8B,UAAA64B,GAAA,SAAAxN,GACA,MAAA3rB,MAAA2uB,GAAAhD,IAIAntB,EAAA8B,UAAAktB,KAAA,WACA,UAGAhvB,EAAA8B,UAAAstB,QAAA,SAAA6C,KAMAjyB,EAAA8B,UAAA0vB,KAAA,SAAAiT,GACA,MAAAA,IAAAjjC,KAAAijC,YACAjjC,KAAAijC,eAKAjjC,KAAAijC,OAAAjiC,KAAAoR,IAAA6wB,EAAAjjC,KAAAmjC,SAGA3kC,EAAA8B,UAAAwC,QAAA,SAAAqQ,EAAAC,GAIA,MAHAA,IAAApT,KAAAmjC,QACA/vB,EAAApT,KAAAmjC,MAAA,GAEAhwB,GAAAnT,KAAAmjC,MACA,GAEAnjC,KAAAkjC,QAAAjqB,MAAA9F,EAAAC,EAAA,IAIA5U,EAAA8B,UAAAyR,SAAA,WACA,MAAA/R,MAAAkjC,SAGAlmC,EAAAwB,e7C8kXM,SAASvB,EAAQD,EAASH,G8C5qXhC,QAAAsN,GAAAi5B,GACA,GAAAvyB,GAAAwyB,EAAAC,aAAAF,EAAA,OAGA,OAFA5kC,GAAApB,KAAA4C,KAAA6Q,GACA7Q,KAAAojC,WACApjC,KARA,GAAAxB,GAAA3B,EAAA,IAAA2B,YACA+kC,EAAA,mBAAAC,SAAA,mBAAAC,eACAJ,EAAAE,EAAA1mC,EAAA,QASAsN,GAAA7J,UAAAC,OAAAC,OAAAhC,EAAA8B,WACA6J,EAAA7J,UAAAF,YAAA+J,EAEAnN,EAAAmN,c9C0tXM,SAASlN,EAAQD,KAMjB,SAASC,EAAQD,EAASH,G+CttXhC,QAAA+B,GAAAH,EAAAyU,GAGA,MAFAwwB,GAAAtmC,KAAA4C,KAAAvB,GACAuB,KAAAkT,QAAApT,SAAAoT,EAAA1M,EAAAkN,gBAAAR,EACAlT,KANA,GAAAwG,GAAA3J,EAAA,GAAA2J,MACAk9B,EAAA7mC,EAAA,IAAA6mC,mBAQA9kC,GAAA0B,UAAAC,OAAAC,OAAAkjC,EAAApjC,WACA1B,EAAA0B,UAAAF,YAAAxB,EAEAA,EAAA0B,UAAAqjC,gBAAA,SAAAt0B,GACA,MAAArP,MAAA4jC,mBAAAv0B,EAAArP,KAAAkT,UAGAtU,EAAA0B,UAAAujC,GAAA,SAAArqB,GACA,OAAAA,GAAAxZ,KAAAoG,MAAAoT,EAAA,EACA,WAKA,KAHA,GAAAnK,GAAArP,KAAAoG,MACA2N,EAAA,EAEAA,GAAAyF,GAEAnK,EAAArP,KAAA8jC,uBAAAz0B,EAAA,EAAArP,KAAAkT,SACAa,GAAA,CAEA,OAAA1E,GAAA,EACA,KAEArP,KAAA2jB,OAAAtU,IAGAzQ,EAAA0B,UAAA64B,GAAA,SAAA3f,GAEA,GADAxZ,KAAA+jC,WACA,IAAAvqB,EACA,WAEA,IAAAA,EAAA,EACA,MAAAxZ,MAAA6jC,IAAArqB,EAKA,KAHA,GAAAnK,GAAArP,KAAAoG,MACA2N,EAAA,EAEAA,EAAAyF,GAEAxZ,KAAA2gC,KAAAtxB,EAAA,KACAA,EAAArP,KAAA4jC,mBAAAv0B,EAAA,EAAArP,KAAAkT,UAEAa,GAAA,CAEA,OAAA/T,MAAA2jB,OAAAtU,IAIAzQ,EAAA0B,UAAA0jC,2BAAA,WACA,GAAAjwB,GAAA,CACA/T,MAAAikC,MACA,QAAA50B,GAAA,EAAkBA,EAAArP,KAAA2jB,OAAAxX,OAAuBkD,IAAA,CACzC,GAAAQ,GAAA7P,KAAA2jB,OAAAtU,EAIA,IAHAQ,EAAAqD,UAAAlT,KAAAkT,UACAa,GAAA,GAEAlE,EAAAoD,OAAAzM,EAAAD,IACA,MAGA,MAAAwN,IAGA/W,EAAA4B,qB/CuxXM,SAAS3B,EAAQD,EAASH,GgDx2XhC,QAAAqnC,KACA,MAAAlkC,MAGA,QAAA0jC,GAAAS,GAsCA,MApCAD,GAAA9mC,KAAA4C,MAEAA,KAAAmkC,cAKAnkC,KAAA2jB,UAYA3jB,KAAAoG,SAgBApG,KAAAokC,YAAA,EACApkC,KA/CA,GAAAwG,GAAA3J,EAAA,GAAA2J,MACAjB,EAAA1I,EAAA,IAAA0I,MACAgF,EAAA1N,EAAA,IAAA0N,QAgDAm5B,GAAApjC,UAAAC,OAAAC,OAAA0jC,EAAA5jC,WACAojC,EAAApjC,UAAAF,YAAAsjC,EAEAA,EAAApjC,UAAAktB,KAAA,WACA,UAGAkW,EAAApjC,UAAAstB,QAAA,SAAA6C,KAIAiT,EAAApjC,UAAA0lB,MAAA,WACAhmB,KAAAgwB,KAAA,IAGA0T,EAAApjC,UAAA0vB,KAAA,SAAA5pB,GACApG,KAAA+jC,WACA/jC,KAAAoG,MAAApG,KAAA2jC,gBAAAv9B,IAGAs9B,EAAApjC,UAAAkR,IAAA,SAAApL,GAEA,MADApG,MAAA+jC,WACA/jC,KAAA2jB,OAAAvd,IAGAs9B,EAAApjC,UAAAyuB,QAAA,WACA,GAAAsV,IAAA,CAcA,IATAA,EAJArkC,KAAAoG,OAAA,IACApG,KAAAokC,WAGApkC,KAAAoG,MAAApG,KAAA2jB,OAAAxX,OAAA,EAGAnM,KAAAoG,MAAApG,KAAA2jB,OAAAxX,SAMAk4B,GAAArkC,KAAA2uB,GAAA,KAAAnoB,EAAAD,IACA,yBAEAvG,MAAA2gC,KAAA3gC,KAAAoG,MAAA,KACApG,KAAAoG,MAAApG,KAAA2jC,gBAAA3jC,KAAAoG,MAAA,KAUAs9B,EAAApjC,UAAAqgC,KAAA,SAAAtxB,GACA,GAAA0E,GAAA1E,EAAArP,KAAA2jB,OAAAxX,OAAA,CACA,IAAA4H,EAAA,GACA,GAAAuwB,GAAAtkC,KAAAukC,MAAAxwB,EACA,OAAAuwB,IAAAvwB,EAEA,UAOA2vB,EAAApjC,UAAAikC,MAAA,SAAAxwB,GACA,GAAA/T,KAAAokC,WACA,QAEA,QAAA/0B,GAAA,EAAgBA,EAAA0E,EAAO1E,IAAA,CACvB,GAAAQ,GAAA7P,KAAAmkC,YAAA5R,WAGA,IAFA1iB,EAAAwD,WAAArT,KAAA2jB,OAAAxX,OACAnM,KAAA2jB,OAAAvX,KAAAyD,GACAA,EAAAoD,OAAAzM,EAAAD,IAEA,MADAvG,MAAAokC,YAAA,EACA/0B,EAAA,EAGA,MAAA0E,IAIA2vB,EAAApjC,UAAAojB,UAAA,SAAAvQ,EAAAC,EAAAoxB,GAIA,GAHA1kC,SAAA0kC,IACAA,EAAA,MAEArxB,EAAA,GAAAC,EAAA,EACA,WAEApT,MAAA+jC,UACA,IAAAU,KACArxB,IAAApT,KAAA2jB,OAAAxX,SACAiH,EAAApT,KAAA2jB,OAAAxX,OAAA,EAEA,QAAAkD,GAAA8D,EAAoB9D,EAAA+D,EAAU/D,IAAA,CAC9B,GAAAQ,GAAA7P,KAAA2jB,OAAAtU,EACA,IAAAQ,EAAAoD,OAAAzM,EAAAD,IACA,OAEA,OAAAi+B,KAAA73B,SAAAkD,EAAAoD,QACAwxB,EAAAr4B,KAAAyD,GAGA,MAAA40B,IAGAf,EAAApjC,UAAAquB,GAAA,SAAAtf,GACA,MAAArP,MAAAm5B,GAAA9pB,GAAA4D,MAGAywB,EAAApjC,UAAAujC,GAAA,SAAArqB,GACA,MAAAxZ,MAAAoG,MAAAoT,EAAA,EACA,KAEAxZ,KAAA2jB,OAAA3jB,KAAAoG,MAAAoT,IAGAkqB,EAAApjC,UAAA64B,GAAA,SAAA3f,GAEA,GADAxZ,KAAA+jC,WACA,IAAAvqB,EACA,WAEA,IAAAA,EAAA,EACA,MAAAxZ,MAAA6jC,IAAArqB,EAEA,IAAAnK,GAAArP,KAAAoG,MAAAoT,EAAA,CAEA,OADAxZ,MAAA2gC,KAAAtxB,GACAA,GAAArP,KAAA2jB,OAAAxX,OAEAnM,KAAA2jB,OAAA3jB,KAAA2jB,OAAAxX,OAAA,GAEAnM,KAAA2jB,OAAAtU,IAgBAq0B,EAAApjC,UAAAqjC,gBAAA,SAAAt0B,GACA,MAAAA,IAGAq0B,EAAApjC,UAAAyjC,SAAA,WACA/jC,KAAAoG,YACApG,KAAA0kC,SAIAhB,EAAApjC,UAAAokC,MAAA,WACA1kC,KAAA2gC,KAAA,GACA3gC,KAAAoG,MAAApG,KAAA2jC,gBAAA,IAIAD,EAAApjC,UAAAqkC,eAAA,SAAAR,GACAnkC,KAAAmkC,cACAnkC,KAAA2jB,UACA3jB,KAAAoG,UAQAs9B,EAAApjC,UAAAsjC,mBAAA,SAAAv0B,EAAA6D,GAEA,GADAlT,KAAA2gC,KAAAtxB,GACAA,GAAArP,KAAA2jB,OAAAxX,OACA,QAGA,KADA,GAAA2U,GAAA9gB,KAAA2jB,OAAAtU,GACAyR,EAAA5N,UAAAlT,KAAAkT,SAAA,CACA,GAAA4N,EAAA7N,OAAAzM,EAAAD,IACA,QAEA8I,IAAA,EACArP,KAAA2gC,KAAAtxB,GACAyR,EAAA9gB,KAAA2jB,OAAAtU,GAEA,MAAAA,IAMAq0B,EAAApjC,UAAAwjC,uBAAA,SAAAz0B,EAAA6D,GACA,KAAA7D,GAAA,GAAArP,KAAA2jB,OAAAtU,GAAA6D,aACA7D,GAAA,CAEA,OAAAA,IAMAq0B,EAAApjC,UAAAskC,uBAAA,SAAAvxB,EACAH,GAKA,GAJApT,SAAAoT,IACAA,MAEAlT,KAAA+jC,WACA1wB,EAAA,GAAAA,GAAArT,KAAA2jB,OAAAxX,OACA,QAAAkH,EAAA,cAAArT,KAAA2jB,OAAAxX,OAAA,CAEA,IAAA04B,GAAA7kC,KAAA4jC,mBAAAvwB,EAAA,EACA9N,EAAA4sB,uBACAxB,EAAAtd,EAAA,EAEAwd,EAAAgU,OAAA7kC,KAAA2jB,OAAAxX,OAAA,EAAA04B,CACA,OAAA7kC,MAAA8kC,iBAAAnU,EAAAE,EAAA3d,IAMAwwB,EAAApjC,UAAAykC,sBAAA,SAAA1xB,EACAH,GAKA,GAJApT,SAAAoT,IACAA,MAEAlT,KAAA+jC,WACA1wB,EAAA,GAAAA,GAAArT,KAAA2jB,OAAAxX,OACA,QAAAkH,EAAA,cAAArT,KAAA2jB,OAAAxX,OAAA,CAEA,IAAA64B,GAAAhlC,KAAA8jC,uBAAAzwB,EAAA,EACA9N,EAAA4sB,sBACA,IAAA6S,IAAA3xB,EAAA,EACA,WAGA,IAAAsd,GAAAqU,EAAA,EACAnU,EAAAxd,EAAA,CACA,OAAArT,MAAA8kC,iBAAAnU,EAAAE,EAAA3d,IAGAwwB,EAAApjC,UAAAwkC,iBAAA,SAAAG,EAAAC,EAAAhyB,GAEA,OADAiyB,MACA91B,EAAA41B,EAAmB51B,EAAA61B,EAAA,EAAe71B,IAAA,CAClC,GAAAQ,GAAA7P,KAAA2jB,OAAAtU,EACA6D,QACArD,EAAAqD,UAAA3N,EAAA4sB,uBACAgT,EAAA/4B,KAAAyD,GAEGA,EAAAqD,aACHiyB,EAAA/4B,KAAAyD,GAGA,WAAAs1B,EAAAh5B,OACA,KAEAg5B,GAGAzB,EAAApjC,UAAA8kC,cAAA,WACA,MAAAplC,MAAAmkC,YAAAiB,iBAIA1B,EAAApjC,UAAAwC,QAAA,SAAA27B;AACAz+B,KAAA+jC,WACA/jC,KAAAikC,OACAnkC,SAAA2+B,GAAA,OAAAA,IACAA,EAAA,GAAAl0B,GAAA,EAAAvK,KAAA2jB,OAAAxX,OAAA,GAEA,IAAAgH,GAAAsrB,EAAAtrB,KACAA,aAAA3M,KACA2M,IAAAE,WAEA,IAAAD,GAAAqrB,EAAArrB,IAIA,IAHAA,YAAA5M,KACA4M,IAAAC,YAEA,OAAAF,GAAA,OAAAC,GAAAD,EAAA,GAAAC,EAAA,EACA,QAEAA,IAAApT,KAAA2jB,OAAAxX,SACAiH,EAAApT,KAAA2jB,OAAAxX,OAAA,EAGA,QADAX,GAAA,GACA6D,EAAA8D,EAAoB9D,EAAA+D,EAAA,EAAc/D,IAAA,CAClC,GAAAQ,GAAA7P,KAAA2jB,OAAAtU,EACA,IAAAQ,EAAAoD,OAAAzM,EAAAD,IACA,KAEAiF,IAAAqE,EAAAhO,KAEA,MAAA2J,IAIAk4B,EAAApjC,UAAA2jC,KAAA,WAEA,IADAjkC,KAAA+jC,WACA,MAAA/jC,KAAAukC,MAAA,SAKAvnC,EAAA0mC,uBhD65XM,SAASzmC,EAAQD,EAASH,GiDxwYhC,QAAAwoC,GAAAxmC,GAGA,MAFA8hB,GAAAvjB,KAAA4C,MACAA,KAAAnB,SACAmB,KAoBA,QAAAoK,GAAA/E,GA4BA,MA3BAisB,GAAAl0B,KAAA4C,MAEAA,KAAAuxB,OAAA,KAGAvxB,KAAAslC,YAAA,GAAAjF,GACArgC,KAAAulC,oBACAvlC,KAAAulC,iBAAAn5B,KAAA,GAGApM,KAAAs2B,KAAA,KAGAt2B,KAAAwlC,iBAAA,EAMAxlC,KAAAylC,QAAA,KAGAzlC,KAAA0lC,gBAAA,KAGA1lC,KAAA2lC,cAAA,EACA3lC,KAAA4lC,eAAAvgC,GACArF,KA1DA,GAAAwG,GAAA3J,EAAA,GAAA2J,MACAma,EAAA9jB,EAAA,IAAA8jB,kBACA2Q,EAAAz0B,EAAA,IAAAy0B,WACA+O,EAAAxjC,EAAA,IAAAwjC,qBACAt6B,EAAAlJ,EAAA,IAAAkJ,gBACAoe,EAAAtnB,EAAA,IAAAsnB,yBAQAkhB,GAAA/kC,UAAAC,OAAAC,OAAAmgB,GACA0kB,EAAA/kC,UAAAF,YAAAilC,EAEAA,EAAA/kC,UAAAkhB,eAAA,SAAA/V,GACAoiB,QAAAjqB,IAAA,WAAA5D,KAAAnB,OAAAiL,UAAA2B,EAAAgE,WAAA,WAAAzP,KAAAnB,OAAA0yB,OAAA4H,GAAA,GAAAt3B,OAGAwjC,EAAA/kC,UAAA6gB,cAAA,SAAAC,GACAyM,QAAAjqB,IAAA,WAAAwd,EAAApF,OAAA,SAAAhc,KAAAnB,OAAAiL,UAAA9J,KAAAnB,OAAAy3B,KAAA7mB,aAGA41B,EAAA/kC,UAAAmhB,cAAA,SAAAhW,GACAoiB,QAAAjqB,IAAA,WAAA5D,KAAAnB,OAAAiL,UAAA2B,EAAAgE,WAAA,WAAAzP,KAAAnB,OAAA0yB,OAAA4H,GAAA,GAAAt3B,OAoCAuI,EAAA9J,UAAAC,OAAAC,OAAA8wB,EAAAhxB,WACA8J,EAAA9J,UAAA0e,WAAA5U,EAQAA,EAAAy7B,sBAGAz7B,EAAA9J,UAAA0lB,MAAA,WACA,OAAAhmB,KAAAuxB,QACAvxB,KAAAuxB,OAAAvB,KAAA,GAEAhwB,KAAAslC,YAAAtf,MAAAhmB,MACAA,KAAAs2B,KAAA,KACAt2B,KAAA2lC,cAAA,EACA3lC,KAAA8lC,UAAA,GACA9lC,KAAAulC,oBACAvlC,KAAAulC,iBAAAn5B,KAAA,GACA,OAAApM,KAAAwF,SACAxF,KAAAwF,QAAAwgB,SAqBA5b,EAAA9J,UAAAjC,MAAA,SAAAokB,GACA,GAAA5S,GAAA7P,KAAAu2B,iBAaA,OAZA1mB,GAAAoD,OAAAwP,GACAziB,KAAAslC,YAAAtE,YAAAhhC,MACAA,KAAA+uB,YAEAlf,EAAA7P,KAAAslC,YAAA5E,cAAA1gC,MACAA,KAAAwlC,iBAAA31B,EAAAwD,iBAIArT,KAAAs2B,KAAA/S,aAAA1T,IAGAA,GAkBAzF,EAAA9J,UAAAylC,cAAA,WACA,GAAAl2B,GAAA7P,KAAAu2B,iBAaA,OAZA1mB,GAAAoD,KAAA,GACAjT,KAAAslC,YAAAtE,YAAAhhC,MACAA,KAAA+uB,YAEAlf,EAAA7P,KAAAslC,YAAA5E,cAAA1gC,MACAA,KAAAgmC,kBAAAn2B,EAAAwD,iBAIArT,KAAAs2B,KAAA/S,aAAA1T,IAGAA,GAGAzF,EAAA9J,UAAA2lC,kBAAA,WACA,MAAAjmC,MAAA0lC,qBA+BAt7B,EAAA9J,UAAA4lC,iBAAA,SAAArkB,GACA,UAAAA,EACA,eAEA,QAAA7hB,KAAA0lC,kBACA1lC,KAAA0lC,oBAEA1lC,KAAA0lC,gBAAAt5B,KAAAyV,IAUAzX,EAAA9J,UAAA6lC,oBAAA,SAAAtkB,GACA,UAAA7hB,KAAA0lC,gBAAA,CACA,GAAAhc,GAAA1pB,KAAA0lC,gBAAA7zB,QAAAgQ,EACA6H,IAAA,GACA1pB,KAAA0lC,gBAAAluB,OAAAkS,EAAA,GAEA,IAAA1pB,KAAA0lC,gBAAAv5B,SACAnM,KAAA0lC,gBAAA,QAMAt7B,EAAA9J,UAAA8lC,qBAAA,WACApmC,KAAA0lC,gBAAA,MAIAt7B,EAAA9J,UAAA+lC,sBAAA,WACA,UAAArmC,KAAA0lC,gBAAA,CACA,GAAAj6B,GAAAzL,KAAAs2B,IACAt2B,MAAA0lC,gBAAAx/B,IAAA,SAAA2b,GACAA,EAAAL,eAAA/V,GACAA,EAAAsW,UAAAF,OAUAzX,EAAA9J,UAAAgmC,qBAAA,WACA,UAAAtmC,KAAA0lC,gBAAA,CAEA,GAAAj6B,GAAAzL,KAAAs2B,IACAt2B,MAAA0lC,gBAAAzsB,MAAA,GAAAstB,UAAArgC,IAAA,SAAA2b,GACApW,EAAAuW,SAAAH,GACAA,EAAAJ,cAAAhW,OAKArB,EAAA9J,UAAAsiC,gBAAA,WACA,MAAA5iC,MAAAuxB,OAAA4S,YAAA3S,UAIApnB,EAAA9J,UAAAkmC,gBAAA,SAAAC,GACAzmC,KAAAuxB,OAAA4S,YAAA3S,SAAAiV,GASAr8B,EAAA9J,UAAAomC,qBAAA,WACA,GAAAC,GAAA3mC,KAAA4mC,kBACA,WAAAD,EACA,2EAEA,IAAAxoC,GAAA6B,KAAA6lC,mBAAAc,EACA,WAAAxoC,EAAA,CACA,GAAAkmB,GAAA,GAAAF,EACAE,GAAAyC,+BAAA,EACA3oB,EAAA,GAAA4H,GAAAse,GACAre,YAAA2gC,GACA3mC,KAAA6lC,mBAAAc,GAAAxoC,EAEA,MAAAA,GAcA,IAAAoH,GAAA1I,EAAA,IAAA0I,KAEA6E,GAAA9J,UAAAumC,wBAAA,SAAAC,EAAAC,EAAAtoC,GAEA,GADAA,KAAA,KACA,OAAAA,GACA,OAAAuB,KAAA0+B,iBAAA,CACA,GAAAyF,GAAAnkC,KAAA0+B,iBAAAyF,WACAA,aAAA5+B,KACA9G,EAAA0lC,GAIA,UAAA1lC,EACA,2CAEA,IAAApB,GAAA,GAAA2pC,yBAAAvoC,EAAAuB,KACA,OAAA3C,GAAA4pC,QAAAH,EAAAC,IAGA38B,EAAA9J,UAAAuT,eAAA,WACA,MAAA7T,MAAA0+B,kBAGAt0B,EAAA9J,UAAAslC,eAAA,SAAAvgC,GACArF,KAAAknC,eAAA7hC,IAGA+E,EAAA9J,UAAAo+B,eAAA,WACA,MAAA1+B,MAAAuxB,QAIAnnB,EAAA9J,UAAA4mC,eAAA,SAAA7hC,GACArF,KAAAuxB,OAAA,KACAvxB,KAAAgmB,QACAhmB,KAAAuxB,OAAAlsB,GAMA+E,EAAA9J,UAAAi2B,gBAAA,WACA,MAAAv2B,MAAAuxB,OAAA4H,GAAA,IAGA/uB,EAAA9J,UAAA4/B,qBAAA,SAAA5M,EAAA2C,EAAAkR,GACAlR,KAAA,KACAkR,KAAA,KACA,OAAAlR,IACAA,EAAAj2B,KAAAu2B,mBAEAv2B,KAAA2lC,eAAA,CACA,IAAAryB,GAAA2iB,EAAA3iB,KACAC,EAAA0iB,EAAA1iB,OACAsO,EAAA7hB,KAAAwzB,0BACA3R,GAAA4R,YAAAzzB,KAAAi2B,EAAA3iB,EAAAC,EAAA+f,EAAA6T,IAwBA/8B,EAAA9J,UAAAyuB,QAAA,WACA,GAAAxc,GAAAvS,KAAAu2B,iBACAhkB,GAAAU,OAAAzM,EAAAD,KACAvG,KAAA6T,iBAAAkb,SAEA,IAAAqY,GAAA,OAAApnC,KAAA0lC,iBAAA1lC,KAAA0lC,gBAAAv5B,OAAA,CACA,IAAAnM,KAAAwlC,iBAAA4B,EAAA,CACA,GAAAhmB,EAEAA,GADAphB,KAAAslC,YAAA1E,oBAAA5gC,MACAA,KAAAs2B,KAAA/S,aAAAhR,GAEAvS,KAAAs2B,KAAAhT,aAAA/Q,GAEA6O,EAAApU,cAAAhN,KAAAiM,MACAm7B,GACApnC,KAAA0lC,gBAAAx/B,IAAA,SAAA2b,GACAA,EAAAV,cAAAC,KAIA,MAAA7O,IAGAnI,EAAA9J,UAAA+mC,sBAAA,WAEA,OAAArnC,KAAAs2B,KAAAlpB,WACApN,KAAAs2B,KAAAlpB,UAAAgW,SAAApjB,KAAAs2B,OAOAlsB,EAAA9J,UAAAyhB,UAAA,SAAAnJ,EAAA3M,EAAAwD,GACAzP,KAAAiM,QACAjM,KAAAs2B,KAAA1d,EACA5Y,KAAAs2B,KAAAnjB,MAAAnT,KAAAuxB,OAAA4H,GAAA,GACAn5B,KAAAwlC,iBACAxlC,KAAAqnC,wBAEA,OAAArnC,KAAA0lC,iBACA1lC,KAAAqmC,yBAIAj8B,EAAA9J,UAAA0hB,SAAA,WACAhiB,KAAAs2B,KAAAljB,KAAApT,KAAAuxB,OAAA4H,OAEA,OAAAn5B,KAAA0lC,iBACA1lC,KAAAsmC,uBAEAtmC,KAAAiM,MAAAjM,KAAAs2B,KAAAtpB,cACAhN,KAAAs2B,KAAAt2B,KAAAs2B,KAAAlpB,WAGAhD,EAAA9J,UAAAgnC,cAAA,SAAA1uB,EAAA2uB,GACA3uB,EAAAgH,aAAA2nB,GAGAvnC,KAAAwlC,iBAAAxlC,KAAAs2B,OAAA1d,GACA,OAAA5Y,KAAAs2B,KAAAlpB,YACApN,KAAAs2B,KAAAlpB,UAAAiW,kBACArjB,KAAAs2B,KAAAlpB,UAAAgW,SAAAxK,IAGA5Y,KAAAs2B,KAAA1d,GAQAxO,EAAA9J,UAAAg5B,cAAA,WACA,WAAAt5B,KAAAulC,iBAAAp5B,UAGAnM,KAAAulC,iBAAAvlC,KAAAulC,iBAAAp5B,OAAA,IAIA/B,EAAA9J,UAAAknC,mBAAA,SAAA5uB,EAAA3M,EAAAwD,EACAoI,GACA7X,KAAAiM,QACAjM,KAAAulC,iBAAAn5B,KAAAyL,GACA7X,KAAAs2B,KAAA1d,EACA5Y,KAAAs2B,KAAAnjB,MAAAnT,KAAAuxB,OAAA4H,GAAA,GACA,OAAAn5B,KAAA0lC,iBACA1lC,KAAAqmC,yBAQAj8B,EAAA9J,UAAAmnC,wBAAA,SAAA7uB,EAAA3M,EAAAwD,GACA,GAAA2N,GAAApd,KAAAs2B,IACAlZ,GAAAhQ,UAAAwL,EACAwE,EAAApQ,cAAAf,EACAmR,EAAAhK,KAAApT,KAAAuxB,OAAA4H,OAEAn5B,KAAAs2B,KAAA1d,EACA5Y,KAAAs2B,KAAAnjB,MAAAiK,EAAAjK,MACAnT,KAAAwlC,iBACAxlC,KAAAs2B,KAAAlT,SAAAhG,GAEA,OAAApd,KAAA0lC,iBACA1lC,KAAAqmC,yBAKAj8B,EAAA9J,UAAAonC,wBAAA,SAAAt6B,GACApN,KAAAulC,iBAAA3rB,MACA5Z,KAAAs2B,KAAAljB,KAAApT,KAAAuxB,OAAA4H,MACA,IAAAwO,GAAA3nC,KAAAs2B,IAEA,WAAAt2B,KAAA0lC,gBACA,KAAA1lC,KAAAs2B,OAAAlpB,GACApN,KAAAsmC,uBACAtmC,KAAAs2B,KAAAt2B,KAAAs2B,KAAAlpB,cAGApN,MAAAs2B,KAAAlpB,CAGAu6B,GAAAv6B,YACApN,KAAAwlC,iBAAA,OAAAp4B,GAEAA,EAAAgW,SAAAukB,IAIAv9B,EAAA9J,UAAAsnC,mBAAA,SAAAn4B,GAEA,IADA,GAAAhE,GAAAzL,KAAAs2B,KACA,OAAA7qB,GAAA,CACA,GAAAA,EAAAgE,cACA,MAAAhE,EAEAA,KAAA2B,UAEA,aAGAhD,EAAA9J,UAAAwY,SAAA,SAAAF,EAAAf,GACA,MAAAA,IAAA7X,KAAAulC,iBAAAvlC,KAAAulC,iBAAAp5B,OAAA,IAGA/B,EAAA9J,UAAAk9B,UAAA,SAAA78B,GAEA,UAiBAyJ,EAAA9J,UAAAmhC,gBAAA,SAAAzlB,GACA,GAAAvW,GAAAzF,KAAAwF,QAAAC,IACAgG,EAAAzL,KAAAs2B,KACA9qB,EAAA/F,EAAAqF,OAAA9K,KAAAiM,OACAS,EAAAjH,EAAAsG,WAAAP,EACA,IAAAkB,EAAAC,SAAAqP,GACA,QAEA,KAAAtP,EAAAC,SAAAnG,EAAAoG,SACA,QAEA,aAAAnB,KAAAuB,eAAA,GAAAN,EAAAC,SAAAnG,EAAAoG,UAAA,CACA,GAAAI,GAAAvH,EAAAqF,OAAAW,EAAAuB,eACAC,EAAAD,EAAAE,YAAA,EAEA,IADAR,EAAAjH,EAAAsG,WAAAkB,EAAAE,aACAT,EAAAC,SAAAqP,GACA,QAEAvQ,KAAA2B,UAEA,SAAAV,EAAAC,SAAAnG,EAAAoG,UAAAoP,IAAAxV,EAAAD,MAaA6D,EAAA9J,UAAAmM,kBAAA,WACA,MAAAzM,MAAAwF,QAAAC,IAAAgH,kBAAAzM,KAAAiM,MAAAjM,KAAAs2B,OAGAlsB,EAAA9J,UAAAunC,mCAAA,WACA,GAAApiC,GAAAzF,KAAAwF,QAAAC,IACA+F,EAAA/F,EAAAqF,OAAA9K,KAAAiM,MACA,OAAAxG,GAAAsG,WAAAP,IAIApB,EAAA9J,UAAAwnC,aAAA,SAAA1nB,GACA,GAAA3Q,GAAAzP,KAAAy0B,kBAAArU,EACA,eAAA3Q,EACAA,MAaArF,EAAA9J,UAAAw9B,uBAAA,SAAAvgC,GACAA,KAAA,KACA,OAAAA,IACAA,EAAAyC,KAAAs2B,KAGA,KADA,GAAAN,MACA,OAAAz4B,GAAA,CAEA,GAAAkS,GAAAlS,EAAAkS,SACAA,GAAA,EACAumB,EAAA5pB,KAAA,OAEA4pB,EAAA5pB,KAAApM,KAAA8J,UAAA2F,IAEAlS,IAAA6P,UAEA,MAAA4oB,IAIA5rB,EAAA9J,UAAAynC,cAAA,WACA,MAAA/nC,MAAAwF,QAAA8mB,cAAAva,YAGA3H,EAAA9J,UAAA0nC,QAAA,WAEA,OADAC,IAAA,EACA54B,EAAA,EAAgBA,EAAArP,KAAAwF,QAAA8mB,cAAAngB,OAAuCkD,IAAA,CACvD,GAAAhJ,GAAArG,KAAAwF,QAAA8mB,cAAAjd,EACAhJ,GAAAyE,OAAAqB,OAAA,IACA87B,GACApa,QAAAjqB,MAEA5D,KAAAkoC,QAAAC,QAAA,YAAA9hC,EAAAkG,SAAA,KACAvM,KAAAkoC,QAAAE,MAAA/hC,EAAA0L,SAAA/R,KAAA4J,aAAA5J,KAAA6J,gBACAo+B,GAAA,KAYA79B,EAAA9J,UAAA8kC,cAAA,WACA,MAAAplC,MAAAuxB,OAAAwB,YAMA3oB,EAAA9J,UAAAwlC,SAAA,SAAAuC,GACAA,GAIA,OAAAroC,KAAAylC,SACAzlC,KAAAmmC,oBAAAnmC,KAAAylC,SAEAzlC,KAAAylC,QAAA,GAAAJ,GAAArlC,MACAA,KAAAkmC,iBAAAlmC,KAAAylC,WAPAzlC,KAAAmmC,oBAAAnmC,KAAAylC,SACAzlC,KAAAylC,QAAA,OAUAzoC,EAAAoN,UjDkzYM,SAASnN,EAAQD,EAASH,GkDn3ZhC,QAAAiC,GAAAuG,GAMA,MALAC,GAAA8E,OAAAhN,KAAA4C,KAAAqF,GACArF,KAAAwF,QAAA,GAAAF,GAAAG,IAAAiF,mBAAA1K,KAAAyF,EAAAE,EAAA4mB,GACAvsB,KAAA8J,aACA9J,KAAA4J,eACA5J,KAAA6J,iBACA7J,KAqEA,QAAAsoC,GAAAzpC,EAAAyd,EAAAtP,GAUA,MATAlN,UAAAwc,IACAA,EAAA,MAEAxc,SAAAkN,GAAA,OAAAA,IACAA,MAEA1H,EAAAgF,kBAAAlN,KAAA4C,KAAAsc,EAAAtP,GACAhN,KAAAnB,SACAmB,KAAAyP,UAAA3Q,EAAAypC,gBACAvoC,KAyDA,QAAAwoC,GAAA3pC,EAAAyd,EAAAtP,GAUA,MATAlN,UAAAwc,IACAA,EAAA,MAEAxc,SAAAkN,GAAA,OAAAA,IACAA,MAEA1H,EAAAgF,kBAAAlN,KAAA4C,KAAAsc,EAAAtP,GACAhN,KAAAnB,SACAmB,KAAAyP,UAAA3Q,EAAA2pC,gBACAzoC,KAYA,QAAA0oC,GAAA7pC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAA2oC,GAAA9pC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAA4oC,GAAA/pC,EAAA4M,GAIA,MAHA+8B,GAAAprC,KAAA4C,KAAAnB,GACAmB,KAAA4B,GAAA,KACA4mC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KA2BA,QAAA6oC,GAAAhqC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KA+BA,QAAA8oC,GAAAjqC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KA+BA,QAAA+oC,GAAAlqC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KA+BA,QAAAgpC,GAAAnqC,EAAA4M,GAIA,MAHA+8B,GAAAprC,KAAA4C,KAAAnB,GACAmB,KAAA4B,GAAA,KACA4mC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KA2BA,QAAAipC,GAAApqC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAkpC,GAAArqC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAoBA,QAAAmpC,GAAAtqC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAopC,GAAAvqC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAqpC,GAAAxqC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAoBA,QAAAspC,GAAAzqC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAupC,GAAA1qC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAoBA,QAAAwpC,GAAA3qC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAypC,GAAA5qC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAoBA,QAAA0pC,GAAA7qC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAA2pC,GAAA9qC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAA4pC,GAAA/qC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAA6pC,GAAAhrC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAoBA,QAAA8pC,GAAAjrC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAA+pC,GAAAlrC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAgqC,GAAAnrC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAiqC,GAAAprC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KA+BA,QAAAkqC,GAAArrC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAmqC,GAAAtrC,EAAA4M,GAIA,MAHA+8B,GAAAprC,KAAA4C,KAAAnB,GACAmB,KAAA4B,GAAA,KACA4mC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KA2BA,QAAAoqC,GAAAvrC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAqqC,GAAAxrC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAsqC,GAAAzrC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAuqC,GAAA1rC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAwqC,GAAA3rC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KA+BA,QAAAyqC,GAAA5rC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAoBA,QAAA0qC,GAAA7rC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAA2qC,GAAA9rC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAA4qC,GAAA/rC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAA6qC,GAAAhsC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAA8qC,GAAAjsC,EAAA4M,GAIA,MAHA+8B,GAAAprC,KAAA4C,KAAAnB,GACAmB,KAAA4B,GAAA,KACA4mC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KA2BA,QAAA+qC,GAAAlsC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAgrC,GAAAnsC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAwBA,QAAAirC,GAAApsC,EAAA4M,GAGA,MAFA+8B,GAAAprC,KAAA4C,KAAAnB,GACA2pC,EAAAloC,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,GACAzL,KAohBA,QAAAkrC,GAAArsC,EAAAyd,EAAAtP,GAUA,MATAlN,UAAAwc,IACAA,EAAA,MAEAxc,SAAAkN,GAAA,OAAAA,IACAA,MAEA1H,EAAAgF,kBAAAlN,KAAA4C,KAAAsc,EAAAtP,GACAhN,KAAAnB,SACAmB,KAAAyP,UAAA3Q,EAAAqsC,iBACAnrC,KA72DA,GAAAsF,GAAAzI,EAAA,GACAuI,EAAAvI,EAAA,IAAAuI,kBAIAS,GAAA,YACA,qBACA,mBACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,eACA,oBACA,eACA,eACA,eACA,eACA,uBACA,eACA,qBACA,gBACA,gBACA,0BACA,sBACA,qBACA,gBACA,gBACA,iBACA,iBACA,kBACA,kBACA,iBACA,oBACA,sBACA,oBACA,qBACA,oBACA,oBACA,qBACA,oBACA,oBACA,mBACA,oBACA,oBACA,kBACA,oBACA,oBACA,oBACA,kBACA,qBACA,oBACA,uBACA,kBACA,oBACA,gBACA,gBACA,iBACA,iBACA,mBACA,kBACA,oBACA,oBACA,kBACA,oBACA,oBACA,oBACA,yBACA,uBACA,oBACA,yBACA,yBACA,4BACA,uBACA,uBACA,oBACA,kBACA,oBACA,oBACA,iBACA,oBACA,MAAAC,KAAA,IAGAL,GAAA,GAAAH,GAAAG,IAAAM,iBAAAC,YAAAH,GAEAF,EAAAF,EAAAQ,gBAAAC,IAAA,SAAAC,EAAAC,GAAmE,UAAAd,GAAAe,IAAAC,IAAAH,EAAAC,KAEnEmmB,EAAA,GAAAjnB,GAAAM,uBAEAgE,GAAA,iBAAqC,+BACrC,6CACA,mBAEAC,IAAA,6CACA,4CACA,sDACA,mDACA,+CACA,mDACA,4CACA,sBAEAC,IAAA,wCAWAhL,GAAAwB,UAAAC,OAAAC,OAAA8E,EAAA8E,OAAA9J,WACAxB,EAAAwB,UAAAF,YAAAtB,EAEAyB,OAAAgR,eAAAzS,EAAAwB,UAAA,OACAkR,IAAA,WACA,MAAA/L,MAIA3G,EAAAyH,IAAAjB,EAAAkB,MAAAD,IACAzH,EAAA2H,KAAA,EACA3H,EAAA4H,KAAA,EACA5H,EAAA6H,KAAA,EACA7H,EAAA8H,KAAA,EACA9H,EAAA+H,KAAA,EACA/H,EAAAgI,KAAA,EACAhI,EAAAiI,KAAA,EACAjI,EAAAkI,KAAA,EACAlI,EAAAmI,KAAA,EACAnI,EAAAoI,OAAA,GACApI,EAAAqI,MAAA,GACArI,EAAAsI,MAAA,GACAtI,EAAAuI,IAAA,GACAvI,EAAAwI,MAAA,GACAxI,EAAAyI,IAAA,GACAzI,EAAA0I,IAAA,GACA1I,EAAA2I,IAAA,GACA3I,EAAA4I,IAAA,GACA5I,EAAAoD,GAAA,GACApD,EAAA6I,SAAA,GACA7I,EAAA8I,YAAA,GACA9I,EAAA+I,MAAA,GACA/I,EAAAgJ,KAAA,GACAhJ,EAAAiJ,IAAA,GACAjJ,EAAAkJ,MAAA,GACAlJ,EAAAmJ,KAAA,GACAnJ,EAAAoJ,IAAA,GACApJ,EAAAqJ,OAAA,GACArJ,EAAAsJ,MAAA,GACAtJ,EAAAuJ,MAAA,GACAvJ,EAAAwJ,IAAA,GACAxJ,EAAAyJ,IAAA,GACAzJ,EAAA0J,IAAA,GACA1J,EAAA2J,IAAA,GACA3J,EAAA4J,KAAA,GACA5J,EAAA6J,KAAA,GACA7J,EAAA8J,KAAA,GACA9J,EAAA+J,OAAA,GACA/J,EAAAgK,OAAA,GACAhK,EAAAiK,OAAA,GACAjK,EAAAkK,QAAA,GACAlK,EAAAmK,OAAA,GACAnK,EAAAoK,IAAA,GACApK,EAAAqK,GAAA,GACArK,EAAAsK,IAAA,GACAtK,EAAAuK,IAAA,GACAvK,EAAAwK,IAAA,GACAxK,EAAAyK,IAAA,GACAzK,EAAA0K,GAAA,GACA1K,EAAA2K,IAAA,GACA3K,EAAA4K,QAAA,GAEA5K,EAAAypC,gBAAA,EACAzpC,EAAA2pC,gBAAA,EACA3pC,EAAAqsC,iBAAA,EAeA7C,EAAAhoC,UAAAC,OAAAC,OAAA8E,EAAAgF,kBAAAhK,WACAgoC,EAAAhoC,UAAAF,YAAAkoC,EAEAA,EAAAhoC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAGAF,EAAAhoC,UAAA8qC,YAAA,WACA,MAAAprC,MAAA4jB,oBAAAsnB,EAAA,IAGA5C,EAAAhoC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAK,gBAAAS,MAEAd,EAAA6gB,cAAA/f,OAOAlB,EAAAwpC,oBAEAxpC,EAAAwB,UAAAjB,WAAA,WAEA,GAAAuZ,GAAA,GAAA0vB,GAAAtoC,UAAAs2B,KAAAt2B,KAAAiM,MACAjM,MAAA+hB,UAAAnJ,EAAA,EAAA9Z,EAAAypC,gBACA,KACAvoC,KAAAsnC,cAAA1uB,EAAA,GACA5Y,KAAAiM,MAAA,EACAjM,KAAAY,WAAA,GACAZ,KAAAiM,MAAA,EACAjM,KAAAslC,YAAA3E,KAAA3gC,KACA,IAAAqrC,GAAArrC,KAAAwF,QAAAyzB,gBAAAj5B,KAAAuxB,OAAA,EAAAvxB,KAAAs2B,KACA,KAAA+U,IACArrC,KAAAiM,MAAA,EACAjM,KAAAorC,eAGK,MAAAxX,GACL,KAAAA,YAAAtuB,GAAA2E,MAAA4rB,sBAKA,KAAAjC,EAJAhb,GAAAqK,UAAA2Q,EACA5zB,KAAAslC,YAAAzE,YAAA7gC,KAAA4zB,GACA5zB,KAAAslC,YAAAzS,QAAA7yB,KAAA4zB,GAIK,QACL5zB,KAAAgiB,WAEA,MAAApJ,IAgBA4vB,EAAAloC,UAAAC,OAAAC,OAAA8E,EAAAgF,kBAAAhK,WACAkoC,EAAAloC,UAAAF,YAAAooC,EAIAA,EAAAloC,UAAA6iB,SAAA,SAAA1X,GACAnG,EAAAgF,kBAAAhK,UAAA6iB,SAAA/lB,KAAA4C,KAAAyL,IASAi9B,EAAApoC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAooC,EAAApoC,UAAAF,YAAAsoC,EAEA5pC,EAAA4pC,aAEAA,EAAApoC,UAAAkI,IAAA,WACA,MAAAxI,MAAAyjB,SAAA3kB,EAAA0J,IAAA,IAGAkgC,EAAApoC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAE,EAAApoC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA6B,SAAAf,MAEAd,EAAA6gB,cAAA/f,OAWA2oC,EAAAroC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAqoC,EAAAroC,UAAAF,YAAAuoC,EAEA7pC,EAAA6pC,cAEAA,EAAAroC,UAAAqI,KAAA,WACA,MAAA3I,MAAAyjB,SAAA3kB,EAAA6J,KAAA,IAGAggC,EAAAroC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAG,EAAAroC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAgC,UAAAlB,MAEAd,EAAA6gB,cAAA/f,OAYA4oC,EAAAtoC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAsoC,EAAAtoC,UAAAF,YAAAwoC,EAEA9pC,EAAA8pC,gBAEAA,EAAAtoC,UAAAM,WAAA,SAAAyO,GAIA,MAHAvP,UAAAuP,IACAA,EAAA,MAEA,OAAAA,EACArP,KAAA8jB,qBAAA0kB,GAEAxoC,KAAA4jB,oBAAA4kB,EAAAn5B,IAGAu5B,EAAAtoC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAkC,YAAApB,MAEAd,EAAA6gB,cAAA/f,OAWA6oC,EAAAvoC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAuoC,EAAAvoC,UAAAF,YAAAyoC,EAEA/pC,EAAA+pC,qBAEAA,EAAAvoC,UAAAM,WAAA,SAAAyO,GAIA,MAHAvP,UAAAuP,IACAA,EAAA,MAEA,OAAAA,EACArP,KAAA8jB,qBAAA0kB,GAEAxoC,KAAA4jB,oBAAA4kB,EAAAn5B,IAIAw5B,EAAAvoC,UAAAsH,YAAA,WACA,MAAA5H,MAAAyjB,SAAA3kB,EAAA8I,YAAA,IAEAihC,EAAAvoC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAqC,iBAAAvB,MAEAd,EAAA6gB,cAAA/f,OAWA8oC,EAAAxoC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAwoC,EAAAxoC,UAAAF,YAAA0oC,EAEAhqC,EAAAgqC,kBAEAA,EAAAxoC,UAAAM,WAAA,SAAAyO,GAIA,MAHAvP,UAAAuP,IACAA,EAAA,MAEA,OAAAA,EACArP,KAAA8jB,qBAAA0kB,GAEAxoC,KAAA4jB,oBAAA4kB,EAAAn5B,IAIAy5B,EAAAxoC,UAAAqH,SAAA,WACA,MAAA3H,MAAAyjB,SAAA3kB,EAAA6I,SAAA,IAEAmhC,EAAAxoC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAsC,cAAAxB,MAEAd,EAAA6gB,cAAA/f,OAWA+oC,EAAAzoC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAyoC,EAAAzoC,UAAAF,YAAA2oC,EAEAjqC,EAAAiqC,iBAEAA,EAAAzoC,UAAA0I,QAAA,WACA,MAAAhJ,MAAAyjB,SAAA3kB,EAAAkK,QAAA,IAGA+/B,EAAAzoC,UAAAM,WAAA,SAAAyO,GAIA,MAHAvP,UAAAuP,IACAA,EAAA,MAEA,OAAAA,EACArP,KAAA8jB,qBAAA0kB,GAEAxoC,KAAA4jB,oBAAA4kB,EAAAn5B,IAGA05B,EAAAzoC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAuC,aAAAzB,MAEAd,EAAA6gB,cAAA/f,OAYAgpC,EAAA1oC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA0oC,EAAA1oC,UAAAF,YAAA4oC,EAEAlqC,EAAAkqC,gBAEAA,EAAA1oC,UAAAM,WAAA,SAAAyO,GAIA,MAHAvP,UAAAuP,IACAA,EAAA,MAEA,OAAAA,EACArP,KAAA8jB,qBAAA0kB,GAEAxoC,KAAA4jB,oBAAA4kB,EAAAn5B,IAGA25B,EAAA1oC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAyC,YAAA3B,MAEAd,EAAA6gB,cAAA/f,OAWAipC,EAAA3oC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA2oC,EAAA3oC,UAAAF,YAAA6oC,EAEAnqC,EAAAmqC,gBAEAA,EAAA3oC,UAAAuI,OAAA,WACA,MAAA7I,MAAAyjB,SAAA3kB,EAAA+J,OAAA,IAGAogC,EAAA3oC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAS,EAAA3oC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA6C,YAAA/B,MAEAd,EAAA6gB,cAAA/f,OAWAkpC,EAAA5oC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA4oC,EAAA5oC,UAAAF,YAAA8oC,EAEApqC,EAAAoqC,mBAEAA,EAAA5oC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAU,EAAA5oC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAuF,eAAAzE,MAEAd,EAAA6gB,cAAA/f,OAWAmpC,EAAA7oC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA6oC,EAAA7oC,UAAAF,YAAA+oC,EAEArqC,EAAAqqC,gBAEAA,EAAA7oC,UAAA2I,OAAA,WACA,MAAAjJ,MAAAyjB,SAAA3kB,EAAAmK,OAAA,IAGAkgC,EAAA7oC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAW,EAAA7oC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA+C,YAAAjC,MAEAd,EAAA6gB,cAAA/f,OAWAopC,EAAA9oC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA8oC,EAAA9oC,UAAAF,YAAAgpC,EAEAtqC,EAAAsqC,gBAEAA,EAAA9oC,UAAAwI,OAAA,WACA,MAAA9I,MAAAyjB,SAAA3kB,EAAAgK,OAAA,IAGAsgC,EAAA9oC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAY,EAAA9oC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAkD,YAAApC,MAEAd,EAAA6gB,cAAA/f,OAWAqpC,EAAA/oC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA+oC,EAAA/oC,UAAAF,YAAAipC,EAEAvqC,EAAAuqC,eAEAA,EAAA/oC,UAAAuH,MAAA,WACA,MAAA7H,MAAAyjB,SAAA3kB,EAAA+I,MAAA,IAEAwhC,EAAA/oC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAoD,WAAAtC,MAEAd,EAAA6gB,cAAA/f,OAWAspC,EAAAhpC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAgpC,EAAAhpC,UAAAF,YAAAkpC,EAEAxqC,EAAAwqC,gBAEAA,EAAAhpC,UAAAyI,OAAA,WACA,MAAA/I,MAAAyjB,SAAA3kB,EAAAiK,OAAA,IAGAugC,EAAAhpC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAc,EAAAhpC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAsD,YAAAxC,MAEAd,EAAA6gB,cAAA/f,OAWAupC,EAAAjpC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAipC,EAAAjpC,UAAAF,YAAAmpC,EAEAzqC,EAAAyqC,qBAEAA,EAAAjpC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAe,EAAAjpC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAuD,iBAAAzC,MAEAd,EAAA6gB,cAAA/f,OAWAwpC,EAAAlpC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAkpC,EAAAlpC,UAAAF,YAAAopC,EAEA1qC,EAAA0qC,aAEAA,EAAAlpC,UAAA4H,IAAA,WACA,MAAAlI,MAAAyjB,SAAA3kB,EAAAoJ,IAAA,IAGAshC,EAAAlpC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAgB,EAAAlpC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAwD,SAAA1C,MAEAd,EAAA6gB,cAAA/f,OAWAypC,EAAAnpC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAmpC,EAAAnpC,UAAAF,YAAAqpC,EAEA3qC,EAAA2qC,gBAEAA,EAAAnpC,UAAA4G,OAAA,WACA,MAAAlH,MAAAyjB,SAAA3kB,EAAAoI,OAAA,IAEAuiC,EAAAnpC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA0D,YAAA5C,MAEAd,EAAA6gB,cAAA/f,OAWA0pC,EAAAppC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAopC,EAAAppC,UAAAF,YAAAspC,EAEA5qC,EAAA4qC,cAEAA,EAAAppC,UAAAoI,KAAA,WACA,MAAA1I,MAAAyjB,SAAA3kB,EAAA4J,KAAA,IAGAghC,EAAAppC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAkB,EAAAppC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA8D,UAAAhD,MAEAd,EAAA6gB,cAAA/f,OAWA2pC,EAAArpC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAqpC,EAAArpC,UAAAF,YAAAupC,EAEA7qC,EAAA6qC,eAEAA,EAAArpC,UAAA8H,MAAA,WACA,MAAApI,MAAAyjB,SAAA3kB,EAAAsJ,MAAA,IAGAuhC,EAAArpC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAmB,EAAArpC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAgE,WAAAlD,MAEAd,EAAA6gB,cAAA/f,OAWA4pC,EAAAtpC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAspC,EAAAtpC,UAAAF,YAAAwpC,EAEA9qC,EAAA8qC,eAEAA,EAAAtpC,UAAA+H,MAAA,WACA,MAAArI,MAAAyjB,SAAA3kB,EAAAuJ,MAAA,IAGAuhC,EAAAtpC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAoB,EAAAtpC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAkE,WAAApD,MAEAd,EAAA6gB,cAAA/f,OAWA6pC,EAAAvpC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAupC,EAAAvpC,UAAAF,YAAAypC,EAEA/qC,EAAA+qC,YAEAA,EAAAvpC,UAAA4B,GAAA,WACA,MAAAlC,MAAAyjB,SAAA3kB,EAAAoD,GAAA,IAEA2nC,EAAAvpC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAoE,QAAAtD,MAEAd,EAAA6gB,cAAA/f,OAWA8pC,EAAAxpC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAwpC,EAAAxpC,UAAAF,YAAA0pC,EAEAhrC,EAAAgrC,cAEAA,EAAAxpC,UAAAsI,KAAA,WACA,MAAA5I,MAAAyjB,SAAA3kB,EAAA8J,KAAA,IAGAkhC,EAAAxpC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAsB,EAAAxpC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAqE,UAAAvD,MAEAd,EAAA6gB,cAAA/f,OAWA+pC,EAAAzpC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAypC,EAAAzpC,UAAAF,YAAA2pC,EAEAjrC,EAAAirC,eAEAA,EAAAzpC,UAAA0H,MAAA,WACA,MAAAhI,MAAAyjB,SAAA3kB,EAAAkJ,MAAA,IAGA+hC,EAAAzpC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAuB,EAAAzpC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAuE,WAAAzD,MAEAd,EAAA6gB,cAAA/f,OAWAgqC,EAAA1pC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA0pC,EAAA1pC,UAAAF,YAAA4pC,EAEAlrC,EAAAkrC,YAEAA,EAAA1pC,UAAA6I,GAAA,WACA,MAAAnJ,MAAAyjB,SAAA3kB,EAAAqK,GAAA,IAGA6gC,EAAA1pC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAwB,EAAA1pC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAyE,QAAA3D,MAEAd,EAAA6gB,cAAA/f,OAWAiqC,EAAA3pC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA2pC,EAAA3pC,UAAAF,YAAA6pC,EAEAnrC,EAAAmrC,aAEAA,EAAA3pC,UAAAM,WAAA,SAAAyO,GAIA,MAHAvP,UAAAuP,IACAA,EAAA,MAEA,OAAAA,EACArP,KAAA8jB,qBAAA0kB,GAEAxoC,KAAA4jB,oBAAA4kB,EAAAn5B,IAIA46B,EAAA3pC,UAAA+G,IAAA,WACA,MAAArH,MAAAyjB,SAAA3kB,EAAAuI,IAAA,IAEA4iC,EAAA3pC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA2E,SAAA7D,MAEAd,EAAA6gB,cAAA/f,OAWAkqC,EAAA5pC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA4pC,EAAA5pC,UAAAF,YAAA8pC,EAEAprC,EAAAorC,aAEAA,EAAA5pC,UAAA+I,IAAA,WACA,MAAArJ,MAAAyjB,SAAA3kB,EAAAuK,IAAA,IAGA6gC,EAAA5pC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEA0B,EAAA5pC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA4E,SAAA9D,MAEAd,EAAA6gB,cAAA/f,OAYAmqC,EAAA7pC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA6pC,EAAA7pC,UAAAF,YAAA+pC,EAEArrC,EAAAqrC,gBAEAA,EAAA7pC,UAAAM,WAAA,SAAAyO,GAIA,MAHAvP,UAAAuP,IACAA,EAAA,MAEA,OAAAA,EACArP,KAAA8jB,qBAAA0kB,GAEAxoC,KAAA4jB,oBAAA4kB,EAAAn5B,IAGA86B,EAAA7pC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA8E,YAAAhE,MAEAd,EAAA6gB,cAAA/f,OAWAoqC,EAAA9pC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA8pC,EAAA9pC,UAAAF,YAAAgqC,EAEAtrC,EAAAsrC,aAEAA,EAAA9pC,UAAAiI,IAAA,WACA,MAAAvI,MAAAyjB,SAAA3kB,EAAAyJ,IAAA,IAGA6hC,EAAA9pC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEA4B,EAAA9pC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA+E,SAAAjE,MAEAd,EAAA6gB,cAAA/f,OAWAqqC,EAAA/pC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA+pC,EAAA/pC,UAAAF,YAAAiqC,EAEAvrC,EAAAurC,aAEAA,EAAA/pC,UAAAiJ,IAAA,WACA,MAAAvJ,MAAAyjB,SAAA3kB,EAAAyK,IAAA,IAGA8gC,EAAA/pC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEA6B,EAAA/pC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAiF,SAAAnE,MAEAd,EAAA6gB,cAAA/f,OAWAsqC,EAAAhqC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAgqC,EAAAhqC,UAAAF,YAAAkqC,EAEAxrC,EAAAwrC,cAEAA,EAAAhqC,UAAAwH,KAAA,WACA,MAAA9H,MAAAyjB,SAAA3kB,EAAAgJ,KAAA,IAGAwiC,EAAAhqC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEA8B,EAAAhqC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAkF,UAAApE,MAEAd,EAAA6gB,cAAA/f,OAWAuqC,EAAAjqC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAiqC,EAAAjqC,UAAAF,YAAAmqC,EAEAzrC,EAAAyrC,aAEAA,EAAAjqC,UAAAmI,IAAA,WACA,MAAAzI,MAAAyjB,SAAA3kB,EAAA2J,IAAA,IAGA8hC,EAAAjqC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEA+B,EAAAjqC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAoF,SAAAtE,MAEAd,EAAA6gB,cAAA/f,OAWAwqC,EAAAlqC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAkqC,EAAAlqC,UAAAF,YAAAoqC,EAEA1rC,EAAA0rC,eAEAA,EAAAlqC,UAAAM,WAAA,SAAAyO,GAIA,MAHAvP,UAAAuP,IACAA,EAAA,MAEA,OAAAA,EACArP,KAAA8jB,qBAAA0kB,GAEAxoC,KAAA4jB,oBAAA4kB,EAAAn5B,IAIAm7B,EAAAlqC,UAAAgH,MAAA,WACA,MAAAtH,MAAAyjB,SAAA3kB,EAAAwI,MAAA,IAEAkjC,EAAAlqC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAqF,WAAAvE,MAEAd,EAAA6gB,cAAA/f,OAWAyqC,EAAAnqC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAmqC,EAAAnqC,UAAAF,YAAAqqC,EAEA3rC,EAAA2rC,eAEAA,EAAAnqC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAiC,EAAAnqC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAsF,WAAAxE,MAEAd,EAAA6gB,cAAA/f,OAWA0qC,EAAApqC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAoqC,EAAApqC,UAAAF,YAAAsqC,EAEA5rC,EAAA4rC,aAEAA,EAAApqC,UAAAgJ,IAAA,WACA,MAAAtJ,MAAAyjB,SAAA3kB,EAAAwK,IAAA,IAGAohC,EAAApqC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAkC,EAAApqC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAwF,SAAA1E,MAEAd,EAAA6gB,cAAA/f,OAWA2qC,EAAArqC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAqqC,EAAArqC,UAAAF,YAAAuqC,EAEA7rC,EAAA6rC,aAEAA,EAAArqC,UAAAyH,IAAA,WACA,MAAA/H,MAAAyjB,SAAA3kB,EAAAiJ,IAAA,IAGA4iC,EAAArqC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAmC,EAAArqC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAyF,SAAA3E,MAEAd,EAAA6gB,cAAA/f,OAWA4qC,EAAAtqC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAsqC,EAAAtqC,UAAAF,YAAAwqC,EAEA9rC,EAAA8rC,aAEAA,EAAAtqC,UAAAgI,IAAA,WACA,MAAAtI,MAAAyjB,SAAA3kB,EAAAwJ,IAAA,IAGAsiC,EAAAtqC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAoC,EAAAtqC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA0F,SAAA5E,MAEAd,EAAA6gB,cAAA/f,OAWA6qC,EAAAvqC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAuqC,EAAAvqC,UAAAF,YAAAyqC,EAEA/rC,EAAA+rC,aAEAA,EAAAvqC,UAAA8I,IAAA,WACA,MAAApJ,MAAAyjB,SAAA3kB,EAAAsK,IAAA,IAGAyhC,EAAAvqC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAqC,EAAAvqC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA4F,SAAA9E,MAEAd,EAAA6gB,cAAA/f,OAYA8qC,EAAAxqC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAwqC,EAAAxqC,UAAAF,YAAA0qC,EAEAhsC,EAAAgsC,aAEAA,EAAAxqC,UAAAM,WAAA,SAAAyO,GAIA,MAHAvP,UAAAuP,IACAA,EAAA,MAEA,OAAAA,EACArP,KAAA8jB,qBAAA0kB,GAEAxoC,KAAA4jB,oBAAA4kB,EAAAn5B,IAGAy7B,EAAAxqC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA6F,SAAA/E,MAEAd,EAAA6gB,cAAA/f,OAWA+qC,EAAAzqC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACAyqC,EAAAzqC,UAAAF,YAAA2qC,EAEAjsC,EAAAisC,cAEAA,EAAAzqC,UAAA2H,KAAA,WACA,MAAAjI,MAAAyjB,SAAA3kB,EAAAmJ,KAAA,IAGA8iC,EAAAzqC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAuC,EAAAzqC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA8F,UAAAhF,MAEAd,EAAA6gB,cAAA/f,OAWAgrC,EAAA1qC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA0qC,EAAA1qC,UAAAF,YAAA4qC,EAEAlsC,EAAAksC,aAEAA,EAAA1qC,UAAA4I,IAAA,WACA,MAAAlJ,MAAAyjB,SAAA3kB,EAAAoK,IAAA,IAGA8hC,EAAA1qC,UAAAM,WAAA,WACA,MAAAZ,MAAA4jB,oBAAA4kB,EAAA,IAEAwC,EAAA1qC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAgG,SAAAlF,MAEAd,EAAA6gB,cAAA/f,OAWAirC,EAAA3qC,UAAAC,OAAAC,OAAAgoC,EAAAloC,WACA2qC,EAAA3qC,UAAAF,YAAA6qC,EAEAnsC,EAAAmsC,gBAEAA,EAAA3qC,UAAA6H,OAAA,WACA,MAAAnI,MAAAyjB,SAAA3kB,EAAAqJ,OAAA,IAGA8iC,EAAA3qC,UAAAM,WAAA,SAAAyO,GAIA,MAHAvP,UAAAuP,IACAA,EAAA,MAEA,OAAAA,EACArP,KAAA8jB,qBAAA0kB,GAEAxoC,KAAA4jB,oBAAA4kB,EAAAn5B,IAGA47B,EAAA3qC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAAiG,YAAAnF,MAEAd,EAAA6gB,cAAA/f,OAMAlB,EAAAwB,UAAAM,WAAA,SAAA0qC,GACAxrC,SAAAwrC,IACAA,EAAA,EAEA,IAAAC,GAAAvrC,KAAAs2B,KACAkV,EAAAxrC,KAAAiM,MACA2M,EAAA,GAAA4vB,GAAAxoC,UAAAs2B,KAAAkV,GACAC,EAAA7yB,EACA8yB,EAAA,CACA1rC,MAAAwnC,mBAAA5uB,EAAA,EAAA9Z,EAAA2pC,gBAAA6C,EACA,IAAAK,GAAA,CACA,KAGA,OAFA3rC,KAAAsnC,cAAA1uB,EAAA,GACA5Y,KAAAiM,MAAA,GACAjM,KAAAuxB,OAAA5C,GAAA,IACA,IAAA7vB,GAAAkJ,MACA4Q,EAAA,GAAAmxB,GAAA/pC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EAEA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAkJ,OACAhI,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAmJ,KACA2Q,EAAA,GAAAmyB,GAAA/qC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAmJ,MACAjI,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAoJ,IACA0Q,EAAA,GAAA4wB,GAAAxpC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAoJ,KACAlI,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAsJ,MACAwQ,EAAA,GAAA+wB,GAAA3pC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAsJ,OACApI,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAuJ,MACAuQ,EAAA,GAAAgxB,GAAA5pC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAuJ,OACArI,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAwJ,IACAsQ,EAAA,GAAAgyB,GAAA5qC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAwJ,KACAtI,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAyJ,IACAqQ,EAAA,GAAAwxB,GAAApqC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAyJ,KACAvI,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAA0J,IACAoQ,EAAA,GAAA8vB,GAAA1oC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA0J,KACAxI,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAA2J,IACAmQ,EAAA,GAAA2xB,GAAAvqC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA2J,KACAzI,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAA4J,KACAkQ,EAAA,GAAA8wB,GAAA1pC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA4J,MACA1I,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAA6J,KACAiQ,EAAA,GAAA+vB,GAAA3oC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA6J,MACA3I,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAA8J,KACAgQ,EAAA,GAAAkxB,GAAA9pC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA8J,MACA5I,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAA+J,OACA+P,EAAA,GAAAqwB,GAAAjpC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA+J,QACA7I,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAgK,OACA8P,EAAA,GAAAwwB,GAAAppC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAgK,QACA9I,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAiK,OACA6P,EAAA,GAAA0wB,GAAAtpC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAiK,QACA/I,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAmK,OACA2P,EAAA,GAAAuwB,GAAAnpC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAmK,QACAjJ,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAoK,IACA0P,EAAA,GAAAoyB,GAAAhrC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAoK,KACAlJ,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAqK,GACAyP,EAAA,GAAAoxB,GAAAhqC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAqK,IACAnJ,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAsK,IACAwP,EAAA,GAAAiyB,GAAA7qC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAsK,KACApJ,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAuK,IACAuP,EAAA,GAAAsxB,GAAAlqC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAuK,KACArJ,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAwK,IACAsP,EAAA,GAAA8xB,GAAA1qC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAwK,KACAtJ,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAyK,IACAqP,EAAA,GAAAyxB,GAAArqC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAyK,KACAvJ,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAgJ,KACA8Q,EAAA,GAAA0xB,GAAAtqC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAgJ,MACA9H,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAAiJ,IACA6Q,EAAA,GAAA+xB,GAAA3qC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAiJ,KACA/H,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MACA,KAAA9B,GAAA4I,IACAkR,EAAA,GAAA6xB,GAAAzqC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA4I,KACA1H,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,EACA,MACA,KAAA9B,GAAA2I,IACAmR,EAAA,GAAAswB,GAAAlpC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA2I,KACAzH,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,EACA,MACA,KAAA9B,GAAAqJ,OACAyQ,EAAA,GAAAqyB,GAAAjrC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAqJ,QACAnI,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA2H,MACAzG,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACAZ,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA4H,MACA1G,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACAZ,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA6H;AACA,KACA,KAAA7H,GAAAkK,QACA4P,EAAA,GAAAmwB,GAAA/oC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAkK,SACAhJ,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA2H,MACAzG,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACAZ,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA4H,MACA1G,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACAZ,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA6H,KACA,MACA,KAAA7H,GAAAoI,OACA0R,EAAA,GAAA6wB,GAAAzpC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAoI,OACA,MACA,KAAApI,GAAA2H,KACAmS,EAAA,GAAA2wB,GAAAvpC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA2H,MACAzG,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACAZ,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA6H,KACA,MACA,KAAA7H,GAAAoD,GACA0W,EAAA,GAAAixB,GAAA7pC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAoD,IACAlC,KAAAiM,MAAA,GACAjM,KAAAslC,YAAA3E,KAAA3gC,KACA,IAAAqrC,GAAArrC,KAAAwF,QAAAyzB,gBAAAj5B,KAAAuxB,OAAA,EAAAvxB,KAAAs2B,KACA,KAAA+U,IACArrC,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAmI,MAGA,MACA,KAAAnI,GAAA+I,MACA+Q,EAAA,GAAAywB,GAAArpC,KAAA4Y,GACA5Y,KAAAs2B,KAAA1d,EACA6yB,EAAA7yB,EACA5Y,KAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAA+I,MACA,MACA,SACA,SAAAvC,GAAA2E,MAAAmsB,qBAAAp2B,MAEAA,KAAAs2B,KAAAljB,KAAApT,KAAAuxB,OAAA4H,OACAn5B,KAAAiM,MAAA,IACAjM,KAAAslC,YAAA3E,KAAA3gC,KAEA,KADA,GAAA4rC,GAAA5rC,KAAAwF,QAAAyzB,gBAAAj5B,KAAAuxB,OAAA,EAAAvxB,KAAAs2B,MACA,GAAAsV,MAAAtmC,EAAAG,IAAAgF,IAAA6C,oBAAA,CACA,OAAAs+B,EAAA,CACA,OAAA5rC,KAAA0lC,iBACA1lC,KAAAsmC,uBAEAmF,EAAA7yB,EACA5Y,KAAAiM,MAAA,IACAjM,KAAAslC,YAAA3E,KAAA3gC,KACA,IAAAqrC,GAAArrC,KAAAwF,QAAAyzB,gBAAAj5B,KAAAuxB,OAAA,EAAAvxB,KAAAs2B,KACA,QAAA+U,GACA,OAIA,GAHAzyB,EAAA,GAAAkyB,GAAA9qC,KAAA,GAAAwoC,GAAAxoC,KAAAurC,EAAAC,IACAxrC,KAAAynC,wBAAA7uB,EAAA8yB,EAAA5sC,EAAA2pC,iBACAzoC,KAAAiM,MAAA,IACAjM,KAAA8Y,SAAA9Y,KAAAs2B,KAAA,IACA,SAAAhxB,GAAA2E,MAAAwsB,yBAAAz2B,KAAA,+BAEAA,MAAAiM,MAAA,GACA2M,EAAAhX,GAAA5B,KAAAuxB,OAAA4H,GAAA,GACAwS,EAAA3rC,KAAAuxB,OAAA5C,GAAA,GACAgd,IAAA7sC,EAAA8H,MAAA+kC,IAAA7sC,EAAA+H,KACA+R,EAAAhX,GAAA5B,KAAAslC,YAAA5E,cAAA1gC,MAGAA,KAAA+uB,UAEA/uB,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MAEA,QAIA,GAHAgY,EAAA,GAAAqxB,GAAAjqC,KAAA,GAAAwoC,GAAAxoC,KAAAurC,EAAAC,IACAxrC,KAAAynC,wBAAA7uB,EAAA8yB,EAAA5sC,EAAA2pC,iBACAzoC,KAAAiM,MAAA,IACAjM,KAAA8Y,SAAA9Y,KAAAs2B,KAAA,IACA,SAAAhxB,GAAA2E,MAAAwsB,yBAAAz2B,KAAA,+BAEAA,MAAAiM,MAAA,GACA0/B,EAAA3rC,KAAAuxB,OAAA5C,GAAA,GACAgd,IAAA7sC,EAAAgI,MAAA6kC,IAAA7sC,EAAAuI,IACArH,KAAAslC,YAAA5E,cAAA1gC,MAGAA,KAAA+uB,UAEA/uB,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MAEA,QAIA,GAHAgY,EAAA,GAAA4xB,GAAAxqC,KAAA,GAAAwoC,GAAAxoC,KAAAurC,EAAAC,IACAxrC,KAAAynC,wBAAA7uB,EAAA8yB,EAAA5sC,EAAA2pC,iBACAzoC,KAAAiM,MAAA,IACAjM,KAAA8Y,SAAA9Y,KAAAs2B,KAAA,IACA,SAAAhxB,GAAA2E,MAAAwsB,yBAAAz2B,KAAA,+BAEAA,MAAAiM,MAAA,GACAjM,KAAA3B,MAAAS,EAAAwI,OACAtH,KAAAiM,MAAA,GACAjM,KAAAY,WAAA,GACA,MAEA,QAIA,GAHAgY,EAAA,GAAAgwB,GAAA5oC,KAAA,GAAAwoC,GAAAxoC,KAAAurC,EAAAC,IACAxrC,KAAAynC,wBAAA7uB,EAAA8yB,EAAA5sC,EAAA2pC,iBACAzoC,KAAAiM,MAAA,IACAjM,KAAA8Y,SAAA9Y,KAAAs2B,KAAA,IACA,SAAAhxB,GAAA2E,MAAAwsB,yBAAAz2B,KAAA,+BAEAA,MAAAiM,MAAA,GACA2M,EAAAhX,GAAA5B,KAAAuxB,OAAA4H,GAAA,GACAwS,EAAA3rC,KAAAuxB,OAAA5C,GAAA,GACAgd,IAAA7sC,EAAAiI,MAAA4kC,IAAA7sC,EAAAkI,KACA4R,EAAAhX,GAAA5B,KAAAslC,YAAA5E,cAAA1gC,MAGAA,KAAA+uB,UAEA/uB,KAAAiM,MAAA,IACAjM,KAAAY,WAAA,GACA,MAEA,QAIA,GAHAgY,EAAA,GAAAowB,GAAAhpC,KAAA,GAAAwoC,GAAAxoC,KAAAurC,EAAAC,IACAxrC,KAAAynC,wBAAA7uB,EAAA8yB,EAAA5sC,EAAA2pC,iBACAzoC,KAAAiM,MAAA,KACAjM,KAAA8Y,SAAA9Y,KAAAs2B,KAAA,IACA,SAAAhxB,GAAA2E,MAAAwsB,yBAAAz2B,KAAA,+BAEAA,MAAAiM,MAAA,IACA2M,EAAAhX,GAAA5B,KAAAuxB,OAAA4H,GAAA,GACAwS,EAAA3rC,KAAAuxB,OAAA5C,GAAA,GACAgd,IAAA7sC,EAAAyI,KAAAokC,IAAA7sC,EAAA0I,IACAoR,EAAAhX,GAAA5B,KAAAslC,YAAA5E,cAAA1gC,MAGAA,KAAA+uB,UAEA/uB,KAAAiM,MAAA,IACAjM,KAAAY,WAAA,GACA,MAEA,QAIA,GAHAgY,EAAA,GAAAuxB,GAAAnqC,KAAA,GAAAwoC,GAAAxoC,KAAAurC,EAAAC,IACAxrC,KAAAynC,wBAAA7uB,EAAA8yB,EAAA5sC,EAAA2pC,iBACAzoC,KAAAiM,MAAA,KACAjM,KAAA8Y,SAAA9Y,KAAAs2B,KAAA,GACA,SAAAhxB,GAAA2E,MAAAwsB,yBAAAz2B,KAAA,8BAEAA,MAAAiM,MAAA,IACA2M,EAAAhX,GAAA5B,KAAAuxB,OAAA4H,GAAA,GACAwS,EAAA3rC,KAAAuxB,OAAA5C,GAAA,GACAgd,IAAA7sC,EAAA2I,KAAAkkC,IAAA7sC,EAAA4I,IACAkR,EAAAhX,GAAA5B,KAAAslC,YAAA5E,cAAA1gC,MAGAA,KAAA+uB,UAEA/uB,KAAAiM,MAAA,IACAjM,KAAAY,WAAA,GACA,MAEA,QAIA,GAHAgY,EAAA,GAAAkwB,GAAA9oC,KAAA,GAAAwoC,GAAAxoC,KAAAurC,EAAAC,IACAxrC,KAAAynC,wBAAA7uB,EAAA8yB,EAAA5sC,EAAA2pC,iBACAzoC,KAAAiM,MAAA,KACAjM,KAAA8Y,SAAA9Y,KAAAs2B,KAAA,GACA,SAAAhxB,GAAA2E,MAAAwsB,yBAAAz2B,KAAA,8BAEAA,MAAAiM,MAAA,IACAjM,KAAA3B,MAAAS,EAAA6I,UACA3H,KAAAiM,MAAA,IACAjM,KAAAY,WAAA,EACA,MAEA,QAIA,GAHAgY,EAAA,GAAAiwB,GAAA7oC,KAAA,GAAAwoC,GAAAxoC,KAAAurC,EAAAC,IACAxrC,KAAAynC,wBAAA7uB,EAAA8yB,EAAA5sC,EAAA2pC,iBACAzoC,KAAAiM,MAAA,KACAjM,KAAA8Y,SAAA9Y,KAAAs2B,KAAA,GACA,SAAAhxB,GAAA2E,MAAAwsB,yBAAAz2B,KAAA,8BAEAA,MAAAiM,MAAA,IACAjM,KAAA3B,MAAAS,EAAA8I,aACA5H,KAAAiM,MAAA,IACAjM,KAAAY,WAAA,IAKAZ,KAAAiM,MAAA,IACAjM,KAAAslC,YAAA3E,KAAA3gC,MACA4rC,EAAA5rC,KAAAwF,QAAAyzB,gBAAAj5B,KAAAuxB,OAAA,EAAAvxB,KAAAs2B,OAGK,MAAArsB,GACL,KAAAA,YAAA3E,GAAA2E,MAAA4rB,sBAKA,KAAA5rB,EAJA2O,GAAAqK,UAAAhZ,EACAjK,KAAAslC,YAAAzE,YAAA7gC,KAAAiK,GACAjK,KAAAslC,YAAAzS,QAAA7yB,KAAAiK,GAIK,QACLjK,KAAA0nC,wBAAA6D,GAEA,MAAA3yB,IAgBAsyB,EAAA5qC,UAAAC,OAAAC,OAAA8E,EAAAgF,kBAAAhK,WACA4qC,EAAA5qC,UAAAF,YAAA8qC,EAEAA,EAAA5qC,UAAAiG,IAAA,WACA,MAAAvG,MAAAyjB,SAAA3kB,EAAAyH,IAAA,IAGA2kC,EAAA5qC,UAAAO,OAAA,SAAA3B,GACA,MAAAA,aAAAkG,GACAlG,EAAA2sC,iBAAA7rC,MAEAd,EAAA6gB,cAAA/f,OAOAlB,EAAAosC,qBAEApsC,EAAAwB,UAAA8qC,YAAA,WAEA,GAAAxyB,GAAA,GAAAsyB,GAAAlrC,UAAAs2B,KAAAt2B,KAAAiM,MACAjM,MAAA+hB,UAAAnJ,EAAA,EAAA9Z,EAAAqsC,iBACA,KACAnrC,KAAAsnC,cAAA1uB,EAAA,GACA5Y,KAAAiM,MAAA,IACAjM,KAAA3B,MAAAS,EAAAyH,KACK,MAAAqtB,GACL,KAAAA,YAAAtuB,GAAA2E,MAAA4rB,sBAKA,KAAAjC,EAJAhb,GAAAqK,UAAA2Q,EACA5zB,KAAAslC,YAAAzE,YAAA7gC,KAAA4zB,GACA5zB,KAAAslC,YAAAzS,QAAA7yB,KAAA4zB,GAIK,QACL5zB,KAAAgiB,WAEA,MAAApJ,IAIA9Z,EAAAwB,UAAAuY,QAAA,SAAAD,EAAAnJ,EAAAiI,GACA,OAAAjI,GACA,OACA,MAAAzP,MAAA8rC,mBAAAlzB,EAAAlB,EACA,SACA,gCAAAjI,IAIA3Q,EAAAwB,UAAAwrC,mBAAA,SAAAlzB,EAAAlB,GACA,OAAAA,GACA,OACA,MAAA1X,MAAA8Y,SAAA9Y,KAAAs2B,KAAA,GACA,QACA,MAAAt2B,MAAA8Y,SAAA9Y,KAAAs2B,KAAA,GACA,QACA,MAAAt2B,MAAA8Y,SAAA9Y,KAAAs2B,KAAA,GACA,QACA,MAAAt2B,MAAA8Y,SAAA9Y,KAAAs2B,KAAA,GACA,QACA,MAAAt2B,MAAA8Y,SAAA9Y,KAAAs2B,KAAA,GACA,QACA,MAAAt2B,MAAA8Y,SAAA9Y,KAAAs2B,KAAA,EACA,QACA,MAAAt2B,MAAA8Y,SAAA9Y,KAAAs2B,KAAA,EACA,QACA,MAAAt2B,MAAA8Y,SAAA9Y,KAAAs2B,KAAA,EACA,SACA,gCAAA5e,IAKA1a,EAAA8B,oBlD4+ZM,SAAS7B,EAAQD,EAASH,GmDp6dhC,QAAAuI,KAEA,MADAE,GAAA0E,KAAA0W,iBAAAtjB,KAAA4C,MACAA,KANA,GAAAsF,GAAAzI,EAAA,EASAuI,GAAA9E,UAAAC,OAAAC,OAAA8E,EAAA0E,KAAA0W,iBAAApgB,WACA8E,EAAA9E,UAAAF,YAAAgF,EAGAA,EAAA9E,UAAAf,gBAAA,SAAAkM,KAKArG,EAAA9E,UAAAS,SAAA,SAAA0K,KAKArG,EAAA9E,UAAAY,UAAA,SAAAuK,KAKArG,EAAA9E,UAAAc,YAAA,SAAAqK,KAKArG,EAAA9E,UAAAiB,iBAAA,SAAAkK,KAKArG,EAAA9E,UAAAkB,cAAA,SAAAiK,KAKArG,EAAA9E,UAAAmB,aAAA,SAAAgK,KAKArG,EAAA9E,UAAAqB,YAAA,SAAA8J,KAKArG,EAAA9E,UAAAyB,YAAA,SAAA0J,KAKArG,EAAA9E,UAAAmE,eAAA,SAAAgH,KAKArG,EAAA9E,UAAA2B,YAAA,SAAAwJ,KAKArG,EAAA9E,UAAA8B,YAAA,SAAAqJ,KAKArG,EAAA9E,UAAAgC,WAAA,SAAAmJ,KAKArG,EAAA9E,UAAAkC,YAAA,SAAAiJ,KAKArG,EAAA9E,UAAAmC,iBAAA,SAAAgJ,KAKArG,EAAA9E,UAAAoC,SAAA,SAAA+I,KAKArG,EAAA9E,UAAAsC,YAAA,SAAA6I,KAKArG,EAAA9E,UAAA0C,UAAA,SAAAyI,KAKArG,EAAA9E,UAAA4C,WAAA,SAAAuI,KAKArG,EAAA9E,UAAA8C,WAAA,SAAAqI,KAKArG,EAAA9E,UAAAgD,QAAA,SAAAmI,KAKArG,EAAA9E,UAAAiD,UAAA,SAAAkI,KAKArG,EAAA9E,UAAAmD,WAAA,SAAAgI,KAKArG,EAAA9E,UAAAqD,QAAA,SAAA8H,KAKArG,EAAA9E,UAAAuD,SAAA,SAAA4H,KAKArG,EAAA9E,UAAAwD,SAAA,SAAA2H,KAKArG,EAAA9E,UAAA0D,YAAA,SAAAyH,KAKArG,EAAA9E,UAAA2D,SAAA,SAAAwH,KAKArG,EAAA9E,UAAA6D,SAAA,SAAAsH,KAKArG,EAAA9E,UAAA8D,UAAA,SAAAqH,KAKArG,EAAA9E,UAAAgE,SAAA,SAAAmH,KAKArG,EAAA9E,UAAAiE,WAAA,SAAAkH,KAKArG,EAAA9E,UAAAkE,WAAA,SAAAiH,KAKArG,EAAA9E,UAAAoE,SAAA,SAAA+G,KAKArG,EAAA9E,UAAAqE,SAAA,SAAA8G,KAKArG,EAAA9E,UAAAsE,SAAA,SAAA6G,KAKArG,EAAA9E,UAAAwE,SAAA,SAAA2G,KAKArG,EAAA9E,UAAAyE,SAAA,SAAA0G,KAKArG,EAAA9E,UAAA0E,UAAA,SAAAyG,KAKArG,EAAA9E,UAAA4E,SAAA,SAAAuG,KAKArG,EAAA9E,UAAA6E,YAAA,SAAAsG,KAKArG,EAAA9E,UAAAurC,iBAAA,SAAApgC,KAKAzO,EAAAoI,qBnDg7dM,SAASnI,EAAQD,EAASH,GAE/B,GAAIW,GAA8BC,CAAgCD,IAAgCX,EAAqBG,GAAUS,EAAgC,SAAUC,EAASV,GAChL,YoDppeL,IAAAoB,GAAA,mBAAAA,KACW4B,KAAA1B,SAAmB,EACnB0B,KAAAN,cAAwB,KACxBM,KAAAJ,aAAuB,KACvBI,KAAA7B,OAAiBsB,IAC5B,MAAArB,KALapB,GAAAoB,kBAAiBA,GpD+pe3ByB,MAAM7C,EAASQ,KAAiEsC,SAAlCrC,IAAgDR,EAAOD,QAAUS,KAK5G,SAASR,EAAQD,EAASH,GAE/B,GAAIW,GAA8BC,CAAgCD,IAAgCX,EAAqBG,GAAUS,EAAgC,SAAUC,EAASV,GAChL,YqDvqeL,IAAAgC,GAAA,mBAAAA,KAEYgB,KAAA+rC,UAAW,EACX/rC,KAAAgsC,eAAgC,KAyD5C,MAtDIzrC,QAAAgR,eAAWvS,EAAAsB,UAAA,WrDwqeFkR,IqDxqeT,WACI,MAAOxR,MAAK+rC,UrD0qePE,YAAY,EACZC,cAAc,IqDxqevB3rC,OAAAgR,eAAWvS,EAAAsB,UAAA,iBrD2qeFkR,IqD3qeT,WACI,MAAOxR,MAAKgsC,gBrD6qePC,YAAY,EACZC,cAAc,IqD3qevB3rC,OAAAgR,eAAWvS,EAAAsB,UAAA,gBrD8qeFkR,IqD9qeT,WACI,MAAOxR,MAAKmsC,erDgrePF,YAAY,EACZC,cAAc,IqD9qehBltC,EAAAsB,UAAAmzB,YAAP,SAAmBwB,EAAYC,EAAiB5hB,EAAMC,EAAQ+f,EAAKX,GAC/D3yB,KAAK+rC,UAAW,EAChB/rC,KAAKgsC,eAAiBz4B,EACtBvT,KAAKmsC,cAAgB7Y,GAalBt0B,EAAAsB,UAAA60B,gBAAP,SAAuBF,EAAY5uB,EAAKomB,EAAY2I,EAAWC,EAAOC,EAAW9G,KAY1ExvB,EAAAsB,UAAAi1B,4BAAP,SAAmCN,EAAY5uB,EAAKomB,EAAY2I,EAAWI,EAAiBhH,KAYrFxvB,EAAAsB,UAAAm1B,yBAAP,SAAgCR,EAAY5uB,EAAKomB,EAAY2I,EAAW9F,EAAYd,KAExFxvB,IA5DahC,GAAAgC,qBAAoBA,GrD+ue9Ba,MAAM7C,EAASQ,KAAiEsC,SAAlCrC,IAAgDR,EAAOD,QAAUS","file":"./dist/bundle.js","sourcesContent":["var antlrCalc =\n/******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId])\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\texports: {},\n/******/ \t\t\tid: moduleId,\n/******/ \t\t\tloaded: false\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.loaded = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"\";\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(0);\n/******/ })\n/************************************************************************/\n/******/ ([\n/* 0 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__, exports, __webpack_require__(1), __webpack_require__(51), __webpack_require__(52), __webpack_require__(4), __webpack_require__(2)], __WEBPACK_AMD_DEFINE_RESULT__ = function (require, exports, FormulaVisitor_1, CalculationResult_1, FormulaErrorListener_1, antlr4_1, GeneratedAntlr_1) {\r\n\t    \"use strict\";\r\n\t    var Calculator = (function () {\r\n\t        function Calculator() {\r\n\t        }\r\n\t        Calculator.calculate = function (formula) {\r\n\t            var result = new CalculationResult_1.CalculationResult();\r\n\t            if (formula === null || formula.match(/^\\s*$/) !== null) {\r\n\t                result.result = 0;\r\n\t                result.isValid = true;\r\n\t                return result;\r\n\t            }\r\n\t            var inputStream = new antlr4_1.InputStream(formula);\r\n\t            var lexer = new GeneratedAntlr_1.CalculatorLexer(inputStream);\r\n\t            var commonTokenStream = new antlr4_1.CommonTokenStream(lexer);\r\n\t            var parser = new GeneratedAntlr_1.CalculatorParser(commonTokenStream);\r\n\t            var errorListener = new FormulaErrorListener_1.FormulaErrorListener();\r\n\t            parser._listeners = [errorListener];\r\n\t            var visitor = new FormulaVisitor_1.FormulaVisitor();\r\n\t            var parseTree = parser.calculator();\r\n\t            if (errorListener.isValid) {\r\n\t                var visitorResult = visitor.visitCalculator(parseTree);\r\n\t                if (isNaN(visitorResult)) {\r\n\t                    result.isValid = false;\r\n\t                    result.result = NaN;\r\n\t                }\r\n\t                else {\r\n\t                    result.isValid = true;\r\n\t                    result.result = visitorResult;\r\n\t                }\r\n\t                return result;\r\n\t            }\r\n\t            result.isValid = false;\r\n\t            result.errorPosition = errorListener.errorLocation;\r\n\t            result.errorMessage = errorListener.errorMessage;\r\n\t            result.result = NaN;\r\n\t            return result;\r\n\t        };\r\n\t        return Calculator;\r\n\t    }());\r\n\t    exports.Calculator = Calculator;\r\n\t}.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__), __WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\r\n\n\n/***/ },\n/* 1 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;var __extends = (this && this.__extends) || function (d, b) {\r\n\t    for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\r\n\t    function __() { this.constructor = d; }\r\n\t    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n\t};\r\n\t!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__, exports, __webpack_require__(2)], __WEBPACK_AMD_DEFINE_RESULT__ = function (require, exports, GeneratedAntlr_1) {\r\n\t    \"use strict\";\r\n\t    // This class defines a complete visitor for a parse tree produced by the CalculatorParser.\r\n\t    var FormulaVisitor = (function (_super) {\r\n\t        __extends(FormulaVisitor, _super);\r\n\t        function FormulaVisitor() {\r\n\t            _super.apply(this, arguments);\r\n\t        }\r\n\t        // Visit a parse tree produced by calculatorParser#calculator.\r\n\t        FormulaVisitor.prototype.visitCalculator = function (context) {\r\n\t            return context.expression(0).accept(this);\r\n\t        };\r\n\t        ;\r\n\t        FormulaVisitor.prototype.visitExpression = function (context) {\r\n\t            return context.accept(this);\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Tan.\r\n\t        FormulaVisitor.prototype.visitTan = function (context) {\r\n\t            return Math.tan(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Cosh.\r\n\t        FormulaVisitor.prototype.visitCosh = function (context) {\r\n\t            return Math.cosh(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#SqRoot.\r\n\t        FormulaVisitor.prototype.visitSqRoot = function (context) {\r\n\t            var nthRoot = this.visitExpression(context.expression(0));\r\n\t            if (nthRoot === 0) {\r\n\t                return NaN;\r\n\t            }\r\n\t            return Math.pow(this.visitExpression(context.expression(1)), 1 / nthRoot);\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#NegExponent.\r\n\t        FormulaVisitor.prototype.visitNegExponent = function (context) {\r\n\t            return this.visitExpression(context.expression(0)) * Math.pow(10, -1 * this.visitExpression(context.expression(1)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Exponent.\r\n\t        FormulaVisitor.prototype.visitExponent = function (context) {\r\n\t            return this.visitExpression(context.expression(0)) * Math.pow(10, this.visitExpression(context.expression(1)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Arctan2.\r\n\t        FormulaVisitor.prototype.visitArctan2 = function (context) {\r\n\t            return Math.atan2(this.visitExpression(context.expression(0)), this.visitExpression(context.expression(1)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#MulDiv.\r\n\t        FormulaVisitor.prototype.visitMulDiv = function (context) {\r\n\t            if (context.op.text === '*') {\r\n\t                return this.visitExpression(context.expression(0)) * this.visitExpression(context.expression(1));\r\n\t            }\r\n\t            else {\r\n\t                var divisor = this.visitExpression(context.expression(1));\r\n\t                if (divisor !== 0) {\r\n\t                    return this.visitExpression(context.expression(0)) / divisor;\r\n\t                }\r\n\t                return NaN;\r\n\t            }\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Arcsin.\r\n\t        FormulaVisitor.prototype.visitArcsin = function (context) {\r\n\t            return Math.asin(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Arccot.\r\n\t        FormulaVisitor.prototype.visitArccot = function (context) {\r\n\t            return Math.PI * 0.5 - Math.atan(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Arccos.\r\n\t        FormulaVisitor.prototype.visitArccos = function (context) {\r\n\t            return Math.acos(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Euler.\r\n\t        FormulaVisitor.prototype.visitEuler = function (context) {\r\n\t            return Math.E;\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Arctan.\r\n\t        FormulaVisitor.prototype.visitArctan = function (context) {\r\n\t            return Math.atan(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Parenthesis.\r\n\t        FormulaVisitor.prototype.visitParenthesis = function (context) {\r\n\t            return this.visitExpression(context.expression(0));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Abs.\r\n\t        FormulaVisitor.prototype.visitAbs = function (context) {\r\n\t            return Math.abs(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Number.\r\n\t        FormulaVisitor.prototype.visitNumber = function (context) {\r\n\t            return Number(context.getText().replace(',', '.'));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Sinh.\r\n\t        FormulaVisitor.prototype.visitSinh = function (context) {\r\n\t            return Math.sinh(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Round.\r\n\t        FormulaVisitor.prototype.visitRound = function (context) {\r\n\t            return Math.round(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Trunc.\r\n\t        FormulaVisitor.prototype.visitTrunc = function (context) {\r\n\t            return Math.trunc(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Pi.\r\n\t        FormulaVisitor.prototype.visitPi = function (context) {\r\n\t            return Math.PI;\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Tanh.\r\n\t        FormulaVisitor.prototype.visitTanh = function (context) {\r\n\t            return Math.tanh(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Floor.\r\n\t        FormulaVisitor.prototype.visitFloor = function (context) {\r\n\t            return Math.floor(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Ln.\r\n\t        FormulaVisitor.prototype.visitLn = function (context) {\r\n\t            return Math.log(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Mod.\r\n\t        FormulaVisitor.prototype.visitMod = function (context) {\r\n\t            return this.visitExpression(context.expression(0)) % this.visitExpression(context.expression(1));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Log.\r\n\t        FormulaVisitor.prototype.visitLog = function (context) {\r\n\t            return Math.log10(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#AddSub.\r\n\t        FormulaVisitor.prototype.visitAddSub = function (context) {\r\n\t            return context.op.text === '+'\r\n\t                ? (this.visitExpression(context.expression(0)) + this.visitExpression(context.expression(1)))\r\n\t                : (this.visitExpression(context.expression(0)) - this.visitExpression(context.expression(1)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Cos.\r\n\t        FormulaVisitor.prototype.visitCos = function (context) {\r\n\t            return Math.cos(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Deg.\r\n\t        FormulaVisitor.prototype.visitDeg = function (context) {\r\n\t            return this.visitExpression(context.expression(0)) * 180 / Math.PI;\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Sqrt.\r\n\t        FormulaVisitor.prototype.visitSqrt = function (context) {\r\n\t            return Math.sqrt(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Cot.\r\n\t        FormulaVisitor.prototype.visitCot = function (context) {\r\n\t            return 1 / Math.tan(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Whole.\r\n\t        FormulaVisitor.prototype.visitWhole = function (context) {\r\n\t            return Math.trunc(this.visitExpression(context.expression(0)) / this.visitExpression(context.expression(1)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Unary.\r\n\t        FormulaVisitor.prototype.visitUnary = function (context) {\r\n\t            return -1 * this.visitExpression(context.expression(0));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#UnaryPlus.\r\n\t        FormulaVisitor.prototype.visitUnaryPlus = function (context) {\r\n\t            return this.visitExpression(context.expression(0));\r\n\t        };\r\n\t        // Visit a parse tree produced by calculatorParser#Rad.\r\n\t        FormulaVisitor.prototype.visitRad = function (context) {\r\n\t            return this.visitExpression(context.expression(0)) * Math.PI / 180;\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Sqr.\r\n\t        FormulaVisitor.prototype.visitSqr = function (context) {\r\n\t            return this.visitExpression(context.expression(0)) * this.visitExpression(context.expression(0));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Sin.\r\n\t        FormulaVisitor.prototype.visitSin = function (context) {\r\n\t            return Math.sin(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Eex.\r\n\t        FormulaVisitor.prototype.visitEex = function (context) {\r\n\t            return Math.pow(10, this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Pow.\r\n\t        FormulaVisitor.prototype.visitPow = function (context) {\r\n\t            return Math.pow(this.visitExpression(context.expression(0)), this.visitExpression(context.expression(1)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Ceil.\r\n\t        FormulaVisitor.prototype.visitCeil = function (context) {\r\n\t            return Math.ceil(this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Exp.\r\n\t        FormulaVisitor.prototype.visitExp = function (context) {\r\n\t            return Math.pow(Math.E, this.visitExpression(context.expression(0)));\r\n\t        };\r\n\t        ;\r\n\t        // Visit a parse tree produced by calculatorParser#Roundk.\r\n\t        FormulaVisitor.prototype.visitRoundk = function (context) {\r\n\t            return Math.round(this.visitExpression(context.expression(0)) * Math.pow(10, this.visitExpression(context.expression(1)))) /\r\n\t                Math.pow(10, this.visitExpression(context.expression(1)));\r\n\t        };\r\n\t        ;\r\n\t        return FormulaVisitor;\r\n\t    }(GeneratedAntlr_1.CalculatorVisitor));\r\n\t    exports.FormulaVisitor = FormulaVisitor;\r\n\t}.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__), __WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\r\n\n\n/***/ },\n/* 2 */\n/***/ function(module, exports, __webpack_require__) {\n\n\texports.CalculatorLexer = __webpack_require__(3).CalculatorLexer;\r\n\texports.CalculatorParser = __webpack_require__(49).CalculatorParser;\r\n\texports.CalculatorVisitor = __webpack_require__(50).CalculatorVisitor;\n\n/***/ },\n/* 3 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// Generated from Calculator.g4 by ANTLR 4.5.2\r\n\t// jshint ignore: start\r\n\tvar antlr4 = __webpack_require__(4);\r\n\t\r\n\t\r\n\tvar serializedATN = [\"\\u0003\\u0430\\ud6d1\\u8206\\uad2d\\u4417\\uaef1\\u8d80\\uaadd\",\r\n\t    \"\\u00025\\u0165\\b\\u0001\\u0004\\u0002\\t\\u0002\\u0004\\u0003\\t\\u0003\\u0004\",\r\n\t    \"\\u0004\\t\\u0004\\u0004\\u0005\\t\\u0005\\u0004\\u0006\\t\\u0006\\u0004\\u0007\\t\",\r\n\t    \"\\u0007\\u0004\\b\\t\\b\\u0004\\t\\t\\t\\u0004\\n\\t\\n\\u0004\\u000b\\t\\u000b\\u0004\",\r\n\t    \"\\f\\t\\f\\u0004\\r\\t\\r\\u0004\\u000e\\t\\u000e\\u0004\\u000f\\t\\u000f\\u0004\\u0010\",\r\n\t    \"\\t\\u0010\\u0004\\u0011\\t\\u0011\\u0004\\u0012\\t\\u0012\\u0004\\u0013\\t\\u0013\",\r\n\t    \"\\u0004\\u0014\\t\\u0014\\u0004\\u0015\\t\\u0015\\u0004\\u0016\\t\\u0016\\u0004\\u0017\",\r\n\t    \"\\t\\u0017\\u0004\\u0018\\t\\u0018\\u0004\\u0019\\t\\u0019\\u0004\\u001a\\t\\u001a\",\r\n\t    \"\\u0004\\u001b\\t\\u001b\\u0004\\u001c\\t\\u001c\\u0004\\u001d\\t\\u001d\\u0004\\u001e\",\r\n\t    \"\\t\\u001e\\u0004\\u001f\\t\\u001f\\u0004 \\t \\u0004!\\t!\\u0004\\\"\\t\\\"\\u0004#\",\r\n\t    \"\\t#\\u0004$\\t$\\u0004%\\t%\\u0004&\\t&\\u0004\\'\\t\\'\\u0004(\\t(\\u0004)\\t)\\u0004\",\r\n\t    \"*\\t*\\u0004+\\t+\\u0004,\\t,\\u0004-\\t-\\u0004.\\t.\\u0004/\\t/\\u00040\\t0\\u0004\",\r\n\t    \"1\\t1\\u00042\\t2\\u00043\\t3\\u00044\\t4\\u00045\\t5\\u0003\\u0002\\u0003\\u0002\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0004\\u0003\\u0004\\u0003\\u0005\\u0003\\u0005\",\r\n\t    \"\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0007\\u0003\\u0007\\u0003\\b\",\r\n\t    \"\\u0003\\b\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\n\\u0003\\n\\u0003\\n\\u0003\\u000b\",\r\n\t    \"\\u0003\\u000b\\u0006\\u000b\\u0083\\n\\u000b\\r\\u000b\\u000e\\u000b\\u0084\\u0005\",\r\n\t    \"\\u000b\\u0087\\n\\u000b\\u0003\\f\\u0006\\f\\u008a\\n\\f\\r\\f\\u000e\\f\\u008b\\u0003\",\r\n\t    \"\\f\\u0003\\f\\u0007\\f\\u0090\\n\\f\\f\\f\\u000e\\f\\u0093\\u000b\\f\\u0003\\f\\u0003\",\r\n\t    \"\\f\\u0006\\f\\u0097\\n\\f\\r\\f\\u000e\\f\\u0098\\u0005\\f\\u009b\\n\\f\\u0003\\r\\u0003\",\r\n\t    \"\\r\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000f\\u0003\",\r\n\t    \"\\u000f\\u0003\\u000f\\u0003\\u000f\\u0003\\u0010\\u0003\\u0010\\u0003\\u0011\\u0003\",\r\n\t    \"\\u0011\\u0003\\u0012\\u0003\\u0012\\u0003\\u0013\\u0003\\u0013\\u0003\\u0014\\u0003\",\r\n\t    \"\\u0014\\u0003\\u0014\\u0003\\u0015\\u0003\\u0015\\u0003\\u0015\\u0003\\u0016\\u0003\",\r\n\t    \"\\u0016\\u0003\\u0016\\u0003\\u0017\\u0003\\u0017\\u0003\\u0018\\u0003\\u0018\\u0003\",\r\n\t    \"\\u0018\\u0003\\u0018\\u0003\\u0018\\u0003\\u0019\\u0003\\u0019\\u0003\\u0019\\u0003\",\r\n\t    \"\\u0019\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a\\u0003\",\r\n\t    \"\\u001a\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\",\r\n\t    \"\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001d\\u0003\\u001d\\u0003\",\r\n\t    \"\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001e\\u0003\",\r\n\t    \"\\u001e\\u0003\\u001e\\u0003\\u001e\\u0003\\u001e\\u0003\\u001e\\u0003\\u001f\\u0003\",\r\n\t    \"\\u001f\\u0003\\u001f\\u0003\\u001f\\u0003\\u001f\\u0003\\u001f\\u0003 \\u0003\",\r\n\t    \" \\u0003 \\u0003 \\u0003!\\u0003!\\u0003!\\u0003!\\u0003\\\"\\u0003\\\"\\u0003\\\"\",\r\n\t    \"\\u0003\\\"\\u0003#\\u0003#\\u0003#\\u0003#\\u0003$\\u0003$\\u0003$\\u0003$\\u0003\",\r\n\t    \"$\\u0003%\\u0003%\\u0003%\\u0003%\\u0003%\\u0003&\\u0003&\\u0003&\\u0003&\\u0003\",\r\n\t    \"&\\u0003\\'\\u0003\\'\\u0003\\'\\u0003\\'\\u0003\\'\\u0003\\'\\u0003\\'\\u0003(\\u0003\",\r\n\t    \"(\\u0003(\\u0003(\\u0003(\\u0003(\\u0003(\\u0003)\\u0003)\\u0003)\\u0003)\\u0003\",\r\n\t    \")\\u0003)\\u0003)\\u0003*\\u0003*\\u0003*\\u0003*\\u0003*\\u0003*\\u0003*\\u0003\",\r\n\t    \"*\\u0003+\\u0003+\\u0003+\\u0003+\\u0003+\\u0003+\\u0003+\\u0003,\\u0003,\\u0003\",\r\n\t    \",\\u0003,\\u0003-\\u0003-\\u0003-\\u0003.\\u0003.\\u0003.\\u0003.\\u0003/\\u0003\",\r\n\t    \"/\\u0003/\\u0003/\\u00030\\u00030\\u00030\\u00030\\u00031\\u00031\\u00031\\u0003\",\r\n\t    \"1\\u00032\\u00032\\u00032\\u00032\\u00033\\u00033\\u00033\\u00033\\u00034\\u0003\",\r\n\t    \"4\\u00035\\u00035\\u00035\\u00035\\u00075\\u014d\\n5\\f5\\u000e5\\u0150\\u000b\",\r\n\t    \"5\\u00035\\u00035\\u00035\\u00035\\u00075\\u0156\\n5\\f5\\u000e5\\u0159\\u000b\",\r\n\t    \"5\\u00035\\u00035\\u00035\\u00075\\u015e\\n5\\f5\\u000e5\\u0161\\u000b5\\u0003\",\r\n\t    \"5\\u00055\\u0164\\n5\\u0005\\u014e\\u0157\\u015f\\u00026\\u0003\\u0003\\u0005\\u0004\",\r\n\t    \"\\u0007\\u0005\\t\\u0006\\u000b\\u0007\\r\\b\\u000f\\t\\u0011\\n\\u0013\\u000b\\u0015\",\r\n\t    \"\\f\\u0017\\r\\u0019\\u000e\\u001b\\u000f\\u001d\\u0010\\u001f\\u0011!\\u0012#\\u0013\",\r\n\t    \"%\\u0014\\'\\u0015)\\u0016+\\u0017-\\u0018/\\u00191\\u001a3\\u001b5\\u001c7\\u001d\",\r\n\t    \"9\\u001e;\\u001f= ?!A\\\"C#E$G%I&K\\'M(O)Q*S+U,W-Y.[/]0_1a2c3e4g5i\\u0002\",\r\n\t    \"\\u0003\\u0002\\u001c\\u0004\\u0002..00\\u0003\\u00022;\\u0004\\u0002OOoo\\u0004\",\r\n\t    \"\\u0002QQqq\\u0004\\u0002FFff\\u0004\\u0002KKkk\\u0004\\u0002XXxx\\u0004\\u0002\",\r\n\t    \"RRrr\\u0004\\u0002GGgg\\u0004\\u0002UUuu\\u0004\\u0002SSss\\u0004\\u0002TTt\",\r\n\t    \"t\\u0004\\u0002VVvv\\u0004\\u0002HHhh\\u0004\\u0002NNnn\\u0004\\u0002EEee\\u0004\",\r\n\t    \"\\u0002CCcc\\u0004\\u0002DDdd\\u0004\\u0002WWww\\u0004\\u0002PPpp\\u0004\\u0002\",\r\n\t    \"MMmm\\u0004\\u0002JJjj\\u0003\\u000244\\u0004\\u0002ZZzz\\u0004\\u0002IIii\\u0005\",\r\n\t    \"\\u0002\\u000b\\f\\u000f\\u000f\\\"\\\"\\u016e\\u0002\\u0003\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0005\\u0003\\u0002\\u0002\\u0002\\u0002\\u0007\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0002\\t\\u0003\\u0002\\u0002\\u0002\\u0002\\u000b\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0002\\r\\u0003\\u0002\\u0002\\u0002\\u0002\\u000f\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0011\\u0003\\u0002\\u0002\\u0002\\u0002\\u0013\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0015\\u0003\\u0002\\u0002\\u0002\\u0002\\u0017\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0019\\u0003\\u0002\\u0002\\u0002\\u0002\\u001b\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0002\\u001d\\u0003\\u0002\\u0002\\u0002\\u0002\\u001f\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0002!\\u0003\\u0002\\u0002\\u0002\\u0002#\\u0003\\u0002\\u0002\\u0002\\u0002\",\r\n\t    \"%\\u0003\\u0002\\u0002\\u0002\\u0002\\'\\u0003\\u0002\\u0002\\u0002\\u0002)\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0002+\\u0003\\u0002\\u0002\\u0002\\u0002-\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u0002/\\u0003\\u0002\\u0002\\u0002\\u00021\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u00023\\u0003\\u0002\\u0002\\u0002\\u00025\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u00027\\u0003\\u0002\\u0002\\u0002\\u00029\\u0003\\u0002\\u0002\\u0002\\u0002\",\r\n\t    \";\\u0003\\u0002\\u0002\\u0002\\u0002=\\u0003\\u0002\\u0002\\u0002\\u0002?\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0002A\\u0003\\u0002\\u0002\\u0002\\u0002C\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u0002E\\u0003\\u0002\\u0002\\u0002\\u0002G\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0002I\\u0003\\u0002\\u0002\\u0002\\u0002K\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0002M\\u0003\\u0002\\u0002\\u0002\\u0002O\\u0003\\u0002\\u0002\\u0002\\u0002\",\r\n\t    \"Q\\u0003\\u0002\\u0002\\u0002\\u0002S\\u0003\\u0002\\u0002\\u0002\\u0002U\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0002W\\u0003\\u0002\\u0002\\u0002\\u0002Y\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u0002[\\u0003\\u0002\\u0002\\u0002\\u0002]\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0002_\\u0003\\u0002\\u0002\\u0002\\u0002a\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0002c\\u0003\\u0002\\u0002\\u0002\\u0002e\\u0003\\u0002\\u0002\\u0002\\u0002\",\r\n\t    \"g\\u0003\\u0002\\u0002\\u0002\\u0003k\\u0003\\u0002\\u0002\\u0002\\u0005m\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0007o\\u0003\\u0002\\u0002\\u0002\\tq\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u000bs\\u0003\\u0002\\u0002\\u0002\\rv\\u0003\\u0002\\u0002\\u0002\\u000f\",\r\n\t    \"x\\u0003\\u0002\\u0002\\u0002\\u0011z\\u0003\\u0002\\u0002\\u0002\\u0013}\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0015\\u0086\\u0003\\u0002\\u0002\\u0002\\u0017\\u009a\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0019\\u009c\\u0003\\u0002\\u0002\\u0002\\u001b\\u009e\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u001d\\u00a2\\u0003\\u0002\\u0002\\u0002\\u001f\\u00a6\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002!\\u00a8\\u0003\\u0002\\u0002\\u0002#\\u00aa\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002%\\u00ac\\u0003\\u0002\\u0002\\u0002\\'\\u00ae\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002)\\u00b1\\u0003\\u0002\\u0002\\u0002+\\u00b4\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"-\\u00b7\\u0003\\u0002\\u0002\\u0002/\\u00b9\\u0003\\u0002\\u0002\\u00021\\u00be\",\r\n\t    \"\\u0003\\u0002\\u0002\\u00023\\u00c2\\u0003\\u0002\\u0002\\u00025\\u00c8\\u0003\",\r\n\t    \"\\u0002\\u0002\\u00027\\u00cd\\u0003\\u0002\\u0002\\u00029\\u00d1\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002;\\u00d8\\u0003\\u0002\\u0002\\u0002=\\u00de\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002?\\u00e4\\u0003\\u0002\\u0002\\u0002A\\u00e8\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"C\\u00ec\\u0003\\u0002\\u0002\\u0002E\\u00f0\\u0003\\u0002\\u0002\\u0002G\\u00f4\",\r\n\t    \"\\u0003\\u0002\\u0002\\u0002I\\u00f9\\u0003\\u0002\\u0002\\u0002K\\u00fe\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002M\\u0103\\u0003\\u0002\\u0002\\u0002O\\u010a\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002Q\\u0111\\u0003\\u0002\\u0002\\u0002S\\u0118\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002U\\u0120\\u0003\\u0002\\u0002\\u0002W\\u0127\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"Y\\u012b\\u0003\\u0002\\u0002\\u0002[\\u012e\\u0003\\u0002\\u0002\\u0002]\\u0132\",\r\n\t    \"\\u0003\\u0002\\u0002\\u0002_\\u0136\\u0003\\u0002\\u0002\\u0002a\\u013a\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002c\\u013e\\u0003\\u0002\\u0002\\u0002e\\u0142\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002g\\u0146\\u0003\\u0002\\u0002\\u0002i\\u0163\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002kl\\u0007*\\u0002\\u0002l\\u0004\\u0003\\u0002\\u0002\\u0002mn\\u0007=\",\r\n\t    \"\\u0002\\u0002n\\u0006\\u0003\\u0002\\u0002\\u0002op\\u0007+\\u0002\\u0002p\\b\",\r\n\t    \"\\u0003\\u0002\\u0002\\u0002qr\\u0007`\\u0002\\u0002r\\n\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"st\\u0007,\\u0002\\u0002tu\\u0007,\\u0002\\u0002u\\f\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"vw\\u0007\\'\\u0002\\u0002w\\u000e\\u0003\\u0002\\u0002\\u0002xy\\u0007\\u0080\",\r\n\t    \"\\u0002\\u0002y\\u0010\\u0003\\u0002\\u0002\\u0002z{\\u00071\\u0002\\u0002{|\\u0007\",\r\n\t    \"1\\u0002\\u0002|\\u0012\\u0003\\u0002\\u0002\\u0002}~\\u0007*\\u0002\\u0002~\\u007f\",\r\n\t    \"\\u0007+\\u0002\\u0002\\u007f\\u0014\\u0003\\u0002\\u0002\\u0002\\u0080\\u0087\",\r\n\t    \"\\u0005\\u0017\\f\\u0002\\u0081\\u0083\\u0005\\u0019\\r\\u0002\\u0082\\u0081\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0083\\u0084\\u0003\\u0002\\u0002\\u0002\\u0084\\u0082\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0084\\u0085\\u0003\\u0002\\u0002\\u0002\\u0085\\u0087\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0086\\u0080\\u0003\\u0002\\u0002\\u0002\\u0086\\u0082\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0087\\u0016\\u0003\\u0002\\u0002\\u0002\\u0088\\u008a\\u0005\",\r\n\t    \"\\u0019\\r\\u0002\\u0089\\u0088\\u0003\\u0002\\u0002\\u0002\\u008a\\u008b\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u008b\\u0089\\u0003\\u0002\\u0002\\u0002\\u008b\\u008c\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u008c\\u008d\\u0003\\u0002\\u0002\\u0002\\u008d\\u0091\\t\",\r\n\t    \"\\u0002\\u0002\\u0002\\u008e\\u0090\\u0005\\u0019\\r\\u0002\\u008f\\u008e\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0090\\u0093\\u0003\\u0002\\u0002\\u0002\\u0091\\u008f\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0091\\u0092\\u0003\\u0002\\u0002\\u0002\\u0092\\u009b\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0093\\u0091\\u0003\\u0002\\u0002\\u0002\\u0094\\u0096\\t\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0095\\u0097\\u0005\\u0019\\r\\u0002\\u0096\\u0095\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0097\\u0098\\u0003\\u0002\\u0002\\u0002\\u0098\\u0096\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0098\\u0099\\u0003\\u0002\\u0002\\u0002\\u0099\\u009b\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u009a\\u0089\\u0003\\u0002\\u0002\\u0002\\u009a\\u0094\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u009b\\u0018\\u0003\\u0002\\u0002\\u0002\\u009c\\u009d\\t\",\r\n\t    \"\\u0003\\u0002\\u0002\\u009d\\u001a\\u0003\\u0002\\u0002\\u0002\\u009e\\u009f\\t\",\r\n\t    \"\\u0004\\u0002\\u0002\\u009f\\u00a0\\t\\u0005\\u0002\\u0002\\u00a0\\u00a1\\t\\u0006\",\r\n\t    \"\\u0002\\u0002\\u00a1\\u001c\\u0003\\u0002\\u0002\\u0002\\u00a2\\u00a3\\t\\u0006\",\r\n\t    \"\\u0002\\u0002\\u00a3\\u00a4\\t\\u0007\\u0002\\u0002\\u00a4\\u00a5\\t\\b\\u0002\\u0002\",\r\n\t    \"\\u00a5\\u001e\\u0003\\u0002\\u0002\\u0002\\u00a6\\u00a7\\u0007,\\u0002\\u0002\",\r\n\t    \"\\u00a7 \\u0003\\u0002\\u0002\\u0002\\u00a8\\u00a9\\u00071\\u0002\\u0002\\u00a9\",\r\n\t    \"\\\"\\u0003\\u0002\\u0002\\u0002\\u00aa\\u00ab\\u0007-\\u0002\\u0002\\u00ab$\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u00ac\\u00ad\\u0007/\\u0002\\u0002\\u00ad&\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u00ae\\u00af\\t\\t\\u0002\\u0002\\u00af\\u00b0\\t\\u0007\\u0002\\u0002\",\r\n\t    \"\\u00b0(\\u0003\\u0002\\u0002\\u0002\\u00b1\\u00b2\\t\\n\\u0002\\u0002\\u00b2\\u00b3\",\r\n\t    \"\\u0007-\\u0002\\u0002\\u00b3*\\u0003\\u0002\\u0002\\u0002\\u00b4\\u00b5\\t\\n\\u0002\",\r\n\t    \"\\u0002\\u00b5\\u00b6\\u0007/\\u0002\\u0002\\u00b6,\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u00b7\\u00b8\\t\\n\\u0002\\u0002\\u00b8.\\u0003\\u0002\\u0002\\u0002\\u00b9\\u00ba\",\r\n\t    \"\\t\\u000b\\u0002\\u0002\\u00ba\\u00bb\\t\\f\\u0002\\u0002\\u00bb\\u00bc\\t\\r\\u0002\",\r\n\t    \"\\u0002\\u00bc\\u00bd\\t\\u000e\\u0002\\u0002\\u00bd0\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u00be\\u00bf\\t\\u000b\\u0002\\u0002\\u00bf\\u00c0\\t\\f\\u0002\\u0002\\u00c0\\u00c1\",\r\n\t    \"\\t\\r\\u0002\\u0002\\u00c12\\u0003\\u0002\\u0002\\u0002\\u00c2\\u00c3\\t\\u000f\",\r\n\t    \"\\u0002\\u0002\\u00c3\\u00c4\\t\\u0010\\u0002\\u0002\\u00c4\\u00c5\\t\\u0005\\u0002\",\r\n\t    \"\\u0002\\u00c5\\u00c6\\t\\u0005\\u0002\\u0002\\u00c6\\u00c7\\t\\r\\u0002\\u0002\\u00c7\",\r\n\t    \"4\\u0003\\u0002\\u0002\\u0002\\u00c8\\u00c9\\t\\u0011\\u0002\\u0002\\u00c9\\u00ca\",\r\n\t    \"\\t\\n\\u0002\\u0002\\u00ca\\u00cb\\t\\u0007\\u0002\\u0002\\u00cb\\u00cc\\t\\u0010\",\r\n\t    \"\\u0002\\u0002\\u00cc6\\u0003\\u0002\\u0002\\u0002\\u00cd\\u00ce\\t\\u0012\\u0002\",\r\n\t    \"\\u0002\\u00ce\\u00cf\\t\\u0013\\u0002\\u0002\\u00cf\\u00d0\\t\\u000b\\u0002\\u0002\",\r\n\t    \"\\u00d08\\u0003\\u0002\\u0002\\u0002\\u00d1\\u00d2\\t\\r\\u0002\\u0002\\u00d2\\u00d3\",\r\n\t    \"\\t\\u0005\\u0002\\u0002\\u00d3\\u00d4\\t\\u0014\\u0002\\u0002\\u00d4\\u00d5\\t\\u0015\",\r\n\t    \"\\u0002\\u0002\\u00d5\\u00d6\\t\\u0006\\u0002\\u0002\\u00d6\\u00d7\\t\\u0016\\u0002\",\r\n\t    \"\\u0002\\u00d7:\\u0003\\u0002\\u0002\\u0002\\u00d8\\u00d9\\t\\r\\u0002\\u0002\\u00d9\",\r\n\t    \"\\u00da\\t\\u0005\\u0002\\u0002\\u00da\\u00db\\t\\u0014\\u0002\\u0002\\u00db\\u00dc\",\r\n\t    \"\\t\\u0015\\u0002\\u0002\\u00dc\\u00dd\\t\\u0006\\u0002\\u0002\\u00dd<\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u00de\\u00df\\t\\u000e\\u0002\\u0002\\u00df\\u00e0\\t\\r\\u0002\\u0002\",\r\n\t    \"\\u00e0\\u00e1\\t\\u0014\\u0002\\u0002\\u00e1\\u00e2\\t\\u0015\\u0002\\u0002\\u00e2\",\r\n\t    \"\\u00e3\\t\\u0011\\u0002\\u0002\\u00e3>\\u0003\\u0002\\u0002\\u0002\\u00e4\\u00e5\",\r\n\t    \"\\t\\u000b\\u0002\\u0002\\u00e5\\u00e6\\t\\u0007\\u0002\\u0002\\u00e6\\u00e7\\t\\u0015\",\r\n\t    \"\\u0002\\u0002\\u00e7@\\u0003\\u0002\\u0002\\u0002\\u00e8\\u00e9\\t\\u0011\\u0002\",\r\n\t    \"\\u0002\\u00e9\\u00ea\\t\\u0005\\u0002\\u0002\\u00ea\\u00eb\\t\\u000b\\u0002\\u0002\",\r\n\t    \"\\u00ebB\\u0003\\u0002\\u0002\\u0002\\u00ec\\u00ed\\t\\u000e\\u0002\\u0002\\u00ed\",\r\n\t    \"\\u00ee\\t\\u0012\\u0002\\u0002\\u00ee\\u00ef\\t\\u0015\\u0002\\u0002\\u00efD\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u00f0\\u00f1\\t\\u0011\\u0002\\u0002\\u00f1\\u00f2\\t\\u0005\",\r\n\t    \"\\u0002\\u0002\\u00f2\\u00f3\\t\\u000e\\u0002\\u0002\\u00f3F\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u00f4\\u00f5\\t\\u000b\\u0002\\u0002\\u00f5\\u00f6\\t\\u0007\\u0002\\u0002\",\r\n\t    \"\\u00f6\\u00f7\\t\\u0015\\u0002\\u0002\\u00f7\\u00f8\\t\\u0017\\u0002\\u0002\\u00f8\",\r\n\t    \"H\\u0003\\u0002\\u0002\\u0002\\u00f9\\u00fa\\t\\u0011\\u0002\\u0002\\u00fa\\u00fb\",\r\n\t    \"\\t\\u0005\\u0002\\u0002\\u00fb\\u00fc\\t\\u000b\\u0002\\u0002\\u00fc\\u00fd\\t\\u0017\",\r\n\t    \"\\u0002\\u0002\\u00fdJ\\u0003\\u0002\\u0002\\u0002\\u00fe\\u00ff\\t\\u000e\\u0002\",\r\n\t    \"\\u0002\\u00ff\\u0100\\t\\u0012\\u0002\\u0002\\u0100\\u0101\\t\\u0015\\u0002\\u0002\",\r\n\t    \"\\u0101\\u0102\\t\\u0017\\u0002\\u0002\\u0102L\\u0003\\u0002\\u0002\\u0002\\u0103\",\r\n\t    \"\\u0104\\t\\u0012\\u0002\\u0002\\u0104\\u0105\\t\\r\\u0002\\u0002\\u0105\\u0106\\t\",\r\n\t    \"\\u0011\\u0002\\u0002\\u0106\\u0107\\t\\u000b\\u0002\\u0002\\u0107\\u0108\\t\\u0007\",\r\n\t    \"\\u0002\\u0002\\u0108\\u0109\\t\\u0015\\u0002\\u0002\\u0109N\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u010a\\u010b\\t\\u0012\\u0002\\u0002\\u010b\\u010c\\t\\r\\u0002\\u0002\\u010c\",\r\n\t    \"\\u010d\\t\\u0011\\u0002\\u0002\\u010d\\u010e\\t\\u0011\\u0002\\u0002\\u010e\\u010f\",\r\n\t    \"\\t\\u0005\\u0002\\u0002\\u010f\\u0110\\t\\u000b\\u0002\\u0002\\u0110P\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u0111\\u0112\\t\\u0012\\u0002\\u0002\\u0112\\u0113\\t\\r\\u0002\\u0002\",\r\n\t    \"\\u0113\\u0114\\t\\u0011\\u0002\\u0002\\u0114\\u0115\\t\\u000e\\u0002\\u0002\\u0115\",\r\n\t    \"\\u0116\\t\\u0012\\u0002\\u0002\\u0116\\u0117\\t\\u0015\\u0002\\u0002\\u0117R\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0118\\u0119\\t\\u0012\\u0002\\u0002\\u0119\\u011a\\t\\r\\u0002\",\r\n\t    \"\\u0002\\u011a\\u011b\\t\\u0011\\u0002\\u0002\\u011b\\u011c\\t\\u000e\\u0002\\u0002\",\r\n\t    \"\\u011c\\u011d\\t\\u0012\\u0002\\u0002\\u011d\\u011e\\t\\u0015\\u0002\\u0002\\u011e\",\r\n\t    \"\\u011f\\t\\u0018\\u0002\\u0002\\u011fT\\u0003\\u0002\\u0002\\u0002\\u0120\\u0121\",\r\n\t    \"\\t\\u0012\\u0002\\u0002\\u0121\\u0122\\t\\r\\u0002\\u0002\\u0122\\u0123\\t\\u0011\",\r\n\t    \"\\u0002\\u0002\\u0123\\u0124\\t\\u0011\\u0002\\u0002\\u0124\\u0125\\t\\u0005\\u0002\",\r\n\t    \"\\u0002\\u0125\\u0126\\t\\u000e\\u0002\\u0002\\u0126V\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0127\\u0128\\t\\n\\u0002\\u0002\\u0128\\u0129\\t\\u0019\\u0002\\u0002\\u0129\\u012a\",\r\n\t    \"\\t\\t\\u0002\\u0002\\u012aX\\u0003\\u0002\\u0002\\u0002\\u012b\\u012c\\t\\u0010\",\r\n\t    \"\\u0002\\u0002\\u012c\\u012d\\t\\u0015\\u0002\\u0002\\u012dZ\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u012e\\u012f\\t\\n\\u0002\\u0002\\u012f\\u0130\\t\\n\\u0002\\u0002\\u0130\",\r\n\t    \"\\u0131\\t\\u0019\\u0002\\u0002\\u0131\\\\\\u0003\\u0002\\u0002\\u0002\\u0132\\u0133\",\r\n\t    \"\\t\\u0010\\u0002\\u0002\\u0133\\u0134\\t\\u0005\\u0002\\u0002\\u0134\\u0135\\t\\u001a\",\r\n\t    \"\\u0002\\u0002\\u0135^\\u0003\\u0002\\u0002\\u0002\\u0136\\u0137\\t\\r\\u0002\\u0002\",\r\n\t    \"\\u0137\\u0138\\t\\u0012\\u0002\\u0002\\u0138\\u0139\\t\\u0006\\u0002\\u0002\\u0139\",\r\n\t    \"`\\u0003\\u0002\\u0002\\u0002\\u013a\\u013b\\t\\u0006\\u0002\\u0002\\u013b\\u013c\",\r\n\t    \"\\t\\n\\u0002\\u0002\\u013c\\u013d\\t\\u001a\\u0002\\u0002\\u013db\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u013e\\u013f\\t\\u001b\\u0002\\u0002\\u013f\\u0140\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u0140\\u0141\\b2\\u0002\\u0002\\u0141d\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\u0142\\u0143\\u0005i5\\u0002\\u0143\\u0144\\u0003\\u0002\\u0002\\u0002\\u0144\",\r\n\t    \"\\u0145\\b3\\u0002\\u0002\\u0145f\\u0003\\u0002\\u0002\\u0002\\u0146\\u0147\\u000b\",\r\n\t    \"\\u0002\\u0002\\u0002\\u0147h\\u0003\\u0002\\u0002\\u0002\\u0148\\u0149\\u0007\",\r\n\t    \"1\\u0002\\u0002\\u0149\\u014a\\u0007,\\u0002\\u0002\\u014a\\u014e\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u014b\\u014d\\u000b\\u0002\\u0002\\u0002\\u014c\\u014b\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u014d\\u0150\\u0003\\u0002\\u0002\\u0002\\u014e\\u014f\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u014e\\u014c\\u0003\\u0002\\u0002\\u0002\\u014f\\u0151\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002\\u0150\\u014e\\u0003\\u0002\\u0002\\u0002\\u0151\\u0152\\u0007,\",\r\n\t    \"\\u0002\\u0002\\u0152\\u0164\\u00071\\u0002\\u0002\\u0153\\u0157\\u0007)\\u0002\",\r\n\t    \"\\u0002\\u0154\\u0156\\u000b\\u0002\\u0002\\u0002\\u0155\\u0154\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0156\\u0159\\u0003\\u0002\\u0002\\u0002\\u0157\\u0158\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0157\\u0155\\u0003\\u0002\\u0002\\u0002\\u0158\\u015a\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0159\\u0157\\u0003\\u0002\\u0002\\u0002\\u015a\\u0164\\u0007)\\u0002\",\r\n\t    \"\\u0002\\u015b\\u015f\\u0007$\\u0002\\u0002\\u015c\\u015e\\u000b\\u0002\\u0002\",\r\n\t    \"\\u0002\\u015d\\u015c\\u0003\\u0002\\u0002\\u0002\\u015e\\u0161\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u015f\\u0160\\u0003\\u0002\\u0002\\u0002\\u015f\\u015d\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0160\\u0162\\u0003\\u0002\\u0002\\u0002\\u0161\\u015f\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0162\\u0164\\u0007$\\u0002\\u0002\\u0163\\u0148\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0163\\u0153\\u0003\\u0002\\u0002\\u0002\\u0163\\u015b\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0164j\\u0003\\u0002\\u0002\\u0002\\r\\u0002\\u0084\\u0086\\u008b\\u0091\",\r\n\t    \"\\u0098\\u009a\\u014e\\u0157\\u015f\\u0163\\u0003\\b\\u0002\\u0002\"].join(\"\");\r\n\t\r\n\t\r\n\tvar atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);\r\n\t\r\n\tvar decisionsToDFA = atn.decisionToState.map( function(ds, index) { return new antlr4.dfa.DFA(ds, index); });\r\n\t\r\n\tfunction CalculatorLexer(input) {\r\n\t\tantlr4.Lexer.call(this, input);\r\n\t    this._interp = new antlr4.atn.LexerATNSimulator(this, atn, decisionsToDFA, new antlr4.PredictionContextCache());\r\n\t    return this;\r\n\t}\r\n\t\r\n\tCalculatorLexer.prototype = Object.create(antlr4.Lexer.prototype);\r\n\tCalculatorLexer.prototype.constructor = CalculatorLexer;\r\n\t\r\n\tCalculatorLexer.EOF = antlr4.Token.EOF;\r\n\tCalculatorLexer.T__0 = 1;\r\n\tCalculatorLexer.T__1 = 2;\r\n\tCalculatorLexer.T__2 = 3;\r\n\tCalculatorLexer.T__3 = 4;\r\n\tCalculatorLexer.T__4 = 5;\r\n\tCalculatorLexer.T__5 = 6;\r\n\tCalculatorLexer.T__6 = 7;\r\n\tCalculatorLexer.T__7 = 8;\r\n\tCalculatorLexer.T__8 = 9;\r\n\tCalculatorLexer.NUMBER = 10;\r\n\tCalculatorLexer.FLOAT = 11;\r\n\tCalculatorLexer.DIGIT = 12;\r\n\tCalculatorLexer.MOD = 13;\r\n\tCalculatorLexer.WHOLE = 14;\r\n\tCalculatorLexer.MUL = 15;\r\n\tCalculatorLexer.DIV = 16;\r\n\tCalculatorLexer.ADD = 17;\r\n\tCalculatorLexer.SUB = 18;\r\n\tCalculatorLexer.PI = 19;\r\n\tCalculatorLexer.EXPONENT = 20;\r\n\tCalculatorLexer.NEGEXPONENT = 21;\r\n\tCalculatorLexer.EULER = 22;\r\n\tCalculatorLexer.SQRT = 23;\r\n\tCalculatorLexer.SQR = 24;\r\n\tCalculatorLexer.FLOOR = 25;\r\n\tCalculatorLexer.CEIL = 26;\r\n\tCalculatorLexer.ABS = 27;\r\n\tCalculatorLexer.ROUNDK = 28;\r\n\tCalculatorLexer.ROUND = 29;\r\n\tCalculatorLexer.TRUNC = 30;\r\n\tCalculatorLexer.SIN = 31;\r\n\tCalculatorLexer.COS = 32;\r\n\tCalculatorLexer.TAN = 33;\r\n\tCalculatorLexer.COT = 34;\r\n\tCalculatorLexer.SINH = 35;\r\n\tCalculatorLexer.COSH = 36;\r\n\tCalculatorLexer.TANH = 37;\r\n\tCalculatorLexer.ARCSIN = 38;\r\n\tCalculatorLexer.ARCCOS = 39;\r\n\tCalculatorLexer.ARCTAN = 40;\r\n\tCalculatorLexer.ARCTAN2 = 41;\r\n\tCalculatorLexer.ARCCOT = 42;\r\n\tCalculatorLexer.EXP = 43;\r\n\tCalculatorLexer.LN = 44;\r\n\tCalculatorLexer.EEX = 45;\r\n\tCalculatorLexer.LOG = 46;\r\n\tCalculatorLexer.RAD = 47;\r\n\tCalculatorLexer.DEG = 48;\r\n\tCalculatorLexer.WS = 49;\r\n\tCalculatorLexer.COM = 50;\r\n\tCalculatorLexer.INVALID = 51;\r\n\t\r\n\t\r\n\tCalculatorLexer.modeNames = [ \"DEFAULT_MODE\" ];\r\n\t\r\n\tCalculatorLexer.literalNames = [ null, \"'('\", \"';'\", \"')'\", \"'^'\", \"'**'\", \r\n\t                                 \"'%'\", \"'~'\", \"'//'\", \"'()'\", null, null, \r\n\t                                 null, null, null, \"'*'\", \"'/'\", \"'+'\", \r\n\t                                 \"'-'\" ];\r\n\t\r\n\tCalculatorLexer.symbolicNames = [ null, null, null, null, null, null, null, \r\n\t                                  null, null, null, \"NUMBER\", \"FLOAT\", \"DIGIT\", \r\n\t                                  \"MOD\", \"WHOLE\", \"MUL\", \"DIV\", \"ADD\", \"SUB\", \r\n\t                                  \"PI\", \"EXPONENT\", \"NEGEXPONENT\", \"EULER\", \r\n\t                                  \"SQRT\", \"SQR\", \"FLOOR\", \"CEIL\", \"ABS\", \r\n\t                                  \"ROUNDK\", \"ROUND\", \"TRUNC\", \"SIN\", \"COS\", \r\n\t                                  \"TAN\", \"COT\", \"SINH\", \"COSH\", \"TANH\", \r\n\t                                  \"ARCSIN\", \"ARCCOS\", \"ARCTAN\", \"ARCTAN2\", \r\n\t                                  \"ARCCOT\", \"EXP\", \"LN\", \"EEX\", \"LOG\", \"RAD\", \r\n\t                                  \"DEG\", \"WS\", \"COM\", \"INVALID\" ];\r\n\t\r\n\tCalculatorLexer.ruleNames = [ \"T__0\", \"T__1\", \"T__2\", \"T__3\", \"T__4\", \"T__5\", \r\n\t                              \"T__6\", \"T__7\", \"T__8\", \"NUMBER\", \"FLOAT\", \r\n\t                              \"DIGIT\", \"MOD\", \"WHOLE\", \"MUL\", \"DIV\", \"ADD\", \r\n\t                              \"SUB\", \"PI\", \"EXPONENT\", \"NEGEXPONENT\", \"EULER\", \r\n\t                              \"SQRT\", \"SQR\", \"FLOOR\", \"CEIL\", \"ABS\", \"ROUNDK\", \r\n\t                              \"ROUND\", \"TRUNC\", \"SIN\", \"COS\", \"TAN\", \"COT\", \r\n\t                              \"SINH\", \"COSH\", \"TANH\", \"ARCSIN\", \"ARCCOS\", \r\n\t                              \"ARCTAN\", \"ARCTAN2\", \"ARCCOT\", \"EXP\", \"LN\", \r\n\t                              \"EEX\", \"LOG\", \"RAD\", \"DEG\", \"WS\", \"COM\", \"INVALID\", \r\n\t                              \"COMMENT\" ];\r\n\t\r\n\tCalculatorLexer.grammarFileName = \"Calculator.g4\";\r\n\t\r\n\t\r\n\t\r\n\texports.CalculatorLexer = CalculatorLexer;\r\n\t\r\n\n\n/***/ },\n/* 4 */\n/***/ function(module, exports, __webpack_require__) {\n\n\texports.atn = __webpack_require__(5);\n\texports.dfa = __webpack_require__(36);\n\texports.tree = __webpack_require__(39);\n\texports.error = __webpack_require__(40);\n\texports.Token = __webpack_require__(9).Token;\n\texports.CommonToken = __webpack_require__(9).CommonToken;\n\texports.InputStream = __webpack_require__(43).InputStream;\n\texports.FileStream = __webpack_require__(44).FileStream;\n\texports.CommonTokenStream = __webpack_require__(46).CommonTokenStream;\n\texports.Lexer = __webpack_require__(25).Lexer;\n\texports.Parser = __webpack_require__(48).Parser;\n\tvar pc = __webpack_require__(15);\n\texports.PredictionContextCache = pc.PredictionContextCache;\n\texports.ParserRuleContext = __webpack_require__(19).ParserRuleContext;\n\texports.Interval = __webpack_require__(13).Interval;\n\texports.Utils = __webpack_require__(8);\n\n\n/***/ },\n/* 5 */\n/***/ function(module, exports, __webpack_require__) {\n\n\texports.ATN = __webpack_require__(6).ATN;\n\texports.ATNDeserializer = __webpack_require__(20).ATNDeserializer;\n\texports.LexerATNSimulator = __webpack_require__(24).LexerATNSimulator;\n\texports.ParserATNSimulator = __webpack_require__(34).ParserATNSimulator;\n\texports.PredictionMode = __webpack_require__(35).PredictionMode;\n\n/***/ },\n/* 6 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2013 Terence Parr\n\t//  Copyright (c) 2013 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\tvar LL1Analyzer = __webpack_require__(7).LL1Analyzer;\n\tvar IntervalSet = __webpack_require__(13).IntervalSet;\n\t\n\tfunction ATN(grammarType , maxTokenType) {\n\t\n\t    // Used for runtime deserialization of ATNs from strings///\n\t    // The type of the ATN.\n\t    this.grammarType = grammarType;\n\t    // The maximum value for any symbol recognized by a transition in the ATN.\n\t    this.maxTokenType = maxTokenType;\n\t    this.states = [];\n\t    // Each subrule/rule is a decision point and we must track them so we\n\t    //  can go back later and build DFA predictors for them.  This includes\n\t    //  all the rules, subrules, optional blocks, ()+, ()* etc...\n\t    this.decisionToState = [];\n\t    // Maps from rule index to starting state number.\n\t    this.ruleToStartState = [];\n\t    // Maps from rule index to stop state number.\n\t    this.ruleToStopState = null;\n\t    this.modeNameToStartState = {};\n\t    // For lexer ATNs, this maps the rule index to the resulting token type.\n\t    // For parser ATNs, this maps the rule index to the generated bypass token\n\t    // type if the\n\t    // {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}\n\t    // deserialization option was specified; otherwise, this is {@code null}.\n\t    this.ruleToTokenType = null;\n\t    // For lexer ATNs, this is an array of {@link LexerAction} objects which may\n\t    // be referenced by action transitions in the ATN.\n\t    this.lexerActions = null;\n\t    this.modeToStartState = [];\n\t\n\t    return this;\n\t}\n\t\t\n\t// Compute the set of valid tokens that can occur starting in state {@code s}.\n\t//  If {@code ctx} is null, the set of tokens will not include what can follow\n\t//  the rule surrounding {@code s}. In other words, the set will be\n\t//  restricted to tokens reachable staying within {@code s}'s rule.\n\tATN.prototype.nextTokensInContext = function(s, ctx) {\n\t    var anal = new LL1Analyzer(this);\n\t    return anal.LOOK(s, null, ctx);\n\t};\n\t\n\t// Compute the set of valid tokens that can occur starting in {@code s} and\n\t// staying in same rule. {@link Token//EPSILON} is in set if we reach end of\n\t// rule.\n\tATN.prototype.nextTokensNoContext = function(s) {\n\t    if (s.nextTokenWithinRule !== null ) {\n\t        return s.nextTokenWithinRule;\n\t    }\n\t    s.nextTokenWithinRule = this.nextTokensInContext(s, null);\n\t    s.nextTokenWithinRule.readOnly = true;\n\t    return s.nextTokenWithinRule;\n\t};\n\t\n\tATN.prototype.nextTokens = function(s, ctx) {\n\t    if ( ctx===undefined ) {\n\t        return this.nextTokensNoContext(s);\n\t    } else {\n\t        return this.nextTokensInContext(s, ctx);\n\t    }\n\t};\n\t\n\tATN.prototype.addState = function( state) {\n\t    if ( state !== null ) {\n\t        state.atn = this;\n\t        state.stateNumber = this.states.length;\n\t    }\n\t    this.states.push(state);\n\t};\n\t\n\tATN.prototype.removeState = function( state) {\n\t    this.states[state.stateNumber] = null; // just free mem, don't shift states in list\n\t};\n\t\n\tATN.prototype.defineDecisionState = function( s) {\n\t    this.decisionToState.push(s);\n\t    s.decision = this.decisionToState.length-1;\n\t    return s.decision;\n\t};\n\t\n\tATN.prototype.getDecisionState = function( decision) {\n\t    if (this.decisionToState.length===0) {\n\t        return null;\n\t    } else {\n\t        return this.decisionToState[decision];\n\t    }\n\t};\n\t\n\t// Computes the set of input symbols which could follow ATN state number\n\t// {@code stateNumber} in the specified full {@code context}. This method\n\t// considers the complete parser context, but does not evaluate semantic\n\t// predicates (i.e. all predicates encountered during the calculation are\n\t// assumed true). If a path in the ATN exists from the starting state to the\n\t// {@link RuleStopState} of the outermost context without matching any\n\t// symbols, {@link Token//EOF} is added to the returned set.\n\t//\n\t// <p>If {@code context} is {@code null}, it is treated as\n\t// {@link ParserRuleContext//EMPTY}.</p>\n\t//\n\t// @param stateNumber the ATN state number\n\t// @param context the full parse context\n\t// @return The set of potentially valid input symbols which could follow the\n\t// specified state in the specified context.\n\t// @throws IllegalArgumentException if the ATN does not contain a state with\n\t// number {@code stateNumber}\n\tvar Token = __webpack_require__(9).Token;\n\t\n\tATN.prototype.getExpectedTokens = function( stateNumber, ctx ) {\n\t    if ( stateNumber < 0 || stateNumber >= this.states.length ) {\n\t        throw(\"Invalid state number.\");\n\t    }\n\t    var s = this.states[stateNumber];\n\t    var following = this.nextTokens(s);\n\t    if (!following.contains(Token.EPSILON)) {\n\t        return following;\n\t    }\n\t    var expected = new IntervalSet();\n\t    expected.addSet(following);\n\t    expected.removeOne(Token.EPSILON);\n\t    while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n\t        var invokingState = this.states[ctx.invokingState];\n\t        var rt = invokingState.transitions[0];\n\t        following = this.nextTokens(rt.followState);\n\t        expected.addSet(following);\n\t        expected.removeOne(Token.EPSILON);\n\t        ctx = ctx.parentCtx;\n\t    }\n\t    if (following.contains(Token.EPSILON)) {\n\t        expected.addOne(Token.EOF);\n\t    }\n\t    return expected;\n\t};\n\t\n\tATN.INVALID_ALT_NUMBER = 0;\n\t\n\texports.ATN = ATN;\n\n/***/ },\n/* 7 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\tvar Set = __webpack_require__(8).Set;\n\tvar BitSet = __webpack_require__(8).BitSet;\n\tvar Token = __webpack_require__(9).Token;\n\tvar ATNConfig = __webpack_require__(10).ATNConfig;\n\tvar Interval = __webpack_require__(13).Interval;\n\tvar IntervalSet = __webpack_require__(13).IntervalSet;\n\tvar RuleStopState = __webpack_require__(11).RuleStopState;\n\tvar RuleTransition = __webpack_require__(14).RuleTransition;\n\tvar NotSetTransition = __webpack_require__(14).NotSetTransition;\n\tvar WildcardTransition = __webpack_require__(14).WildcardTransition;\n\tvar AbstractPredicateTransition = __webpack_require__(14).AbstractPredicateTransition;\n\t\n\tvar pc = __webpack_require__(15);\n\tvar predictionContextFromRuleContext = pc.predictionContextFromRuleContext;\n\tvar PredictionContext = pc.PredictionContext;\n\tvar SingletonPredictionContext = pc.SingletonPredictionContext;\n\t\n\tfunction LL1Analyzer (atn) {\n\t    this.atn = atn;\n\t}\n\t\n\t//* Special value added to the lookahead sets to indicate that we hit\n\t//  a predicate during analysis if {@code seeThruPreds==false}.\n\t///\n\tLL1Analyzer.HIT_PRED = Token.INVALID_TYPE;\n\t\n\t\n\t//*\n\t// Calculates the SLL(1) expected lookahead set for each outgoing transition\n\t// of an {@link ATNState}. The returned array has one element for each\n\t// outgoing transition in {@code s}. If the closure from transition\n\t// <em>i</em> leads to a semantic predicate before matching a symbol, the\n\t// element at index <em>i</em> of the result will be {@code null}.\n\t//\n\t// @param s the ATN state\n\t// @return the expected symbols for each outgoing transition of {@code s}.\n\t///\n\tLL1Analyzer.prototype.getDecisionLookahead = function(s) {\n\t    if (s === null) {\n\t        return null;\n\t    }\n\t    var count = s.transitions.length;\n\t    var look = [];\n\t    for(var alt=0; alt< count; alt++) {\n\t        look[alt] = new IntervalSet();\n\t        var lookBusy = new Set();\n\t        var seeThruPreds = false; // fail to get lookahead upon pred\n\t        this._LOOK(s.transition(alt).target, null, PredictionContext.EMPTY,\n\t              look[alt], lookBusy, new BitSet(), seeThruPreds, false);\n\t        // Wipe out lookahead for this alternative if we found nothing\n\t        // or we had a predicate when we !seeThruPreds\n\t        if (look[alt].length===0 || look[alt].contains(LL1Analyzer.HIT_PRED)) {\n\t            look[alt] = null;\n\t        }\n\t    }\n\t    return look;\n\t};\n\t\n\t//*\n\t// Compute set of tokens that can follow {@code s} in the ATN in the\n\t// specified {@code ctx}.\n\t//\n\t// <p>If {@code ctx} is {@code null} and the end of the rule containing\n\t// {@code s} is reached, {@link Token//EPSILON} is added to the result set.\n\t// If {@code ctx} is not {@code null} and the end of the outermost rule is\n\t// reached, {@link Token//EOF} is added to the result set.</p>\n\t//\n\t// @param s the ATN state\n\t// @param stopState the ATN state to stop at. This can be a\n\t// {@link BlockEndState} to detect epsilon paths through a closure.\n\t// @param ctx the complete parser context, or {@code null} if the context\n\t// should be ignored\n\t//\n\t// @return The set of tokens that can follow {@code s} in the ATN in the\n\t// specified {@code ctx}.\n\t///\n\tLL1Analyzer.prototype.LOOK = function(s, stopState, ctx) {\n\t    var r = new IntervalSet();\n\t    var seeThruPreds = true; // ignore preds; get all lookahead\n\t\tctx = ctx || null;\n\t    var lookContext = ctx!==null ? predictionContextFromRuleContext(s.atn, ctx) : null;\n\t    this._LOOK(s, stopState, lookContext, r, new Set(), new BitSet(), seeThruPreds, true);\n\t    return r;\n\t};\n\t    \n\t//*\n\t// Compute set of tokens that can follow {@code s} in the ATN in the\n\t// specified {@code ctx}.\n\t//\n\t// <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the\n\t// rule containing {@code s} is reached, {@link Token//EPSILON} is added to\n\t// the result set. If {@code ctx} is not {@code null} and {@code addEOF} is\n\t// {@code true} and {@code stopState} or the end of the outermost rule is\n\t// reached, {@link Token//EOF} is added to the result set.</p>\n\t//\n\t// @param s the ATN state.\n\t// @param stopState the ATN state to stop at. This can be a\n\t// {@link BlockEndState} to detect epsilon paths through a closure.\n\t// @param ctx The outer context, or {@code null} if the outer context should\n\t// not be used.\n\t// @param look The result lookahead set.\n\t// @param lookBusy A set used for preventing epsilon closures in the ATN\n\t// from causing a stack overflow. Outside code should pass\n\t// {@code new Set<ATNConfig>} for this argument.\n\t// @param calledRuleStack A set used for preventing left recursion in the\n\t// ATN from causing a stack overflow. Outside code should pass\n\t// {@code new BitSet()} for this argument.\n\t// @param seeThruPreds {@code true} to true semantic predicates as\n\t// implicitly {@code true} and \"see through them\", otherwise {@code false}\n\t// to treat semantic predicates as opaque and add {@link //HIT_PRED} to the\n\t// result if one is encountered.\n\t// @param addEOF Add {@link Token//EOF} to the result if the end of the\n\t// outermost context is reached. This parameter has no effect if {@code ctx}\n\t// is {@code null}.\n\t///\n\tLL1Analyzer.prototype._LOOK = function(s, stopState , ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {\n\t    var c = new ATNConfig({state:s, alt:0, context: ctx}, null);\n\t    if (lookBusy.contains(c)) {\n\t        return;\n\t    }\n\t    lookBusy.add(c);\n\t    if (s === stopState) {\n\t        if (ctx ===null) {\n\t            look.addOne(Token.EPSILON);\n\t            return;\n\t        } else if (ctx.isEmpty() && addEOF) {\n\t            look.addOne(Token.EOF);\n\t            return;\n\t        }\n\t    }\n\t    if (s instanceof RuleStopState ) {\n\t        if (ctx ===null) {\n\t            look.addOne(Token.EPSILON);\n\t            return;\n\t        } else if (ctx.isEmpty() && addEOF) {\n\t            look.addOne(Token.EOF);\n\t            return;\n\t        }\n\t        if (ctx !== PredictionContext.EMPTY) {\n\t            // run thru all possible stack tops in ctx\n\t            for(var i=0; i<ctx.length; i++) {\n\t                var returnState = this.atn.states[ctx.getReturnState(i)];\n\t                var removed = calledRuleStack.contains(returnState.ruleIndex);\n\t                try {\n\t                    calledRuleStack.remove(returnState.ruleIndex);\n\t                    this._LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t                } finally {\n\t                    if (removed) {\n\t                        calledRuleStack.add(returnState.ruleIndex);\n\t                    }\n\t                }\n\t            }\n\t            return;\n\t        }\n\t    }\n\t    for(var j=0; j<s.transitions.length; j++) {\n\t        var t = s.transitions[j];\n\t        if (t.constructor === RuleTransition) {\n\t            if (calledRuleStack.contains(t.target.ruleIndex)) {\n\t                continue;\n\t            }\n\t            var newContext = SingletonPredictionContext.create(ctx, t.followState.stateNumber);\n\t            try {\n\t                calledRuleStack.add(t.target.ruleIndex);\n\t                this._LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t            } finally {\n\t                calledRuleStack.remove(t.target.ruleIndex);\n\t            }\n\t        } else if (t instanceof AbstractPredicateTransition ) {\n\t            if (seeThruPreds) {\n\t                this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t            } else {\n\t                look.addOne(LL1Analyzer.HIT_PRED);\n\t            }\n\t        } else if( t.isEpsilon) {\n\t            this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t        } else if (t.constructor === WildcardTransition) {\n\t            look.addRange( Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType );\n\t        } else {\n\t            var set = t.label;\n\t            if (set !== null) {\n\t                if (t instanceof NotSetTransition) {\n\t                    set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);\n\t                }\n\t                look.addSet(set);\n\t            }\n\t        }\n\t    }\n\t};\n\t\n\texports.LL1Analyzer = LL1Analyzer;\n\t\n\n\n/***/ },\n/* 8 */\n/***/ function(module, exports) {\n\n\tfunction arrayToString(a) {\n\t\treturn \"[\" + a.join(\", \") + \"]\";\n\t}\n\t\n\tString.prototype.hashCode = function(s) {\n\t\tvar hash = 0;\n\t\tif (this.length === 0) {\n\t\t\treturn hash;\n\t\t}\n\t\tfor (var i = 0; i < this.length; i++) {\n\t\t\tvar character = this.charCodeAt(i);\n\t\t\thash = ((hash << 5) - hash) + character;\n\t\t\thash = hash & hash; // Convert to 32bit integer\n\t\t}\n\t\treturn hash;\n\t};\n\t\n\tfunction standardEqualsFunction(a,b) {\n\t\treturn a.equals(b);\n\t}\n\t\n\tfunction standardHashFunction(a) {\n\t\treturn a.hashString();\n\t}\n\t\n\tfunction Set(hashFunction, equalsFunction) {\n\t\tthis.data = {};\n\t\tthis.hashFunction = hashFunction || standardHashFunction;\n\t\tthis.equalsFunction = equalsFunction || standardEqualsFunction;\n\t\treturn this;\n\t}\n\t\n\tObject.defineProperty(Set.prototype, \"length\", {\n\t\tget : function() {\n\t\t\treturn this.values().length;\n\t\t}\n\t});\n\t\n\tSet.prototype.add = function(value) {\n\t\tvar hash = this.hashFunction(value);\n\t\tvar key = \"hash_\" + hash.hashCode();\n\t\tif(key in this.data) {\n\t\t\tvar i;\n\t\t\tvar values = this.data[key];\n\t\t\tfor(i=0;i<values.length; i++) {\n\t\t\t\tif(this.equalsFunction(value, values[i])) {\n\t\t\t\t\treturn values[i];\n\t\t\t\t}\n\t\t\t}\n\t\t\tvalues.push(value);\n\t\t\treturn value;\n\t\t} else {\n\t\t\tthis.data[key] = [ value ];\n\t\t\treturn value;\n\t\t}\n\t};\n\t\n\tSet.prototype.contains = function(value) {\n\t\tvar hash = this.hashFunction(value);\n\t\tvar key = hash.hashCode();\n\t\tif(key in this.data) {\n\t\t\tvar i;\n\t\t\tvar values = this.data[key];\n\t\t\tfor(i=0;i<values.length; i++) {\n\t\t\t\tif(this.equalsFunction(value, values[i])) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t};\n\t\n\tSet.prototype.values = function() {\n\t\tvar l = [];\n\t\tfor(var key in this.data) {\n\t\t\tif(key.indexOf(\"hash_\")===0) {\n\t\t\t\tl = l.concat(this.data[key]);\n\t\t\t}\n\t\t}\n\t\treturn l;\n\t};\n\t\n\tSet.prototype.toString = function() {\n\t\treturn arrayToString(this.values());\n\t};\n\t\n\tfunction BitSet() {\n\t\tthis.data = [];\n\t\treturn this;\n\t}\n\t\n\tBitSet.prototype.add = function(value) {\n\t\tthis.data[value] = true;\n\t};\n\t\n\tBitSet.prototype.or = function(set) {\n\t\tvar bits = this;\n\t\tObject.keys(set.data).map( function(alt) { bits.add(alt); });\n\t};\n\t\n\tBitSet.prototype.remove = function(value) {\n\t\tdelete this.data[value];\n\t};\n\t\n\tBitSet.prototype.contains = function(value) {\n\t\treturn this.data[value] === true;\n\t};\n\t\n\tBitSet.prototype.values = function() {\n\t\treturn Object.keys(this.data);\n\t};\n\t\n\tBitSet.prototype.minValue = function() {\n\t\treturn Math.min.apply(null, this.values());\n\t};\n\t\n\tBitSet.prototype.hashString = function() {\n\t\treturn this.values().toString();\n\t};\n\t\n\tBitSet.prototype.equals = function(other) {\n\t\tif(!(other instanceof BitSet)) {\n\t\t\treturn false;\n\t\t}\n\t\treturn this.hashString()===other.hashString();\n\t};\n\t\n\tObject.defineProperty(BitSet.prototype, \"length\", {\n\t\tget : function() {\n\t\t\treturn this.values().length;\n\t\t}\n\t});\n\t\n\tBitSet.prototype.toString = function() {\n\t\treturn \"{\" + this.values().join(\", \") + \"}\";\n\t};\n\t\n\tfunction AltDict() {\n\t\tthis.data = {};\n\t\treturn this;\n\t}\n\t\n\tAltDict.prototype.get = function(key) {\n\t\tkey = \"k-\" + key;\n\t\tif(key in this.data){\n\t\t\treturn this.data[key];\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t};\n\t\n\tAltDict.prototype.put = function(key, value) {\n\t\tkey = \"k-\" + key;\n\t\tthis.data[key] = value;\n\t};\n\t\n\tAltDict.prototype.values = function() {\n\t\tvar data = this.data;\n\t\tvar keys = Object.keys(this.data);\n\t\treturn keys.map(function(key) {\n\t\t\treturn data[key];\n\t\t});\n\t};\n\t\n\tfunction DoubleDict() {\n\t\treturn this;\n\t}\n\t\n\tDoubleDict.prototype.get = function(a, b) {\n\t\tvar d = this[a] || null;\n\t\treturn d===null ? null : (d[b] || null);\n\t};\n\t\n\tDoubleDict.prototype.set = function(a, b, o) {\n\t\tvar d = this[a] || null;\n\t\tif(d===null) {\n\t\t\td = {};\n\t\t\tthis[a] = d;\n\t\t}\n\t\td[b] = o;\n\t};\n\t\n\t\n\tfunction escapeWhitespace(s, escapeSpaces) {\n\t\ts = s.replace(\"\\t\",\"\\\\t\");\n\t\ts = s.replace(\"\\n\",\"\\\\n\");\n\t\ts = s.replace(\"\\r\",\"\\\\r\");\n\t\tif(escapeSpaces) {\n\t\t\ts = s.replace(\" \",\"\\u00B7\");\n\t\t}\n\t\treturn s;\n\t}\n\t\n\texports.isArray = function (entity) {\n\t\treturn Object.prototype.toString.call( entity ) === '[object Array]'\n\t};\n\t\n\texports.titleCase = function(str) {\n\t\treturn str.replace(/\\w\\S*/g, function(txt){return txt.charAt(0).toUpperCase() + txt.substr(1);});\n\t};\n\t\n\texports.Set = Set;\n\texports.BitSet = BitSet;\n\texports.AltDict = AltDict;\n\texports.DoubleDict = DoubleDict;\n\texports.escapeWhitespace = escapeWhitespace;\n\texports.arrayToString = arrayToString;\n\n\n/***/ },\n/* 9 */\n/***/ function(module, exports) {\n\n\t//[The \"BSD license\"]\n\t// Copyright (c) 2012 Terence Parr\n\t// Copyright (c) 2012 Sam Harwell\n\t// Copyright (c) 2014 Eric Vergnaud\n\t// All rights reserved.\n\t//\n\t// Redistribution and use in source and binary forms, with or without\n\t// modification, are permitted provided that the following conditions\n\t// are met:\n\t//\n\t// 1. Redistributions of source code must retain the above copyright\n\t//    notice, this list of conditions and the following disclaimer.\n\t// 2. Redistributions in binary form must reproduce the above copyright\n\t//    notice, this list of conditions and the following disclaimer in the\n\t//    documentation and/or other materials provided with the distribution.\n\t// 3. The name of the author may not be used to endorse or promote products\n\t//    derived from this software without specific prior written permission.\n\t//\n\t// THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t// IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t// INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t// NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t// THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t//\n\t\n\t// A token has properties: text, type, line, character position in the line\n\t// (so we can ignore tabs), token channel, index, and source from which\n\t// we obtained this token.\n\t\n\tfunction Token() {\n\t\tthis.source = null;\n\t\tthis.type = null; // token type of the token\n\t\tthis.channel = null; // The parser ignores everything not on DEFAULT_CHANNEL\n\t\tthis.start = null; // optional; return -1 if not implemented.\n\t\tthis.stop = null; // optional; return -1 if not implemented.\n\t\tthis.tokenIndex = null; // from 0..n-1 of the token object in the input stream\n\t\tthis.line = null; // line=1..n of the 1st character\n\t\tthis.column = null; // beginning of the line at which it occurs, 0..n-1\n\t\tthis._text = null; // text of the token.\n\t\treturn this;\n\t}\n\t\n\tToken.INVALID_TYPE = 0;\n\t\n\t// During lookahead operations, this \"token\" signifies we hit rule end ATN state\n\t// and did not follow it despite needing to.\n\tToken.EPSILON = -2;\n\t\n\tToken.MIN_USER_TOKEN_TYPE = 1;\n\t\n\tToken.EOF = -1;\n\t\n\t// All tokens go to the parser (unless skip() is called in that rule)\n\t// on a particular \"channel\". The parser tunes to a particular channel\n\t// so that whitespace etc... can go to the parser on a \"hidden\" channel.\n\t\n\tToken.DEFAULT_CHANNEL = 0;\n\t\n\t// Anything on different channel than DEFAULT_CHANNEL is not parsed\n\t// by parser.\n\t\n\tToken.HIDDEN_CHANNEL = 1;\n\t\n\t// Explicitly set the text for this token. If {code text} is not\n\t// {@code null}, then {@link //getText} will return this value rather than\n\t// extracting the text from the input.\n\t//\n\t// @param text The explicit text of the token, or {@code null} if the text\n\t// should be obtained from the input along with the start and stop indexes\n\t// of the token.\n\t\n\tObject.defineProperty(Token.prototype, \"text\", {\n\t\tget : function() {\n\t\t\treturn this._text;\n\t\t},\n\t\tset : function(text) {\n\t\t\tthis._text = text;\n\t\t}\n\t});\n\t\n\tToken.prototype.getTokenSource = function() {\n\t\treturn this.source[0];\n\t};\n\t\n\tToken.prototype.getInputStream = function() {\n\t\treturn this.source[1];\n\t};\n\t\n\tfunction CommonToken(source, type, channel, start, stop) {\n\t\tToken.call(this);\n\t\tthis.source = source !== undefined ? source : CommonToken.EMPTY_SOURCE;\n\t\tthis.type = type !== undefined ? type : null;\n\t\tthis.channel = channel !== undefined ? channel : Token.DEFAULT_CHANNEL;\n\t\tthis.start = start !== undefined ? start : -1;\n\t\tthis.stop = stop !== undefined ? stop : -1;\n\t\tthis.tokenIndex = -1;\n\t\tif (this.source[0] !== null) {\n\t\t\tthis.line = source[0].line;\n\t\t\tthis.column = source[0].column;\n\t\t} else {\n\t\t\tthis.column = -1;\n\t\t}\n\t\treturn this;\n\t}\n\t\n\tCommonToken.prototype = Object.create(Token.prototype);\n\tCommonToken.prototype.constructor = CommonToken;\n\t\n\t// An empty {@link Pair} which is used as the default value of\n\t// {@link //source} for tokens that do not have a source.\n\tCommonToken.EMPTY_SOURCE = [ null, null ];\n\t\n\t// Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n\t//\n\t// <p>\n\t// If {@code oldToken} is also a {@link CommonToken} instance, the newly\n\t// constructed token will share a reference to the {@link //text} field and\n\t// the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will\n\t// be assigned the result of calling {@link //getText}, and {@link //source}\n\t// will be constructed from the result of {@link Token//getTokenSource} and\n\t// {@link Token//getInputStream}.</p>\n\t//\n\t// @param oldToken The token to copy.\n\t//\n\tCommonToken.prototype.clone = function() {\n\t\tvar t = new CommonToken(this.source, this.type, this.channel, this.start,\n\t\t\t\tthis.stop);\n\t\tt.tokenIndex = this.tokenIndex;\n\t\tt.line = this.line;\n\t\tt.column = this.column;\n\t\tt.text = this.text;\n\t\treturn t;\n\t};\n\t\n\tObject.defineProperty(CommonToken.prototype, \"text\", {\n\t\tget : function() {\n\t\t\tif (this._text !== null) {\n\t\t\t\treturn this._text;\n\t\t\t}\n\t\t\tvar input = this.getInputStream();\n\t\t\tif (input === null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tvar n = input.size;\n\t\t\tif (this.start < n && this.stop < n) {\n\t\t\t\treturn input.getText(this.start, this.stop);\n\t\t\t} else {\n\t\t\t\treturn \"<EOF>\";\n\t\t\t}\n\t\t},\n\t\tset : function(text) {\n\t\t\tthis._text = text;\n\t\t}\n\t});\n\t\n\tCommonToken.prototype.toString = function() {\n\t\tvar txt = this.text;\n\t\tif (txt !== null) {\n\t\t\ttxt = txt.replace(/\\n/g, \"\\\\n\").replace(/\\r/g, \"\\\\r\").replace(/\\t/g, \"\\\\t\");\n\t\t} else {\n\t\t\ttxt = \"<no text>\";\n\t\t}\n\t\treturn \"[@\" + this.tokenIndex + \",\" + this.start + \":\" + this.stop + \"='\" +\n\t\t\t\ttxt + \"',<\" + this.type + \">\" +\n\t\t\t\t(this.channel > 0 ? \",channel=\" + this.channel : \"\") + \",\" +\n\t\t\t\tthis.line + \":\" + this.column + \"]\";\n\t};\n\t\n\texports.Token = Token;\n\texports.CommonToken = CommonToken;\n\n\n/***/ },\n/* 10 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\t// A tuple: (ATN state, predicted alt, syntactic, semantic context).\n\t//  The syntactic context is a graph-structured stack node whose\n\t//  path(s) to the root is the rule invocation(s)\n\t//  chain used to arrive at the state.  The semantic context is\n\t//  the tree of semantic predicates encountered before reaching\n\t//  an ATN state.\n\t///\n\t\n\tvar DecisionState = __webpack_require__(11).DecisionState;\n\tvar SemanticContext = __webpack_require__(12).SemanticContext;\n\t\n\tfunction checkParams(params, isCfg) {\n\t\tif(params===null) {\n\t\t\tvar result = { state:null, alt:null, context:null, semanticContext:null };\n\t\t\tif(isCfg) {\n\t\t\t\tresult.reachesIntoOuterContext = 0;\n\t\t\t}\n\t\t\treturn result;\n\t\t} else {\n\t\t\tvar props = {};\n\t\t\tprops.state = params.state || null;\n\t\t\tprops.alt = (params.alt === undefined) ? null : params.alt;\n\t\t\tprops.context = params.context || null;\n\t\t\tprops.semanticContext = params.semanticContext || null;\n\t\t\tif(isCfg) {\n\t\t\t\tprops.reachesIntoOuterContext = params.reachesIntoOuterContext || 0;\n\t\t\t\tprops.precedenceFilterSuppressed = params.precedenceFilterSuppressed || false;\n\t\t\t}\n\t\t\treturn props;\n\t\t}\n\t}\n\t\n\tfunction ATNConfig(params, config) {\n\t\tthis.checkContext(params, config);\n\t\tparams = checkParams(params);\n\t\tconfig = checkParams(config, true);\n\t    // The ATN state associated with this configuration///\n\t    this.state = params.state!==null ? params.state : config.state;\n\t    // What alt (or lexer rule) is predicted by this configuration///\n\t    this.alt = params.alt!==null ? params.alt : config.alt;\n\t    // The stack of invoking states leading to the rule/states associated\n\t    //  with this config.  We track only those contexts pushed during\n\t    //  execution of the ATN simulator.\n\t    this.context = params.context!==null ? params.context : config.context;\n\t    this.semanticContext = params.semanticContext!==null ? params.semanticContext :\n\t        (config.semanticContext!==null ? config.semanticContext : SemanticContext.NONE);\n\t    // We cannot execute predicates dependent upon local context unless\n\t    // we know for sure we are in the correct context. Because there is\n\t    // no way to do this efficiently, we simply cannot evaluate\n\t    // dependent predicates unless we are in the rule that initially\n\t    // invokes the ATN simulator.\n\t    //\n\t    // closure() tracks the depth of how far we dip into the\n\t    // outer context: depth &gt; 0.  Note that it may not be totally\n\t    // accurate depth since I don't ever decrement. TODO: make it a boolean then\n\t    this.reachesIntoOuterContext = config.reachesIntoOuterContext;\n\t    this.precedenceFilterSuppressed = config.precedenceFilterSuppressed;\n\t    return this;\n\t}\n\t\n\tATNConfig.prototype.checkContext = function(params, config) {\n\t\tif((params.context===null || params.context===undefined) &&\n\t\t\t\t(config===null || config.context===null || config.context===undefined)) {\n\t\t\tthis.context = null;\n\t\t}\n\t};\n\t\n\t// An ATN configuration is equal to another if both have\n\t//  the same state, they predict the same alternative, and\n\t//  syntactic/semantic contexts are the same.\n\t///\n\tATNConfig.prototype.equals = function(other) {\n\t    if (this === other) {\n\t        return true;\n\t    } else if (! (other instanceof ATNConfig)) {\n\t        return false;\n\t    } else {\n\t        return this.state.stateNumber===other.state.stateNumber &&\n\t            this.alt===other.alt &&\n\t            (this.context===null ? other.context===null : this.context.equals(other.context)) &&\n\t            this.semanticContext.equals(other.semanticContext) &&\n\t            this.precedenceFilterSuppressed===other.precedenceFilterSuppressed;\n\t    }\n\t};\n\t\n\tATNConfig.prototype.shortHashString = function() {\n\t    return \"\" + this.state.stateNumber + \"/\" + this.alt + \"/\" + this.semanticContext;\n\t};\n\t\n\tATNConfig.prototype.hashString = function() {\n\t    return \"\" + this.state.stateNumber + \"/\" + this.alt + \"/\" +\n\t             (this.context===null ? \"\" : this.context.hashString()) +\n\t             \"/\" + this.semanticContext.hashString();\n\t};\n\t\n\tATNConfig.prototype.toString = function() {\n\t    return \"(\" + this.state + \",\" + this.alt +\n\t        (this.context!==null ? \",[\" + this.context.toString() + \"]\" : \"\") +\n\t        (this.semanticContext !== SemanticContext.NONE ?\n\t                (\",\" + this.semanticContext.toString())\n\t                : \"\") +\n\t        (this.reachesIntoOuterContext>0 ?\n\t                (\",up=\" + this.reachesIntoOuterContext)\n\t                : \"\") + \")\";\n\t};\n\t\n\t\n\tfunction LexerATNConfig(params, config) {\n\t\tATNConfig.call(this, params, config);\n\t    \n\t    // This is the backing field for {@link //getLexerActionExecutor}.\n\t\tvar lexerActionExecutor = params.lexerActionExecutor || null;\n\t    this.lexerActionExecutor = lexerActionExecutor || (config!==null ? config.lexerActionExecutor : null);\n\t    this.passedThroughNonGreedyDecision = config!==null ? this.checkNonGreedyDecision(config, this.state) : false;\n\t    return this;\n\t}\n\t\n\tLexerATNConfig.prototype = Object.create(ATNConfig.prototype);\n\tLexerATNConfig.prototype.constructor = LexerATNConfig;\n\t\n\tLexerATNConfig.prototype.hashString = function() {\n\t    return \"\" + this.state.stateNumber + this.alt + this.context +\n\t            this.semanticContext + (this.passedThroughNonGreedyDecision ? 1 : 0) +\n\t            this.lexerActionExecutor;\n\t};\n\t\n\tLexerATNConfig.prototype.equals = function(other) {\n\t    if (this === other) {\n\t        return true;\n\t    } else if (!(other instanceof LexerATNConfig)) {\n\t        return false;\n\t    } else if (this.passedThroughNonGreedyDecision !== other.passedThroughNonGreedyDecision) {\n\t        return false;\n\t    } else if (this.lexerActionExecutor ?\n\t            !this.lexerActionExecutor.equals(other.lexerActionExecutor)\n\t            : !other.lexerActionExecutor) {\n\t        return false;\n\t    } else {\n\t        return ATNConfig.prototype.equals.call(this, other);\n\t    }\n\t};\n\t\n\tLexerATNConfig.prototype.checkNonGreedyDecision = function(source, target) {\n\t    return source.passedThroughNonGreedyDecision ||\n\t        (target instanceof DecisionState) && target.nonGreedy;\n\t};\n\t\n\texports.ATNConfig = ATNConfig;\n\texports.LexerATNConfig = LexerATNConfig;\n\n/***/ },\n/* 11 */\n/***/ function(module, exports) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t//\n\t\n\t// The following images show the relation of states and\n\t// {@link ATNState//transitions} for various grammar constructs.\n\t//\n\t// <ul>\n\t//\n\t// <li>Solid edges marked with an &//0949; indicate a required\n\t// {@link EpsilonTransition}.</li>\n\t//\n\t// <li>Dashed edges indicate locations where any transition derived from\n\t// {@link Transition} might appear.</li>\n\t//\n\t// <li>Dashed nodes are place holders for either a sequence of linked\n\t// {@link BasicState} states or the inclusion of a block representing a nested\n\t// construct in one of the forms below.</li>\n\t//\n\t// <li>Nodes showing multiple outgoing alternatives with a {@code ...} support\n\t// any number of alternatives (one or more). Nodes without the {@code ...} only\n\t// support the exact number of alternatives shown in the diagram.</li>\n\t//\n\t// </ul>\n\t//\n\t// <h2>Basic Blocks</h2>\n\t//\n\t// <h3>Rule</h3>\n\t//\n\t// <embed src=\"images/Rule.svg\" type=\"image/svg+xml\"/>\n\t//\n\t// <h3>Block of 1 or more alternatives</h3>\n\t//\n\t// <embed src=\"images/Block.svg\" type=\"image/svg+xml\"/>\n\t//\n\t// <h2>Greedy Loops</h2>\n\t//\n\t// <h3>Greedy Closure: {@code (...)*}</h3>\n\t//\n\t// <embed src=\"images/ClosureGreedy.svg\" type=\"image/svg+xml\"/>\n\t//\n\t// <h3>Greedy Positive Closure: {@code (...)+}</h3>\n\t//\n\t// <embed src=\"images/PositiveClosureGreedy.svg\" type=\"image/svg+xml\"/>\n\t//\n\t// <h3>Greedy Optional: {@code (...)?}</h3>\n\t//\n\t// <embed src=\"images/OptionalGreedy.svg\" type=\"image/svg+xml\"/>\n\t//\n\t// <h2>Non-Greedy Loops</h2>\n\t//\n\t// <h3>Non-Greedy Closure: {@code (...)*?}</h3>\n\t//\n\t// <embed src=\"images/ClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n\t//\n\t// <h3>Non-Greedy Positive Closure: {@code (...)+?}</h3>\n\t//\n\t// <embed src=\"images/PositiveClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n\t//\n\t// <h3>Non-Greedy Optional: {@code (...)??}</h3>\n\t//\n\t// <embed src=\"images/OptionalNonGreedy.svg\" type=\"image/svg+xml\"/>\n\t//\n\t\n\tvar INITIAL_NUM_TRANSITIONS = 4;\n\t\n\tfunction ATNState() {\n\t    // Which ATN are we in?\n\t    this.atn = null;\n\t    this.stateNumber = ATNState.INVALID_STATE_NUMBER;\n\t    this.stateType = null;\n\t    this.ruleIndex = 0; // at runtime, we don't have Rule objects\n\t    this.epsilonOnlyTransitions = false;\n\t    // Track the transitions emanating from this ATN state.\n\t    this.transitions = [];\n\t    // Used to cache lookahead during parsing, not used during construction\n\t    this.nextTokenWithinRule = null;\n\t    return this;\n\t}\n\t\n\t// constants for serialization\n\tATNState.INVALID_TYPE = 0;\n\tATNState.BASIC = 1;\n\tATNState.RULE_START = 2;\n\tATNState.BLOCK_START = 3;\n\tATNState.PLUS_BLOCK_START = 4;\n\tATNState.STAR_BLOCK_START = 5;\n\tATNState.TOKEN_START = 6;\n\tATNState.RULE_STOP = 7;\n\tATNState.BLOCK_END = 8;\n\tATNState.STAR_LOOP_BACK = 9;\n\tATNState.STAR_LOOP_ENTRY = 10;\n\tATNState.PLUS_LOOP_BACK = 11;\n\tATNState.LOOP_END = 12;\n\t\n\tATNState.serializationNames = [\n\t            \"INVALID\",\n\t            \"BASIC\",\n\t            \"RULE_START\",\n\t            \"BLOCK_START\",\n\t            \"PLUS_BLOCK_START\",\n\t            \"STAR_BLOCK_START\",\n\t            \"TOKEN_START\",\n\t            \"RULE_STOP\",\n\t            \"BLOCK_END\",\n\t            \"STAR_LOOP_BACK\",\n\t            \"STAR_LOOP_ENTRY\",\n\t            \"PLUS_LOOP_BACK\",\n\t            \"LOOP_END\" ];\n\t\n\tATNState.INVALID_STATE_NUMBER = -1;\n\t\n\tATNState.prototype.toString = function() {\n\t\treturn this.stateNumber;\n\t};\n\t\n\tATNState.prototype.equals = function(other) {\n\t    if (other instanceof ATNState) {\n\t        return this.stateNumber===other.stateNumber;\n\t    } else {\n\t        return false;\n\t    }\n\t};\n\t\n\tATNState.prototype.isNonGreedyExitState = function() {\n\t    return false;\n\t};\n\t\n\t\n\tATNState.prototype.addTransition = function(trans, index) {\n\t\tif(index===undefined) {\n\t\t\tindex = -1;\n\t\t}\n\t    if (this.transitions.length===0) {\n\t        this.epsilonOnlyTransitions = trans.isEpsilon;\n\t    } else if(this.epsilonOnlyTransitions !== trans.isEpsilon) {\n\t        this.epsilonOnlyTransitions = false;\n\t    }\n\t    if (index===-1) {\n\t        this.transitions.push(trans);\n\t    } else {\n\t        this.transitions.splice(index, 1, trans);\n\t    }\n\t};\n\t\n\tfunction BasicState() {\n\t\tATNState.call(this);\n\t    this.stateType = ATNState.BASIC;\n\t    return this;\n\t}\n\t\n\tBasicState.prototype = Object.create(ATNState.prototype);\n\tBasicState.prototype.constructor = BasicState;\n\t\n\t\n\tfunction DecisionState() {\n\t\tATNState.call(this);\n\t    this.decision = -1;\n\t    this.nonGreedy = false;\n\t    return this;\n\t}\n\t\n\tDecisionState.prototype = Object.create(ATNState.prototype);\n\tDecisionState.prototype.constructor = DecisionState;\n\t\n\t\n\t//  The start of a regular {@code (...)} block.\n\tfunction BlockStartState() {\n\t\tDecisionState.call(this);\n\t\tthis.endState = null;\n\t\treturn this;\n\t}\n\t\n\tBlockStartState.prototype = Object.create(DecisionState.prototype);\n\tBlockStartState.prototype.constructor = BlockStartState;\n\t\n\t\n\tfunction BasicBlockStartState() {\n\t\tBlockStartState.call(this);\n\t\tthis.stateType = ATNState.BLOCK_START;\n\t\treturn this;\n\t}\n\t\n\tBasicBlockStartState.prototype = Object.create(BlockStartState.prototype);\n\tBasicBlockStartState.prototype.constructor = BasicBlockStartState;\n\t\n\t\n\t// Terminal node of a simple {@code (a|b|c)} block.\n\tfunction BlockEndState() {\n\t\tATNState.call(this);\n\t\tthis.stateType = ATNState.BLOCK_END;\n\t    this.startState = null;\n\t    return this;\n\t}\n\t\n\tBlockEndState.prototype = Object.create(ATNState.prototype);\n\tBlockEndState.prototype.constructor = BlockEndState;\n\t\n\t\n\t// The last node in the ATN for a rule, unless that rule is the start symbol.\n\t//  In that case, there is one transition to EOF. Later, we might encode\n\t//  references to all calls to this rule to compute FOLLOW sets for\n\t//  error handling.\n\t//\n\tfunction RuleStopState() {\n\t\tATNState.call(this);\n\t    this.stateType = ATNState.RULE_STOP;\n\t    return this;\n\t}\n\t\n\tRuleStopState.prototype = Object.create(ATNState.prototype);\n\tRuleStopState.prototype.constructor = RuleStopState;\n\t\n\tfunction RuleStartState() {\n\t\tATNState.call(this);\n\t\tthis.stateType = ATNState.RULE_START;\n\t\tthis.stopState = null;\n\t\tthis.isPrecedenceRule = false;\n\t\treturn this;\n\t}\n\t\n\tRuleStartState.prototype = Object.create(ATNState.prototype);\n\tRuleStartState.prototype.constructor = RuleStartState;\n\t\n\t// Decision state for {@code A+} and {@code (A|B)+}.  It has two transitions:\n\t//  one to the loop back to start of the block and one to exit.\n\t//\n\tfunction PlusLoopbackState() {\n\t\tDecisionState.call(this);\n\t\tthis.stateType = ATNState.PLUS_LOOP_BACK;\n\t\treturn this;\n\t}\n\t\n\tPlusLoopbackState.prototype = Object.create(DecisionState.prototype);\n\tPlusLoopbackState.prototype.constructor = PlusLoopbackState;\n\t        \n\t\n\t// Start of {@code (A|B|...)+} loop. Technically a decision state, but\n\t//  we don't use for code generation; somebody might need it, so I'm defining\n\t//  it for completeness. In reality, the {@link PlusLoopbackState} node is the\n\t//  real decision-making note for {@code A+}.\n\t//\n\tfunction PlusBlockStartState() {\n\t\tBlockStartState.call(this);\n\t\tthis.stateType = ATNState.PLUS_BLOCK_START;\n\t    this.loopBackState = null;\n\t    return this;\n\t}\n\t\n\tPlusBlockStartState.prototype = Object.create(BlockStartState.prototype);\n\tPlusBlockStartState.prototype.constructor = PlusBlockStartState;\n\t\n\t// The block that begins a closure loop.\n\tfunction StarBlockStartState() {\n\t\tBlockStartState.call(this);\n\t\tthis.stateType = ATNState.STAR_BLOCK_START;\n\t\treturn this;\n\t}\n\t\n\tStarBlockStartState.prototype = Object.create(BlockStartState.prototype);\n\tStarBlockStartState.prototype.constructor = StarBlockStartState;\n\t\n\t\n\tfunction StarLoopbackState() {\n\t\tATNState.call(this);\n\t\tthis.stateType = ATNState.STAR_LOOP_BACK;\n\t\treturn this;\n\t}\n\t\n\tStarLoopbackState.prototype = Object.create(ATNState.prototype);\n\tStarLoopbackState.prototype.constructor = StarLoopbackState;\n\t\n\t\n\tfunction StarLoopEntryState() {\n\t\tDecisionState.call(this);\n\t\tthis.stateType = ATNState.STAR_LOOP_ENTRY;\n\t    this.loopBackState = null;\n\t    // Indicates whether this state can benefit from a precedence DFA during SLL decision making.\n\t    this.precedenceRuleDecision = null;\n\t    return this;\n\t}\n\t\n\tStarLoopEntryState.prototype = Object.create(DecisionState.prototype);\n\tStarLoopEntryState.prototype.constructor = StarLoopEntryState;\n\t\n\t\n\t// Mark the end of a * or + loop.\n\tfunction LoopEndState() {\n\t\tATNState.call(this);\n\t\tthis.stateType = ATNState.LOOP_END;\n\t\tthis.loopBackState = null;\n\t\treturn this;\n\t}\n\t\n\tLoopEndState.prototype = Object.create(ATNState.prototype);\n\tLoopEndState.prototype.constructor = LoopEndState;\n\t\n\t\n\t// The Tokens rule start state linking to each lexer rule start state */\n\tfunction TokensStartState() {\n\t\tDecisionState.call(this);\n\t\tthis.stateType = ATNState.TOKEN_START;\n\t\treturn this;\n\t}\n\t\n\tTokensStartState.prototype = Object.create(DecisionState.prototype);\n\tTokensStartState.prototype.constructor = TokensStartState;\n\t\n\texports.ATNState = ATNState;\n\texports.BasicState = BasicState;\n\texports.DecisionState = DecisionState;\n\texports.BlockStartState = BlockStartState;\n\texports.BlockEndState = BlockEndState;\n\texports.LoopEndState = LoopEndState;\n\texports.RuleStartState = RuleStartState;\n\texports.RuleStopState = RuleStopState;\n\texports.TokensStartState = TokensStartState;\n\texports.PlusLoopbackState = PlusLoopbackState;\n\texports.StarLoopbackState = StarLoopbackState;\n\texports.StarLoopEntryState = StarLoopEntryState;\n\texports.PlusBlockStartState = PlusBlockStartState;\n\texports.StarBlockStartState = StarBlockStartState;\n\texports.BasicBlockStartState = BasicBlockStartState;\n\n\n/***/ },\n/* 12 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t//\n\t\n\t// A tree structure used to record the semantic context in which\n\t//  an ATN configuration is valid.  It's either a single predicate,\n\t//  a conjunction {@code p1&&p2}, or a sum of products {@code p1||p2}.\n\t//\n\t//  <p>I have scoped the {@link AND}, {@link OR}, and {@link Predicate} subclasses of\n\t//  {@link SemanticContext} within the scope of this outer class.</p>\n\t//\n\t\n\tvar Set = __webpack_require__(8).Set;\n\t\n\tfunction SemanticContext() {\n\t\treturn this;\n\t}\n\t\n\t// For context independent predicates, we evaluate them without a local\n\t// context (i.e., null context). That way, we can evaluate them without\n\t// having to create proper rule-specific context during prediction (as\n\t// opposed to the parser, which creates them naturally). In a practical\n\t// sense, this avoids a cast exception from RuleContext to myruleContext.\n\t//\n\t// <p>For context dependent predicates, we must pass in a local context so that\n\t// references such as $arg evaluate properly as _localctx.arg. We only\n\t// capture context dependent predicates in the context in which we begin\n\t// prediction, so we passed in the outer context here in case of context\n\t// dependent predicate evaluation.</p>\n\t//\n\tSemanticContext.prototype.evaluate = function(parser, outerContext) {\n\t};\n\t\n\t//\n\t// Evaluate the precedence predicates for the context and reduce the result.\n\t//\n\t// @param parser The parser instance.\n\t// @param outerContext The current parser context object.\n\t// @return The simplified semantic context after precedence predicates are\n\t// evaluated, which will be one of the following values.\n\t// <ul>\n\t// <li>{@link //NONE}: if the predicate simplifies to {@code true} after\n\t// precedence predicates are evaluated.</li>\n\t// <li>{@code null}: if the predicate simplifies to {@code false} after\n\t// precedence predicates are evaluated.</li>\n\t// <li>{@code this}: if the semantic context is not changed as a result of\n\t// precedence predicate evaluation.</li>\n\t// <li>A non-{@code null} {@link SemanticContext}: the new simplified\n\t// semantic context after precedence predicates are evaluated.</li>\n\t// </ul>\n\t//\n\tSemanticContext.prototype.evalPrecedence = function(parser, outerContext) {\n\t\treturn this;\n\t};\n\t\n\tSemanticContext.andContext = function(a, b) {\n\t\tif (a === null || a === SemanticContext.NONE) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b === null || b === SemanticContext.NONE) {\n\t\t\treturn a;\n\t\t}\n\t\tvar result = new AND(a, b);\n\t\tif (result.opnds.length === 1) {\n\t\t\treturn result.opnds[0];\n\t\t} else {\n\t\t\treturn result;\n\t\t}\n\t};\n\t\n\tSemanticContext.orContext = function(a, b) {\n\t\tif (a === null) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b === null) {\n\t\t\treturn a;\n\t\t}\n\t\tif (a === SemanticContext.NONE || b === SemanticContext.NONE) {\n\t\t\treturn SemanticContext.NONE;\n\t\t}\n\t\tvar result = new OR(a, b);\n\t\tif (result.opnds.length === 1) {\n\t\t\treturn result.opnds[0];\n\t\t} else {\n\t\t\treturn result;\n\t\t}\n\t};\n\t\n\tfunction Predicate(ruleIndex, predIndex, isCtxDependent) {\n\t\tSemanticContext.call(this);\n\t\tthis.ruleIndex = ruleIndex === undefined ? -1 : ruleIndex;\n\t\tthis.predIndex = predIndex === undefined ? -1 : predIndex;\n\t\tthis.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred\n\t\treturn this;\n\t}\n\t\n\tPredicate.prototype = Object.create(SemanticContext.prototype);\n\tPredicate.prototype.constructor = Predicate;\n\t\n\t//The default {@link SemanticContext}, which is semantically equivalent to\n\t//a predicate of the form {@code {true}?}.\n\t//\n\tSemanticContext.NONE = new Predicate();\n\t\n\t\n\tPredicate.prototype.evaluate = function(parser, outerContext) {\n\t\tvar localctx = this.isCtxDependent ? outerContext : null;\n\t\treturn parser.sempred(localctx, this.ruleIndex, this.predIndex);\n\t};\n\t\n\tPredicate.prototype.hashString = function() {\n\t\treturn \"\" + this.ruleIndex + \"/\" + this.predIndex + \"/\" + this.isCtxDependent;\n\t};\n\t\n\tPredicate.prototype.equals = function(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof Predicate)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.ruleIndex === other.ruleIndex &&\n\t\t\t\t\tthis.predIndex === other.predIndex &&\n\t\t\t\t\tthis.isCtxDependent === other.isCtxDependent;\n\t\t}\n\t};\n\t\n\tPredicate.prototype.toString = function() {\n\t\treturn \"{\" + this.ruleIndex + \":\" + this.predIndex + \"}?\";\n\t};\n\t\n\tfunction PrecedencePredicate(precedence) {\n\t\tSemanticContext.call(this);\n\t\tthis.precedence = precedence === undefined ? 0 : precedence;\n\t}\n\t\n\tPrecedencePredicate.prototype = Object.create(SemanticContext.prototype);\n\tPrecedencePredicate.prototype.constructor = PrecedencePredicate;\n\t\n\tPrecedencePredicate.prototype.evaluate = function(parser, outerContext) {\n\t\treturn parser.precpred(outerContext, this.precedence);\n\t};\n\t\n\tPrecedencePredicate.prototype.evalPrecedence = function(parser, outerContext) {\n\t\tif (parser.precpred(outerContext, this.precedence)) {\n\t\t\treturn SemanticContext.NONE;\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t};\n\t\n\tPrecedencePredicate.prototype.compareTo = function(other) {\n\t\treturn this.precedence - other.precedence;\n\t};\n\t\n\tPrecedencePredicate.prototype.hashString = function() {\n\t\treturn \"31\";\n\t};\n\t\n\tPrecedencePredicate.prototype.equals = function(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof PrecedencePredicate)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.precedence === other.precedence;\n\t\t}\n\t};\n\t\n\tPrecedencePredicate.prototype.toString = function() {\n\t\treturn \"{\"+this.precedence+\">=prec}?\";\n\t};\n\t\n\t\n\t\n\tPrecedencePredicate.filterPrecedencePredicates = function(set) {\n\t\tvar result = [];\n\t\tset.values().map( function(context) {\n\t\t\tif (context instanceof PrecedencePredicate) {\n\t\t\t\tresult.push(context);\n\t\t\t}\n\t\t});\n\t\treturn result;\n\t};\n\t\n\t\n\t// A semantic context which is true whenever none of the contained contexts\n\t// is false.\n\t//\n\tfunction AND(a, b) {\n\t\tSemanticContext.call(this);\n\t\tvar operands = new Set();\n\t\tif (a instanceof AND) {\n\t\t\ta.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(a);\n\t\t}\n\t\tif (b instanceof AND) {\n\t\t\tb.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(b);\n\t\t}\n\t\tvar precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\t\tif (precedencePredicates.length > 0) {\n\t\t\t// interested in the transition with the lowest precedence\n\t\t\tvar reduced = null;\n\t\t\tprecedencePredicates.map( function(p) {\n\t\t\t\tif(reduced===null || p.precedence<reduced.precedence) {\n\t\t\t\t\treduced = p;\n\t\t\t\t}\n\t\t\t});\n\t\t\toperands.add(reduced);\n\t\t}\n\t\tthis.opnds = operands.values();\n\t\treturn this;\n\t}\n\t\n\tAND.prototype = Object.create(SemanticContext.prototype);\n\tAND.prototype.constructor = AND;\n\t\n\tAND.prototype.equals = function(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof AND)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.opnds === other.opnds;\n\t\t}\n\t};\n\t\n\tAND.prototype.hashString = function() {\n\t\treturn \"\" + this.opnds + \"/AND\";\n\t};\n\t//\n\t// {@inheritDoc}\n\t//\n\t// <p>\n\t// The evaluation of predicates by this context is short-circuiting, but\n\t// unordered.</p>\n\t//\n\tAND.prototype.evaluate = function(parser, outerContext) {\n\t\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\t\tif (!this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t};\n\t\n\tAND.prototype.evalPrecedence = function(parser, outerContext) {\n\t\tvar differs = false;\n\t\tvar operands = [];\n\t\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\t\tvar context = this.opnds[i];\n\t\t\tvar evaluated = context.evalPrecedence(parser, outerContext);\n\t\t\tdiffers |= (evaluated !== context);\n\t\t\tif (evaluated === null) {\n\t\t\t\t// The AND context is false if any element is false\n\t\t\t\treturn null;\n\t\t\t} else if (evaluated !== SemanticContext.NONE) {\n\t\t\t\t// Reduce the result by skipping true elements\n\t\t\t\toperands.push(evaluated);\n\t\t\t}\n\t\t}\n\t\tif (!differs) {\n\t\t\treturn this;\n\t\t}\n\t\tif (operands.length === 0) {\n\t\t\t// all elements were true, so the AND context is true\n\t\t\treturn SemanticContext.NONE;\n\t\t}\n\t\tvar result = null;\n\t\toperands.map(function(o) {\n\t\t\tresult = result === null ? o : SemanticContext.andContext(result, o);\n\t\t});\n\t\treturn result;\n\t};\n\t\n\tAND.prototype.toString = function() {\n\t\tvar s = \"\";\n\t\tthis.opnds.map(function(o) {\n\t\t\ts += \"&& \" + o.toString();\n\t\t});\n\t\treturn s.length > 3 ? s.slice(3) : s;\n\t};\n\t\n\t//\n\t// A semantic context which is true whenever at least one of the contained\n\t// contexts is true.\n\t//\n\tfunction OR(a, b) {\n\t\tSemanticContext.call(this);\n\t\tvar operands = new Set();\n\t\tif (a instanceof OR) {\n\t\t\ta.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(a);\n\t\t}\n\t\tif (b instanceof OR) {\n\t\t\tb.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(b);\n\t\t}\n\t\n\t\tvar precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\t\tif (precedencePredicates.length > 0) {\n\t\t\t// interested in the transition with the highest precedence\n\t\t\tvar s = precedencePredicates.sort(function(a, b) {\n\t\t\t\treturn a.compareTo(b);\n\t\t\t});\n\t\t\tvar reduced = s[s.length-1];\n\t\t\toperands.add(reduced);\n\t\t}\n\t\tthis.opnds = operands.values();\n\t\treturn this;\n\t}\n\t\n\tOR.prototype = Object.create(SemanticContext.prototype);\n\tOR.prototype.constructor = OR;\n\t\n\tOR.prototype.constructor = function(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof OR)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.opnds === other.opnds;\n\t\t}\n\t};\n\t\n\tOR.prototype.hashString = function() {\n\t\treturn \"\" + this.opnds + \"/OR\"; \n\t};\n\t\n\t// <p>\n\t// The evaluation of predicates by this context is short-circuiting, but\n\t// unordered.</p>\n\t//\n\tOR.prototype.evaluate = function(parser, outerContext) {\n\t\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\t\tif (this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t};\n\t\n\tOR.prototype.evalPrecedence = function(parser, outerContext) {\n\t\tvar differs = false;\n\t\tvar operands = [];\n\t\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\t\tvar context = this.opnds[i];\n\t\t\tvar evaluated = context.evalPrecedence(parser, outerContext);\n\t\t\tdiffers |= (evaluated !== context);\n\t\t\tif (evaluated === SemanticContext.NONE) {\n\t\t\t\t// The OR context is true if any element is true\n\t\t\t\treturn SemanticContext.NONE;\n\t\t\t} else if (evaluated !== null) {\n\t\t\t\t// Reduce the result by skipping false elements\n\t\t\t\toperands.push(evaluated);\n\t\t\t}\n\t\t}\n\t\tif (!differs) {\n\t\t\treturn this;\n\t\t}\n\t\tif (operands.length === 0) {\n\t\t\t// all elements were false, so the OR context is false\n\t\t\treturn null;\n\t\t}\n\t\tvar result = null;\n\t\toperands.map(function(o) {\n\t\t\treturn result === null ? o : SemanticContext.orContext(result, o);\n\t\t});\n\t\treturn result;\n\t};\n\t\n\tOR.prototype.toString = function() {\n\t\tvar s = \"\";\n\t\tthis.opnds.map(function(o) {\n\t\t\ts += \"|| \" + o.toString();\n\t\t});\n\t\treturn s.length > 3 ? s.slice(3) : s;\n\t};\n\t\n\texports.SemanticContext = SemanticContext;\n\texports.PrecedencePredicate = PrecedencePredicate;\n\texports.Predicate = Predicate;\n\n\n/***/ },\n/* 13 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/*jslint smarttabs:true */\n\t\n\tvar Token = __webpack_require__(9).Token;\n\t\n\t/* stop is not included! */\n\tfunction Interval(start, stop) {\n\t\tthis.start = start;\n\t\tthis.stop = stop;\n\t\treturn this;\n\t}\n\t\n\tInterval.prototype.contains = function(item) {\n\t\treturn item >= this.start && item < this.stop;\n\t};\n\t\n\tInterval.prototype.toString = function() {\n\t\tif(this.start===this.stop-1) {\n\t\t\treturn this.start.toString();\n\t\t} else {\n\t\t\treturn this.start.toString() + \"..\" + (this.stop-1).toString();\n\t\t}\n\t};\n\t\n\t\n\tObject.defineProperty(Interval.prototype, \"length\", {\n\t\tget : function() {\n\t\t\treturn this.stop - this.start;\n\t\t}\n\t});\n\t\n\tfunction IntervalSet() {\n\t\tthis.intervals = null;\n\t\tthis.readOnly = false;\n\t}\n\t\n\tIntervalSet.prototype.first = function(v) {\n\t\tif (this.intervals === null || this.intervals.length===0) {\n\t\t\treturn Token.INVALID_TYPE;\n\t\t} else {\n\t\t\treturn this.intervals[0].start;\n\t\t}\n\t};\n\t\n\tIntervalSet.prototype.addOne = function(v) {\n\t\tthis.addInterval(new Interval(v, v + 1));\n\t};\n\t\n\tIntervalSet.prototype.addRange = function(l, h) {\n\t\tthis.addInterval(new Interval(l, h + 1));\n\t};\n\t\n\tIntervalSet.prototype.addInterval = function(v) {\n\t\tif (this.intervals === null) {\n\t\t\tthis.intervals = [];\n\t\t\tthis.intervals.push(v);\n\t\t} else {\n\t\t\t// find insert pos\n\t\t\tfor (var k = 0; k < this.intervals.length; k++) {\n\t\t\t\tvar i = this.intervals[k];\n\t\t\t\t// distinct range -> insert\n\t\t\t\tif (v.stop < i.start) {\n\t\t\t\t\tthis.intervals.splice(k, 0, v);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// contiguous range -> adjust\n\t\t\t\telse if (v.stop === i.start) {\n\t\t\t\t\tthis.intervals[k].start = v.start;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// overlapping range -> adjust and reduce\n\t\t\t\telse if (v.start <= i.stop) {\n\t\t\t\t\tthis.intervals[k] = new Interval(Math.min(i.start, v.start), Math.max(i.stop, v.stop));\n\t\t\t\t\tthis.reduce(k);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// greater than any existing\n\t\t\tthis.intervals.push(v);\n\t\t}\n\t};\n\t\n\tIntervalSet.prototype.addSet = function(other) {\n\t\tif (other.intervals !== null) {\n\t\t\tfor (var k = 0; k < other.intervals.length; k++) {\n\t\t\t\tvar i = other.intervals[k];\n\t\t\t\tthis.addInterval(new Interval(i.start, i.stop));\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\t\n\tIntervalSet.prototype.reduce = function(k) {\n\t\t// only need to reduce if k is not the last\n\t\tif (k < this.intervalslength - 1) {\n\t\t\tvar l = this.intervals[k];\n\t\t\tvar r = this.intervals[k + 1];\n\t\t\t// if r contained in l\n\t\t\tif (l.stop >= r.stop) {\n\t\t\t\tthis.intervals.pop(k + 1);\n\t\t\t\tthis.reduce(k);\n\t\t\t} else if (l.stop >= r.start) {\n\t\t\t\tthis.intervals[k] = new Interval(l.start, r.stop);\n\t\t\t\tthis.intervals.pop(k + 1);\n\t\t\t}\n\t\t}\n\t};\n\t\n\tIntervalSet.prototype.complement = function(start, stop) {\n\t    var result = new IntervalSet();\n\t    result.addInterval(new Interval(start,stop+1));\n\t    for(var i=0; i<this.intervals.length; i++) {\n\t        result.removeRange(this.intervals[i]);\n\t    }\n\t    return result;\n\t};\n\t\n\tIntervalSet.prototype.contains = function(item) {\n\t\tif (this.intervals === null) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tfor (var k = 0; k < this.intervals.length; k++) {\n\t\t\t\tif(this.intervals[k].contains(item)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t};\n\t\n\tObject.defineProperty(IntervalSet.prototype, \"length\", {\n\t\tget : function() {\n\t\t\tvar len = 0;\n\t\t\tthis.intervals.map(function(i) {len += i.length;});\n\t\t\treturn len;\n\t\t}\n\t});\n\t\n\tIntervalSet.prototype.removeRange = function(v) {\n\t    if(v.start===v.stop-1) {\n\t        this.removeOne(v.start);\n\t    } else if (this.intervals!==null) {\n\t        var k = 0;\n\t        for(var n=0; n<this.intervals.length; n++) {\n\t            var i = this.intervals[k];\n\t            // intervals are ordered\n\t            if (v.stop<=i.start) {\n\t                return;\n\t            }\n\t            // check for including range, split it\n\t            else if(v.start>i.start && v.stop<i.stop) {\n\t                this.intervals[k] = new Interval(i.start, v.start);\n\t                var x = new Interval(v.stop, i.stop);\n\t                this.intervals.splice(k, 0, x);\n\t                return;\n\t            }\n\t            // check for included range, remove it\n\t            else if(v.start<=i.start && v.stop>=i.stop) {\n\t                this.intervals.splice(k, 1);\n\t                k = k - 1; // need another pass\n\t            }\n\t            // check for lower boundary\n\t            else if(v.start<i.stop) {\n\t                this.intervals[k] = new Interval(i.start, v.start);\n\t            }\n\t            // check for upper boundary\n\t            else if(v.stop<i.stop) {\n\t                this.intervals[k] = new Interval(v.stop, i.stop);\n\t            }\n\t            k += 1;\n\t        }\n\t    }\n\t};\n\t\n\tIntervalSet.prototype.removeOne = function(v) {\n\t\tif (this.intervals !== null) {\n\t\t\tfor (var k = 0; k < this.intervals.length; k++) {\n\t\t\t\tvar i = this.intervals[k];\n\t\t\t\t// intervals is ordered\n\t\t\t\tif (v < i.start) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for single value range\n\t\t\t\telse if (v === i.start && v === i.stop - 1) {\n\t\t\t\t\tthis.intervals.splice(k, 1);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for lower boundary\n\t\t\t\telse if (v === i.start) {\n\t\t\t\t\tthis.intervals[k] = new Interval(i.start + 1, i.stop);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for upper boundary\n\t\t\t\telse if (v === i.stop - 1) {\n\t\t\t\t\tthis.intervals[k] = new Interval(i.start, i.stop - 1);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// split existing range\n\t\t\t\telse if (v < i.stop - 1) {\n\t\t\t\t\tvar x = new Interval(i.start, v);\n\t\t\t\t\ti.start = v + 1;\n\t\t\t\t\tthis.intervals.splice(k, 0, x);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\t\n\tIntervalSet.prototype.toString = function(literalNames, symbolicNames, elemsAreChar) {\n\t\tliteralNames = literalNames || null;\n\t\tsymbolicNames = symbolicNames || null;\n\t\telemsAreChar = elemsAreChar || false;\n\t\tif (this.intervals === null) {\n\t\t\treturn \"{}\";\n\t\t} else if(literalNames!==null || symbolicNames!==null) {\n\t\t\treturn this.toTokenString(literalNames, symbolicNames);\n\t\t} else if(elemsAreChar) {\n\t\t\treturn this.toCharString();\n\t\t} else {\n\t\t\treturn this.toIndexString();\n\t\t}\n\t};\n\t\n\tIntervalSet.prototype.toCharString = function() {\n\t\tvar names = [];\n\t\tfor (var i = 0; i < this.intervals.length; i++) {\n\t\t\tvar v = this.intervals[i];\n\t\t\tif(v.stop===v.start+1) {\n\t\t\t\tif ( v.start===Token.EOF ) {\n\t\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t\t} else {\n\t\t\t\t\tnames.push(\"'\" + String.fromCharCode(v.start) + \"'\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames.push(\"'\" + String.fromCharCode(v.start) + \"'..'\" + String.fromCharCode(v.stop-1) + \"'\");\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t};\n\t\n\t\n\tIntervalSet.prototype.toIndexString = function() {\n\t\tvar names = [];\n\t\tfor (var i = 0; i < this.intervals.length; i++) {\n\t\t\tvar v = this.intervals[i];\n\t\t\tif(v.stop===v.start+1) {\n\t\t\t\tif ( v.start===Token.EOF ) {\n\t\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t\t} else {\n\t\t\t\t\tnames.push(v.start.toString());\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames.push(v.start.toString() + \"..\" + (v.stop-1).toString());\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t};\n\t\n\t\n\tIntervalSet.prototype.toTokenString = function(literalNames, symbolicNames) {\n\t\tvar names = [];\n\t\tfor (var i = 0; i < this.intervals.length; i++) {\n\t\t\tvar v = this.intervals[i];\n\t\t\tfor (var j = v.start; j < v.stop; j++) {\n\t\t\t\tnames.push(this.elementName(literalNames, symbolicNames, j));\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t};\n\t\n\tIntervalSet.prototype.elementName = function(literalNames, symbolicNames, a) {\n\t\tif (a === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else if (a === Token.EPSILON) {\n\t\t\treturn \"<EPSILON>\";\n\t\t} else {\n\t\t\treturn literalNames[a] || symbolicNames[a];\n\t\t}\n\t};\n\t\n\texports.Interval = Interval;\n\texports.IntervalSet = IntervalSet;\n\n\n/***/ },\n/* 14 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t//\n\t\n\t//  An ATN transition between any two ATN states.  Subclasses define\n\t//  atom, set, epsilon, action, predicate, rule transitions.\n\t//\n\t//  <p>This is a one way link.  It emanates from a state (usually via a list of\n\t//  transitions) and has a target state.</p>\n\t//\n\t//  <p>Since we never have to change the ATN transitions once we construct it,\n\t//  we can fix these transitions as specific classes. The DFA transitions\n\t//  on the other hand need to update the labels as it adds transitions to\n\t//  the states. We'll use the term Edge for the DFA to distinguish them from\n\t//  ATN transitions.</p>\n\t\n\tvar Token = __webpack_require__(9).Token;\n\tvar Interval = __webpack_require__(13).Interval;\n\tvar IntervalSet = __webpack_require__(13).IntervalSet;\n\tvar Predicate = __webpack_require__(12).Predicate;\n\tvar PrecedencePredicate = __webpack_require__(12).PrecedencePredicate;\n\t\n\tfunction Transition (target) {\n\t    // The target of this transition.\n\t    if (target===undefined || target===null) {\n\t        throw \"target cannot be null.\";\n\t    }\n\t    this.target = target;\n\t    // Are we epsilon, action, sempred?\n\t    this.isEpsilon = false;\n\t    this.label = null;\n\t    return this;\n\t}\n\t    // constants for serialization\n\tTransition.EPSILON = 1;\n\tTransition.RANGE = 2;\n\tTransition.RULE = 3;\n\tTransition.PREDICATE = 4; // e.g., {isType(input.LT(1))}?\n\tTransition.ATOM = 5;\n\tTransition.ACTION = 6;\n\tTransition.SET = 7; // ~(A|B) or ~atom, wildcard, which convert to next 2\n\tTransition.NOT_SET = 8;\n\tTransition.WILDCARD = 9;\n\tTransition.PRECEDENCE = 10;\n\t\n\tTransition.serializationNames = [\n\t            \"INVALID\",\n\t            \"EPSILON\",\n\t            \"RANGE\",\n\t            \"RULE\",\n\t            \"PREDICATE\",\n\t            \"ATOM\",\n\t            \"ACTION\",\n\t            \"SET\",\n\t            \"NOT_SET\",\n\t            \"WILDCARD\",\n\t            \"PRECEDENCE\"\n\t        ];\n\t\n\tTransition.serializationTypes = {\n\t        EpsilonTransition: Transition.EPSILON,\n\t        RangeTransition: Transition.RANGE,\n\t        RuleTransition: Transition.RULE,\n\t        PredicateTransition: Transition.PREDICATE,\n\t        AtomTransition: Transition.ATOM,\n\t        ActionTransition: Transition.ACTION,\n\t        SetTransition: Transition.SET,\n\t        NotSetTransition: Transition.NOT_SET,\n\t        WildcardTransition: Transition.WILDCARD,\n\t        PrecedencePredicateTransition: Transition.PRECEDENCE\n\t    };\n\t\n\t\n\t// TODO: make all transitions sets? no, should remove set edges\n\tfunction AtomTransition(target, label) {\n\t\tTransition.call(this, target);\n\t\tthis.label_ = label; // The token type or character value; or, signifies special label.\n\t    this.label = this.makeLabel();\n\t    this.serializationType = Transition.ATOM;\n\t    return this;\n\t}\n\t\n\tAtomTransition.prototype = Object.create(Transition.prototype);\n\tAtomTransition.prototype.constructor = AtomTransition;\n\t\n\tAtomTransition.prototype.makeLabel = function() {\n\t\tvar s = new IntervalSet();\n\t    s.addOne(this.label_);\n\t    return s;\n\t};\n\t\n\tAtomTransition.prototype.matches = function( symbol, minVocabSymbol,  maxVocabSymbol) {\n\t    return this.label_ === symbol;\n\t};\n\t\n\tAtomTransition.prototype.toString = function() {\n\t\treturn this.label_;\n\t};\n\t\n\tfunction RuleTransition(ruleStart, ruleIndex, precedence, followState) {\n\t\tTransition.call(this, ruleStart);\n\t    this.ruleIndex = ruleIndex; // ptr to the rule definition object for this rule ref\n\t    this.precedence = precedence;\n\t    this.followState = followState; // what node to begin computations following ref to rule\n\t    this.serializationType = Transition.RULE;\n\t    this.isEpsilon = true;\n\t    return this;\n\t}\n\t\n\tRuleTransition.prototype = Object.create(Transition.prototype);\n\tRuleTransition.prototype.constructor = RuleTransition;\n\t\n\tRuleTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\t\treturn false;\n\t};\n\t\n\t\n\tfunction EpsilonTransition(target, outermostPrecedenceReturn) {\n\t\tTransition.call(this, target);\n\t    this.serializationType = Transition.EPSILON;\n\t    this.isEpsilon = true;\n\t    this.outermostPrecedenceReturn = outermostPrecedenceReturn;\n\t    return this;\n\t}\n\t\n\tEpsilonTransition.prototype = Object.create(Transition.prototype);\n\tEpsilonTransition.prototype.constructor = EpsilonTransition;\n\t\n\tEpsilonTransition.prototype.matches = function( symbol, minVocabSymbol,  maxVocabSymbol) {\n\t\treturn false;\n\t};\n\t\n\tEpsilonTransition.prototype.toString = function() {\n\t\treturn \"epsilon\";\n\t};\n\t\n\tfunction RangeTransition(target, start, stop) {\n\t\tTransition.call(this, target);\n\t\tthis.serializationType = Transition.RANGE;\n\t    this.start = start;\n\t    this.stop = stop;\n\t    this.label = this.makeLabel();\n\t    return this;\n\t}\n\t\n\tRangeTransition.prototype = Object.create(Transition.prototype);\n\tRangeTransition.prototype.constructor = RangeTransition;\n\t\n\tRangeTransition.prototype.makeLabel = function() {\n\t    var s = new IntervalSet();\n\t    s.addRange(this.start, this.stop);\n\t    return s;\n\t};\n\t\n\tRangeTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\t\treturn symbol >= this.start && symbol <= this.stop;\n\t};\n\t\n\tRangeTransition.prototype.toString = function() {\n\t\treturn \"'\" + String.fromCharCode(this.start) + \"'..'\" + String.fromCharCode(this.stop) + \"'\";\n\t};\n\t\n\tfunction AbstractPredicateTransition(target) {\n\t\tTransition.call(this, target);\n\t\treturn this;\n\t}\n\t\n\tAbstractPredicateTransition.prototype = Object.create(Transition.prototype);\n\tAbstractPredicateTransition.prototype.constructor = AbstractPredicateTransition;\n\t\n\tfunction PredicateTransition(target, ruleIndex, predIndex, isCtxDependent) {\n\t\tAbstractPredicateTransition.call(this, target);\n\t    this.serializationType = Transition.PREDICATE;\n\t    this.ruleIndex = ruleIndex;\n\t    this.predIndex = predIndex;\n\t    this.isCtxDependent = isCtxDependent; // e.g., $i ref in pred\n\t    this.isEpsilon = true;\n\t    return this;\n\t}\n\t\n\tPredicateTransition.prototype = Object.create(AbstractPredicateTransition.prototype);\n\tPredicateTransition.prototype.constructor = PredicateTransition;\n\t\n\tPredicateTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\t\treturn false;\n\t};\n\t\n\tPredicateTransition.prototype.getPredicate = function() {\n\t\treturn new Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);\n\t};\n\t\n\tPredicateTransition.prototype.toString = function() {\n\t\treturn \"pred_\" + this.ruleIndex + \":\" + this.predIndex;\n\t};\n\t\n\tfunction ActionTransition(target, ruleIndex, actionIndex, isCtxDependent) {\n\t\tTransition.call(this, target);\n\t    this.serializationType = Transition.ACTION;\n\t    this.ruleIndex = ruleIndex;\n\t    this.actionIndex = actionIndex===undefined ? -1 : actionIndex;\n\t    this.isCtxDependent = isCtxDependent===undefined ? false : isCtxDependent; // e.g., $i ref in pred\n\t    this.isEpsilon = true;\n\t    return this;\n\t}\n\t\n\tActionTransition.prototype = Object.create(Transition.prototype);\n\tActionTransition.prototype.constructor = ActionTransition;\n\t\n\t\n\tActionTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\t\treturn false;\n\t};\n\t\n\tActionTransition.prototype.toString = function() {\n\t\treturn \"action_\" + this.ruleIndex + \":\" + this.actionIndex;\n\t};\n\t        \n\t\n\t// A transition containing a set of values.\n\tfunction SetTransition(target, set) {\n\t\tTransition.call(this, target);\n\t\tthis.serializationType = Transition.SET;\n\t    if (set !==undefined && set !==null) {\n\t        this.label = set;\n\t    } else {\n\t        this.label = new IntervalSet();\n\t        this.label.addOne(Token.INVALID_TYPE);\n\t    }\n\t    return this;\n\t}\n\t\n\tSetTransition.prototype = Object.create(Transition.prototype);\n\tSetTransition.prototype.constructor = SetTransition;\n\t\n\tSetTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\t\treturn this.label.contains(symbol);\n\t};\n\t        \n\t\n\tSetTransition.prototype.toString = function() {\n\t\treturn this.label.toString();\n\t};\n\t\n\tfunction NotSetTransition(target, set) {\n\t\tSetTransition.call(this, target, set);\n\t\tthis.serializationType = Transition.NOT_SET;\n\t\treturn this;\n\t}\n\t\n\tNotSetTransition.prototype = Object.create(SetTransition.prototype);\n\tNotSetTransition.prototype.constructor = NotSetTransition;\n\t\n\tNotSetTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\t\treturn symbol >= minVocabSymbol && symbol <= maxVocabSymbol &&\n\t\t\t\t!SetTransition.prototype.matches.call(this, symbol, minVocabSymbol, maxVocabSymbol);\n\t};\n\t\n\tNotSetTransition.prototype.toString = function() {\n\t\treturn '~' + SetTransition.prototype.toString.call(this);\n\t};\n\t\n\tfunction WildcardTransition(target) {\n\t\tTransition.call(this, target);\n\t\tthis.serializationType = Transition.WILDCARD;\n\t\treturn this;\n\t}\n\t\n\tWildcardTransition.prototype = Object.create(Transition.prototype);\n\tWildcardTransition.prototype.constructor = WildcardTransition;\n\t\n\t\n\tWildcardTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\t\treturn symbol >= minVocabSymbol && symbol <= maxVocabSymbol;\n\t};\n\t\n\tWildcardTransition.prototype.toString = function() {\n\t\treturn \".\";\n\t};\n\t\n\tfunction PrecedencePredicateTransition(target, precedence) {\n\t\tAbstractPredicateTransition.call(this, target);\n\t    this.serializationType = Transition.PRECEDENCE;\n\t    this.precedence = precedence;\n\t    this.isEpsilon = true;\n\t    return this;\n\t}\n\t\n\tPrecedencePredicateTransition.prototype = Object.create(AbstractPredicateTransition.prototype);\n\tPrecedencePredicateTransition.prototype.constructor = PrecedencePredicateTransition;\n\t\n\tPrecedencePredicateTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\t\treturn false;\n\t};\n\t\n\tPrecedencePredicateTransition.prototype.getPredicate = function() {\n\t\treturn new PrecedencePredicate(this.precedence);\n\t};\n\t\n\tPrecedencePredicateTransition.prototype.toString = function() {\n\t\treturn this.precedence + \" >= _p\";\n\t};\n\t        \n\texports.Transition = Transition;\n\texports.AtomTransition = AtomTransition;\n\texports.SetTransition = SetTransition;\n\texports.NotSetTransition = NotSetTransition;\n\texports.RuleTransition = RuleTransition;\n\texports.ActionTransition = ActionTransition;\n\texports.EpsilonTransition = EpsilonTransition;\n\texports.RangeTransition = RangeTransition;\n\texports.WildcardTransition = WildcardTransition;\n\texports.PredicateTransition = PredicateTransition;\n\texports.PrecedencePredicateTransition = PrecedencePredicateTransition;\n\texports.AbstractPredicateTransition = AbstractPredicateTransition;\n\n/***/ },\n/* 15 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\tvar RuleContext = __webpack_require__(16).RuleContext;\n\t\n\tfunction PredictionContext(cachedHashString) {\n\t\tthis.cachedHashString = cachedHashString;\n\t}\n\t\n\t// Represents {@code $} in local context prediction, which means wildcard.\n\t// {@code//+x =//}.\n\t// /\n\tPredictionContext.EMPTY = null;\n\t\n\t// Represents {@code $} in an array in full context mode, when {@code $}\n\t// doesn't mean wildcard: {@code $ + x = [$,x]}. Here,\n\t// {@code $} = {@link //EMPTY_RETURN_STATE}.\n\t// /\n\tPredictionContext.EMPTY_RETURN_STATE = 0x7FFFFFFF;\n\t\n\tPredictionContext.globalNodeCount = 1;\n\tPredictionContext.id = PredictionContext.globalNodeCount;\n\t\n\t// Stores the computed hash code of this {@link PredictionContext}. The hash\n\t// code is computed in parts to match the following reference algorithm.\n\t//\n\t// <pre>\n\t// private int referenceHashCode() {\n\t// int hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link\n\t// //INITIAL_HASH});\n\t//\n\t// for (int i = 0; i &lt; {@link //size()}; i++) {\n\t// hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //getParent\n\t// getParent}(i));\n\t// }\n\t//\n\t// for (int i = 0; i &lt; {@link //size()}; i++) {\n\t// hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link\n\t// //getReturnState getReturnState}(i));\n\t// }\n\t//\n\t// hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link\n\t// //size()});\n\t// return hash;\n\t// }\n\t// </pre>\n\t// /\n\t\n\t// This means only the {@link //EMPTY} context is in set.\n\tPredictionContext.prototype.isEmpty = function() {\n\t\treturn this === PredictionContext.EMPTY;\n\t};\n\t\n\tPredictionContext.prototype.hasEmptyPath = function() {\n\t\treturn this.getReturnState(this.length - 1) === PredictionContext.EMPTY_RETURN_STATE;\n\t};\n\t\n\tPredictionContext.prototype.hashString = function() {\n\t\treturn this.cachedHashString;\n\t};\n\t\n\tfunction calculateHashString(parent, returnState) {\n\t\treturn \"\" + parent + returnState;\n\t}\n\t\n\tfunction calculateEmptyHashString() {\n\t\treturn \"\";\n\t}\n\t\n\t// Used to cache {@link PredictionContext} objects. Its used for the shared\n\t// context cash associated with contexts in DFA states. This cache\n\t// can be used for both lexers and parsers.\n\t\n\tfunction PredictionContextCache() {\n\t\tthis.cache = {};\n\t\treturn this;\n\t}\n\t\n\t// Add a context to the cache and return it. If the context already exists,\n\t// return that one instead and do not add a new context to the cache.\n\t// Protect shared cache from unsafe thread access.\n\t//\n\tPredictionContextCache.prototype.add = function(ctx) {\n\t\tif (ctx === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY;\n\t\t}\n\t\tvar existing = this.cache[ctx] || null;\n\t\tif (existing !== null) {\n\t\t\treturn existing;\n\t\t}\n\t\tthis.cache[ctx] = ctx;\n\t\treturn ctx;\n\t};\n\t\n\tPredictionContextCache.prototype.get = function(ctx) {\n\t\treturn this.cache[ctx] || null;\n\t};\n\t\n\tObject.defineProperty(PredictionContextCache.prototype, \"length\", {\n\t\tget : function() {\n\t\t\treturn this.cache.length;\n\t\t}\n\t});\n\t\n\tfunction SingletonPredictionContext(parent, returnState) {\n\t\tvar hashString = parent !== null ? calculateHashString(parent, returnState)\n\t\t\t\t: calculateEmptyHashString();\n\t\tPredictionContext.call(this, hashString);\n\t\tthis.parentCtx = parent;\n\t\tthis.returnState = returnState;\n\t}\n\t\n\tSingletonPredictionContext.prototype = Object.create(PredictionContext.prototype);\n\tSingletonPredictionContext.prototype.contructor = SingletonPredictionContext;\n\t\n\tSingletonPredictionContext.create = function(parent, returnState) {\n\t\tif (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {\n\t\t\t// someone can pass in the bits of an array ctx that mean $\n\t\t\treturn PredictionContext.EMPTY;\n\t\t} else {\n\t\t\treturn new SingletonPredictionContext(parent, returnState);\n\t\t}\n\t};\n\t\n\tObject.defineProperty(SingletonPredictionContext.prototype, \"length\", {\n\t\tget : function() {\n\t\t\treturn 1;\n\t\t}\n\t});\n\t\n\tSingletonPredictionContext.prototype.getParent = function(index) {\n\t\treturn this.parentCtx;\n\t};\n\t\n\tSingletonPredictionContext.prototype.getReturnState = function(index) {\n\t\treturn this.returnState;\n\t};\n\t\n\tSingletonPredictionContext.prototype.equals = function(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof SingletonPredictionContext)) {\n\t\t\treturn false;\n\t\t} else if (this.hashString() !== other.hashString()) {\n\t\t\treturn false; // can't be same if hash is different\n\t\t} else {\n\t\t\tif(this.returnState !== other.returnState)\n\t            return false;\n\t        else if(this.parentCtx==null)\n\t            return other.parentCtx==null\n\t\t\telse\n\t            return this.parentCtx.equals(other.parentCtx);\n\t\t}\n\t};\n\t\n\tSingletonPredictionContext.prototype.hashString = function() {\n\t\treturn this.cachedHashString;\n\t};\n\t\n\tSingletonPredictionContext.prototype.toString = function() {\n\t\tvar up = this.parentCtx === null ? \"\" : this.parentCtx.toString();\n\t\tif (up.length === 0) {\n\t\t\tif (this.returnState === this.EMPTY_RETURN_STATE) {\n\t\t\t\treturn \"$\";\n\t\t\t} else {\n\t\t\t\treturn \"\" + this.returnState;\n\t\t\t}\n\t\t} else {\n\t\t\treturn \"\" + this.returnState + \" \" + up;\n\t\t}\n\t};\n\t\n\tfunction EmptyPredictionContext() {\n\t\tSingletonPredictionContext.call(this, null, PredictionContext.EMPTY_RETURN_STATE);\n\t\treturn this;\n\t}\n\t\n\tEmptyPredictionContext.prototype = Object.create(SingletonPredictionContext.prototype);\n\tEmptyPredictionContext.prototype.constructor = EmptyPredictionContext;\n\t\n\tEmptyPredictionContext.prototype.isEmpty = function() {\n\t\treturn true;\n\t};\n\t\n\tEmptyPredictionContext.prototype.getParent = function(index) {\n\t\treturn null;\n\t};\n\t\n\tEmptyPredictionContext.prototype.getReturnState = function(index) {\n\t\treturn this.returnState;\n\t};\n\t\n\tEmptyPredictionContext.prototype.equals = function(other) {\n\t\treturn this === other;\n\t};\n\t\n\tEmptyPredictionContext.prototype.toString = function() {\n\t\treturn \"$\";\n\t};\n\t\n\tPredictionContext.EMPTY = new EmptyPredictionContext();\n\t\n\tfunction ArrayPredictionContext(parents, returnStates) {\n\t\t// Parent can be null only if full ctx mode and we make an array\n\t\t// from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using\n\t\t// null parent and\n\t\t// returnState == {@link //EMPTY_RETURN_STATE}.\n\t\tvar hash = calculateHashString(parents, returnStates);\n\t\tPredictionContext.call(this, hash);\n\t\tthis.parents = parents;\n\t\tthis.returnStates = returnStates;\n\t\treturn this;\n\t}\n\t\n\tArrayPredictionContext.prototype = Object.create(PredictionContext.prototype);\n\tArrayPredictionContext.prototype.constructor = ArrayPredictionContext;\n\t\n\tArrayPredictionContext.prototype.isEmpty = function() {\n\t\t// since EMPTY_RETURN_STATE can only appear in the last position, we\n\t\t// don't need to verify that size==1\n\t\treturn this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;\n\t};\n\t\n\tObject.defineProperty(ArrayPredictionContext.prototype, \"length\", {\n\t\tget : function() {\n\t\t\treturn this.returnStates.length;\n\t\t}\n\t});\n\t\n\tArrayPredictionContext.prototype.getParent = function(index) {\n\t\treturn this.parents[index];\n\t};\n\t\n\tArrayPredictionContext.prototype.getReturnState = function(index) {\n\t\treturn this.returnStates[index];\n\t};\n\t\n\tArrayPredictionContext.prototype.equals = function(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof ArrayPredictionContext)) {\n\t\t\treturn false;\n\t\t} else if (this.hashString !== other.hashString()) {\n\t\t\treturn false; // can't be same if hash is different\n\t\t} else {\n\t\t\treturn this.returnStates === other.returnStates &&\n\t\t\t\t\tthis.parents === other.parents;\n\t\t}\n\t};\n\t\n\tArrayPredictionContext.prototype.toString = function() {\n\t\tif (this.isEmpty()) {\n\t\t\treturn \"[]\";\n\t\t} else {\n\t\t\tvar s = \"[\";\n\t\t\tfor (var i = 0; i < this.returnStates.length; i++) {\n\t\t\t\tif (i > 0) {\n\t\t\t\t\ts = s + \", \";\n\t\t\t\t}\n\t\t\t\tif (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\ts = s + \"$\";\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\ts = s + this.returnStates[i];\n\t\t\t\tif (this.parents[i] !== null) {\n\t\t\t\t\ts = s + \" \" + this.parents[i];\n\t\t\t\t} else {\n\t\t\t\t\ts = s + \"null\";\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn s + \"]\";\n\t\t}\n\t};\n\t\n\t// Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.\n\t// Return {@link //EMPTY} if {@code outerContext} is empty or null.\n\t// /\n\tfunction predictionContextFromRuleContext(atn, outerContext) {\n\t\tif (outerContext === undefined || outerContext === null) {\n\t\t\touterContext = RuleContext.EMPTY;\n\t\t}\n\t\t// if we are in RuleContext of start rule, s, then PredictionContext\n\t\t// is EMPTY. Nobody called us. (if we are empty, return empty)\n\t\tif (outerContext.parentCtx === null || outerContext === RuleContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY;\n\t\t}\n\t\t// If we have a parent, convert it to a PredictionContext graph\n\t\tvar parent = predictionContextFromRuleContext(atn, outerContext.parentCtx);\n\t\tvar state = atn.states[outerContext.invokingState];\n\t\tvar transition = state.transitions[0];\n\t\treturn SingletonPredictionContext.create(parent, transition.followState.stateNumber);\n\t}\n\t\n\tfunction calculateListsHashString(parents, returnStates) {\n\t\tvar s = \"\";\n\t\tparents.map(function(p) {\n\t\t\ts = s + p;\n\t\t});\n\t\treturnStates.map(function(r) {\n\t\t\ts = s + r;\n\t\t});\n\t\treturn s;\n\t}\n\t\n\tfunction merge(a, b, rootIsWildcard, mergeCache) {\n\t\t// share same graph if both same\n\t\tif (a === b) {\n\t\t\treturn a;\n\t\t}\n\t\tif (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n\t\t\treturn mergeSingletons(a, b, rootIsWildcard, mergeCache);\n\t\t}\n\t\t// At least one of a or b is array\n\t\t// If one is $ and rootIsWildcard, return $ as// wildcard\n\t\tif (rootIsWildcard) {\n\t\t\tif (a instanceof EmptyPredictionContext) {\n\t\t\t\treturn a;\n\t\t\t}\n\t\t\tif (b instanceof EmptyPredictionContext) {\n\t\t\t\treturn b;\n\t\t\t}\n\t\t}\n\t\t// convert singleton so both are arrays to normalize\n\t\tif (a instanceof SingletonPredictionContext) {\n\t\t\ta = new ArrayPredictionContext([a.getParent()], [a.returnState]);\n\t\t}\n\t\tif (b instanceof SingletonPredictionContext) {\n\t\t\tb = new ArrayPredictionContext([b.getParent()], [b.returnState]);\n\t\t}\n\t\treturn mergeArrays(a, b, rootIsWildcard, mergeCache);\n\t}\n\t\n\t//\n\t// Merge two {@link SingletonPredictionContext} instances.\n\t//\n\t// <p>Stack tops equal, parents merge is same; return left graph.<br>\n\t// <embed src=\"images/SingletonMerge_SameRootSamePar.svg\"\n\t// type=\"image/svg+xml\"/></p>\n\t//\n\t// <p>Same stack top, parents differ; merge parents giving array node, then\n\t// remainders of those graphs. A new root node is created to point to the\n\t// merged parents.<br>\n\t// <embed src=\"images/SingletonMerge_SameRootDiffPar.svg\"\n\t// type=\"image/svg+xml\"/></p>\n\t//\n\t// <p>Different stack tops pointing to same parent. Make array node for the\n\t// root where both element in the root point to the same (original)\n\t// parent.<br>\n\t// <embed src=\"images/SingletonMerge_DiffRootSamePar.svg\"\n\t// type=\"image/svg+xml\"/></p>\n\t//\n\t// <p>Different stack tops pointing to different parents. Make array node for\n\t// the root where each element points to the corresponding original\n\t// parent.<br>\n\t// <embed src=\"images/SingletonMerge_DiffRootDiffPar.svg\"\n\t// type=\"image/svg+xml\"/></p>\n\t//\n\t// @param a the first {@link SingletonPredictionContext}\n\t// @param b the second {@link SingletonPredictionContext}\n\t// @param rootIsWildcard {@code true} if this is a local-context merge,\n\t// otherwise false to indicate a full-context merge\n\t// @param mergeCache\n\t// /\n\tfunction mergeSingletons(a, b, rootIsWildcard, mergeCache) {\n\t\tif (mergeCache !== null) {\n\t\t\tvar previous = mergeCache.get(a, b);\n\t\t\tif (previous !== null) {\n\t\t\t\treturn previous;\n\t\t\t}\n\t\t\tprevious = mergeCache.get(b, a);\n\t\t\tif (previous !== null) {\n\t\t\t\treturn previous;\n\t\t\t}\n\t\t}\n\t\n\t\tvar rootMerge = mergeRoot(a, b, rootIsWildcard);\n\t\tif (rootMerge !== null) {\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, rootMerge);\n\t\t\t}\n\t\t\treturn rootMerge;\n\t\t}\n\t\tif (a.returnState === b.returnState) {\n\t\t\tvar parent = merge(a.parentCtx, b.parentCtx, rootIsWildcard, mergeCache);\n\t\t\t// if parent is same as existing a or b parent or reduced to a parent,\n\t\t\t// return it\n\t\t\tif (parent === a.parentCtx) {\n\t\t\t\treturn a; // ax + bx = ax, if a=b\n\t\t\t}\n\t\t\tif (parent === b.parentCtx) {\n\t\t\t\treturn b; // ax + bx = bx, if a=b\n\t\t\t}\n\t\t\t// else: ax + ay = a'[x,y]\n\t\t\t// merge parents x and y, giving array node with x,y then remainders\n\t\t\t// of those graphs. dup a, a' points at merged array\n\t\t\t// new joined parent so create new singleton pointing to it, a'\n\t\t\tvar spc = SingletonPredictionContext.create(parent, a.returnState);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, spc);\n\t\t\t}\n\t\t\treturn spc;\n\t\t} else { // a != b payloads differ\n\t\t\t// see if we can collapse parents due to $+x parents if local ctx\n\t\t\tvar singleParent = null;\n\t\t\tif (a === b || (a.parentCtx !== null && a.parentCtx === b.parentCtx)) { // ax +\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// bx =\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// [a,b]x\n\t\t\t\tsingleParent = a.parentCtx;\n\t\t\t}\n\t\t\tif (singleParent !== null) { // parents are same\n\t\t\t\t// sort payloads and use same parent\n\t\t\t\tvar payloads = [ a.returnState, b.returnState ];\n\t\t\t\tif (a.returnState > b.returnState) {\n\t\t\t\t\tpayloads[0] = b.returnState;\n\t\t\t\t\tpayloads[1] = a.returnState;\n\t\t\t\t}\n\t\t\t\tvar parents = [ singleParent, singleParent ];\n\t\t\t\tvar apc = new ArrayPredictionContext(parents, payloads);\n\t\t\t\tif (mergeCache !== null) {\n\t\t\t\t\tmergeCache.set(a, b, apc);\n\t\t\t\t}\n\t\t\t\treturn apc;\n\t\t\t}\n\t\t\t// parents differ and can't merge them. Just pack together\n\t\t\t// into array; can't merge.\n\t\t\t// ax + by = [ax,by]\n\t\t\tvar payloads = [ a.returnState, b.returnState ];\n\t\t\tvar parents = [ a.parentCtx, b.parentCtx ];\n\t\t\tif (a.returnState > b.returnState) { // sort by payload\n\t\t\t\tpayloads[0] = b.returnState;\n\t\t\t\tpayloads[1] = a.returnState;\n\t\t\t\tparents = [ b.parentCtx, a.parentCtx ];\n\t\t\t}\n\t\t\tvar a_ = new ArrayPredictionContext(parents, payloads);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, a_);\n\t\t\t}\n\t\t\treturn a_;\n\t\t}\n\t}\n\t\n\t//\n\t// Handle case where at least one of {@code a} or {@code b} is\n\t// {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used\n\t// to represent {@link //EMPTY}.\n\t//\n\t// <h2>Local-Context Merges</h2>\n\t//\n\t// <p>These local-context merge operations are used when {@code rootIsWildcard}\n\t// is true.</p>\n\t//\n\t// <p>{@link //EMPTY} is superset of any graph; return {@link //EMPTY}.<br>\n\t// <embed src=\"images/LocalMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n\t//\n\t// <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is\n\t// {@code //EMPTY}; return left graph.<br>\n\t// <embed src=\"images/LocalMerge_EmptyParent.svg\" type=\"image/svg+xml\"/></p>\n\t//\n\t// <p>Special case of last merge if local context.<br>\n\t// <embed src=\"images/LocalMerge_DiffRoots.svg\" type=\"image/svg+xml\"/></p>\n\t//\n\t// <h2>Full-Context Merges</h2>\n\t//\n\t// <p>These full-context merge operations are used when {@code rootIsWildcard}\n\t// is false.</p>\n\t//\n\t// <p><embed src=\"images/FullMerge_EmptyRoots.svg\" type=\"image/svg+xml\"/></p>\n\t//\n\t// <p>Must keep all contexts; {@link //EMPTY} in array is a special value (and\n\t// null parent).<br>\n\t// <embed src=\"images/FullMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n\t//\n\t// <p><embed src=\"images/FullMerge_SameRoot.svg\" type=\"image/svg+xml\"/></p>\n\t//\n\t// @param a the first {@link SingletonPredictionContext}\n\t// @param b the second {@link SingletonPredictionContext}\n\t// @param rootIsWildcard {@code true} if this is a local-context merge,\n\t// otherwise false to indicate a full-context merge\n\t// /\n\tfunction mergeRoot(a, b, rootIsWildcard) {\n\t\tif (rootIsWildcard) {\n\t\t\tif (a === PredictionContext.EMPTY) {\n\t\t\t\treturn PredictionContext.EMPTY; // // + b =//\n\t\t\t}\n\t\t\tif (b === PredictionContext.EMPTY) {\n\t\t\t\treturn PredictionContext.EMPTY; // a +// =//\n\t\t\t}\n\t\t} else {\n\t\t\tif (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {\n\t\t\t\treturn PredictionContext.EMPTY; // $ + $ = $\n\t\t\t} else if (a === PredictionContext.EMPTY) { // $ + x = [$,x]\n\t\t\t\tvar payloads = [ b.returnState,\n\t\t\t\t\t\tPredictionContext.EMPTY_RETURN_STATE ];\n\t\t\t\tvar parents = [ b.parentCtx, null ];\n\t\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t\t} else if (b === PredictionContext.EMPTY) { // x + $ = [$,x] ($ is always first if present)\n\t\t\t\tvar payloads = [ a.returnState, PredictionContext.EMPTY_RETURN_STATE ];\n\t\t\t\tvar parents = [ a.parentCtx, null ];\n\t\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}\n\t\n\t//\n\t// Merge two {@link ArrayPredictionContext} instances.\n\t//\n\t// <p>Different tops, different parents.<br>\n\t// <embed src=\"images/ArrayMerge_DiffTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n\t//\n\t// <p>Shared top, same parents.<br>\n\t// <embed src=\"images/ArrayMerge_ShareTopSamePar.svg\" type=\"image/svg+xml\"/></p>\n\t//\n\t// <p>Shared top, different parents.<br>\n\t// <embed src=\"images/ArrayMerge_ShareTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n\t//\n\t// <p>Shared top, all shared parents.<br>\n\t// <embed src=\"images/ArrayMerge_ShareTopSharePar.svg\"\n\t// type=\"image/svg+xml\"/></p>\n\t//\n\t// <p>Equal tops, merge parents and reduce top to\n\t// {@link SingletonPredictionContext}.<br>\n\t// <embed src=\"images/ArrayMerge_EqualTop.svg\" type=\"image/svg+xml\"/></p>\n\t// /\n\tfunction mergeArrays(a, b, rootIsWildcard, mergeCache) {\n\t\tif (mergeCache !== null) {\n\t\t\tvar previous = mergeCache.get(a, b);\n\t\t\tif (previous !== null) {\n\t\t\t\treturn previous;\n\t\t\t}\n\t\t\tprevious = mergeCache.get(b, a);\n\t\t\tif (previous !== null) {\n\t\t\t\treturn previous;\n\t\t\t}\n\t\t}\n\t\t// merge sorted payloads a + b => M\n\t\tvar i = 0; // walks a\n\t\tvar j = 0; // walks b\n\t\tvar k = 0; // walks target M array\n\t\n\t\tvar mergedReturnStates = [];\n\t\tvar mergedParents = [];\n\t\t// walk and merge to yield mergedParents, mergedReturnStates\n\t\twhile (i < a.returnStates.length && j < b.returnStates.length) {\n\t\t\tvar a_parent = a.parents[i];\n\t\t\tvar b_parent = b.parents[j];\n\t\t\tif (a.returnStates[i] === b.returnStates[j]) {\n\t\t\t\t// same payload (stack tops are equal), must yield merged singleton\n\t\t\t\tvar payload = a.returnStates[i];\n\t\t\t\t// $+$ = $\n\t\t\t\tvar bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE &&\n\t\t\t\t\t\ta_parent === null && b_parent === null;\n\t\t\t\tvar ax_ax = (a_parent !== null && b_parent !== null && a_parent === b_parent); // ax+ax\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ->\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ax\n\t\t\t\tif (bothDollars || ax_ax) {\n\t\t\t\t\tmergedParents[k] = a_parent; // choose left\n\t\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t\t} else { // ax+ay -> a'[x,y]\n\t\t\t\t\tvar mergedParent = merge(a_parent, b_parent, rootIsWildcard, mergeCache);\n\t\t\t\t\tmergedParents[k] = mergedParent;\n\t\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t\t}\n\t\t\t\ti += 1; // hop over left one as usual\n\t\t\t\tj += 1; // but also skip one in right side since we merge\n\t\t\t} else if (a.returnStates[i] < b.returnStates[j]) { // copy a[i] to M\n\t\t\t\tmergedParents[k] = a_parent;\n\t\t\t\tmergedReturnStates[k] = a.returnStates[i];\n\t\t\t\ti += 1;\n\t\t\t} else { // b > a, copy b[j] to M\n\t\t\t\tmergedParents[k] = b_parent;\n\t\t\t\tmergedReturnStates[k] = b.returnStates[j];\n\t\t\t\tj += 1;\n\t\t\t}\n\t\t\tk += 1;\n\t\t}\n\t\t// copy over any payloads remaining in either array\n\t\tif (i < a.returnStates.length) {\n\t\t\tfor (var p = i; p < a.returnStates.length; p++) {\n\t\t\t\tmergedParents[k] = a.parents[p];\n\t\t\t\tmergedReturnStates[k] = a.returnStates[p];\n\t\t\t\tk += 1;\n\t\t\t}\n\t\t} else {\n\t\t\tfor (var p = j; p < b.returnStates.length; p++) {\n\t\t\t\tmergedParents[k] = b.parents[p];\n\t\t\t\tmergedReturnStates[k] = b.returnStates[p];\n\t\t\t\tk += 1;\n\t\t\t}\n\t\t}\n\t\t// trim merged if we combined a few that had same stack tops\n\t\tif (k < mergedParents.length) { // write index < last position; trim\n\t\t\tif (k === 1) { // for just one merged element, return singleton top\n\t\t\t\tvar a_ = SingletonPredictionContext.create(mergedParents[0],\n\t\t\t\t\t\tmergedReturnStates[0]);\n\t\t\t\tif (mergeCache !== null) {\n\t\t\t\t\tmergeCache.set(a, b, a_);\n\t\t\t\t}\n\t\t\t\treturn a_;\n\t\t\t}\n\t\t\tmergedParents = mergedParents.slice(0, k);\n\t\t\tmergedReturnStates = mergedReturnStates.slice(0, k);\n\t\t}\n\t\n\t\tvar M = new ArrayPredictionContext(mergedParents, mergedReturnStates);\n\t\n\t\t// if we created same array as a or b, return that instead\n\t\t// TODO: track whether this is possible above during merge sort for speed\n\t\tif (M === a) {\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, a);\n\t\t\t}\n\t\t\treturn a;\n\t\t}\n\t\tif (M === b) {\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, b);\n\t\t\t}\n\t\t\treturn b;\n\t\t}\n\t\tcombineCommonParents(mergedParents);\n\t\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, M);\n\t\t}\n\t\treturn M;\n\t}\n\t\n\t//\n\t// Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}\n\t// ones.\n\t// /\n\tfunction combineCommonParents(parents) {\n\t\tvar uniqueParents = {};\n\t\n\t\tfor (var p = 0; p < parents.length; p++) {\n\t\t\tvar parent = parents[p];\n\t\t\tif (!(parent in uniqueParents)) {\n\t\t\t\tuniqueParents[parent] = parent;\n\t\t\t}\n\t\t}\n\t\tfor (var q = 0; q < parents.length; q++) {\n\t\t\tparents[q] = uniqueParents[parents[q]];\n\t\t}\n\t}\n\t\n\tfunction getCachedPredictionContext(context, contextCache, visited) {\n\t\tif (context.isEmpty()) {\n\t\t\treturn context;\n\t\t}\n\t\tvar existing = visited[context] || null;\n\t\tif (existing !== null) {\n\t\t\treturn existing;\n\t\t}\n\t\texisting = contextCache.get(context);\n\t\tif (existing !== null) {\n\t\t\tvisited[context] = existing;\n\t\t\treturn existing;\n\t\t}\n\t\tvar changed = false;\n\t\tvar parents = [];\n\t\tfor (var i = 0; i < parents.length; i++) {\n\t\t\tvar parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);\n\t\t\tif (changed || parent !== context.getParent(i)) {\n\t\t\t\tif (!changed) {\n\t\t\t\t\tparents = [];\n\t\t\t\t\tfor (var j = 0; j < context.length; j++) {\n\t\t\t\t\t\tparents[j] = context.getParent(j);\n\t\t\t\t\t}\n\t\t\t\t\tchanged = true;\n\t\t\t\t}\n\t\t\t\tparents[i] = parent;\n\t\t\t}\n\t\t}\n\t\tif (!changed) {\n\t\t\tcontextCache.add(context);\n\t\t\tvisited[context] = context;\n\t\t\treturn context;\n\t\t}\n\t\tvar updated = null;\n\t\tif (parents.length === 0) {\n\t\t\tupdated = PredictionContext.EMPTY;\n\t\t} else if (parents.length === 1) {\n\t\t\tupdated = SingletonPredictionContext.create(parents[0], context\n\t\t\t\t\t.getReturnState(0));\n\t\t} else {\n\t\t\tupdated = new ArrayPredictionContext(parents, context.returnStates);\n\t\t}\n\t\tcontextCache.add(updated);\n\t\tvisited[updated] = updated;\n\t\tvisited[context] = updated;\n\t\n\t\treturn updated;\n\t}\n\t\n\t// ter's recursive version of Sam's getAllNodes()\n\tfunction getAllContextNodes(context, nodes, visited) {\n\t\tif (nodes === null) {\n\t\t\tnodes = [];\n\t\t\treturn getAllContextNodes(context, nodes, visited);\n\t\t} else if (visited === null) {\n\t\t\tvisited = {};\n\t\t\treturn getAllContextNodes(context, nodes, visited);\n\t\t} else {\n\t\t\tif (context === null || visited[context] !== null) {\n\t\t\t\treturn nodes;\n\t\t\t}\n\t\t\tvisited[context] = context;\n\t\t\tnodes.push(context);\n\t\t\tfor (var i = 0; i < context.length; i++) {\n\t\t\t\tgetAllContextNodes(context.getParent(i), nodes, visited);\n\t\t\t}\n\t\t\treturn nodes;\n\t\t}\n\t}\n\t\n\texports.merge = merge;\n\texports.PredictionContext = PredictionContext;\n\texports.PredictionContextCache = PredictionContextCache;\n\texports.SingletonPredictionContext = SingletonPredictionContext;\n\texports.predictionContextFromRuleContext = predictionContextFromRuleContext;\n\texports.getCachedPredictionContext = getCachedPredictionContext;\n\n\n/***/ },\n/* 16 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2013 Terence Parr\n\t//  Copyright (c) 2013 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\t//  A rule context is a record of a single rule invocation. It knows\n\t//  which context invoked it, if any. If there is no parent context, then\n\t//  naturally the invoking state is not valid.  The parent link\n\t//  provides a chain upwards from the current rule invocation to the root\n\t//  of the invocation tree, forming a stack. We actually carry no\n\t//  information about the rule associated with this context (except\n\t//  when parsing). We keep only the state number of the invoking state from\n\t//  the ATN submachine that invoked this. Contrast this with the s\n\t//  pointer inside ParserRuleContext that tracks the current state\n\t//  being \"executed\" for the current rule.\n\t//\n\t//  The parent contexts are useful for computing lookahead sets and\n\t//  getting error information.\n\t//\n\t//  These objects are used during parsing and prediction.\n\t//  For the special case of parsers, we use the subclass\n\t//  ParserRuleContext.\n\t//\n\t//  @see ParserRuleContext\n\t///\n\t\n\tvar RuleNode = __webpack_require__(17).RuleNode;\n\tvar INVALID_INTERVAL = __webpack_require__(17).INVALID_INTERVAL;\n\tvar INVALID_ALT_NUMBER = __webpack_require__(6).INVALID_ALT_NUMBER;\n\t\n\tfunction RuleContext(parent, invokingState) {\n\t\tRuleNode.call(this);\n\t\t// What context invoked this rule?\n\t\tthis.parentCtx = parent || null;\n\t\t// What state invoked the rule associated with this context?\n\t\t// The \"return address\" is the followState of invokingState\n\t\t// If parent is null, this should be -1.\n\t\tthis.invokingState = invokingState || -1;\n\t\treturn this;\n\t}\n\t\n\tRuleContext.prototype = Object.create(RuleNode.prototype);\n\tRuleContext.prototype.constructor = RuleContext;\n\t\n\tRuleContext.prototype.depth = function() {\n\t\tvar n = 0;\n\t\tvar p = this;\n\t\twhile (p !== null) {\n\t\t\tp = p.parentCtx;\n\t\t\tn += 1;\n\t\t}\n\t\treturn n;\n\t};\n\t\n\t// A context is empty if there is no invoking state; meaning nobody call\n\t// current context.\n\tRuleContext.prototype.isEmpty = function() {\n\t\treturn this.invokingState === -1;\n\t};\n\t\n\t// satisfy the ParseTree / SyntaxTree interface\n\t\n\tRuleContext.prototype.getSourceInterval = function() {\n\t\treturn INVALID_INTERVAL;\n\t};\n\t\n\tRuleContext.prototype.getRuleContext = function() {\n\t\treturn this;\n\t};\n\t\n\tRuleContext.prototype.getPayload = function() {\n\t\treturn this;\n\t};\n\t\n\t// Return the combined text of all child nodes. This method only considers\n\t// tokens which have been added to the parse tree.\n\t// <p>\n\t// Since tokens on hidden channels (e.g. whitespace or comments) are not\n\t// added to the parse trees, they will not appear in the output of this\n\t// method.\n\t// /\n\tRuleContext.prototype.getText = function() {\n\t\tif (this.getChildCount() === 0) {\n\t\t\treturn \"\";\n\t\t} else {\n\t\t\treturn this.children.map(function(child) {\n\t\t\t\treturn child.getText();\n\t\t\t}).join(\"\");\n\t\t}\n\t};\n\t\n\t// For rule associated with this parse tree internal node, return\n\t// the outer alternative number used to match the input. Default\n\t// implementation does not compute nor store this alt num. Create\n\t// a subclass of ParserRuleContext with backing field and set\n\t// option contextSuperClass.\n\t// to set it.\n\tRuleContext.prototype.getAltNumber = function() { return INVALID_ALT_NUMBER; }\n\t\n\t// Set the outer alternative number for this context node. Default\n\t// implementation does nothing to avoid backing field overhead for\n\t// trees that don't need it.  Create\n\t// a subclass of ParserRuleContext with backing field and set\n\t// option contextSuperClass.\n\tRuleContext.prototype.setAltNumber = function(altNumber) { }\n\t\n\tRuleContext.prototype.getChild = function(i) {\n\t\treturn null;\n\t};\n\t\n\tRuleContext.prototype.getChildCount = function() {\n\t\treturn 0;\n\t};\n\t\n\tRuleContext.prototype.accept = function(visitor) {\n\t\treturn visitor.visitChildren(this);\n\t};\n\t\n\t//need to manage circular dependencies, so export now\n\texports.RuleContext = RuleContext;\n\tvar Trees = __webpack_require__(18).Trees;\n\t\n\t\n\t// Print out a whole tree, not just a node, in LISP format\n\t// (root child1 .. childN). Print just a node if this is a leaf.\n\t//\n\t\n\tRuleContext.prototype.toStringTree = function(ruleNames, recog) {\n\t\treturn Trees.toStringTree(this, ruleNames, recog);\n\t};\n\t\n\tRuleContext.prototype.toString = function(ruleNames, stop) {\n\t\truleNames = ruleNames || null;\n\t\tstop = stop || null;\n\t\tvar p = this;\n\t\tvar s = \"[\";\n\t\twhile (p !== null && p !== stop) {\n\t\t\tif (ruleNames === null) {\n\t\t\t\tif (!p.isEmpty()) {\n\t\t\t\t\ts += p.invokingState;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tvar ri = p.ruleIndex;\n\t\t\t\tvar ruleName = (ri >= 0 && ri < ruleNames.length) ? ruleNames[ri]\n\t\t\t\t\t\t: \"\" + ri;\n\t\t\t\ts += ruleName;\n\t\t\t}\n\t\t\tif (p.parentCtx !== null && (ruleNames !== null || !p.parentCtx.isEmpty())) {\n\t\t\t\ts += \" \";\n\t\t\t}\n\t\t\tp = p.parentCtx;\n\t\t}\n\t\ts += \"]\";\n\t\treturn s;\n\t};\n\t\n\n\n/***/ },\n/* 17 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\t// The basic notion of a tree has a parent, a payload, and a list of children.\n\t//  It is the most abstract interface for all the trees used by ANTLR.\n\t///\n\t\n\tvar Token = __webpack_require__(9).Token;\n\tvar Interval = __webpack_require__(13).Interval;\n\tvar INVALID_INTERVAL = new Interval(-1, -2);\n\tvar Utils = __webpack_require__(8);\n\t\n\t\n\tfunction Tree() {\n\t\treturn this;\n\t}\n\t\n\tfunction SyntaxTree() {\n\t\tTree.call(this);\n\t\treturn this;\n\t}\n\t\n\tSyntaxTree.prototype = Object.create(Tree.prototype);\n\tSyntaxTree.prototype.constructor = SyntaxTree;\n\t\n\tfunction ParseTree() {\n\t\tSyntaxTree.call(this);\n\t\treturn this;\n\t}\n\t\n\tParseTree.prototype = Object.create(SyntaxTree.prototype);\n\tParseTree.prototype.constructor = ParseTree;\n\t\n\tfunction RuleNode() {\n\t\tParseTree.call(this);\n\t\treturn this;\n\t}\n\t\n\tRuleNode.prototype = Object.create(ParseTree.prototype);\n\tRuleNode.prototype.constructor = RuleNode;\n\t\n\tfunction TerminalNode() {\n\t\tParseTree.call(this);\n\t\treturn this;\n\t}\n\t\n\tTerminalNode.prototype = Object.create(ParseTree.prototype);\n\tTerminalNode.prototype.constructor = TerminalNode;\n\t\n\tfunction ErrorNode() {\n\t\tTerminalNode.call(this);\n\t\treturn this;\n\t}\n\t\n\tErrorNode.prototype = Object.create(TerminalNode.prototype);\n\tErrorNode.prototype.constructor = ErrorNode;\n\t\n\tfunction ParseTreeVisitor() {\n\t\treturn this;\n\t}\n\t\n\tParseTreeVisitor.prototype.visit = function(ctx) {\n\t\tif (Utils.isArray(ctx)) {\n\t\t\tvar self = this;\n\t\t\treturn ctx.map(function(child) { return visitAtom(self, child)});\n\t\t} else {\n\t\t\treturn visitAtom(this, ctx);\n\t\t}\n\t};\n\t\n\tParseTreeVisitor.prototype.visitTerminal = function(node) {\n\t};\n\t\n\tParseTreeVisitor.prototype.visitErrorNode = function(node) {\n\t};\n\t\n\t\n\tvar visitAtom = function(visitor, ctx) {\n\t\tif (ctx.parser === undefined) { //is terminal\n\t\t\treturn;\n\t\t}\n\t\n\t\tvar name = ctx.parser.ruleNames[ctx.ruleIndex];\n\t\tvar funcName = \"visit\" + Utils.titleCase(name);\n\t\n\t\treturn visitor[funcName](ctx);\n\t};\n\t\n\tfunction ParseTreeListener() {\n\t\treturn this;\n\t}\n\t\n\tParseTreeListener.prototype.visitTerminal = function(node) {\n\t};\n\t\n\tParseTreeListener.prototype.visitErrorNode = function(node) {\n\t};\n\t\n\tParseTreeListener.prototype.enterEveryRule = function(node) {\n\t};\n\t\n\tParseTreeListener.prototype.exitEveryRule = function(node) {\n\t};\n\t\n\tfunction TerminalNodeImpl(symbol) {\n\t\tTerminalNode.call(this);\n\t\tthis.parentCtx = null;\n\t\tthis.symbol = symbol;\n\t\treturn this;\n\t}\n\t\n\tTerminalNodeImpl.prototype = Object.create(TerminalNode.prototype);\n\tTerminalNodeImpl.prototype.constructor = TerminalNodeImpl;\n\t\n\tTerminalNodeImpl.prototype.getChild = function(i) {\n\t\treturn null;\n\t};\n\t\n\tTerminalNodeImpl.prototype.getSymbol = function() {\n\t\treturn this.symbol;\n\t};\n\t\n\tTerminalNodeImpl.prototype.getParent = function() {\n\t\treturn this.parentCtx;\n\t};\n\t\n\tTerminalNodeImpl.prototype.getPayload = function() {\n\t\treturn this.symbol;\n\t};\n\t\n\tTerminalNodeImpl.prototype.getSourceInterval = function() {\n\t\tif (this.symbol === null) {\n\t\t\treturn INVALID_INTERVAL;\n\t\t}\n\t\tvar tokenIndex = this.symbol.tokenIndex;\n\t\treturn new Interval(tokenIndex, tokenIndex);\n\t};\n\t\n\tTerminalNodeImpl.prototype.getChildCount = function() {\n\t\treturn 0;\n\t};\n\t\n\tTerminalNodeImpl.prototype.accept = function(visitor) {\n\t\treturn visitor.visitTerminal(this);\n\t};\n\t\n\tTerminalNodeImpl.prototype.getText = function() {\n\t\treturn this.symbol.text;\n\t};\n\t\n\tTerminalNodeImpl.prototype.toString = function() {\n\t\tif (this.symbol.type === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else {\n\t\t\treturn this.symbol.text;\n\t\t}\n\t};\n\t\n\t// Represents a token that was consumed during resynchronization\n\t// rather than during a valid match operation. For example,\n\t// we will create this kind of a node during single token insertion\n\t// and deletion as well as during \"consume until error recovery set\"\n\t// upon no viable alternative exceptions.\n\t\n\tfunction ErrorNodeImpl(token) {\n\t\tTerminalNodeImpl.call(this, token);\n\t\treturn this;\n\t}\n\t\n\tErrorNodeImpl.prototype = Object.create(TerminalNodeImpl.prototype);\n\tErrorNodeImpl.prototype.constructor = ErrorNodeImpl;\n\t\n\tErrorNodeImpl.prototype.isErrorNode = function() {\n\t\treturn true;\n\t};\n\t\n\tErrorNodeImpl.prototype.accept = function(visitor) {\n\t\treturn visitor.visitErrorNode(this);\n\t};\n\t\n\tfunction ParseTreeWalker() {\n\t\treturn this;\n\t}\n\t\n\tParseTreeWalker.prototype.walk = function(listener, t) {\n\t\tvar errorNode = t instanceof ErrorNode ||\n\t\t\t\t(t.isErrorNode !== undefined && t.isErrorNode());\n\t\tif (errorNode) {\n\t\t\tlistener.visitErrorNode(t);\n\t\t} else if (t instanceof TerminalNode) {\n\t\t\tlistener.visitTerminal(t);\n\t\t} else {\n\t\t\tthis.enterRule(listener, t);\n\t\t\tfor (var i = 0; i < t.getChildCount(); i++) {\n\t\t\t\tvar child = t.getChild(i);\n\t\t\t\tthis.walk(listener, child);\n\t\t\t}\n\t\t\tthis.exitRule(listener, t);\n\t\t}\n\t};\n\t//\n\t// The discovery of a rule node, involves sending two events: the generic\n\t// {@link ParseTreeListener//enterEveryRule} and a\n\t// {@link RuleContext}-specific event. First we trigger the generic and then\n\t// the rule specific. We to them in reverse order upon finishing the node.\n\t//\n\tParseTreeWalker.prototype.enterRule = function(listener, r) {\n\t\tvar ctx = r.getRuleContext();\n\t\tlistener.enterEveryRule(ctx);\n\t\tctx.enterRule(listener);\n\t};\n\t\n\tParseTreeWalker.prototype.exitRule = function(listener, r) {\n\t\tvar ctx = r.getRuleContext();\n\t\tctx.exitRule(listener);\n\t\tlistener.exitEveryRule(ctx);\n\t};\n\t\n\tParseTreeWalker.DEFAULT = new ParseTreeWalker();\n\t\n\texports.RuleNode = RuleNode;\n\texports.ErrorNode = ErrorNode;\n\texports.TerminalNode = TerminalNode;\n\texports.ErrorNodeImpl = ErrorNodeImpl;\n\texports.TerminalNodeImpl = TerminalNodeImpl;\n\texports.ParseTreeListener = ParseTreeListener;\n\texports.ParseTreeVisitor = ParseTreeVisitor;\n\texports.ParseTreeWalker = ParseTreeWalker;\n\texports.INVALID_INTERVAL = INVALID_INTERVAL;\n\n/***/ },\n/* 18 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t/*\n\t * [The \"BSD license\"]\n\t *  Copyright (c) 2012 Terence Parr\n\t *  Copyright (c) 2012 Sam Harwell\n\t *  All rights reserved.\n\t *\n\t *  Redistribution and use in source and binary forms, with or without\n\t *  modification, are permitted provided that the following conditions\n\t *  are met:\n\t *\n\t *  1. Redistributions of source code must retain the above copyright\n\t *     notice, this list of conditions and the following disclaimer.\n\t *  2. Redistributions in binary form must reproduce the above copyright\n\t *     notice, this list of conditions and the following disclaimer in the\n\t *     documentation and/or other materials provided with the distribution.\n\t *  3. The name of the author may not be used to endorse or promote products\n\t *     derived from this software without specific prior written permission.\n\t *\n\t *  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t *  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t *  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t *  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t *  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t *  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t *  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t */\n\t\n\tvar Utils = __webpack_require__(8);\n\tvar Token = __webpack_require__(9).Token;\n\tvar RuleNode = __webpack_require__(17).RuleNode;\n\tvar ErrorNode = __webpack_require__(17).ErrorNode;\n\tvar TerminalNode = __webpack_require__(17).TerminalNode;\n\tvar ParserRuleContext = __webpack_require__(19).ParserRuleContext;\n\tvar RuleContext = __webpack_require__(16).RuleContext;\n\tvar INVALID_ALT_NUMBER = __webpack_require__(6).INVALID_ALT_NUMBER;\n\t\n\t\n\t/** A set of utility routines useful for all kinds of ANTLR trees. */\n\tfunction Trees() {\n\t}\n\t\n\t// Print out a whole tree in LISP form. {@link //getNodeText} is used on the\n\t//  node payloads to get the text for the nodes.  Detect\n\t//  parse trees and extract data appropriately.\n\tTrees.toStringTree = function(tree, ruleNames, recog) {\n\t\truleNames = ruleNames || null;\n\t\trecog = recog || null;\n\t    if(recog!==null) {\n\t       ruleNames = recog.ruleNames;\n\t    }\n\t    var s = Trees.getNodeText(tree, ruleNames);\n\t    s = Utils.escapeWhitespace(s, false);\n\t    var c = tree.getChildCount();\n\t    if(c===0) {\n\t        return s;\n\t    }\n\t    var res = \"(\" + s + ' ';\n\t    if(c>0) {\n\t        s = Trees.toStringTree(tree.getChild(0), ruleNames);\n\t        res = res.concat(s);\n\t    }\n\t    for(var i=1;i<c;i++) {\n\t        s = Trees.toStringTree(tree.getChild(i), ruleNames);\n\t        res = res.concat(' ' + s);\n\t    }\n\t    res = res.concat(\")\");\n\t    return res;\n\t};\n\t\n\tTrees.getNodeText = function(t, ruleNames, recog) {\n\t\truleNames = ruleNames || null;\n\t\trecog = recog || null;\n\t    if(recog!==null) {\n\t        ruleNames = recog.ruleNames;\n\t    }\n\t    if(ruleNames!==null) {\n\t       if (t instanceof RuleContext) {\n\t           var altNumber = t.getAltNumber();\n\t           if ( altNumber!=INVALID_ALT_NUMBER ) {\n\t               return ruleNames[t.ruleIndex]+\":\"+altNumber;\n\t           }\n\t           return ruleNames[t.ruleIndex];\n\t       } else if ( t instanceof ErrorNode) {\n\t           return t.toString();\n\t       } else if(t instanceof TerminalNode) {\n\t           if(t.symbol!==null) {\n\t               return t.symbol.text;\n\t           }\n\t       }\n\t    }\n\t    // no recog for rule names\n\t    var payload = t.getPayload();\n\t    if (payload instanceof Token ) {\n\t       return payload.text;\n\t    }\n\t    return t.getPayload().toString();\n\t};\n\t\n\t\n\t// Return ordered list of all children of this node\n\tTrees.getChildren = function(t) {\n\t\tvar list = [];\n\t\tfor(var i=0;i<t.getChildCount();i++) {\n\t\t\tlist.push(t.getChild(i));\n\t\t}\n\t\treturn list;\n\t};\n\t\n\t// Return a list of all ancestors of this node.  The first node of\n\t//  list is the root and the last is the parent of this node.\n\t//\n\tTrees.getAncestors = function(t) {\n\t    var ancestors = [];\n\t    t = t.getParent();\n\t    while(t!==null) {\n\t        ancestors = [t].concat(ancestors);\n\t        t = t.getParent();\n\t    }\n\t    return ancestors;\n\t};\n\t\n\tTrees.findAllTokenNodes = function(t, ttype) {\n\t    return Trees.findAllNodes(t, ttype, true);\n\t};\n\t\n\tTrees.findAllRuleNodes = function(t, ruleIndex) {\n\t\treturn Trees.findAllNodes(t, ruleIndex, false);\n\t};\n\t\n\tTrees.findAllNodes = function(t, index, findTokens) {\n\t\tvar nodes = [];\n\t\tTrees._findAllNodes(t, index, findTokens, nodes);\n\t\treturn nodes;\n\t};\n\t\n\tTrees._findAllNodes = function(t, index, findTokens, nodes) {\n\t\t// check this node (the root) first\n\t\tif(findTokens && (t instanceof TerminalNode)) {\n\t\t\tif(t.symbol.type===index) {\n\t\t\t\tnodes.push(t);\n\t\t\t}\n\t\t} else if(!findTokens && (t instanceof ParserRuleContext)) {\n\t\t\tif(t.ruleIndex===index) {\n\t\t\t\tnodes.push(t);\n\t\t\t}\n\t\t}\n\t\t// check children\n\t\tfor(var i=0;i<t.getChildCount();i++) {\n\t\t\tTrees._findAllNodes(t.getChild(i), index, findTokens, nodes);\n\t\t}\n\t};\n\t\n\tTrees.descendants = function(t) {\n\t\tvar nodes = [t];\n\t    for(var i=0;i<t.getChildCount();i++) {\n\t        nodes = nodes.concat(Trees.descendants(t.getChild(i)));\n\t    }\n\t    return nodes;\n\t};\n\t\n\t\n\texports.Trees = Trees;\n\n/***/ },\n/* 19 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\t//* A rule invocation record for parsing.\n\t//\n\t//  Contains all of the information about the current rule not stored in the\n\t//  RuleContext. It handles parse tree children list, Any ATN state\n\t//  tracing, and the default values available for rule indications:\n\t//  start, stop, rule index, current alt number, current\n\t//  ATN state.\n\t//\n\t//  Subclasses made for each rule and grammar track the parameters,\n\t//  return values, locals, and labels specific to that rule. These\n\t//  are the objects that are returned from rules.\n\t//\n\t//  Note text is not an actual field of a rule return value; it is computed\n\t//  from start and stop using the input stream's toString() method.  I\n\t//  could add a ctor to this so that we can pass in and store the input\n\t//  stream, but I'm not sure we want to do that.  It would seem to be undefined\n\t//  to get the .text property anyway if the rule matches tokens from multiple\n\t//  input streams.\n\t//\n\t//  I do not use getters for fields of objects that are used simply to\n\t//  group values such as this aggregate.  The getters/setters are there to\n\t//  satisfy the superclass interface.\n\t\n\tvar RuleContext = __webpack_require__(16).RuleContext;\n\tvar Tree = __webpack_require__(17);\n\tvar INVALID_INTERVAL = Tree.INVALID_INTERVAL;\n\tvar TerminalNode = Tree.TerminalNode;\n\tvar TerminalNodeImpl = Tree.TerminalNodeImpl;\n\tvar ErrorNodeImpl = Tree.ErrorNodeImpl;\n\tvar Interval = __webpack_require__(13).Interval;\n\t\n\tfunction ParserRuleContext(parent, invokingStateNumber) {\n\t\tparent = parent || null;\n\t\tinvokingStateNumber = invokingStateNumber || null;\n\t\tRuleContext.call(this, parent, invokingStateNumber);\n\t\tthis.ruleIndex = -1;\n\t    // * If we are debugging or building a parse tree for a visitor,\n\t    // we need to track all of the tokens and rule invocations associated\n\t    // with this rule's context. This is empty for parsing w/o tree constr.\n\t    // operation because we don't the need to track the details about\n\t    // how we parse this rule.\n\t    // /\n\t    this.children = null;\n\t    this.start = null;\n\t    this.stop = null;\n\t    // The exception that forced this rule to return. If the rule successfully\n\t    // completed, this is {@code null}.\n\t    this.exception = null;\n\t}\n\t\n\tParserRuleContext.prototype = Object.create(RuleContext.prototype);\n\tParserRuleContext.prototype.constructor = ParserRuleContext;\n\t\n\t// * COPY a ctx (I'm deliberately not using copy constructor)///\n\tParserRuleContext.prototype.copyFrom = function(ctx) {\n\t    // from RuleContext\n\t    this.parentCtx = ctx.parentCtx;\n\t    this.invokingState = ctx.invokingState;\n\t    this.children = null;\n\t    this.start = ctx.start;\n\t    this.stop = ctx.stop;\n\t};\n\t\n\t// Double dispatch methods for listeners\n\tParserRuleContext.prototype.enterRule = function(listener) {\n\t};\n\t\n\tParserRuleContext.prototype.exitRule = function(listener) {\n\t};\n\t\n\t// * Does not set parent link; other add methods do that///\n\tParserRuleContext.prototype.addChild = function(child) {\n\t    if (this.children === null) {\n\t        this.children = [];\n\t    }\n\t    this.children.push(child);\n\t    return child;\n\t};\n\t\n\t// * Used by enterOuterAlt to toss out a RuleContext previously added as\n\t// we entered a rule. If we have // label, we will need to remove\n\t// generic ruleContext object.\n\t// /\n\tParserRuleContext.prototype.removeLastChild = function() {\n\t    if (this.children !== null) {\n\t        this.children.pop();\n\t    }\n\t};\n\t\n\tParserRuleContext.prototype.addTokenNode = function(token) {\n\t    var node = new TerminalNodeImpl(token);\n\t    this.addChild(node);\n\t    node.parentCtx = this;\n\t    return node;\n\t};\n\t\n\tParserRuleContext.prototype.addErrorNode = function(badToken) {\n\t    var node = new ErrorNodeImpl(badToken);\n\t    this.addChild(node);\n\t    node.parentCtx = this;\n\t    return node;\n\t};\n\t\n\tParserRuleContext.prototype.getChild = function(i, type) {\n\t\ttype = type || null;\n\t\tif (type === null) {\n\t\t\treturn this.children.length>=i ? this.children[i] : null;\n\t\t} else {\n\t\t\tfor(var j=0; j<this.children.length; j++) {\n\t\t\t\tvar child = this.children[j];\n\t\t\t\tif(child instanceof type) {\n\t\t\t\t\tif(i===0) {\n\t\t\t\t\t\treturn child;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ti -= 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn null;\n\t    }\n\t};\n\t\n\t\n\tParserRuleContext.prototype.getToken = function(ttype, i) {\n\t\tfor(var j=0; j<this.children.length; j++) {\n\t\t\tvar child = this.children[j];\n\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\tif(i===0) {\n\t\t\t\t\t\treturn child;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ti -= 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t        }\n\t\t}\n\t    return null;\n\t};\n\t\n\tParserRuleContext.prototype.getTokens = function(ttype ) {\n\t    if (this.children=== null) {\n\t        return [];\n\t    } else {\n\t\t\tvar tokens = [];\n\t\t\tfor(var j=0; j<this.children.length; j++) {\n\t\t\t\tvar child = this.children[j];\n\t\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\t\ttokens.push(child);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn tokens;\n\t    }\n\t};\n\t\n\tParserRuleContext.prototype.getTypedRuleContext = function(ctxType, i) {\n\t    return this.getChild(i, ctxType);\n\t};\n\t\n\tParserRuleContext.prototype.getTypedRuleContexts = function(ctxType) {\n\t    if (this.children=== null) {\n\t        return [];\n\t    } else {\n\t\t\tvar contexts = [];\n\t\t\tfor(var j=0; j<this.children.length; j++) {\n\t\t\t\tvar child = this.children[j];\n\t\t\t\tif (child instanceof ctxType) {\n\t\t\t\t\tcontexts.push(child);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn contexts;\n\t\t}\n\t};\n\t\n\tParserRuleContext.prototype.getChildCount = function() {\n\t\tif (this.children=== null) {\n\t\t\treturn 0;\n\t\t} else {\n\t\t\treturn this.children.length;\n\t\t}\n\t};\n\t\n\tParserRuleContext.prototype.getSourceInterval = function() {\n\t    if( this.start === null || this.stop === null) {\n\t        return INVALID_INTERVAL;\n\t    } else {\n\t        return new Interval(this.start.tokenIndex, this.stop.tokenIndex);\n\t    }\n\t};\n\t\n\tRuleContext.EMPTY = new ParserRuleContext();\n\t\n\tfunction InterpreterRuleContext(parent, invokingStateNumber, ruleIndex) {\n\t\tParserRuleContext.call(parent, invokingStateNumber);\n\t    this.ruleIndex = ruleIndex;\n\t    return this;\n\t}\n\t\n\tInterpreterRuleContext.prototype = Object.create(ParserRuleContext.prototype);\n\tInterpreterRuleContext.prototype.constructor = InterpreterRuleContext;\n\t\n\texports.ParserRuleContext = ParserRuleContext;\n\n/***/ },\n/* 20 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2013 Terence Parr\n\t//  Copyright (c) 2013 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\tvar Token = __webpack_require__(9).Token;\n\tvar ATN = __webpack_require__(6).ATN;\n\tvar ATNType = __webpack_require__(21).ATNType;\n\tvar ATNStates = __webpack_require__(11);\n\tvar ATNState = ATNStates.ATNState;\n\tvar BasicState = ATNStates.BasicState;\n\tvar DecisionState = ATNStates.DecisionState;\n\tvar BlockStartState = ATNStates.BlockStartState;\n\tvar BlockEndState = ATNStates.BlockEndState;\n\tvar LoopEndState = ATNStates.LoopEndState;\n\tvar RuleStartState = ATNStates.RuleStartState;\n\tvar RuleStopState = ATNStates.RuleStopState;\n\tvar TokensStartState = ATNStates.TokensStartState;\n\tvar PlusLoopbackState = ATNStates.PlusLoopbackState;\n\tvar StarLoopbackState = ATNStates.StarLoopbackState;\n\tvar StarLoopEntryState = ATNStates.StarLoopEntryState;\n\tvar PlusBlockStartState = ATNStates.PlusBlockStartState;\n\tvar StarBlockStartState = ATNStates.StarBlockStartState;\n\tvar BasicBlockStartState = ATNStates.BasicBlockStartState;\n\tvar Transitions = __webpack_require__(14);\n\tvar Transition = Transitions.Transition;\n\tvar AtomTransition = Transitions.AtomTransition;\n\tvar SetTransition = Transitions.SetTransition;\n\tvar NotSetTransition = Transitions.NotSetTransition;\n\tvar RuleTransition = Transitions.RuleTransition;\n\tvar RangeTransition = Transitions.RangeTransition;\n\tvar ActionTransition = Transitions.ActionTransition;\n\tvar EpsilonTransition = Transitions.EpsilonTransition;\n\tvar WildcardTransition = Transitions.WildcardTransition;\n\tvar PredicateTransition = Transitions.PredicateTransition;\n\tvar PrecedencePredicateTransition = Transitions.PrecedencePredicateTransition;\n\tvar IntervalSet = __webpack_require__(13).IntervalSet;\n\tvar Interval = __webpack_require__(13).Interval;\n\tvar ATNDeserializationOptions = __webpack_require__(22).ATNDeserializationOptions;\n\tvar LexerActions = __webpack_require__(23);\n\tvar LexerActionType = LexerActions.LexerActionType;\n\tvar LexerSkipAction = LexerActions.LexerSkipAction;\n\tvar LexerChannelAction = LexerActions.LexerChannelAction;\n\tvar LexerCustomAction = LexerActions.LexerCustomAction;\n\tvar LexerMoreAction = LexerActions.LexerMoreAction;\n\tvar LexerTypeAction = LexerActions.LexerTypeAction;\n\tvar LexerPushModeAction = LexerActions.LexerPushModeAction;\n\tvar LexerPopModeAction = LexerActions.LexerPopModeAction;\n\tvar LexerModeAction = LexerActions.LexerModeAction;\n\t// This is the earliest supported serialized UUID.\n\t// stick to serialized version for now, we don't need a UUID instance\n\tvar BASE_SERIALIZED_UUID = \"AADB8D7E-AEEF-4415-AD2B-8204D6CF042E\";\n\t\n\t// This list contains all of the currently supported UUIDs, ordered by when\n\t// the feature first appeared in this branch.\n\tvar SUPPORTED_UUIDS = [ BASE_SERIALIZED_UUID ];\n\t\n\tvar SERIALIZED_VERSION = 3;\n\t\n\t// This is the current serialized UUID.\n\tvar SERIALIZED_UUID = BASE_SERIALIZED_UUID;\n\t\n\tfunction initArray( length, value) {\n\t\tvar tmp = [];\n\t\ttmp[length-1] = value;\n\t\treturn tmp.map(function(i) {return value;});\n\t}\n\t\n\tfunction ATNDeserializer (options) {\n\t\t\n\t    if ( options=== undefined || options === null ) {\n\t        options = ATNDeserializationOptions.defaultOptions;\n\t    }\n\t    this.deserializationOptions = options;\n\t    this.stateFactories = null;\n\t    this.actionFactories = null;\n\t    \n\t    return this;\n\t}\n\t\n\t// Determines if a particular serialized representation of an ATN supports\n\t// a particular feature, identified by the {@link UUID} used for serializing\n\t// the ATN at the time the feature was first introduced.\n\t//\n\t// @param feature The {@link UUID} marking the first time the feature was\n\t// supported in the serialized ATN.\n\t// @param actualUuid The {@link UUID} of the actual serialized ATN which is\n\t// currently being deserialized.\n\t// @return {@code true} if the {@code actualUuid} value represents a\n\t// serialized ATN at or after the feature identified by {@code feature} was\n\t// introduced; otherwise, {@code false}.\n\t\n\tATNDeserializer.prototype.isFeatureSupported = function(feature, actualUuid) {\n\t    var idx1 = SUPPORTED_UUIDS.index(feature);\n\t    if (idx1<0) {\n\t        return false;\n\t    }\n\t    var idx2 = SUPPORTED_UUIDS.index(actualUuid);\n\t    return idx2 >= idx1;\n\t};\n\t\n\tATNDeserializer.prototype.deserialize = function(data) {\n\t    this.reset(data);\n\t    this.checkVersion();\n\t    this.checkUUID();\n\t    var atn = this.readATN();\n\t    this.readStates(atn);\n\t    this.readRules(atn);\n\t    this.readModes(atn);\n\t    var sets = this.readSets(atn);\n\t    this.readEdges(atn, sets);\n\t    this.readDecisions(atn);\n\t    this.readLexerActions(atn);\n\t    this.markPrecedenceDecisions(atn);\n\t    this.verifyATN(atn);\n\t    if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATNType.PARSER ) {\n\t        this.generateRuleBypassTransitions(atn);\n\t        // re-verify after modification\n\t        this.verifyATN(atn);\n\t    }\n\t    return atn;\n\t};\n\t\n\tATNDeserializer.prototype.reset = function(data) {\n\t\tvar adjust = function(c) {\n\t        var v = c.charCodeAt(0);\n\t        return v>1  ? v-2 : -1;\n\t\t};\n\t    var temp = data.split(\"\").map(adjust);\n\t    // don't adjust the first value since that's the version number\n\t    temp[0] = data.charCodeAt(0);\n\t    this.data = temp;\n\t    this.pos = 0;\n\t};\n\t\n\tATNDeserializer.prototype.checkVersion = function() {\n\t    var version = this.readInt();\n\t    if ( version !== SERIALIZED_VERSION ) {\n\t        throw (\"Could not deserialize ATN with version \" + version + \" (expected \" + SERIALIZED_VERSION + \").\");\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.checkUUID = function() {\n\t    var uuid = this.readUUID();\n\t    if (SUPPORTED_UUIDS.indexOf(uuid)<0) {\n\t        throw (\"Could not deserialize ATN with UUID: \" + uuid +\n\t                        \" (expected \" + SERIALIZED_UUID + \" or a legacy UUID).\", uuid, SERIALIZED_UUID);\n\t    }\n\t    this.uuid = uuid;\n\t};\n\t\n\tATNDeserializer.prototype.readATN = function() {\n\t    var grammarType = this.readInt();\n\t    var maxTokenType = this.readInt();\n\t    return new ATN(grammarType, maxTokenType);\n\t};\n\t\n\tATNDeserializer.prototype.readStates = function(atn) {\n\t\tvar j, pair, stateNumber;\n\t    var loopBackStateNumbers = [];\n\t    var endStateNumbers = [];\n\t    var nstates = this.readInt();\n\t    for(var i=0; i<nstates; i++) {\n\t        var stype = this.readInt();\n\t        // ignore bad type of states\n\t        if (stype===ATNState.INVALID_TYPE) {\n\t            atn.addState(null);\n\t            continue;\n\t        }\n\t        var ruleIndex = this.readInt();\n\t        if (ruleIndex === 0xFFFF) {\n\t            ruleIndex = -1;\n\t        }\n\t        var s = this.stateFactory(stype, ruleIndex);\n\t        if (stype === ATNState.LOOP_END) { // special case\n\t            var loopBackStateNumber = this.readInt();\n\t            loopBackStateNumbers.push([s, loopBackStateNumber]);\n\t        } else if(s instanceof BlockStartState) {\n\t            var endStateNumber = this.readInt();\n\t            endStateNumbers.push([s, endStateNumber]);\n\t        }\n\t        atn.addState(s);\n\t    }\n\t    // delay the assignment of loop back and end states until we know all the\n\t\t// state instances have been initialized\n\t    for (j=0; j<loopBackStateNumbers.length; j++) {\n\t        pair = loopBackStateNumbers[j];\n\t        pair[0].loopBackState = atn.states[pair[1]];\n\t    }\n\t\n\t    for (j=0; j<endStateNumbers.length; j++) {\n\t        pair = endStateNumbers[j];\n\t        pair[0].endState = atn.states[pair[1]];\n\t    }\n\t    \n\t    var numNonGreedyStates = this.readInt();\n\t    for (j=0; j<numNonGreedyStates; j++) {\n\t        stateNumber = this.readInt();\n\t        atn.states[stateNumber].nonGreedy = true;\n\t    }\n\t\n\t    var numPrecedenceStates = this.readInt();\n\t    for (j=0; j<numPrecedenceStates; j++) {\n\t        stateNumber = this.readInt();\n\t        atn.states[stateNumber].isPrecedenceRule = true;\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.readRules = function(atn) {\n\t    var i;\n\t    var nrules = this.readInt();\n\t    if (atn.grammarType === ATNType.LEXER ) {\n\t        atn.ruleToTokenType = initArray(nrules, 0);\n\t    }\n\t    atn.ruleToStartState = initArray(nrules, 0);\n\t    for (i=0; i<nrules; i++) {\n\t        var s = this.readInt();\n\t        var startState = atn.states[s];\n\t        atn.ruleToStartState[i] = startState;\n\t        if ( atn.grammarType === ATNType.LEXER ) {\n\t            var tokenType = this.readInt();\n\t            if (tokenType === 0xFFFF) {\n\t                tokenType = Token.EOF;\n\t            }\n\t            atn.ruleToTokenType[i] = tokenType;\n\t        }\n\t    }\n\t    atn.ruleToStopState = initArray(nrules, 0);\n\t    for (i=0; i<atn.states.length; i++) {\n\t        var state = atn.states[i];\n\t        if (!(state instanceof RuleStopState)) {\n\t            continue;\n\t        }\n\t        atn.ruleToStopState[state.ruleIndex] = state;\n\t        atn.ruleToStartState[state.ruleIndex].stopState = state;\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.readModes = function(atn) {\n\t    var nmodes = this.readInt();\n\t    for (var i=0; i<nmodes; i++) {\n\t        var s = this.readInt();\n\t        atn.modeToStartState.push(atn.states[s]);\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.readSets = function(atn) {\n\t    var sets = [];\n\t    var m = this.readInt();\n\t    for (var i=0; i<m; i++) {\n\t        var iset = new IntervalSet();\n\t        sets.push(iset);\n\t        var n = this.readInt();\n\t        var containsEof = this.readInt();\n\t        if (containsEof!==0) {\n\t            iset.addOne(-1);\n\t        }\n\t        for (var j=0; j<n; j++) {\n\t            var i1 = this.readInt();\n\t            var i2 = this.readInt();\n\t            iset.addRange(i1, i2);\n\t        }\n\t    }\n\t    return sets;\n\t};\n\t\n\tATNDeserializer.prototype.readEdges = function(atn, sets) {\n\t\tvar i, j, state, trans, target;\n\t    var nedges = this.readInt();\n\t    for (i=0; i<nedges; i++) {\n\t        var src = this.readInt();\n\t        var trg = this.readInt();\n\t        var ttype = this.readInt();\n\t        var arg1 = this.readInt();\n\t        var arg2 = this.readInt();\n\t        var arg3 = this.readInt();\n\t        trans = this.edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);\n\t        var srcState = atn.states[src];\n\t        srcState.addTransition(trans);\n\t    }\n\t    // edges for rule stop states can be derived, so they aren't serialized\n\t    for (i=0; i<atn.states.length; i++) {\n\t        state = atn.states[i];\n\t        for (j=0; j<state.transitions.length; j++) {\n\t            var t = state.transitions[j];\n\t            if (!(t instanceof RuleTransition)) {\n\t                continue;\n\t            }\n\t\t\t\tvar outermostPrecedenceReturn = -1;\n\t\t\t\tif (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {\n\t\t\t\t\tif (t.precedence === 0) {\n\t\t\t\t\t\toutermostPrecedenceReturn = t.target.ruleIndex;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\n\t\t\t\ttrans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);\n\t            atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);\n\t        }\n\t    }\n\t\n\t    for (i=0; i<atn.states.length; i++) {\n\t        state = atn.states[i];\n\t        if (state instanceof BlockStartState) {\n\t            // we need to know the end state to set its start state\n\t            if (state.endState === null) {\n\t                throw (\"IllegalState\");\n\t            }\n\t            // block end states can only be associated to a single block start\n\t\t\t\t// state\n\t            if ( state.endState.startState !== null) {\n\t                throw (\"IllegalState\");\n\t            }\n\t            state.endState.startState = state;\n\t        }\n\t        if (state instanceof PlusLoopbackState) {\n\t            for (j=0; j<state.transitions.length; j++) {\n\t                target = state.transitions[j].target;\n\t                if (target instanceof PlusBlockStartState) {\n\t                    target.loopBackState = state;\n\t                }\n\t            }\n\t        } else if (state instanceof StarLoopbackState) {\n\t            for (j=0; j<state.transitions.length; j++) {\n\t                target = state.transitions[j].target;\n\t                if (target instanceof StarLoopEntryState) {\n\t                    target.loopBackState = state;\n\t                }\n\t            }\n\t        }\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.readDecisions = function(atn) {\n\t    var ndecisions = this.readInt();\n\t    for (var i=0; i<ndecisions; i++) {\n\t        var s = this.readInt();\n\t        var decState = atn.states[s];\n\t        atn.decisionToState.push(decState);\n\t        decState.decision = i;\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.readLexerActions = function(atn) {\n\t    if (atn.grammarType === ATNType.LEXER) {\n\t        var count = this.readInt();\n\t        atn.lexerActions = initArray(count, null);\n\t        for (var i=0; i<count; i++) {\n\t            var actionType = this.readInt();\n\t            var data1 = this.readInt();\n\t            if (data1 === 0xFFFF) {\n\t                data1 = -1;\n\t            }\n\t            var data2 = this.readInt();\n\t            if (data2 === 0xFFFF) {\n\t                data2 = -1;\n\t            }\n\t            var lexerAction = this.lexerActionFactory(actionType, data1, data2);\n\t            atn.lexerActions[i] = lexerAction;\n\t        }\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.generateRuleBypassTransitions = function(atn) {\n\t\tvar i;\n\t    var count = atn.ruleToStartState.length;\n\t    for(i=0; i<count; i++) {\n\t        atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;\n\t    }\n\t    for(i=0; i<count; i++) {\n\t        this.generateRuleBypassTransition(atn, i);\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.generateRuleBypassTransition = function(atn, idx) {\n\t\tvar i, state;\n\t    var bypassStart = new BasicBlockStartState();\n\t    bypassStart.ruleIndex = idx;\n\t    atn.addState(bypassStart);\n\t\n\t    var bypassStop = new BlockEndState();\n\t    bypassStop.ruleIndex = idx;\n\t    atn.addState(bypassStop);\n\t\n\t    bypassStart.endState = bypassStop;\n\t    atn.defineDecisionState(bypassStart);\n\t\n\t    bypassStop.startState = bypassStart;\n\t\n\t    var excludeTransition = null;\n\t    var endState = null;\n\t    \n\t    if (atn.ruleToStartState[idx].isPrecedenceRule) {\n\t        // wrap from the beginning of the rule to the StarLoopEntryState\n\t        endState = null;\n\t        for(i=0; i<atn.states.length; i++) {\n\t            state = atn.states[i];\n\t            if (this.stateIsEndStateFor(state, idx)) {\n\t                endState = state;\n\t                excludeTransition = state.loopBackState.transitions[0];\n\t                break;\n\t            }\n\t        }\n\t        if (excludeTransition === null) {\n\t            throw (\"Couldn't identify final state of the precedence rule prefix section.\");\n\t        }\n\t    } else {\n\t        endState = atn.ruleToStopState[idx];\n\t    }\n\t    \n\t    // all non-excluded transitions that currently target end state need to\n\t\t// target blockEnd instead\n\t    for(i=0; i<atn.states.length; i++) {\n\t        state = atn.states[i];\n\t        for(var j=0; j<state.transitions.length; j++) {\n\t            var transition = state.transitions[j];\n\t            if (transition === excludeTransition) {\n\t                continue;\n\t            }\n\t            if (transition.target === endState) {\n\t                transition.target = bypassStop;\n\t            }\n\t        }\n\t    }\n\t\n\t    // all transitions leaving the rule start state need to leave blockStart\n\t\t// instead\n\t    var ruleToStartState = atn.ruleToStartState[idx];\n\t    var count = ruleToStartState.transitions.length;\n\t    while ( count > 0) {\n\t        bypassStart.addTransition(ruleToStartState.transitions[count-1]);\n\t        ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);\n\t    }\n\t    // link the new states\n\t    atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));\n\t    bypassStop.addTransition(new EpsilonTransition(endState));\n\t\n\t    var matchState = new BasicState();\n\t    atn.addState(matchState);\n\t    matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));\n\t    bypassStart.addTransition(new EpsilonTransition(matchState));\n\t};\n\t\n\tATNDeserializer.prototype.stateIsEndStateFor = function(state, idx) {\n\t    if ( state.ruleIndex !== idx) {\n\t        return null;\n\t    }\n\t    if (!( state instanceof StarLoopEntryState)) {\n\t        return null;\n\t    }\n\t    var maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n\t    if (!( maybeLoopEndState instanceof LoopEndState)) {\n\t        return null;\n\t    }\n\t    if (maybeLoopEndState.epsilonOnlyTransitions &&\n\t        (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n\t        return state;\n\t    } else {\n\t        return null;\n\t    }\n\t};\n\t\n\t//\n\t// Analyze the {@link StarLoopEntryState} states in the specified ATN to set\n\t// the {@link StarLoopEntryState//precedenceRuleDecision} field to the\n\t// correct value.\n\t//\n\t// @param atn The ATN.\n\t//\n\tATNDeserializer.prototype.markPrecedenceDecisions = function(atn) {\n\t\tfor(var i=0; i<atn.states.length; i++) {\n\t\t\tvar state = atn.states[i];\n\t\t\tif (!( state instanceof StarLoopEntryState)) {\n\t            continue;\n\t        }\n\t        // We analyze the ATN to determine if this ATN decision state is the\n\t        // decision for the closure block that determines whether a\n\t        // precedence rule should continue or complete.\n\t        //\n\t        if ( atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {\n\t            var maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n\t            if (maybeLoopEndState instanceof LoopEndState) {\n\t                if ( maybeLoopEndState.epsilonOnlyTransitions &&\n\t                        (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n\t                    state.precedenceRuleDecision = true;\n\t                }\n\t            }\n\t        }\n\t\t}\n\t};\n\t\n\tATNDeserializer.prototype.verifyATN = function(atn) {\n\t    if (!this.deserializationOptions.verifyATN) {\n\t        return;\n\t    }\n\t    // verify assumptions\n\t\tfor(var i=0; i<atn.states.length; i++) {\n\t        var state = atn.states[i];\n\t        if (state === null) {\n\t            continue;\n\t        }\n\t        this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);\n\t        if (state instanceof PlusBlockStartState) {\n\t            this.checkCondition(state.loopBackState !== null);\n\t        } else  if (state instanceof StarLoopEntryState) {\n\t            this.checkCondition(state.loopBackState !== null);\n\t            this.checkCondition(state.transitions.length === 2);\n\t            if (state.transitions[0].target instanceof StarBlockStartState) {\n\t                this.checkCondition(state.transitions[1].target instanceof LoopEndState);\n\t                this.checkCondition(!state.nonGreedy);\n\t            } else if (state.transitions[0].target instanceof LoopEndState) {\n\t                this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);\n\t                this.checkCondition(state.nonGreedy);\n\t            } else {\n\t                throw(\"IllegalState\");\n\t            }\n\t        } else if (state instanceof StarLoopbackState) {\n\t            this.checkCondition(state.transitions.length === 1);\n\t            this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);\n\t        } else if (state instanceof LoopEndState) {\n\t            this.checkCondition(state.loopBackState !== null);\n\t        } else if (state instanceof RuleStartState) {\n\t            this.checkCondition(state.stopState !== null);\n\t        } else if (state instanceof BlockStartState) {\n\t            this.checkCondition(state.endState !== null);\n\t        } else if (state instanceof BlockEndState) {\n\t            this.checkCondition(state.startState !== null);\n\t        } else if (state instanceof DecisionState) {\n\t            this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);\n\t        } else {\n\t            this.checkCondition(state.transitions.length <= 1 || (state instanceof RuleStopState));\n\t        }\n\t\t}\n\t};\n\t\n\tATNDeserializer.prototype.checkCondition = function(condition, message) {\n\t    if (!condition) {\n\t        if (message === undefined || message===null) {\n\t            message = \"IllegalState\";\n\t        }\n\t        throw (message);\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.readInt = function() {\n\t    return this.data[this.pos++];\n\t};\n\t\n\tATNDeserializer.prototype.readInt32 = function() {\n\t    var low = this.readInt();\n\t    var high = this.readInt();\n\t    return low | (high << 16);\n\t};\n\t\n\tATNDeserializer.prototype.readLong = function() {\n\t    var low = this.readInt32();\n\t    var high = this.readInt32();\n\t    return (low & 0x00000000FFFFFFFF) | (high << 32);\n\t};\n\t\n\tfunction createByteToHex() {\n\t\tvar bth = [];\n\t\tfor (var i = 0; i < 256; i++) {\n\t\t\tbth[i] = (i + 0x100).toString(16).substr(1).toUpperCase();\n\t\t}\n\t\treturn bth;\n\t}\n\t\n\tvar byteToHex = createByteToHex();\n\t\t\n\tATNDeserializer.prototype.readUUID = function() {\n\t\tvar bb = [];\n\t\tfor(var i=7;i>=0;i--) {\n\t\t\tvar int = this.readInt();\n\t\t\t/* jshint bitwise: false */\n\t\t\tbb[(2*i)+1] = int & 0xFF;\n\t\t\tbb[2*i] = (int >> 8) & 0xFF;\n\t\t}\n\t    return byteToHex[bb[0]] + byteToHex[bb[1]] +\n\t    byteToHex[bb[2]] + byteToHex[bb[3]] + '-' +\n\t    byteToHex[bb[4]] + byteToHex[bb[5]] + '-' +\n\t    byteToHex[bb[6]] + byteToHex[bb[7]] + '-' +\n\t    byteToHex[bb[8]] + byteToHex[bb[9]] + '-' +\n\t    byteToHex[bb[10]] + byteToHex[bb[11]] +\n\t    byteToHex[bb[12]] + byteToHex[bb[13]] +\n\t    byteToHex[bb[14]] + byteToHex[bb[15]];\n\t};\n\t\n\tATNDeserializer.prototype.edgeFactory = function(atn, type, src, trg, arg1, arg2, arg3, sets) {\n\t    var target = atn.states[trg];\n\t    switch(type) {\n\t    case Transition.EPSILON:\n\t        return new EpsilonTransition(target);\n\t    case Transition.RANGE:\n\t        return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);\n\t    case Transition.RULE:\n\t        return new RuleTransition(atn.states[arg1], arg2, arg3, target);\n\t    case Transition.PREDICATE:\n\t        return new PredicateTransition(target, arg1, arg2, arg3 !== 0);\n\t    case Transition.PRECEDENCE:\n\t        return new PrecedencePredicateTransition(target, arg1);\n\t    case Transition.ATOM:\n\t        return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);\n\t    case Transition.ACTION:\n\t        return new ActionTransition(target, arg1, arg2, arg3 !== 0);\n\t    case Transition.SET:\n\t        return new SetTransition(target, sets[arg1]);\n\t    case Transition.NOT_SET:\n\t        return new NotSetTransition(target, sets[arg1]);\n\t    case Transition.WILDCARD:\n\t        return new WildcardTransition(target);\n\t    default:\n\t        throw \"The specified transition type: \" + type + \" is not valid.\";\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.stateFactory = function(type, ruleIndex) {\n\t    if (this.stateFactories === null) {\n\t        var sf = [];\n\t        sf[ATNState.INVALID_TYPE] = null;\n\t        sf[ATNState.BASIC] = function() { return new BasicState(); };\n\t        sf[ATNState.RULE_START] = function() { return new RuleStartState(); };\n\t        sf[ATNState.BLOCK_START] = function() { return new BasicBlockStartState(); };\n\t        sf[ATNState.PLUS_BLOCK_START] = function() { return new PlusBlockStartState(); };\n\t        sf[ATNState.STAR_BLOCK_START] = function() { return new StarBlockStartState(); };\n\t        sf[ATNState.TOKEN_START] = function() { return new TokensStartState(); };\n\t        sf[ATNState.RULE_STOP] = function() { return new RuleStopState(); };\n\t        sf[ATNState.BLOCK_END] = function() { return new BlockEndState(); };\n\t        sf[ATNState.STAR_LOOP_BACK] = function() { return new StarLoopbackState(); };\n\t        sf[ATNState.STAR_LOOP_ENTRY] = function() { return new StarLoopEntryState(); };\n\t        sf[ATNState.PLUS_LOOP_BACK] = function() { return new PlusLoopbackState(); };\n\t        sf[ATNState.LOOP_END] = function() { return new LoopEndState(); };\n\t        this.stateFactories = sf;\n\t    }\n\t    if (type>this.stateFactories.length || this.stateFactories[type] === null) {\n\t        throw(\"The specified state type \" + type + \" is not valid.\");\n\t    } else {\n\t        var s = this.stateFactories[type]();\n\t        if (s!==null) {\n\t            s.ruleIndex = ruleIndex;\n\t            return s;\n\t        }\n\t    }\n\t};\n\t\n\tATNDeserializer.prototype.lexerActionFactory = function(type, data1, data2) {\n\t    if (this.actionFactories === null) {\n\t        var af = [];\n\t        af[LexerActionType.CHANNEL] = function(data1, data2) { return new LexerChannelAction(data1); };\n\t        af[LexerActionType.CUSTOM] = function(data1, data2) { return new LexerCustomAction(data1, data2); };\n\t        af[LexerActionType.MODE] = function(data1, data2) { return new LexerModeAction(data1); };\n\t        af[LexerActionType.MORE] = function(data1, data2) { return LexerMoreAction.INSTANCE; };\n\t        af[LexerActionType.POP_MODE] = function(data1, data2) { return LexerPopModeAction.INSTANCE; };\n\t        af[LexerActionType.PUSH_MODE] = function(data1, data2) { return new LexerPushModeAction(data1); };\n\t        af[LexerActionType.SKIP] = function(data1, data2) { return LexerSkipAction.INSTANCE; };\n\t        af[LexerActionType.TYPE] = function(data1, data2) { return new LexerTypeAction(data1); };\n\t        this.actionFactories = af;\n\t    }\n\t    if (type>this.actionFactories.length || this.actionFactories[type] === null) {\n\t        throw(\"The specified lexer action type \" + type + \" is not valid.\");\n\t    } else {\n\t        return this.actionFactories[type](data1, data2);\n\t    }\n\t};\n\t   \n\t\n\texports.ATNDeserializer = ATNDeserializer;\n\n/***/ },\n/* 21 */\n/***/ function(module, exports) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2013 Terence Parr\n\t//  Copyright (c) 2013 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\t// Represents the type of recognizer an ATN applies to.\n\t\n\tfunction ATNType() {\n\t\t\n\t}\n\t\n\tATNType.LEXER = 0;\n\tATNType.PARSER = 1;\n\t\n\texports.ATNType = ATNType;\n\t\n\n\n/***/ },\n/* 22 */\n/***/ function(module, exports) {\n\n\t//[The \"BSD license\"]\n\t// Copyright (c) 2013 Terence Parr\n\t// Copyright (c) 2013 Sam Harwell\n\t// Copyright (c) 2014 Eric Vergnaud\n\t// All rights reserved.\n\t//\n\t// Redistribution and use in source and binary forms, with or without\n\t// modification, are permitted provided that the following conditions\n\t// are met:\n\t//\n\t// 1. Redistributions of source code must retain the above copyright\n\t//    notice, this list of conditions and the following disclaimer.\n\t// 2. Redistributions in binary form must reproduce the above copyright\n\t//    notice, this list of conditions and the following disclaimer in the\n\t//    documentation and/or other materials provided with the distribution.\n\t// 3. The name of the author may not be used to endorse or promote products\n\t//    derived from this software without specific prior written permission.\n\t//\n\t// THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t// IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t// INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t// NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t// THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\tfunction ATNDeserializationOptions(copyFrom) {\n\t\tif(copyFrom===undefined) {\n\t\t\tcopyFrom = null;\n\t\t}\n\t\tthis.readOnly = false;\n\t    this.verifyATN = copyFrom===null ? true : copyFrom.verifyATN;\n\t    this.generateRuleBypassTransitions = copyFrom===null ? false : copyFrom.generateRuleBypassTransitions;\n\t\n\t    return this;\n\t}\n\t\n\tATNDeserializationOptions.defaultOptions = new ATNDeserializationOptions();\n\tATNDeserializationOptions.defaultOptions.readOnly = true;\n\t\n\t//    def __setattr__(self, key, value):\n\t//        if key!=\"readOnly\" and self.readOnly:\n\t//            raise Exception(\"The object is read only.\")\n\t//        super(type(self), self).__setattr__(key,value)\n\t\n\texports.ATNDeserializationOptions = ATNDeserializationOptions;\n\n\n/***/ },\n/* 23 */\n/***/ function(module, exports) {\n\n\t//\n\t //[The \"BSD license\"]\n\t // Copyright (c) 2013 Terence Parr\n\t // Copyright (c) 2013 Sam Harwell\n\t // Copyright (c) 2014 Eric Vergnaud\n\t // All rights reserved.\n\t //\n\t // Redistribution and use in source and binary forms, with or without\n\t // modification, are permitted provided that the following conditions\n\t // are met:\n\t //\n\t // 1. Redistributions of source code must retain the above copyright\n\t //    notice, this list of conditions and the following disclaimer.\n\t // 2. Redistributions in binary form must reproduce the above copyright\n\t //    notice, this list of conditions and the following disclaimer in the\n\t //    documentation and/or other materials provided with the distribution.\n\t // 3. The name of the author may not be used to endorse or promote products\n\t //    derived from this software without specific prior written permission.\n\t //\n\t // THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t // IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t // OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t // IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t // INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t // NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t // THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t //\n\t\n\tfunction LexerActionType() {\n\t}\n\t\n\tLexerActionType.CHANNEL = 0;     //The type of a {@link LexerChannelAction} action.\n\tLexerActionType.CUSTOM = 1;      //The type of a {@link LexerCustomAction} action.\n\tLexerActionType.MODE = 2;        //The type of a {@link LexerModeAction} action.\n\tLexerActionType.MORE = 3;        //The type of a {@link LexerMoreAction} action.\n\tLexerActionType.POP_MODE = 4;    //The type of a {@link LexerPopModeAction} action.\n\tLexerActionType.PUSH_MODE = 5;   //The type of a {@link LexerPushModeAction} action.\n\tLexerActionType.SKIP = 6;        //The type of a {@link LexerSkipAction} action.\n\tLexerActionType.TYPE = 7;        //The type of a {@link LexerTypeAction} action.\n\t\n\tfunction LexerAction(action) {\n\t    this.actionType = action;\n\t    this.isPositionDependent = false;\n\t    return this;\n\t}\n\t\n\tLexerAction.prototype.hashString = function() {\n\t    return \"\" + this.actionType;\n\t};\n\t\n\tLexerAction.prototype.equals = function(other) {\n\t    return this === other;\n\t};\n\t\n\t\n\t\n\t//\n\t// Implements the {@code skip} lexer action by calling {@link Lexer//skip}.\n\t//\n\t// <p>The {@code skip} command does not have any parameters, so this action is\n\t// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n\tfunction LexerSkipAction() {\n\t\tLexerAction.call(this, LexerActionType.SKIP);\n\t\treturn this;\n\t}\n\t\n\tLexerSkipAction.prototype = Object.create(LexerAction.prototype);\n\tLexerSkipAction.prototype.constructor = LexerSkipAction;\n\t\n\t// Provides a singleton instance of this parameterless lexer action.\n\tLexerSkipAction.INSTANCE = new LexerSkipAction();\n\t\n\tLexerSkipAction.prototype.execute = function(lexer) {\n\t    lexer.skip();\n\t};\n\t\n\tLexerSkipAction.prototype.toString = function() {\n\t\treturn \"skip\";\n\t};\n\t\n\t//  Implements the {@code type} lexer action by calling {@link Lexer//setType}\n\t// with the assigned type.\n\tfunction LexerTypeAction(type) {\n\t\tLexerAction.call(this, LexerActionType.TYPE);\n\t\tthis.type = type;\n\t\treturn this;\n\t}\n\t\n\tLexerTypeAction.prototype = Object.create(LexerAction.prototype);\n\tLexerTypeAction.prototype.constructor = LexerTypeAction;\n\t\n\tLexerTypeAction.prototype.execute = function(lexer) {\n\t    lexer.type = this.type;\n\t};\n\t\n\tLexerTypeAction.prototype.hashString = function() {\n\t\treturn \"\" + this.actionType + this.type;\n\t};\n\t\n\t\n\tLexerTypeAction.prototype.equals = function(other) {\n\t    if(this === other) {\n\t        return true;\n\t    } else if (! (other instanceof LexerTypeAction)) {\n\t        return false;\n\t    } else {\n\t        return this.type === other.type;\n\t    }\n\t};\n\t\n\tLexerTypeAction.prototype.toString = function() {\n\t    return \"type(\" + this.type + \")\";\n\t};\n\t\n\t// Implements the {@code pushMode} lexer action by calling\n\t// {@link Lexer//pushMode} with the assigned mode.\n\tfunction LexerPushModeAction(mode) {\n\t\tLexerAction.call(this, LexerActionType.PUSH_MODE);\n\t    this.mode = mode;\n\t    return this;\n\t}\n\t\n\tLexerPushModeAction.prototype = Object.create(LexerAction.prototype);\n\tLexerPushModeAction.prototype.constructor = LexerPushModeAction;\n\t\n\t// <p>This action is implemented by calling {@link Lexer//pushMode} with the\n\t// value provided by {@link //getMode}.</p>\n\tLexerPushModeAction.prototype.execute = function(lexer) {\n\t    lexer.pushMode(this.mode);\n\t};\n\t\n\tLexerPushModeAction.prototype.hashString = function() {\n\t    return \"\" + this.actionType + this.mode;\n\t};\n\t\n\tLexerPushModeAction.prototype.equals = function(other) {\n\t    if (this === other) {\n\t        return true;\n\t    } else if (! (other instanceof LexerPushModeAction)) {\n\t        return false;\n\t    } else {\n\t        return this.mode === other.mode;\n\t    }\n\t};\n\t\n\tLexerPushModeAction.prototype.toString = function() {\n\t\treturn \"pushMode(\" + this.mode + \")\";\n\t};\n\t\n\t\n\t// Implements the {@code popMode} lexer action by calling {@link Lexer//popMode}.\n\t//\n\t// <p>The {@code popMode} command does not have any parameters, so this action is\n\t// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n\tfunction LexerPopModeAction() {\n\t\tLexerAction.call(this,LexerActionType.POP_MODE);\n\t\treturn this;\n\t}\n\t\n\tLexerPopModeAction.prototype = Object.create(LexerAction.prototype);\n\tLexerPopModeAction.prototype.constructor = LexerPopModeAction;\n\t\n\tLexerPopModeAction.INSTANCE = new LexerPopModeAction();\n\t\n\t// <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n\tLexerPopModeAction.prototype.execute = function(lexer) {\n\t    lexer.popMode();\n\t};\n\t\n\tLexerPopModeAction.prototype.toString = function() {\n\t\treturn \"popMode\";\n\t};\n\t\n\t// Implements the {@code more} lexer action by calling {@link Lexer//more}.\n\t//\n\t// <p>The {@code more} command does not have any parameters, so this action is\n\t// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n\tfunction LexerMoreAction() {\n\t\tLexerAction.call(this, LexerActionType.MORE);\n\t\treturn this;\n\t}\n\t\n\tLexerMoreAction.prototype = Object.create(LexerAction.prototype);\n\tLexerMoreAction.prototype.constructor = LexerMoreAction;\n\t\n\tLexerMoreAction.INSTANCE = new LexerMoreAction();\n\t\n\t// <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n\tLexerMoreAction.prototype.execute = function(lexer) {\n\t    lexer.more();\n\t};\n\t\n\tLexerMoreAction.prototype.toString = function() {\n\t    return \"more\";\n\t};\n\t\n\t\n\t// Implements the {@code mode} lexer action by calling {@link Lexer//mode} with\n\t// the assigned mode.\n\tfunction LexerModeAction(mode) {\n\t\tLexerAction.call(this, LexerActionType.MODE);\n\t    this.mode = mode;\n\t    return this;\n\t}\n\t\n\tLexerModeAction.prototype = Object.create(LexerAction.prototype);\n\tLexerModeAction.prototype.constructor = LexerModeAction;\n\t\n\t// <p>This action is implemented by calling {@link Lexer//mode} with the\n\t// value provided by {@link //getMode}.</p>\n\tLexerModeAction.prototype.execute = function(lexer) {\n\t    lexer.mode(this.mode);\n\t};\n\t\n\tLexerModeAction.prototype.hashString = function() {\n\t\treturn \"\" + this.actionType + this.mode;\n\t};\n\t\n\tLexerModeAction.prototype.equals = function(other) {\n\t    if (this === other) {\n\t        return true;\n\t    } else if (! (other instanceof LexerModeAction)) {\n\t        return false;\n\t    } else {\n\t        return this.mode === other.mode;\n\t    }\n\t};\n\t\n\tLexerModeAction.prototype.toString = function() {\n\t    return \"mode(\" + this.mode + \")\";\n\t};\n\t\n\t// Executes a custom lexer action by calling {@link Recognizer//action} with the\n\t// rule and action indexes assigned to the custom action. The implementation of\n\t// a custom action is added to the generated code for the lexer in an override\n\t// of {@link Recognizer//action} when the grammar is compiled.\n\t//\n\t// <p>This class may represent embedded actions created with the <code>{...}</code>\n\t// syntax in ANTLR 4, as well as actions created for lexer commands where the\n\t// command argument could not be evaluated when the grammar was compiled.</p>\n\t\n\t\n\t    // Constructs a custom lexer action with the specified rule and action\n\t    // indexes.\n\t    //\n\t    // @param ruleIndex The rule index to use for calls to\n\t    // {@link Recognizer//action}.\n\t    // @param actionIndex The action index to use for calls to\n\t    // {@link Recognizer//action}.\n\t\n\tfunction LexerCustomAction(ruleIndex, actionIndex) {\n\t\tLexerAction.call(this, LexerActionType.CUSTOM);\n\t    this.ruleIndex = ruleIndex;\n\t    this.actionIndex = actionIndex;\n\t    this.isPositionDependent = true;\n\t    return this;\n\t}\n\t\n\tLexerCustomAction.prototype = Object.create(LexerAction.prototype);\n\tLexerCustomAction.prototype.constructor = LexerCustomAction;\n\t\n\t// <p>Custom actions are implemented by calling {@link Lexer//action} with the\n\t// appropriate rule and action indexes.</p>\n\tLexerCustomAction.prototype.execute = function(lexer) {\n\t    lexer.action(null, this.ruleIndex, this.actionIndex);\n\t};\n\t\n\tLexerCustomAction.prototype.hashString = function() {\n\t    return \"\" + this.actionType + this.ruleIndex + this.actionIndex;\n\t};\n\t\n\tLexerCustomAction.prototype.equals = function(other) {\n\t    if (this === other) {\n\t        return true;\n\t    } else if (! (other instanceof LexerCustomAction)) {\n\t        return false;\n\t    } else {\n\t        return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;\n\t    }\n\t};\n\t\n\t// Implements the {@code channel} lexer action by calling\n\t// {@link Lexer//setChannel} with the assigned channel.\n\t// Constructs a new {@code channel} action with the specified channel value.\n\t// @param channel The channel value to pass to {@link Lexer//setChannel}.\n\tfunction LexerChannelAction(channel) {\n\t\tLexerAction.call(this, LexerActionType.CHANNEL);\n\t    this.channel = channel;\n\t    return this;\n\t}\n\t\n\tLexerChannelAction.prototype = Object.create(LexerAction.prototype);\n\tLexerChannelAction.prototype.constructor = LexerChannelAction;\n\t\n\t// <p>This action is implemented by calling {@link Lexer//setChannel} with the\n\t// value provided by {@link //getChannel}.</p>\n\tLexerChannelAction.prototype.execute = function(lexer) {\n\t    lexer._channel = this.channel;\n\t};\n\t\n\tLexerChannelAction.prototype.hashString = function() {\n\t    return \"\" + this.actionType + this.channel;\n\t};\n\t\n\tLexerChannelAction.prototype.equals = function(other) {\n\t    if (this === other) {\n\t        return true;\n\t    } else if (! (other instanceof LexerChannelAction)) {\n\t        return false;\n\t    } else {\n\t        return this.channel === other.channel;\n\t    }\n\t};\n\t\n\tLexerChannelAction.prototype.toString = function() {\n\t    return \"channel(\" + this.channel + \")\";\n\t};\n\t\n\t// This implementation of {@link LexerAction} is used for tracking input offsets\n\t// for position-dependent actions within a {@link LexerActionExecutor}.\n\t//\n\t// <p>This action is not serialized as part of the ATN, and is only required for\n\t// position-dependent lexer actions which appear at a location other than the\n\t// end of a rule. For more information about DFA optimizations employed for\n\t// lexer actions, see {@link LexerActionExecutor//append} and\n\t// {@link LexerActionExecutor//fixOffsetBeforeMatch}.</p>\n\t\n\t// Constructs a new indexed custom action by associating a character offset\n\t// with a {@link LexerAction}.\n\t//\n\t// <p>Note: This class is only required for lexer actions for which\n\t// {@link LexerAction//isPositionDependent} returns {@code true}.</p>\n\t//\n\t// @param offset The offset into the input {@link CharStream}, relative to\n\t// the token start index, at which the specified lexer action should be\n\t// executed.\n\t// @param action The lexer action to execute at a particular offset in the\n\t// input {@link CharStream}.\n\tfunction LexerIndexedCustomAction(offset, action) {\n\t\tLexerAction.call(this, action.actionType);\n\t    this.offset = offset;\n\t    this.action = action;\n\t    this.isPositionDependent = true;\n\t    return this;\n\t}\n\t\n\tLexerIndexedCustomAction.prototype = Object.create(LexerAction.prototype);\n\tLexerIndexedCustomAction.prototype.constructor = LexerIndexedCustomAction;\n\t\n\t// <p>This method calls {@link //execute} on the result of {@link //getAction}\n\t// using the provided {@code lexer}.</p>\n\tLexerIndexedCustomAction.prototype.execute = function(lexer) {\n\t    // assume the input stream position was properly set by the calling code\n\t    this.action.execute(lexer);\n\t};\n\t\n\tLexerIndexedCustomAction.prototype.hashString = function() {\n\t    return \"\" + this.actionType + this.offset + this.action;\n\t};\n\t\n\tLexerIndexedCustomAction.prototype.equals = function(other) {\n\t    if (this === other) {\n\t        return true;\n\t    } else if (! (other instanceof LexerIndexedCustomAction)) {\n\t        return false;\n\t    } else {\n\t        return this.offset === other.offset && this.action === other.action;\n\t    }\n\t};\n\t\n\t\n\texports.LexerActionType = LexerActionType;\n\texports.LexerSkipAction = LexerSkipAction;\n\texports.LexerChannelAction = LexerChannelAction;\n\texports.LexerCustomAction = LexerCustomAction;\n\texports.LexerIndexedCustomAction = LexerIndexedCustomAction;\n\texports.LexerMoreAction = LexerMoreAction;\n\texports.LexerTypeAction = LexerTypeAction;\n\texports.LexerPushModeAction = LexerPushModeAction;\n\texports.LexerPopModeAction = LexerPopModeAction;\n\texports.LexerModeAction = LexerModeAction;\n\n/***/ },\n/* 24 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\t// When we hit an accept state in either the DFA or the ATN, we\n\t//  have to notify the character stream to start buffering characters\n\t//  via {@link IntStream//mark} and record the current state. The current sim state\n\t//  includes the current index into the input, the current line,\n\t//  and current character position in that line. Note that the Lexer is\n\t//  tracking the starting line and characterization of the token. These\n\t//  variables track the \"state\" of the simulator when it hits an accept state.\n\t//\n\t//  <p>We track these variables separately for the DFA and ATN simulation\n\t//  because the DFA simulation often has to fail over to the ATN\n\t//  simulation. If the ATN simulation fails, we need the DFA to fall\n\t//  back to its previously accepted state, if any. If the ATN succeeds,\n\t//  then the ATN does the accept and the DFA simulator that invoked it\n\t//  can simply return the predicted token type.</p>\n\t///\n\t\n\tvar Token = __webpack_require__(9).Token;\n\tvar Lexer = __webpack_require__(25).Lexer;\n\tvar ATN = __webpack_require__(6).ATN;\n\tvar ATNSimulator = __webpack_require__(30).ATNSimulator;\n\tvar DFAState = __webpack_require__(31).DFAState;\n\tvar ATNConfigSet = __webpack_require__(32).ATNConfigSet;\n\tvar OrderedATNConfigSet = __webpack_require__(32).OrderedATNConfigSet;\n\tvar PredictionContext = __webpack_require__(15).PredictionContext;\n\tvar SingletonPredictionContext = __webpack_require__(15).SingletonPredictionContext;\n\tvar RuleStopState = __webpack_require__(11).RuleStopState;\n\tvar LexerATNConfig = __webpack_require__(10).LexerATNConfig;\n\tvar Transition = __webpack_require__(14).Transition;\n\tvar LexerActionExecutor = __webpack_require__(33).LexerActionExecutor;\n\tvar LexerNoViableAltException = __webpack_require__(29).LexerNoViableAltException;\n\t\n\tfunction resetSimState(sim) {\n\t\tsim.index = -1;\n\t\tsim.line = 0;\n\t\tsim.column = -1;\n\t\tsim.dfaState = null;\n\t}\n\t\n\tfunction SimState() {\n\t\tresetSimState(this);\n\t\treturn this;\n\t}\n\t\n\tSimState.prototype.reset = function() {\n\t\tresetSimState(this);\n\t};\n\t\n\tfunction LexerATNSimulator(recog, atn, decisionToDFA, sharedContextCache) {\n\t\tATNSimulator.call(this, atn, sharedContextCache);\n\t\tthis.decisionToDFA = decisionToDFA;\n\t\tthis.recog = recog;\n\t\t// The current token's starting index into the character stream.\n\t\t// Shared across DFA to ATN simulation in case the ATN fails and the\n\t\t// DFA did not have a previous accept state. In this case, we use the\n\t\t// ATN-generated exception object.\n\t\tthis.startIndex = -1;\n\t\t// line number 1..n within the input///\n\t\tthis.line = 1;\n\t\t// The index of the character relative to the beginning of the line\n\t\t// 0..n-1///\n\t\tthis.column = 0;\n\t\tthis.mode = Lexer.DEFAULT_MODE;\n\t\t// Used during DFA/ATN exec to record the most recent accept configuration\n\t\t// info\n\t\tthis.prevAccept = new SimState();\n\t\t// done\n\t\treturn this;\n\t}\n\t\n\tLexerATNSimulator.prototype = Object.create(ATNSimulator.prototype);\n\tLexerATNSimulator.prototype.constructor = LexerATNSimulator;\n\t\n\tLexerATNSimulator.debug = false;\n\tLexerATNSimulator.dfa_debug = false;\n\t\n\tLexerATNSimulator.MIN_DFA_EDGE = 0;\n\tLexerATNSimulator.MAX_DFA_EDGE = 127; // forces unicode to stay in ATN\n\t\n\tLexerATNSimulator.match_calls = 0;\n\t\n\tLexerATNSimulator.prototype.copyState = function(simulator) {\n\t\tthis.column = simulator.column;\n\t\tthis.line = simulator.line;\n\t\tthis.mode = simulator.mode;\n\t\tthis.startIndex = simulator.startIndex;\n\t};\n\t\n\tLexerATNSimulator.prototype.match = function(input, mode) {\n\t\tthis.match_calls += 1;\n\t\tthis.mode = mode;\n\t\tvar mark = input.mark();\n\t\ttry {\n\t\t\tthis.startIndex = input.index;\n\t\t\tthis.prevAccept.reset();\n\t\t\tvar dfa = this.decisionToDFA[mode];\n\t\t\tif (dfa.s0 === null) {\n\t\t\t\treturn this.matchATN(input);\n\t\t\t} else {\n\t\t\t\treturn this.execATN(input, dfa.s0);\n\t\t\t}\n\t\t} finally {\n\t\t\tinput.release(mark);\n\t\t}\n\t};\n\t\n\tLexerATNSimulator.prototype.reset = function() {\n\t\tthis.prevAccept.reset();\n\t\tthis.startIndex = -1;\n\t\tthis.line = 1;\n\t\tthis.column = 0;\n\t\tthis.mode = Lexer.DEFAULT_MODE;\n\t};\n\t\n\tLexerATNSimulator.prototype.matchATN = function(input) {\n\t\tvar startState = this.atn.modeToStartState[this.mode];\n\t\n\t\tif (this.debug) {\n\t\t\tconsole.log(\"matchATN mode \" + this.mode + \" start: \" + startState);\n\t\t}\n\t\tvar old_mode = this.mode;\n\t\tvar s0_closure = this.computeStartState(input, startState);\n\t\tvar suppressEdge = s0_closure.hasSemanticContext;\n\t\ts0_closure.hasSemanticContext = false;\n\t\n\t\tvar next = this.addDFAState(s0_closure);\n\t\tif (!suppressEdge) {\n\t\t\tthis.decisionToDFA[this.mode].s0 = next;\n\t\t}\n\t\n\t\tvar predict = this.execATN(input, next);\n\t\n\t\tif (this.debug) {\n\t\t\tconsole.log(\"DFA after matchATN: \" + this.decisionToDFA[old_mode].toLexerString());\n\t\t}\n\t\treturn predict;\n\t};\n\t\n\tLexerATNSimulator.prototype.execATN = function(input, ds0) {\n\t\tif (this.debug) {\n\t\t\tconsole.log(\"start state closure=\" + ds0.configs);\n\t\t}\n\t\tif (ds0.isAcceptState) {\n\t\t\t// allow zero-length tokens\n\t\t\tthis.captureSimState(this.prevAccept, input, ds0);\n\t\t}\n\t\tvar t = input.LA(1);\n\t\tvar s = ds0; // s is current/from DFA state\n\t\n\t\twhile (true) { // while more work\n\t\t\tif (this.debug) {\n\t\t\t\tconsole.log(\"execATN loop starting closure: \" + s.configs);\n\t\t\t}\n\t\n\t\t\t// As we move src->trg, src->trg, we keep track of the previous trg to\n\t\t\t// avoid looking up the DFA state again, which is expensive.\n\t\t\t// If the previous target was already part of the DFA, we might\n\t\t\t// be able to avoid doing a reach operation upon t. If s!=null,\n\t\t\t// it means that semantic predicates didn't prevent us from\n\t\t\t// creating a DFA state. Once we know s!=null, we check to see if\n\t\t\t// the DFA state has an edge already for t. If so, we can just reuse\n\t\t\t// it's configuration set; there's no point in re-computing it.\n\t\t\t// This is kind of like doing DFA simulation within the ATN\n\t\t\t// simulation because DFA simulation is really just a way to avoid\n\t\t\t// computing reach/closure sets. Technically, once we know that\n\t\t\t// we have a previously added DFA state, we could jump over to\n\t\t\t// the DFA simulator. But, that would mean popping back and forth\n\t\t\t// a lot and making things more complicated algorithmically.\n\t\t\t// This optimization makes a lot of sense for loops within DFA.\n\t\t\t// A character will take us back to an existing DFA state\n\t\t\t// that already has lots of edges out of it. e.g., .* in comments.\n\t\t\t// print(\"Target for:\" + str(s) + \" and:\" + str(t))\n\t\t\tvar target = this.getExistingTargetState(s, t);\n\t\t\t// print(\"Existing:\" + str(target))\n\t\t\tif (target === null) {\n\t\t\t\ttarget = this.computeTargetState(input, s, t);\n\t\t\t\t// print(\"Computed:\" + str(target))\n\t\t\t}\n\t\t\tif (target === ATNSimulator.ERROR) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t// If this is a consumable input element, make sure to consume before\n\t\t\t// capturing the accept state so the input index, line, and char\n\t\t\t// position accurately reflect the state of the interpreter at the\n\t\t\t// end of the token.\n\t\t\tif (t !== Token.EOF) {\n\t\t\t\tthis.consume(input);\n\t\t\t}\n\t\t\tif (target.isAcceptState) {\n\t\t\t\tthis.captureSimState(this.prevAccept, input, target);\n\t\t\t\tif (t === Token.EOF) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tt = input.LA(1);\n\t\t\ts = target; // flip; current DFA target becomes new src/from state\n\t\t}\n\t\treturn this.failOrAccept(this.prevAccept, input, s.configs, t);\n\t};\n\t\n\t// Get an existing target state for an edge in the DFA. If the target state\n\t// for the edge has not yet been computed or is otherwise not available,\n\t// this method returns {@code null}.\n\t//\n\t// @param s The current DFA state\n\t// @param t The next input symbol\n\t// @return The existing target DFA state for the given input symbol\n\t// {@code t}, or {@code null} if the target state for this edge is not\n\t// already cached\n\tLexerATNSimulator.prototype.getExistingTargetState = function(s, t) {\n\t\tif (s.edges === null || t < LexerATNSimulator.MIN_DFA_EDGE || t > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\t\treturn null;\n\t\t}\n\t\n\t\tvar target = s.edges[t - LexerATNSimulator.MIN_DFA_EDGE];\n\t\tif(target===undefined) {\n\t\t\ttarget = null;\n\t\t}\n\t\tif (this.debug && target !== null) {\n\t\t\tconsole.log(\"reuse state \" + s.stateNumber + \" edge to \" + target.stateNumber);\n\t\t}\n\t\treturn target;\n\t};\n\t\n\t// Compute a target state for an edge in the DFA, and attempt to add the\n\t// computed state and corresponding edge to the DFA.\n\t//\n\t// @param input The input stream\n\t// @param s The current DFA state\n\t// @param t The next input symbol\n\t//\n\t// @return The computed target DFA state for the given input symbol\n\t// {@code t}. If {@code t} does not lead to a valid DFA state, this method\n\t// returns {@link //ERROR}.\n\tLexerATNSimulator.prototype.computeTargetState = function(input, s, t) {\n\t\tvar reach = new OrderedATNConfigSet();\n\t\t// if we don't find an existing DFA state\n\t\t// Fill reach starting from closure, following t transitions\n\t\tthis.getReachableConfigSet(input, s.configs, reach, t);\n\t\n\t\tif (reach.items.length === 0) { // we got nowhere on t from s\n\t\t\tif (!reach.hasSemanticContext) {\n\t\t\t\t// we got nowhere on t, don't throw out this knowledge; it'd\n\t\t\t\t// cause a failover from DFA later.\n\t\t\t\tthis.addDFAEdge(s, t, ATNSimulator.ERROR);\n\t\t\t}\n\t\t\t// stop when we can't match any more char\n\t\t\treturn ATNSimulator.ERROR;\n\t\t}\n\t\t// Add an edge from s to target DFA found/created for reach\n\t\treturn this.addDFAEdge(s, t, null, reach);\n\t};\n\t\n\tLexerATNSimulator.prototype.failOrAccept = function(prevAccept, input, reach, t) {\n\t\tif (this.prevAccept.dfaState !== null) {\n\t\t\tvar lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;\n\t\t\tthis.accept(input, lexerActionExecutor, this.startIndex,\n\t\t\t\t\tprevAccept.index, prevAccept.line, prevAccept.column);\n\t\t\treturn prevAccept.dfaState.prediction;\n\t\t} else {\n\t\t\t// if no accept and EOF is first char, return EOF\n\t\t\tif (t === Token.EOF && input.index === this.startIndex) {\n\t\t\t\treturn Token.EOF;\n\t\t\t}\n\t\t\tthrow new LexerNoViableAltException(this.recog, input, this.startIndex, reach);\n\t\t}\n\t};\n\t\n\t// Given a starting configuration set, figure out all ATN configurations\n\t// we can reach upon input {@code t}. Parameter {@code reach} is a return\n\t// parameter.\n\tLexerATNSimulator.prototype.getReachableConfigSet = function(input, closure,\n\t\t\treach, t) {\n\t\t// this is used to skip processing for configs which have a lower priority\n\t\t// than a config that already reached an accept state for the same rule\n\t\tvar skipAlt = ATN.INVALID_ALT_NUMBER;\n\t\tfor (var i = 0; i < closure.items.length; i++) {\n\t\t\tvar cfg = closure.items[i];\n\t\t\tvar currentAltReachedAcceptState = (cfg.alt === skipAlt);\n\t\t\tif (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (this.debug) {\n\t\t\t\tconsole.log(\"testing %s at %s\\n\", this.getTokenName(t), cfg\n\t\t\t\t\t\t.toString(this.recog, true));\n\t\t\t}\n\t\t\tfor (var j = 0; j < cfg.state.transitions.length; j++) {\n\t\t\t\tvar trans = cfg.state.transitions[j]; // for each transition\n\t\t\t\tvar target = this.getReachableTarget(trans, t);\n\t\t\t\tif (target !== null) {\n\t\t\t\t\tvar lexerActionExecutor = cfg.lexerActionExecutor;\n\t\t\t\t\tif (lexerActionExecutor !== null) {\n\t\t\t\t\t\tlexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);\n\t\t\t\t\t}\n\t\t\t\t\tvar treatEofAsEpsilon = (t === Token.EOF);\n\t\t\t\t\tvar config = new LexerATNConfig({state:target, lexerActionExecutor:lexerActionExecutor}, cfg);\n\t\t\t\t\tif (this.closure(input, config, reach,\n\t\t\t\t\t\t\tcurrentAltReachedAcceptState, true, treatEofAsEpsilon)) {\n\t\t\t\t\t\t// any remaining configs for this alt have a lower priority\n\t\t\t\t\t\t// than the one that just reached an accept state.\n\t\t\t\t\t\tskipAlt = cfg.alt;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\t\n\tLexerATNSimulator.prototype.accept = function(input, lexerActionExecutor,\n\t\t\tstartIndex, index, line, charPos) {\n\t\tif (this.debug) {\n\t\t\tconsole.log(\"ACTION %s\\n\", lexerActionExecutor);\n\t\t}\n\t\t// seek to after last char in token\n\t\tinput.seek(index);\n\t\tthis.line = line;\n\t\tthis.column = charPos;\n\t\tif (lexerActionExecutor !== null && this.recog !== null) {\n\t\t\tlexerActionExecutor.execute(this.recog, input, startIndex);\n\t\t}\n\t};\n\t\n\tLexerATNSimulator.prototype.getReachableTarget = function(trans, t) {\n\t\tif (trans.matches(t, 0, 0xFFFE)) {\n\t\t\treturn trans.target;\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t};\n\t\n\tLexerATNSimulator.prototype.computeStartState = function(input, p) {\n\t\tvar initialContext = PredictionContext.EMPTY;\n\t\tvar configs = new OrderedATNConfigSet();\n\t\tfor (var i = 0; i < p.transitions.length; i++) {\n\t\t\tvar target = p.transitions[i].target;\n\t        var cfg = new LexerATNConfig({state:target, alt:i+1, context:initialContext}, null);\n\t\t\tthis.closure(input, cfg, configs, false, false, false);\n\t\t}\n\t\treturn configs;\n\t};\n\t\n\t// Since the alternatives within any lexer decision are ordered by\n\t// preference, this method stops pursuing the closure as soon as an accept\n\t// state is reached. After the first accept state is reached by depth-first\n\t// search from {@code config}, all other (potentially reachable) states for\n\t// this rule would have a lower priority.\n\t//\n\t// @return {@code true} if an accept state is reached, otherwise\n\t// {@code false}.\n\tLexerATNSimulator.prototype.closure = function(input, config, configs,\n\t\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon) {\n\t\tvar cfg = null;\n\t\tif (this.debug) {\n\t\t\tconsole.log(\"closure(\" + config.toString(this.recog, true) + \")\");\n\t\t}\n\t\tif (config.state instanceof RuleStopState) {\n\t\t\tif (this.debug) {\n\t\t\t\tif (this.recog !== null) {\n\t\t\t\t\tconsole.log(\"closure at %s rule stop %s\\n\", this.recog.getRuleNames()[config.state.ruleIndex], config);\n\t\t\t\t} else {\n\t\t\t\t\tconsole.log(\"closure at rule stop %s\\n\", config);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\t\tif (config.context === null || config.context.isEmpty()) {\n\t\t\t\t\tconfigs.add(config);\n\t\t\t\t\treturn true;\n\t\t\t\t} else {\n\t\t\t\t\tconfigs.add(new LexerATNConfig({ state:config.state, context:PredictionContext.EMPTY}, config));\n\t\t\t\t\tcurrentAltReachedAcceptState = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (config.context !== null && !config.context.isEmpty()) {\n\t\t\t\tfor (var i = 0; i < config.context.length; i++) {\n\t\t\t\t\tif (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\t\tvar newContext = config.context.getParent(i); // \"pop\" return state\n\t\t\t\t\t\tvar returnState = this.atn.states[config.context.getReturnState(i)];\n\t\t\t\t\t\tcfg = new LexerATNConfig({ state:returnState, context:newContext }, config);\n\t\t\t\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg,\n\t\t\t\t\t\t\t\tconfigs, currentAltReachedAcceptState, speculative,\n\t\t\t\t\t\t\t\ttreatEofAsEpsilon);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn currentAltReachedAcceptState;\n\t\t}\n\t\t// optimization\n\t\tif (!config.state.epsilonOnlyTransitions) {\n\t\t\tif (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {\n\t\t\t\tconfigs.add(config);\n\t\t\t}\n\t\t}\n\t\tfor (var j = 0; j < config.state.transitions.length; j++) {\n\t\t\tvar trans = config.state.transitions[j];\n\t\t\tcfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);\n\t\t\tif (cfg !== null) {\n\t\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg, configs,\n\t\t\t\t\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon);\n\t\t\t}\n\t\t}\n\t\treturn currentAltReachedAcceptState;\n\t};\n\t\n\t// side-effect: can alter configs.hasSemanticContext\n\tLexerATNSimulator.prototype.getEpsilonTarget = function(input, config, trans,\n\t\t\tconfigs, speculative, treatEofAsEpsilon) {\n\t\tvar cfg = null;\n\t\tif (trans.serializationType === Transition.RULE) {\n\t\t\tvar newContext = SingletonPredictionContext.create(config.context, trans.followState.stateNumber);\n\t\t\tcfg = new LexerATNConfig( { state:trans.target, context:newContext}, config);\n\t\t} else if (trans.serializationType === Transition.PRECEDENCE) {\n\t\t\tthrow \"Precedence predicates are not supported in lexers.\";\n\t\t} else if (trans.serializationType === Transition.PREDICATE) {\n\t\t\t// Track traversing semantic predicates. If we traverse,\n\t\t\t// we cannot add a DFA state for this \"reach\" computation\n\t\t\t// because the DFA would not test the predicate again in the\n\t\t\t// future. Rather than creating collections of semantic predicates\n\t\t\t// like v3 and testing them on prediction, v4 will test them on the\n\t\t\t// fly all the time using the ATN not the DFA. This is slower but\n\t\t\t// semantically it's not used that often. One of the key elements to\n\t\t\t// this predicate mechanism is not adding DFA states that see\n\t\t\t// predicates immediately afterwards in the ATN. For example,\n\t\n\t\t\t// a : ID {p1}? | ID {p2}? ;\n\t\n\t\t\t// should create the start state for rule 'a' (to save start state\n\t\t\t// competition), but should not create target of ID state. The\n\t\t\t// collection of ATN states the following ID references includes\n\t\t\t// states reached by traversing predicates. Since this is when we\n\t\t\t// test them, we cannot cash the DFA state target of ID.\n\t\n\t\t\tif (this.debug) {\n\t\t\t\tconsole.log(\"EVAL rule \" + trans.ruleIndex + \":\" + trans.predIndex);\n\t\t\t}\n\t\t\tconfigs.hasSemanticContext = true;\n\t\t\tif (this.evaluatePredicate(input, trans.ruleIndex, trans.predIndex, speculative)) {\n\t\t\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t\t\t}\n\t\t} else if (trans.serializationType === Transition.ACTION) {\n\t\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\t\t// execute actions anywhere in the start rule for a token.\n\t\t\t\t//\n\t\t\t\t// TODO: if the entry rule is invoked recursively, some\n\t\t\t\t// actions may be executed during the recursive call. The\n\t\t\t\t// problem can appear when hasEmptyPath() is true but\n\t\t\t\t// isEmpty() is false. In this case, the config needs to be\n\t\t\t\t// split into two contexts - one with just the empty path\n\t\t\t\t// and another with everything but the empty path.\n\t\t\t\t// Unfortunately, the current algorithm does not allow\n\t\t\t\t// getEpsilonTarget to return two configurations, so\n\t\t\t\t// additional modifications are needed before we can support\n\t\t\t\t// the split operation.\n\t\t\t\tvar lexerActionExecutor = LexerActionExecutor.append(config.lexerActionExecutor,\n\t\t\t\t\t\tthis.atn.lexerActions[trans.actionIndex]);\n\t\t\t\tcfg = new LexerATNConfig({ state:trans.target, lexerActionExecutor:lexerActionExecutor }, config);\n\t\t\t} else {\n\t\t\t\t// ignore actions in referenced rules\n\t\t\t\tcfg = new LexerATNConfig( { state:trans.target}, config);\n\t\t\t}\n\t\t} else if (trans.serializationType === Transition.EPSILON) {\n\t\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t\t} else if (trans.serializationType === Transition.ATOM ||\n\t\t\t\t\ttrans.serializationType === Transition.RANGE ||\n\t\t\t\t\ttrans.serializationType === Transition.SET) {\n\t\t\tif (treatEofAsEpsilon) {\n\t\t\t\tif (trans.matches(Token.EOF, 0, 0xFFFF)) {\n\t\t\t\t\tcfg = new LexerATNConfig( { state:trans.target }, config);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn cfg;\n\t};\n\t\n\t// Evaluate a predicate specified in the lexer.\n\t//\n\t// <p>If {@code speculative} is {@code true}, this method was called before\n\t// {@link //consume} for the matched character. This method should call\n\t// {@link //consume} before evaluating the predicate to ensure position\n\t// sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},\n\t// and {@link Lexer//getcolumn}, properly reflect the current\n\t// lexer state. This method should restore {@code input} and the simulator\n\t// to the original state before returning (i.e. undo the actions made by the\n\t// call to {@link //consume}.</p>\n\t//\n\t// @param input The input stream.\n\t// @param ruleIndex The rule containing the predicate.\n\t// @param predIndex The index of the predicate within the rule.\n\t// @param speculative {@code true} if the current index in {@code input} is\n\t// one character before the predicate's location.\n\t//\n\t// @return {@code true} if the specified predicate evaluates to\n\t// {@code true}.\n\t// /\n\tLexerATNSimulator.prototype.evaluatePredicate = function(input, ruleIndex,\n\t\t\tpredIndex, speculative) {\n\t\t// assume true if no recognizer was provided\n\t\tif (this.recog === null) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!speculative) {\n\t\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t\t}\n\t\tvar savedcolumn = this.column;\n\t\tvar savedLine = this.line;\n\t\tvar index = input.index;\n\t\tvar marker = input.mark();\n\t\ttry {\n\t\t\tthis.consume(input);\n\t\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t\t} finally {\n\t\t\tthis.column = savedcolumn;\n\t\t\tthis.line = savedLine;\n\t\t\tinput.seek(index);\n\t\t\tinput.release(marker);\n\t\t}\n\t};\n\t\n\tLexerATNSimulator.prototype.captureSimState = function(settings, input, dfaState) {\n\t\tsettings.index = input.index;\n\t\tsettings.line = this.line;\n\t\tsettings.column = this.column;\n\t\tsettings.dfaState = dfaState;\n\t};\n\t\n\tLexerATNSimulator.prototype.addDFAEdge = function(from_, tk, to, cfgs) {\n\t\tif (to === undefined) {\n\t\t\tto = null;\n\t\t}\n\t\tif (cfgs === undefined) {\n\t\t\tcfgs = null;\n\t\t}\n\t\tif (to === null && cfgs !== null) {\n\t\t\t// leading to this call, ATNConfigSet.hasSemanticContext is used as a\n\t\t\t// marker indicating dynamic predicate evaluation makes this edge\n\t\t\t// dependent on the specific input sequence, so the static edge in the\n\t\t\t// DFA should be omitted. The target DFAState is still created since\n\t\t\t// execATN has the ability to resynchronize with the DFA state cache\n\t\t\t// following the predicate evaluation step.\n\t\t\t//\n\t\t\t// TJP notes: next time through the DFA, we see a pred again and eval.\n\t\t\t// If that gets us to a previously created (but dangling) DFA\n\t\t\t// state, we can continue in pure DFA mode from there.\n\t\t\t// /\n\t\t\tvar suppressEdge = cfgs.hasSemanticContext;\n\t\t\tcfgs.hasSemanticContext = false;\n\t\n\t\t\tto = this.addDFAState(cfgs);\n\t\n\t\t\tif (suppressEdge) {\n\t\t\t\treturn to;\n\t\t\t}\n\t\t}\n\t\t// add the edge\n\t\tif (tk < LexerATNSimulator.MIN_DFA_EDGE || tk > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\t\t// Only track edges within the DFA bounds\n\t\t\treturn to;\n\t\t}\n\t\tif (this.debug) {\n\t\t\tconsole.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + tk);\n\t\t}\n\t\tif (from_.edges === null) {\n\t\t\t// make room for tokens 1..n and -1 masquerading as index 0\n\t\t\tfrom_.edges = [];\n\t\t}\n\t\tfrom_.edges[tk - LexerATNSimulator.MIN_DFA_EDGE] = to; // connect\n\t\n\t\treturn to;\n\t};\n\t\n\t// Add a new DFA state if there isn't one with this set of\n\t// configurations already. This method also detects the first\n\t// configuration containing an ATN rule stop state. Later, when\n\t// traversing the DFA, we will know which rule to accept.\n\tLexerATNSimulator.prototype.addDFAState = function(configs) {\n\t\tvar proposed = new DFAState(null, configs);\n\t\tvar firstConfigWithRuleStopState = null;\n\t\tfor (var i = 0; i < configs.items.length; i++) {\n\t\t\tvar cfg = configs.items[i];\n\t\t\tif (cfg.state instanceof RuleStopState) {\n\t\t\t\tfirstConfigWithRuleStopState = cfg;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (firstConfigWithRuleStopState !== null) {\n\t\t\tproposed.isAcceptState = true;\n\t\t\tproposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;\n\t\t\tproposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];\n\t\t}\n\t\tvar hash = proposed.hashString();\n\t\tvar dfa = this.decisionToDFA[this.mode];\n\t\tvar existing = dfa.states[hash] || null;\n\t\tif (existing!==null) {\n\t\t\treturn existing;\n\t\t}\n\t\tvar newState = proposed;\n\t\tnewState.stateNumber = dfa.states.length;\n\t\tconfigs.setReadonly(true);\n\t\tnewState.configs = configs;\n\t\tdfa.states[hash] = newState;\n\t\treturn newState;\n\t};\n\t\n\tLexerATNSimulator.prototype.getDFA = function(mode) {\n\t\treturn this.decisionToDFA[mode];\n\t};\n\t\n\t// Get the text matched so far for the current token.\n\tLexerATNSimulator.prototype.getText = function(input) {\n\t\t// index is first lookahead char, don't include.\n\t\treturn input.getText(this.startIndex, input.index - 1);\n\t};\n\t\n\tLexerATNSimulator.prototype.consume = function(input) {\n\t\tvar curChar = input.LA(1);\n\t\tif (curChar === \"\\n\".charCodeAt(0)) {\n\t\t\tthis.line += 1;\n\t\t\tthis.column = 0;\n\t\t} else {\n\t\t\tthis.column += 1;\n\t\t}\n\t\tinput.consume();\n\t};\n\t\n\tLexerATNSimulator.prototype.getTokenName = function(tt) {\n\t\tif (tt === -1) {\n\t\t\treturn \"EOF\";\n\t\t} else {\n\t\t\treturn \"'\" + String.fromCharCode(tt) + \"'\";\n\t\t}\n\t};\n\t\n\texports.LexerATNSimulator = LexerATNSimulator;\n\n\n/***/ },\n/* 25 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  this SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  this SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\t// A lexer is recognizer that draws input symbols from a character stream.\n\t//  lexer grammars result in a subclass of this object. A Lexer object\n\t//  uses simplified match() and error recovery mechanisms in the interest\n\t//  of speed.\n\t///\n\t\n\tvar Token = __webpack_require__(9).Token;\n\tvar Recognizer = __webpack_require__(26).Recognizer;\n\tvar CommonTokenFactory = __webpack_require__(28).CommonTokenFactory;\n\tvar LexerNoViableAltException = __webpack_require__(29).LexerNoViableAltException;\n\t\n\tfunction TokenSource() {\n\t\treturn this;\n\t}\n\t\n\tfunction Lexer(input) {\n\t\tRecognizer.call(this);\n\t\tthis._input = input;\n\t\tthis._factory = CommonTokenFactory.DEFAULT;\n\t\tthis._tokenFactorySourcePair = [ this, input ];\n\t\n\t\tthis._interp = null; // child classes must populate this\n\t\n\t\t// The goal of all lexer rules/methods is to create a token object.\n\t\t// this is an instance variable as multiple rules may collaborate to\n\t\t// create a single token. nextToken will return this object after\n\t\t// matching lexer rule(s). If you subclass to allow multiple token\n\t\t// emissions, then set this to the last token to be matched or\n\t\t// something nonnull so that the auto token emit mechanism will not\n\t\t// emit another token.\n\t\tthis._token = null;\n\t\n\t\t// What character index in the stream did the current token start at?\n\t\t// Needed, for example, to get the text for current token. Set at\n\t\t// the start of nextToken.\n\t\tthis._tokenStartCharIndex = -1;\n\t\n\t\t// The line on which the first character of the token resides///\n\t\tthis._tokenStartLine = -1;\n\t\n\t\t// The character position of first character within the line///\n\t\tthis._tokenStartColumn = -1;\n\t\n\t\t// Once we see EOF on char stream, next token will be EOF.\n\t\t// If you have DONE : EOF ; then you see DONE EOF.\n\t\tthis._hitEOF = false;\n\t\n\t\t// The channel number for the current token///\n\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\n\t\t// The token type for the current token///\n\t\tthis._type = Token.INVALID_TYPE;\n\t\n\t\tthis._modeStack = [];\n\t\tthis._mode = Lexer.DEFAULT_MODE;\n\t\n\t\t// You can set the text for the current token to override what is in\n\t\t// the input char buffer. Use setText() or can set this instance var.\n\t\t// /\n\t\tthis._text = null;\n\t\n\t\treturn this;\n\t}\n\t\n\tLexer.prototype = Object.create(Recognizer.prototype);\n\tLexer.prototype.constructor = Lexer;\n\t\n\tLexer.DEFAULT_MODE = 0;\n\tLexer.MORE = -2;\n\tLexer.SKIP = -3;\n\t\n\tLexer.DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\n\tLexer.HIDDEN = Token.HIDDEN_CHANNEL;\n\tLexer.MIN_CHAR_VALUE = '\\u0000';\n\tLexer.MAX_CHAR_VALUE = '\\uFFFE';\n\t\n\tLexer.prototype.reset = function() {\n\t\t// wack Lexer state variables\n\t\tif (this._input !== null) {\n\t\t\tthis._input.seek(0); // rewind the input\n\t\t}\n\t\tthis._token = null;\n\t\tthis._type = Token.INVALID_TYPE;\n\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\tthis._tokenStartCharIndex = -1;\n\t\tthis._tokenStartColumn = -1;\n\t\tthis._tokenStartLine = -1;\n\t\tthis._text = null;\n\t\n\t\tthis._hitEOF = false;\n\t\tthis._mode = Lexer.DEFAULT_MODE;\n\t\tthis._modeStack = [];\n\t\n\t\tthis._interp.reset();\n\t};\n\t\n\t// Return a token from this source; i.e., match a token on the char stream.\n\tLexer.prototype.nextToken = function() {\n\t\tif (this._input === null) {\n\t\t\tthrow \"nextToken requires a non-null input stream.\";\n\t\t}\n\t\n\t\t// Mark start location in char stream so unbuffered streams are\n\t\t// guaranteed at least have text of current token\n\t\tvar tokenStartMarker = this._input.mark();\n\t\ttry {\n\t\t\twhile (true) {\n\t\t\t\tif (this._hitEOF) {\n\t\t\t\t\tthis.emitEOF();\n\t\t\t\t\treturn this._token;\n\t\t\t\t}\n\t\t\t\tthis._token = null;\n\t\t\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\t\t\tthis._tokenStartCharIndex = this._input.index;\n\t\t\t\tthis._tokenStartColumn = this._interp.column;\n\t\t\t\tthis._tokenStartLine = this._interp.line;\n\t\t\t\tthis._text = null;\n\t\t\t\tvar continueOuter = false;\n\t\t\t\twhile (true) {\n\t\t\t\t\tthis._type = Token.INVALID_TYPE;\n\t\t\t\t\tvar ttype = Lexer.SKIP;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tttype = this._interp.match(this._input, this._mode);\n\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\tthis.notifyListeners(e); // report error\n\t\t\t\t\t\tthis.recover(e);\n\t\t\t\t\t}\n\t\t\t\t\tif (this._input.LA(1) === Token.EOF) {\n\t\t\t\t\t\tthis._hitEOF = true;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type === Token.INVALID_TYPE) {\n\t\t\t\t\t\tthis._type = ttype;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type === Lexer.SKIP) {\n\t\t\t\t\t\tcontinueOuter = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type !== Lexer.MORE) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (continueOuter) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (this._token === null) {\n\t\t\t\t\tthis.emit();\n\t\t\t\t}\n\t\t\t\treturn this._token;\n\t\t\t}\n\t\t} finally {\n\t\t\t// make sure we release marker after match or\n\t\t\t// unbuffered char stream will keep buffering\n\t\t\tthis._input.release(tokenStartMarker);\n\t\t}\n\t};\n\t\n\t// Instruct the lexer to skip creating a token for current lexer rule\n\t// and look for another token. nextToken() knows to keep looking when\n\t// a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n\t// if token==null at end of any token rule, it creates one for you\n\t// and emits it.\n\t// /\n\tLexer.prototype.skip = function() {\n\t\tthis._type = Lexer.SKIP;\n\t};\n\t\n\tLexer.prototype.more = function() {\n\t\tthis._type = Lexer.MORE;\n\t};\n\t\n\tLexer.prototype.mode = function(m) {\n\t\tthis._mode = m;\n\t};\n\t\n\tLexer.prototype.pushMode = function(m) {\n\t\tif (this._interp.debug) {\n\t\t\tconsole.log(\"pushMode \" + m);\n\t\t}\n\t\tthis._modeStack.push(this._mode);\n\t\tthis.mode(m);\n\t};\n\t\n\tLexer.prototype.popMode = function() {\n\t\tif (this._modeStack.length === 0) {\n\t\t\tthrow \"Empty Stack\";\n\t\t}\n\t\tif (this._interp.debug) {\n\t\t\tconsole.log(\"popMode back to \" + this._modeStack.slice(0, -1));\n\t\t}\n\t\tthis.mode(this._modeStack.pop());\n\t\treturn this._mode;\n\t};\n\t\n\t// Set the char stream and reset the lexer\n\tObject.defineProperty(Lexer.prototype, \"inputStream\", {\n\t\tget : function() {\n\t\t\treturn this._input;\n\t\t},\n\t\tset : function(input) {\n\t\t\tthis._input = null;\n\t\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t\t\tthis.reset();\n\t\t\tthis._input = input;\n\t\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t\t}\n\t});\n\t\n\tObject.defineProperty(Lexer.prototype, \"sourceName\", {\n\t\tget : function sourceName() {\n\t\t\treturn this._input.sourceName;\n\t\t}\n\t});\n\t\n\t// By default does not support multiple emits per nextToken invocation\n\t// for efficiency reasons. Subclass and override this method, nextToken,\n\t// and getToken (to push tokens into a list and pull from that list\n\t// rather than a single variable as this implementation does).\n\t// /\n\tLexer.prototype.emitToken = function(token) {\n\t\tthis._token = token;\n\t};\n\t\n\t// The standard method called to automatically emit a token at the\n\t// outermost lexical rule. The token object should point into the\n\t// char buffer start..stop. If there is a text override in 'text',\n\t// use that to set the token's text. Override this method to emit\n\t// custom Token objects or provide a new factory.\n\t// /\n\tLexer.prototype.emit = function() {\n\t\tvar t = this._factory.create(this._tokenFactorySourcePair, this._type,\n\t\t\t\tthis._text, this._channel, this._tokenStartCharIndex, this\n\t\t\t\t\t\t.getCharIndex() - 1, this._tokenStartLine,\n\t\t\t\tthis._tokenStartColumn);\n\t\tthis.emitToken(t);\n\t\treturn t;\n\t};\n\t\n\tLexer.prototype.emitEOF = function() {\n\t\tvar cpos = this.column;\n\t\tvar lpos = this.line;\n\t\tvar eof = this._factory.create(this._tokenFactorySourcePair, Token.EOF,\n\t\t\t\tnull, Token.DEFAULT_CHANNEL, this._input.index,\n\t\t\t\tthis._input.index - 1, lpos, cpos);\n\t\tthis.emitToken(eof);\n\t\treturn eof;\n\t};\n\t\n\tObject.defineProperty(Lexer.prototype, \"type\", {\n\t\tget : function() {\n\t\t\treturn this.type;\n\t\t},\n\t\tset : function(type) {\n\t\t\tthis._type = type;\n\t\t}\n\t});\n\t\n\tObject.defineProperty(Lexer.prototype, \"line\", {\n\t\tget : function() {\n\t\t\treturn this._interp.line;\n\t\t},\n\t\tset : function(line) {\n\t\t\tthis._interp.line = line;\n\t\t}\n\t});\n\t\n\tObject.defineProperty(Lexer.prototype, \"column\", {\n\t\tget : function() {\n\t\t\treturn this._interp.column;\n\t\t},\n\t\tset : function(column) {\n\t\t\tthis._interp.column = column;\n\t\t}\n\t});\n\t\n\t\n\t// What is the index of the current character of lookahead?///\n\tLexer.prototype.getCharIndex = function() {\n\t\treturn this._input.index;\n\t};\n\t\n\t// Return the text matched so far for the current token or any text override.\n\t//Set the complete text of this token; it wipes any previous changes to the text.\n\tObject.defineProperty(Lexer.prototype, \"text\", {\n\t\tget : function() {\n\t\t\tif (this._text !== null) {\n\t\t\t\treturn this._text;\n\t\t\t} else {\n\t\t\t\treturn this._interp.getText(this._input);\n\t\t\t}\n\t\t},\n\t\tset : function(text) {\n\t\t\tthis._text = text;\n\t\t}\n\t});\n\t// Return a list of all Token objects in input char stream.\n\t// Forces load of all tokens. Does not include EOF token.\n\t// /\n\tLexer.prototype.getAllTokens = function() {\n\t\tvar tokens = [];\n\t\tvar t = this.nextToken();\n\t\twhile (t.type !== Token.EOF) {\n\t\t\ttokens.push(t);\n\t\t\tt = this.nextToken();\n\t\t}\n\t\treturn tokens;\n\t};\n\t\n\tLexer.prototype.notifyListeners = function(e) {\n\t\tvar start = this._tokenStartCharIndex;\n\t\tvar stop = this._input.index;\n\t\tvar text = this._input.getText(start, stop);\n\t\tvar msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n\t\tvar listener = this.getErrorListenerDispatch();\n\t\tlistener.syntaxError(this, null, this._tokenStartLine,\n\t\t\t\tthis._tokenStartColumn, msg, e);\n\t};\n\t\n\tLexer.prototype.getErrorDisplay = function(s) {\n\t\tvar d = [];\n\t\tfor (var i = 0; i < s.length; i++) {\n\t\t\td.push(s[i]);\n\t\t}\n\t\treturn d.join('');\n\t};\n\t\n\tLexer.prototype.getErrorDisplayForChar = function(c) {\n\t\tif (c.charCodeAt(0) === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else if (c === '\\n') {\n\t\t\treturn \"\\\\n\";\n\t\t} else if (c === '\\t') {\n\t\t\treturn \"\\\\t\";\n\t\t} else if (c === '\\r') {\n\t\t\treturn \"\\\\r\";\n\t\t} else {\n\t\t\treturn c;\n\t\t}\n\t};\n\t\n\tLexer.prototype.getCharErrorDisplay = function(c) {\n\t\treturn \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n\t};\n\t\n\t// Lexers can normally match any char in it's vocabulary after matching\n\t// a token, so do the easy thing and just kill a character and hope\n\t// it all works out. You can instead use the rule invocation stack\n\t// to do sophisticated error recovery if you are in a fragment rule.\n\t// /\n\tLexer.prototype.recover = function(re) {\n\t\tif (this._input.LA(1) !== Token.EOF) {\n\t\t\tif (re instanceof LexerNoViableAltException) {\n\t\t\t\t// skip a char and try again\n\t\t\t\tthis._interp.consume(this._input);\n\t\t\t} else {\n\t\t\t\t// TODO: Do we lose character or line position information?\n\t\t\t\tthis._input.consume();\n\t\t\t}\n\t\t}\n\t};\n\t\n\texports.Lexer = Lexer;\n\n\n/***/ },\n/* 26 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t//\n\t\n\tvar Token = __webpack_require__(9).Token;\n\tvar ConsoleErrorListener = __webpack_require__(27).ConsoleErrorListener;\n\tvar ProxyErrorListener = __webpack_require__(27).ProxyErrorListener;\n\t\n\tfunction Recognizer() {\n\t    this._listeners = [ ConsoleErrorListener.INSTANCE ];\n\t    this._interp = null;\n\t    this._stateNumber = -1;\n\t    return this;\n\t}\n\t\n\tRecognizer.tokenTypeMapCache = {};\n\tRecognizer.ruleIndexMapCache = {};\n\t\n\t\n\tRecognizer.prototype.checkVersion = function(toolVersion) {\n\t    var runtimeVersion = \"4.5.3\";\n\t    if (runtimeVersion!==toolVersion) {\n\t        console.log(\"ANTLR runtime and generated code versions disagree: \"+runtimeVersion+\"!=\"+toolVersion);\n\t    }\n\t};\n\t\n\tRecognizer.prototype.addErrorListener = function(listener) {\n\t    this._listeners.push(listener);\n\t};\n\t\n\tRecognizer.prototype.removeErrorListeners = function() {\n\t    this._listeners = [];\n\t};\n\t\n\tRecognizer.prototype.getTokenTypeMap = function() {\n\t    var tokenNames = this.getTokenNames();\n\t    if (tokenNames===null) {\n\t        throw(\"The current recognizer does not provide a list of token names.\");\n\t    }\n\t    var result = this.tokenTypeMapCache[tokenNames];\n\t    if(result===undefined) {\n\t        result = tokenNames.reduce(function(o, k, i) { o[k] = i; });\n\t        result.EOF = Token.EOF;\n\t        this.tokenTypeMapCache[tokenNames] = result;\n\t    }\n\t    return result;\n\t};\n\t\n\t// Get a map from rule names to rule indexes.\n\t//\n\t// <p>Used for XPath and tree pattern compilation.</p>\n\t//\n\tRecognizer.prototype.getRuleIndexMap = function() {\n\t    var ruleNames = this.getRuleNames();\n\t    if (ruleNames===null) {\n\t        throw(\"The current recognizer does not provide a list of rule names.\");\n\t    }\n\t    var result = this.ruleIndexMapCache[ruleNames];\n\t    if(result===undefined) {\n\t        result = ruleNames.reduce(function(o, k, i) { o[k] = i; });\n\t        this.ruleIndexMapCache[ruleNames] = result;\n\t    }\n\t    return result;\n\t};\n\t\n\tRecognizer.prototype.getTokenType = function(tokenName) {\n\t    var ttype = this.getTokenTypeMap()[tokenName];\n\t    if (ttype !==undefined) {\n\t        return ttype;\n\t    } else {\n\t        return Token.INVALID_TYPE;\n\t    }\n\t};\n\t\n\t\n\t// What is the error header, normally line/character position information?//\n\tRecognizer.prototype.getErrorHeader = function(e) {\n\t    var line = e.getOffendingToken().line;\n\t    var column = e.getOffendingToken().column;\n\t    return \"line \" + line + \":\" + column;\n\t};\n\t\n\t\n\t// How should a token be displayed in an error message? The default\n\t//  is to display just the text, but during development you might\n\t//  want to have a lot of information spit out.  Override in that case\n\t//  to use t.toString() (which, for CommonToken, dumps everything about\n\t//  the token). This is better than forcing you to override a method in\n\t//  your token objects because you don't have to go modify your lexer\n\t//  so that it creates a new Java type.\n\t//\n\t// @deprecated This method is not called by the ANTLR 4 Runtime. Specific\n\t// implementations of {@link ANTLRErrorStrategy} may provide a similar\n\t// feature when necessary. For example, see\n\t// {@link DefaultErrorStrategy//getTokenErrorDisplay}.\n\t//\n\tRecognizer.prototype.getTokenErrorDisplay = function(t) {\n\t    if (t===null) {\n\t        return \"<no token>\";\n\t    }\n\t    var s = t.text;\n\t    if (s===null) {\n\t        if (t.type===Token.EOF) {\n\t            s = \"<EOF>\";\n\t        } else {\n\t            s = \"<\" + t.type + \">\";\n\t        }\n\t    }\n\t    s = s.replace(\"\\n\",\"\\\\n\").replace(\"\\r\",\"\\\\r\").replace(\"\\t\",\"\\\\t\");\n\t    return \"'\" + s + \"'\";\n\t};\n\t\n\tRecognizer.prototype.getErrorListenerDispatch = function() {\n\t    return new ProxyErrorListener(this._listeners);\n\t};\n\t\n\t// subclass needs to override these if there are sempreds or actions\n\t// that the ATN interp needs to execute\n\tRecognizer.prototype.sempred = function(localctx, ruleIndex, actionIndex) {\n\t    return true;\n\t};\n\t\n\tRecognizer.prototype.precpred = function(localctx , precedence) {\n\t    return true;\n\t};\n\t\n\t//Indicate that the recognizer has changed internal state that is\n\t//consistent with the ATN state passed in.  This way we always know\n\t//where we are in the ATN as the parser goes along. The rule\n\t//context objects form a stack that lets us see the stack of\n\t//invoking rules. Combine this and we have complete ATN\n\t//configuration information.\n\t\n\tObject.defineProperty(Recognizer.prototype, \"state\", {\n\t\tget : function() {\n\t\t\treturn this._stateNumber;\n\t\t},\n\t\tset : function(state) {\n\t\t\tthis._stateNumber = state;\n\t\t}\n\t});\n\t\n\t\n\texports.Recognizer = Recognizer;\n\n\n/***/ },\n/* 27 */\n/***/ function(module, exports) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\t// Provides an empty default implementation of {@link ANTLRErrorListener}. The\n\t// default implementation of each method does nothing, but can be overridden as\n\t// necessary.\n\t\n\tfunction ErrorListener() {\n\t\treturn this;\n\t}\n\t\n\tErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {\n\t};\n\t\n\tErrorListener.prototype.reportAmbiguity = function(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n\t};\n\t\n\tErrorListener.prototype.reportAttemptingFullContext = function(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\t};\n\t\n\tErrorListener.prototype.reportContextSensitivity = function(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\t};\n\t\n\tfunction ConsoleErrorListener() {\n\t\tErrorListener.call(this);\n\t\treturn this;\n\t}\n\t\n\tConsoleErrorListener.prototype = Object.create(ErrorListener.prototype);\n\tConsoleErrorListener.prototype.constructor = ConsoleErrorListener;\n\t\n\t//\n\t// Provides a default instance of {@link ConsoleErrorListener}.\n\t//\n\tConsoleErrorListener.INSTANCE = new ConsoleErrorListener();\n\t\n\t//\n\t// {@inheritDoc}\n\t//\n\t// <p>\n\t// This implementation prints messages to {@link System//err} containing the\n\t// values of {@code line}, {@code charPositionInLine}, and {@code msg} using\n\t// the following format.</p>\n\t//\n\t// <pre>\n\t// line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>\n\t// </pre>\n\t//\n\tConsoleErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {\n\t    console.error(\"line \" + line + \":\" + column + \" \" + msg);\n\t};\n\t\n\tfunction ProxyErrorListener(delegates) {\n\t\tErrorListener.call(this);\n\t    if (delegates===null) {\n\t        throw \"delegates\";\n\t    }\n\t    this.delegates = delegates;\n\t\treturn this;\n\t}\n\t\n\tProxyErrorListener.prototype = Object.create(ErrorListener.prototype);\n\tProxyErrorListener.prototype.constructor = ProxyErrorListener;\n\t\n\tProxyErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {\n\t    this.delegates.map(function(d) { d.syntaxError(recognizer, offendingSymbol, line, column, msg, e); });\n\t};\n\t\n\tProxyErrorListener.prototype.reportAmbiguity = function(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n\t    this.delegates.map(function(d) { d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs); });\n\t};\n\t\n\tProxyErrorListener.prototype.reportAttemptingFullContext = function(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\t\tthis.delegates.map(function(d) { d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs); });\n\t};\n\t\n\tProxyErrorListener.prototype.reportContextSensitivity = function(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\t\tthis.delegates.map(function(d) { d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs); });\n\t};\n\t\n\texports.ErrorListener = ErrorListener;\n\texports.ConsoleErrorListener = ConsoleErrorListener;\n\texports.ProxyErrorListener = ProxyErrorListener;\n\t\n\n\n/***/ },\n/* 28 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t//\n\t\n\t//\n\t// This default implementation of {@link TokenFactory} creates\n\t// {@link CommonToken} objects.\n\t//\n\t\n\tvar CommonToken = __webpack_require__(9).CommonToken;\n\t\n\tfunction TokenFactory() {\n\t\treturn this;\n\t}\n\t\n\tfunction CommonTokenFactory(copyText) {\n\t\tTokenFactory.call(this);\n\t    // Indicates whether {@link CommonToken//setText} should be called after\n\t    // constructing tokens to explicitly set the text. This is useful for cases\n\t    // where the input stream might not be able to provide arbitrary substrings\n\t    // of text from the input after the lexer creates a token (e.g. the\n\t    // implementation of {@link CharStream//getText} in\n\t    // {@link UnbufferedCharStream} throws an\n\t    // {@link UnsupportedOperationException}). Explicitly setting the token text\n\t    // allows {@link Token//getText} to be called at any time regardless of the\n\t    // input stream implementation.\n\t    //\n\t    // <p>\n\t    // The default value is {@code false} to avoid the performance and memory\n\t    // overhead of copying text for every token unless explicitly requested.</p>\n\t    //\n\t    this.copyText = copyText===undefined ? false : copyText;\n\t\treturn this;\n\t}\n\t\n\tCommonTokenFactory.prototype = Object.create(TokenFactory.prototype);\n\tCommonTokenFactory.prototype.constructor = CommonTokenFactory;\n\t\n\t//\n\t// The default {@link CommonTokenFactory} instance.\n\t//\n\t// <p>\n\t// This token factory does not explicitly copy token text when constructing\n\t// tokens.</p>\n\t//\n\tCommonTokenFactory.DEFAULT = new CommonTokenFactory();\n\t\n\tCommonTokenFactory.prototype.create = function(source, type, text, channel, start, stop, line, column) {\n\t    var t = new CommonToken(source, type, channel, start, stop);\n\t    t.line = line;\n\t    t.column = column;\n\t    if (text !==null) {\n\t        t.text = text;\n\t    } else if (this.copyText && source[1] !==null) {\n\t        t.text = source[1].getText(start,stop);\n\t    }\n\t    return t;\n\t};\n\t\n\tCommonTokenFactory.prototype.createThin = function(type, text) {\n\t    var t = new CommonToken(null, type);\n\t    t.text = text;\n\t    return t;\n\t};\n\t\n\texports.CommonTokenFactory = CommonTokenFactory;\n\n\n/***/ },\n/* 29 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\t// The root of the ANTLR exception hierarchy. In general, ANTLR tracks just\n\t//  3 kinds of errors: prediction errors, failed predicate errors, and\n\t//  mismatched input errors. In each case, the parser knows where it is\n\t//  in the input, where it is in the ATN, the rule invocation stack,\n\t//  and what kind of problem occurred.\n\t\n\tvar PredicateTransition = __webpack_require__(14).PredicateTransition;\n\t\n\tfunction RecognitionException(params) {\n\t\tError.call(this);\n\t\tif (!!Error.captureStackTrace) {\n\t        Error.captureStackTrace(this, RecognitionException);\n\t\t} else {\n\t\t\tvar stack = new Error().stack;\n\t\t}\n\t\tthis.message = params.message;\n\t    this.recognizer = params.recognizer;\n\t    this.input = params.input;\n\t    this.ctx = params.ctx;\n\t    // The current {@link Token} when an error occurred. Since not all streams\n\t    // support accessing symbols by index, we have to track the {@link Token}\n\t    // instance itself.\n\t    this.offendingToken = null;\n\t    // Get the ATN state number the parser was in at the time the error\n\t    // occurred. For {@link NoViableAltException} and\n\t    // {@link LexerNoViableAltException} exceptions, this is the\n\t    // {@link DecisionState} number. For others, it is the state whose outgoing\n\t    // edge we couldn't match.\n\t    this.offendingState = -1;\n\t    if (this.recognizer!==null) {\n\t        this.offendingState = this.recognizer.state;\n\t    }\n\t    return this;\n\t}\n\t\n\tRecognitionException.prototype = Object.create(Error.prototype);\n\tRecognitionException.prototype.constructor = RecognitionException;\n\t\n\t// <p>If the state number is not known, this method returns -1.</p>\n\t\n\t//\n\t// Gets the set of input symbols which could potentially follow the\n\t// previously matched symbol at the time this exception was thrown.\n\t//\n\t// <p>If the set of expected tokens is not known and could not be computed,\n\t// this method returns {@code null}.</p>\n\t//\n\t// @return The set of token types that could potentially follow the current\n\t// state in the ATN, or {@code null} if the information is not available.\n\t// /\n\tRecognitionException.prototype.getExpectedTokens = function() {\n\t    if (this.recognizer!==null) {\n\t        return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);\n\t    } else {\n\t        return null;\n\t    }\n\t};\n\t\n\tRecognitionException.prototype.toString = function() {\n\t    return this.message;\n\t};\n\t\n\tfunction LexerNoViableAltException(lexer, input, startIndex, deadEndConfigs) {\n\t\tRecognitionException.call(this, {message:\"\", recognizer:lexer, input:input, ctx:null});\n\t    this.startIndex = startIndex;\n\t    this.deadEndConfigs = deadEndConfigs;\n\t    return this;\n\t}\n\t\n\tLexerNoViableAltException.prototype = Object.create(RecognitionException.prototype);\n\tLexerNoViableAltException.prototype.constructor = LexerNoViableAltException;\n\t\n\tLexerNoViableAltException.prototype.toString = function() {\n\t    var symbol = \"\";\n\t    if (this.startIndex >= 0 && this.startIndex < this.input.size) {\n\t        symbol = this.input.getText((this.startIndex,this.startIndex));\n\t    }\n\t    return \"LexerNoViableAltException\" + symbol;\n\t};\n\t\n\t// Indicates that the parser could not decide which of two or more paths\n\t// to take based upon the remaining input. It tracks the starting token\n\t// of the offending input and also knows where the parser was\n\t// in the various paths when the error. Reported by reportNoViableAlternative()\n\t//\n\tfunction NoViableAltException(recognizer, input, startToken, offendingToken, deadEndConfigs, ctx) {\n\t\tctx = ctx || recognizer._ctx;\n\t\toffendingToken = offendingToken || recognizer.getCurrentToken();\n\t\tstartToken = startToken || recognizer.getCurrentToken();\n\t\tinput = input || recognizer.getInputStream();\n\t\tRecognitionException.call(this, {message:\"\", recognizer:recognizer, input:input, ctx:ctx});\n\t    // Which configurations did we try at input.index() that couldn't match\n\t\t// input.LT(1)?//\n\t    this.deadEndConfigs = deadEndConfigs;\n\t    // The token object at the start index; the input stream might\n\t    // not be buffering tokens so get a reference to it. (At the\n\t    // time the error occurred, of course the stream needs to keep a\n\t    // buffer all of the tokens but later we might not have access to those.)\n\t    this.startToken = startToken;\n\t    this.offendingToken = offendingToken;\n\t}\n\t\n\tNoViableAltException.prototype = Object.create(RecognitionException.prototype);\n\tNoViableAltException.prototype.constructor = NoViableAltException;\n\t\n\t// This signifies any kind of mismatched input exceptions such as\n\t// when the current input does not match the expected token.\n\t//\n\tfunction InputMismatchException(recognizer) {\n\t\tRecognitionException.call(this, {message:\"\", recognizer:recognizer, input:recognizer.getInputStream(), ctx:recognizer._ctx});\n\t    this.offendingToken = recognizer.getCurrentToken();\n\t}\n\t\n\tInputMismatchException.prototype = Object.create(RecognitionException.prototype);\n\tInputMismatchException.prototype.constructor = InputMismatchException;\n\t\n\t// A semantic predicate failed during validation. Validation of predicates\n\t// occurs when normally parsing the alternative just like matching a token.\n\t// Disambiguating predicate evaluation occurs when we test a predicate during\n\t// prediction.\n\t\n\tfunction FailedPredicateException(recognizer, predicate, message) {\n\t\tRecognitionException.call(this, {message:this.formatMessage(predicate,message || null), recognizer:recognizer,\n\t                         input:recognizer.getInputStream(), ctx:recognizer._ctx});\n\t    var s = recognizer._interp.atn.states[recognizer.state];\n\t    var trans = s.transitions[0];\n\t    if (trans instanceof PredicateTransition) {\n\t        this.ruleIndex = trans.ruleIndex;\n\t        this.predicateIndex = trans.predIndex;\n\t    } else {\n\t        this.ruleIndex = 0;\n\t        this.predicateIndex = 0;\n\t    }\n\t    this.predicate = predicate;\n\t    this.offendingToken = recognizer.getCurrentToken();\n\t    return this;\n\t}\n\t\n\tFailedPredicateException.prototype = Object.create(RecognitionException.prototype);\n\tFailedPredicateException.prototype.constructor = FailedPredicateException;\n\t\n\tFailedPredicateException.prototype.formatMessage = function(predicate, message) {\n\t    if (message !==null) {\n\t        return message;\n\t    } else {\n\t        return \"failed predicate: {\" + predicate + \"}?\";\n\t    }\n\t};\n\t\n\tfunction ParseCancellationException() {\n\t\tError.call(this);\n\t\tError.captureStackTrace(this, ParseCancellationException);\n\t\treturn this;\n\t}\n\t\n\tParseCancellationException.prototype = Object.create(Error.prototype);\n\tParseCancellationException.prototype.constructor = ParseCancellationException;\n\t\n\texports.RecognitionException = RecognitionException;\n\texports.NoViableAltException = NoViableAltException;\n\texports.LexerNoViableAltException = LexerNoViableAltException;\n\texports.InputMismatchException = InputMismatchException;\n\texports.FailedPredicateException = FailedPredicateException;\n\n\n/***/ },\n/* 30 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2013 Terence Parr\n\t//  Copyright (c) 2013 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\tvar DFAState = __webpack_require__(31).DFAState;\n\tvar ATNConfigSet = __webpack_require__(32).ATNConfigSet;\n\tvar getCachedPredictionContext = __webpack_require__(15).getCachedPredictionContext;\n\t\n\tfunction ATNSimulator(atn, sharedContextCache) {\n\t\t\n\t    // The context cache maps all PredictionContext objects that are ==\n\t    //  to a single cached copy. This cache is shared across all contexts\n\t    //  in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet\n\t    //  to use only cached nodes/graphs in addDFAState(). We don't want to\n\t    //  fill this during closure() since there are lots of contexts that\n\t    //  pop up but are not used ever again. It also greatly slows down closure().\n\t    //\n\t    //  <p>This cache makes a huge difference in memory and a little bit in speed.\n\t    //  For the Java grammar on java.*, it dropped the memory requirements\n\t    //  at the end from 25M to 16M. We don't store any of the full context\n\t    //  graphs in the DFA because they are limited to local context only,\n\t    //  but apparently there's a lot of repetition there as well. We optimize\n\t    //  the config contexts before storing the config set in the DFA states\n\t    //  by literally rebuilding them with cached subgraphs only.</p>\n\t    //\n\t    //  <p>I tried a cache for use during closure operations, that was\n\t    //  whacked after each adaptivePredict(). It cost a little bit\n\t    //  more time I think and doesn't save on the overall footprint\n\t    //  so it's not worth the complexity.</p>\n\t    ///\n\t    this.atn = atn;\n\t    this.sharedContextCache = sharedContextCache;\n\t    return this;\n\t}\n\t\n\t// Must distinguish between missing edge and edge we know leads nowhere///\n\tATNSimulator.ERROR = new DFAState(0x7FFFFFFF, new ATNConfigSet());\n\t\n\t\n\tATNSimulator.prototype.getCachedContext = function(context) {\n\t    if (this.sharedContextCache ===null) {\n\t        return context;\n\t    }\n\t    var visited = {};\n\t    return getCachedPredictionContext(context, this.sharedContextCache, visited);\n\t};\n\t\n\texports.ATNSimulator = ATNSimulator;\n\n\n/***/ },\n/* 31 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\tvar ATNConfigSet = __webpack_require__(32).ATNConfigSet;\n\tvar Utils = __webpack_require__(8);\n\tvar Set = Utils.Set;\n\t\n\t// Map a predicate to a predicted alternative.///\n\t\n\tfunction PredPrediction(pred, alt) {\n\t\tthis.alt = alt;\n\t\tthis.pred = pred;\n\t\treturn this;\n\t}\n\t\n\tPredPrediction.prototype.toString = function() {\n\t\treturn \"(\" + this.pred + \", \" + this.alt + \")\";\n\t};\n\t\n\t// A DFA state represents a set of possible ATN configurations.\n\t// As Aho, Sethi, Ullman p. 117 says \"The DFA uses its state\n\t// to keep track of all possible states the ATN can be in after\n\t// reading each input symbol. That is to say, after reading\n\t// input a1a2..an, the DFA is in a state that represents the\n\t// subset T of the states of the ATN that are reachable from the\n\t// ATN's start state along some path labeled a1a2..an.\"\n\t// In conventional NFA&rarr;DFA conversion, therefore, the subset T\n\t// would be a bitset representing the set of states the\n\t// ATN could be in. We need to track the alt predicted by each\n\t// state as well, however. More importantly, we need to maintain\n\t// a stack of states, tracking the closure operations as they\n\t// jump from rule to rule, emulating rule invocations (method calls).\n\t// I have to add a stack to simulate the proper lookahead sequences for\n\t// the underlying LL grammar from which the ATN was derived.\n\t//\n\t// <p>I use a set of ATNConfig objects not simple states. An ATNConfig\n\t// is both a state (ala normal conversion) and a RuleContext describing\n\t// the chain of rules (if any) followed to arrive at that state.</p>\n\t//\n\t// <p>A DFA state may have multiple references to a particular state,\n\t// but with different ATN contexts (with same or different alts)\n\t// meaning that state was reached via a different set of rule invocations.</p>\n\t// /\n\t\n\tfunction DFAState(stateNumber, configs) {\n\t\tif (stateNumber === null) {\n\t\t\tstateNumber = -1;\n\t\t}\n\t\tif (configs === null) {\n\t\t\tconfigs = new ATNConfigSet();\n\t\t}\n\t\tthis.stateNumber = stateNumber;\n\t\tthis.configs = configs;\n\t\t// {@code edges[symbol]} points to target of symbol. Shift up by 1 so (-1)\n\t\t// {@link Token//EOF} maps to {@code edges[0]}.\n\t\tthis.edges = null;\n\t\tthis.isAcceptState = false;\n\t\t// if accept state, what ttype do we match or alt do we predict?\n\t\t// This is set to {@link ATN//INVALID_ALT_NUMBER} when {@link\n\t\t// //predicates}{@code !=null} or\n\t\t// {@link //requiresFullContext}.\n\t\tthis.prediction = 0;\n\t\tthis.lexerActionExecutor = null;\n\t\t// Indicates that this state was created during SLL prediction that\n\t\t// discovered a conflict between the configurations in the state. Future\n\t\t// {@link ParserATNSimulator//execATN} invocations immediately jumped doing\n\t\t// full context prediction if this field is true.\n\t\tthis.requiresFullContext = false;\n\t\t// During SLL parsing, this is a list of predicates associated with the\n\t\t// ATN configurations of the DFA state. When we have predicates,\n\t\t// {@link //requiresFullContext} is {@code false} since full context\n\t\t// prediction evaluates predicates\n\t\t// on-the-fly. If this is not null, then {@link //prediction} is\n\t\t// {@link ATN//INVALID_ALT_NUMBER}.\n\t\t//\n\t\t// <p>We only use these for non-{@link //requiresFullContext} but\n\t\t// conflicting states. That\n\t\t// means we know from the context (it's $ or we don't dip into outer\n\t\t// context) that it's an ambiguity not a conflict.</p>\n\t\t//\n\t\t// <p>This list is computed by {@link\n\t\t// ParserATNSimulator//predicateDFAState}.</p>\n\t\tthis.predicates = null;\n\t\treturn this;\n\t}\n\t\n\t// Get the set of all alts mentioned by all ATN configurations in this\n\t// DFA state.\n\tDFAState.prototype.getAltSet = function() {\n\t\tvar alts = new Set();\n\t\tif (this.configs !== null) {\n\t\t\tfor (var i = 0; i < this.configs.length; i++) {\n\t\t\t\tvar c = this.configs[i];\n\t\t\t\talts.add(c.alt);\n\t\t\t}\n\t\t}\n\t\tif (alts.length === 0) {\n\t\t\treturn null;\n\t\t} else {\n\t\t\treturn alts;\n\t\t}\n\t};\n\t\n\t// Two {@link DFAState} instances are equal if their ATN configuration sets\n\t// are the same. This method is used to see if a state already exists.\n\t//\n\t// <p>Because the number of alternatives and number of ATN configurations are\n\t// finite, there is a finite number of DFA states that can be processed.\n\t// This is necessary to show that the algorithm terminates.</p>\n\t//\n\t// <p>Cannot test the DFA state numbers here because in\n\t// {@link ParserATNSimulator//addDFAState} we need to know if any other state\n\t// exists that has this exact set of ATN configurations. The\n\t// {@link //stateNumber} is irrelevant.</p>\n\tDFAState.prototype.equals = function(other) {\n\t\t// compare set of ATN configurations in this set with other\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof DFAState)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn this.configs.equals(other.configs);\n\t\t}\n\t};\n\t\n\tDFAState.prototype.toString = function() {\n\t\treturn \"\" + this.stateNumber + \":\" + this.hashString();\n\t};\n\t\n\tDFAState.prototype.hashString = function() {\n\t\treturn \"\" +  this.configs +\n\t\t\t\t(this.isAcceptState ?\n\t\t\t\t\t\t\"=>\" + (this.predicates !== null ?\n\t\t\t\t\t\t\t\t\tthis.predicates :\n\t\t\t\t\t\t\t\t\tthis.prediction) :\n\t\t\t\t\t\t\"\");\n\t};\n\t\n\texports.DFAState = DFAState;\n\texports.PredPrediction = PredPrediction;\n\n\n/***/ },\n/* 32 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\t//\n\t// Specialized {@link Set}{@code <}{@link ATNConfig}{@code >} that can track\n\t// info about the set, with support for combining similar configurations using a\n\t// graph-structured stack.\n\t///\n\t\n\tvar ATN = __webpack_require__(6).ATN;\n\tvar Utils = __webpack_require__(8);\n\tvar Set = Utils.Set;\n\tvar SemanticContext = __webpack_require__(12).SemanticContext;\n\tvar merge = __webpack_require__(15).merge;\n\t\n\tfunction hashATNConfig(c) {\n\t\treturn c.shortHashString();\n\t}\n\t\n\tfunction equalATNConfigs(a, b) {\n\t\tif ( a===b ) {\n\t\t\treturn true;\n\t\t}\n\t\tif ( a===null || b===null ) {\n\t\t\treturn false;\n\t\t}\n\t\treturn a.state.stateNumber===b.state.stateNumber &&\n\t\t\ta.alt===b.alt && a.semanticContext.equals(b.semanticContext);\n\t}\n\t\n\t\n\tfunction ATNConfigSet(fullCtx) {\n\t\t//\n\t\t// The reason that we need this is because we don't want the hash map to use\n\t\t// the standard hash code and equals. We need all configurations with the\n\t\t// same\n\t\t// {@code (s,i,_,semctx)} to be equal. Unfortunately, this key effectively\n\t\t// doubles\n\t\t// the number of objects associated with ATNConfigs. The other solution is\n\t\t// to\n\t\t// use a hash table that lets us specify the equals/hashcode operation.\n\t\t// All configs but hashed by (s, i, _, pi) not including context. Wiped out\n\t\t// when we go readonly as this set becomes a DFA state.\n\t\tthis.configLookup = new Set(hashATNConfig, equalATNConfigs);\n\t\t// Indicates that this configuration set is part of a full context\n\t\t// LL prediction. It will be used to determine how to merge $. With SLL\n\t\t// it's a wildcard whereas it is not for LL context merge.\n\t\tthis.fullCtx = fullCtx === undefined ? true : fullCtx;\n\t\t// Indicates that the set of configurations is read-only. Do not\n\t\t// allow any code to manipulate the set; DFA states will point at\n\t\t// the sets and they must not change. This does not protect the other\n\t\t// fields; in particular, conflictingAlts is set after\n\t\t// we've made this readonly.\n\t\tthis.readOnly = false;\n\t\t// Track the elements as they are added to the set; supports get(i)///\n\t\tthis.configs = [];\n\t\n\t\t// TODO: these fields make me pretty uncomfortable but nice to pack up info\n\t\t// together, saves recomputation\n\t\t// TODO: can we track conflicts as they are added to save scanning configs\n\t\t// later?\n\t\tthis.uniqueAlt = 0;\n\t\tthis.conflictingAlts = null;\n\t\n\t\t// Used in parser and lexer. In lexer, it indicates we hit a pred\n\t\t// while computing a closure operation. Don't make a DFA state from this.\n\t\tthis.hasSemanticContext = false;\n\t\tthis.dipsIntoOuterContext = false;\n\t\n\t\tthis.cachedHashString = \"-1\";\n\t\n\t\treturn this;\n\t}\n\t\n\t// Adding a new config means merging contexts with existing configs for\n\t// {@code (s, i, pi, _)}, where {@code s} is the\n\t// {@link ATNConfig//state}, {@code i} is the {@link ATNConfig//alt}, and\n\t// {@code pi} is the {@link ATNConfig//semanticContext}. We use\n\t// {@code (s,i,pi)} as key.\n\t//\n\t// <p>This method updates {@link //dipsIntoOuterContext} and\n\t// {@link //hasSemanticContext} when necessary.</p>\n\t// /\n\tATNConfigSet.prototype.add = function(config, mergeCache) {\n\t\tif (mergeCache === undefined) {\n\t\t\tmergeCache = null;\n\t\t}\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tif (config.semanticContext !== SemanticContext.NONE) {\n\t\t\tthis.hasSemanticContext = true;\n\t\t}\n\t\tif (config.reachesIntoOuterContext > 0) {\n\t\t\tthis.dipsIntoOuterContext = true;\n\t\t}\n\t\tvar existing = this.configLookup.add(config);\n\t\tif (existing === config) {\n\t\t\tthis.cachedHashString = \"-1\";\n\t\t\tthis.configs.push(config); // track order here\n\t\t\treturn true;\n\t\t}\n\t\t// a previous (s,i,pi,_), merge with it and save result\n\t\tvar rootIsWildcard = !this.fullCtx;\n\t\tvar merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);\n\t\t// no need to check for existing.context, config.context in cache\n\t\t// since only way to create new graphs is \"call rule\" and here. We\n\t\t// cache at both places.\n\t\texisting.reachesIntoOuterContext = Math.max( existing.reachesIntoOuterContext, config.reachesIntoOuterContext);\n\t\t// make sure to preserve the precedence filter suppression during the merge\n\t\tif (config.precedenceFilterSuppressed) {\n\t\t\texisting.precedenceFilterSuppressed = true;\n\t\t}\n\t\texisting.context = merged; // replace context; no need to alt mapping\n\t\treturn true;\n\t};\n\t\n\tATNConfigSet.prototype.getStates = function() {\n\t\tvar states = new Set();\n\t\tfor (var i = 0; i < this.configs.length; i++) {\n\t\t\tstates.add(this.configs[i].state);\n\t\t}\n\t\treturn states;\n\t};\n\t\n\tATNConfigSet.prototype.getPredicates = function() {\n\t\tvar preds = [];\n\t\tfor (var i = 0; i < this.configs.length; i++) {\n\t\t\tvar c = this.configs[i].semanticContext;\n\t\t\tif (c !== SemanticContext.NONE) {\n\t\t\t\tpreds.push(c.semanticContext);\n\t\t\t}\n\t\t}\n\t\treturn preds;\n\t};\n\t\n\tObject.defineProperty(ATNConfigSet.prototype, \"items\", {\n\t\tget : function() {\n\t\t\treturn this.configs;\n\t\t}\n\t});\n\t\n\tATNConfigSet.prototype.optimizeConfigs = function(interpreter) {\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tif (this.configLookup.length === 0) {\n\t\t\treturn;\n\t\t}\n\t\tfor (var i = 0; i < this.configs.length; i++) {\n\t\t\tvar config = this.configs[i];\n\t\t\tconfig.context = interpreter.getCachedContext(config.context);\n\t\t}\n\t};\n\t\n\tATNConfigSet.prototype.addAll = function(coll) {\n\t\tfor (var i = 0; i < coll.length; i++) {\n\t\t\tthis.add(coll[i]);\n\t\t}\n\t\treturn false;\n\t};\n\t\n\tATNConfigSet.prototype.equals = function(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof ATNConfigSet)) {\n\t\t\treturn false;\n\t\t}\n\t\treturn this.configs !== null && this.configs.equals(other.configs) &&\n\t\t\t\tthis.fullCtx === other.fullCtx &&\n\t\t\t\tthis.uniqueAlt === other.uniqueAlt &&\n\t\t\t\tthis.conflictingAlts === other.conflictingAlts &&\n\t\t\t\tthis.hasSemanticContext === other.hasSemanticContext &&\n\t\t\t\tthis.dipsIntoOuterContext === other.dipsIntoOuterContext;\n\t};\n\t\n\tATNConfigSet.prototype.hashString = function() {\n\t\tif (this.readOnly) {\n\t\t\tif (this.cachedHashString === \"-1\") {\n\t\t\t\tthis.cachedHashString = this.hashConfigs();\n\t\t\t}\n\t\t\treturn this.cachedHashString;\n\t\t} else {\n\t\t\treturn this.hashConfigs();\n\t\t}\n\t};\n\t\n\tATNConfigSet.prototype.hashConfigs = function() {\n\t\tvar s = \"\";\n\t\tthis.configs.map(function(c) {\n\t\t\ts += c.toString();\n\t\t});\n\t\treturn s;\n\t};\n\t\n\tObject.defineProperty(ATNConfigSet.prototype, \"length\", {\n\t\tget : function() {\n\t\t\treturn this.configs.length;\n\t\t}\n\t});\n\t\n\tATNConfigSet.prototype.isEmpty = function() {\n\t\treturn this.configs.length === 0;\n\t};\n\t\n\tATNConfigSet.prototype.contains = function(item) {\n\t\tif (this.configLookup === null) {\n\t\t\tthrow \"This method is not implemented for readonly sets.\";\n\t\t}\n\t\treturn this.configLookup.contains(item);\n\t};\n\t\n\tATNConfigSet.prototype.containsFast = function(item) {\n\t\tif (this.configLookup === null) {\n\t\t\tthrow \"This method is not implemented for readonly sets.\";\n\t\t}\n\t\treturn this.configLookup.containsFast(item);\n\t};\n\t\n\tATNConfigSet.prototype.clear = function() {\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tthis.configs = [];\n\t\tthis.cachedHashString = \"-1\";\n\t\tthis.configLookup = new Set();\n\t};\n\t\n\tATNConfigSet.prototype.setReadonly = function(readOnly) {\n\t\tthis.readOnly = readOnly;\n\t\tif (readOnly) {\n\t\t\tthis.configLookup = null; // can't mod, no need for lookup cache\n\t\t}\n\t};\n\t\n\tATNConfigSet.prototype.toString = function() {\n\t\treturn Utils.arrayToString(this.configs) +\n\t\t\t(this.hasSemanticContext ? \",hasSemanticContext=\" + this.hasSemanticContext : \"\") +\n\t\t\t(this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? \",uniqueAlt=\" + this.uniqueAlt : \"\") +\n\t\t\t(this.conflictingAlts !== null ? \",conflictingAlts=\" + this.conflictingAlts : \"\") +\n\t\t\t(this.dipsIntoOuterContext ? \",dipsIntoOuterContext\" : \"\");\n\t};\n\t\n\tfunction OrderedATNConfigSet() {\n\t\tATNConfigSet.call(this);\n\t\tthis.configLookup = new Set();\n\t\treturn this;\n\t}\n\t\n\tOrderedATNConfigSet.prototype = Object.create(ATNConfigSet.prototype);\n\tOrderedATNConfigSet.prototype.constructor = OrderedATNConfigSet;\n\t\n\texports.ATNConfigSet = ATNConfigSet;\n\texports.OrderedATNConfigSet = OrderedATNConfigSet;\n\n\n/***/ },\n/* 33 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2013 Terence Parr\n\t//  Copyright (c) 2013 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\t// Represents an executor for a sequence of lexer actions which traversed during\n\t// the matching operation of a lexer rule (token).\n\t//\n\t// <p>The executor tracks position information for position-dependent lexer actions\n\t// efficiently, ensuring that actions appearing only at the end of the rule do\n\t// not cause bloating of the {@link DFA} created for the lexer.</p>\n\t\n\tvar LexerIndexedCustomAction = __webpack_require__(23).LexerIndexedCustomAction;\n\t\n\tfunction LexerActionExecutor(lexerActions) {\n\t\tthis.lexerActions = lexerActions === null ? [] : lexerActions;\n\t\t// Caches the result of {@link //hashCode} since the hash code is an element\n\t\t// of the performance-critical {@link LexerATNConfig//hashCode} operation.\n\t\tthis._hashString = lexerActions.toString(); // \"\".join([str(la) for la in\n\t\t// lexerActions]))\n\t\treturn this;\n\t}\n\t\n\t// Creates a {@link LexerActionExecutor} which executes the actions for\n\t// the input {@code lexerActionExecutor} followed by a specified\n\t// {@code lexerAction}.\n\t//\n\t// @param lexerActionExecutor The executor for actions already traversed by\n\t// the lexer while matching a token within a particular\n\t// {@link LexerATNConfig}. If this is {@code null}, the method behaves as\n\t// though it were an empty executor.\n\t// @param lexerAction The lexer action to execute after the actions\n\t// specified in {@code lexerActionExecutor}.\n\t//\n\t// @return A {@link LexerActionExecutor} for executing the combine actions\n\t// of {@code lexerActionExecutor} and {@code lexerAction}.\n\tLexerActionExecutor.append = function(lexerActionExecutor, lexerAction) {\n\t\tif (lexerActionExecutor === null) {\n\t\t\treturn new LexerActionExecutor([ lexerAction ]);\n\t\t}\n\t\tvar lexerActions = lexerActionExecutor.lexerActions.concat([ lexerAction ]);\n\t\treturn new LexerActionExecutor(lexerActions);\n\t};\n\t\n\t// Creates a {@link LexerActionExecutor} which encodes the current offset\n\t// for position-dependent lexer actions.\n\t//\n\t// <p>Normally, when the executor encounters lexer actions where\n\t// {@link LexerAction//isPositionDependent} returns {@code true}, it calls\n\t// {@link IntStream//seek} on the input {@link CharStream} to set the input\n\t// position to the <em>end</em> of the current token. This behavior provides\n\t// for efficient DFA representation of lexer actions which appear at the end\n\t// of a lexer rule, even when the lexer rule matches a variable number of\n\t// characters.</p>\n\t//\n\t// <p>Prior to traversing a match transition in the ATN, the current offset\n\t// from the token start index is assigned to all position-dependent lexer\n\t// actions which have not already been assigned a fixed offset. By storing\n\t// the offsets relative to the token start index, the DFA representation of\n\t// lexer actions which appear in the middle of tokens remains efficient due\n\t// to sharing among tokens of the same length, regardless of their absolute\n\t// position in the input stream.</p>\n\t//\n\t// <p>If the current executor already has offsets assigned to all\n\t// position-dependent lexer actions, the method returns {@code this}.</p>\n\t//\n\t// @param offset The current offset to assign to all position-dependent\n\t// lexer actions which do not already have offsets assigned.\n\t//\n\t// @return A {@link LexerActionExecutor} which stores input stream offsets\n\t// for all position-dependent lexer actions.\n\t// /\n\tLexerActionExecutor.prototype.fixOffsetBeforeMatch = function(offset) {\n\t\tvar updatedLexerActions = null;\n\t\tfor (var i = 0; i < this.lexerActions.length; i++) {\n\t\t\tif (this.lexerActions[i].isPositionDependent &&\n\t\t\t\t\t!(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {\n\t\t\t\tif (updatedLexerActions === null) {\n\t\t\t\t\tupdatedLexerActions = this.lexerActions.concat([]);\n\t\t\t\t}\n\t\t\t\tupdatedLexerActions[i] = new LexerIndexedCustomAction(offset,\n\t\t\t\t\t\tthis.lexerActions[i]);\n\t\t\t}\n\t\t}\n\t\tif (updatedLexerActions === null) {\n\t\t\treturn this;\n\t\t} else {\n\t\t\treturn new LexerActionExecutor(updatedLexerActions);\n\t\t}\n\t};\n\t\n\t// Execute the actions encapsulated by this executor within the context of a\n\t// particular {@link Lexer}.\n\t//\n\t// <p>This method calls {@link IntStream//seek} to set the position of the\n\t// {@code input} {@link CharStream} prior to calling\n\t// {@link LexerAction//execute} on a position-dependent action. Before the\n\t// method returns, the input position will be restored to the same position\n\t// it was in when the method was invoked.</p>\n\t//\n\t// @param lexer The lexer instance.\n\t// @param input The input stream which is the source for the current token.\n\t// When this method is called, the current {@link IntStream//index} for\n\t// {@code input} should be the start of the following token, i.e. 1\n\t// character past the end of the current token.\n\t// @param startIndex The token start index. This value may be passed to\n\t// {@link IntStream//seek} to set the {@code input} position to the beginning\n\t// of the token.\n\t// /\n\tLexerActionExecutor.prototype.execute = function(lexer, input, startIndex) {\n\t\tvar requiresSeek = false;\n\t\tvar stopIndex = input.index;\n\t\ttry {\n\t\t\tfor (var i = 0; i < this.lexerActions.length; i++) {\n\t\t\t\tvar lexerAction = this.lexerActions[i];\n\t\t\t\tif (lexerAction instanceof LexerIndexedCustomAction) {\n\t\t\t\t\tvar offset = lexerAction.offset;\n\t\t\t\t\tinput.seek(startIndex + offset);\n\t\t\t\t\tlexerAction = lexerAction.action;\n\t\t\t\t\trequiresSeek = (startIndex + offset) !== stopIndex;\n\t\t\t\t} else if (lexerAction.isPositionDependent) {\n\t\t\t\t\tinput.seek(stopIndex);\n\t\t\t\t\trequiresSeek = false;\n\t\t\t\t}\n\t\t\t\tlexerAction.execute(lexer);\n\t\t\t}\n\t\t} finally {\n\t\t\tif (requiresSeek) {\n\t\t\t\tinput.seek(stopIndex);\n\t\t\t}\n\t\t}\n\t};\n\t\n\tLexerActionExecutor.prototype.hashString = function() {\n\t\treturn this._hashString;\n\t};\n\t\n\tLexerActionExecutor.prototype.equals = function(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof LexerActionExecutor)) {\n\t\t\treturn false;\n\t\t} else if (this._hashString != other._hashString) {\n\t\t\treturn false;\n\t\t} else if (this.lexerActions.length != other.lexerActions.length) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tvar numActions = this.lexerActions.length\n\t\t\tfor (var idx = 0; idx < numActions; ++idx) {\n\t\t\t\tif (!this.lexerActions[idx].equals(other.lexerActions[idx])) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t};\n\t\n\texports.LexerActionExecutor = LexerActionExecutor;\n\n\n/***/ },\n/* 34 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t//\n\t\n\t//\n\t// The embodiment of the adaptive LL(*), ALL(*), parsing strategy.\n\t//\n\t// <p>\n\t// The basic complexity of the adaptive strategy makes it harder to understand.\n\t// We begin with ATN simulation to build paths in a DFA. Subsequent prediction\n\t// requests go through the DFA first. If they reach a state without an edge for\n\t// the current symbol, the algorithm fails over to the ATN simulation to\n\t// complete the DFA path for the current input (until it finds a conflict state\n\t// or uniquely predicting state).</p>\n\t//\n\t// <p>\n\t// All of that is done without using the outer context because we want to create\n\t// a DFA that is not dependent upon the rule invocation stack when we do a\n\t// prediction. One DFA works in all contexts. We avoid using context not\n\t// necessarily because it's slower, although it can be, but because of the DFA\n\t// caching problem. The closure routine only considers the rule invocation stack\n\t// created during prediction beginning in the decision rule. For example, if\n\t// prediction occurs without invoking another rule's ATN, there are no context\n\t// stacks in the configurations. When lack of context leads to a conflict, we\n\t// don't know if it's an ambiguity or a weakness in the strong LL(*) parsing\n\t// strategy (versus full LL(*)).</p>\n\t//\n\t// <p>\n\t// When SLL yields a configuration set with conflict, we rewind the input and\n\t// retry the ATN simulation, this time using full outer context without adding\n\t// to the DFA. Configuration context stacks will be the full invocation stacks\n\t// from the start rule. If we get a conflict using full context, then we can\n\t// definitively say we have a true ambiguity for that input sequence. If we\n\t// don't get a conflict, it implies that the decision is sensitive to the outer\n\t// context. (It is not context-sensitive in the sense of context-sensitive\n\t// grammars.)</p>\n\t//\n\t// <p>\n\t// The next time we reach this DFA state with an SLL conflict, through DFA\n\t// simulation, we will again retry the ATN simulation using full context mode.\n\t// This is slow because we can't save the results and have to \"interpret\" the\n\t// ATN each time we get that input.</p>\n\t//\n\t// <p>\n\t// <strong>CACHING FULL CONTEXT PREDICTIONS</strong></p>\n\t//\n\t// <p>\n\t// We could cache results from full context to predicted alternative easily and\n\t// that saves a lot of time but doesn't work in presence of predicates. The set\n\t// of visible predicates from the ATN start state changes depending on the\n\t// context, because closure can fall off the end of a rule. I tried to cache\n\t// tuples (stack context, semantic context, predicted alt) but it was slower\n\t// than interpreting and much more complicated. Also required a huge amount of\n\t// memory. The goal is not to create the world's fastest parser anyway. I'd like\n\t// to keep this algorithm simple. By launching multiple threads, we can improve\n\t// the speed of parsing across a large number of files.</p>\n\t//\n\t// <p>\n\t// There is no strict ordering between the amount of input used by SLL vs LL,\n\t// which makes it really hard to build a cache for full context. Let's say that\n\t// we have input A B C that leads to an SLL conflict with full context X. That\n\t// implies that using X we might only use A B but we could also use A B C D to\n\t// resolve conflict. Input A B C D could predict alternative 1 in one position\n\t// in the input and A B C E could predict alternative 2 in another position in\n\t// input. The conflicting SLL configurations could still be non-unique in the\n\t// full context prediction, which would lead us to requiring more input than the\n\t// original A B C.\tTo make a\tprediction cache work, we have to track\tthe exact\n\t// input\tused during the previous prediction. That amounts to a cache that maps\n\t// X to a specific DFA for that context.</p>\n\t//\n\t// <p>\n\t// Something should be done for left-recursive expression predictions. They are\n\t// likely LL(1) + pred eval. Easier to do the whole SLL unless error and retry\n\t// with full LL thing Sam does.</p>\n\t//\n\t// <p>\n\t// <strong>AVOIDING FULL CONTEXT PREDICTION</strong></p>\n\t//\n\t// <p>\n\t// We avoid doing full context retry when the outer context is empty, we did not\n\t// dip into the outer context by falling off the end of the decision state rule,\n\t// or when we force SLL mode.</p>\n\t//\n\t// <p>\n\t// As an example of the not dip into outer context case, consider as super\n\t// constructor calls versus function calls. One grammar might look like\n\t// this:</p>\n\t//\n\t// <pre>\n\t// ctorBody\n\t//   : '{' superCall? stat* '}'\n\t//   ;\n\t// </pre>\n\t//\n\t// <p>\n\t// Or, you might see something like</p>\n\t//\n\t// <pre>\n\t// stat\n\t//   : superCall ';'\n\t//   | expression ';'\n\t//   | ...\n\t//   ;\n\t// </pre>\n\t//\n\t// <p>\n\t// In both cases I believe that no closure operations will dip into the outer\n\t// context. In the first case ctorBody in the worst case will stop at the '}'.\n\t// In the 2nd case it should stop at the ';'. Both cases should stay within the\n\t// entry rule and not dip into the outer context.</p>\n\t//\n\t// <p>\n\t// <strong>PREDICATES</strong></p>\n\t//\n\t// <p>\n\t// Predicates are always evaluated if present in either SLL or LL both. SLL and\n\t// LL simulation deals with predicates differently. SLL collects predicates as\n\t// it performs closure operations like ANTLR v3 did. It delays predicate\n\t// evaluation until it reaches and accept state. This allows us to cache the SLL\n\t// ATN simulation whereas, if we had evaluated predicates on-the-fly during\n\t// closure, the DFA state configuration sets would be different and we couldn't\n\t// build up a suitable DFA.</p>\n\t//\n\t// <p>\n\t// When building a DFA accept state during ATN simulation, we evaluate any\n\t// predicates and return the sole semantically valid alternative. If there is\n\t// more than 1 alternative, we report an ambiguity. If there are 0 alternatives,\n\t// we throw an exception. Alternatives without predicates act like they have\n\t// true predicates. The simple way to think about it is to strip away all\n\t// alternatives with false predicates and choose the minimum alternative that\n\t// remains.</p>\n\t//\n\t// <p>\n\t// When we start in the DFA and reach an accept state that's predicated, we test\n\t// those and return the minimum semantically viable alternative. If no\n\t// alternatives are viable, we throw an exception.</p>\n\t//\n\t// <p>\n\t// During full LL ATN simulation, closure always evaluates predicates and\n\t// on-the-fly. This is crucial to reducing the configuration set size during\n\t// closure. It hits a landmine when parsing with the Java grammar, for example,\n\t// without this on-the-fly evaluation.</p>\n\t//\n\t// <p>\n\t// <strong>SHARING DFA</strong></p>\n\t//\n\t// <p>\n\t// All instances of the same parser share the same decision DFAs through a\n\t// static field. Each instance gets its own ATN simulator but they share the\n\t// same {@link //decisionToDFA} field. They also share a\n\t// {@link PredictionContextCache} object that makes sure that all\n\t// {@link PredictionContext} objects are shared among the DFA states. This makes\n\t// a big size difference.</p>\n\t//\n\t// <p>\n\t// <strong>THREAD SAFETY</strong></p>\n\t//\n\t// <p>\n\t// The {@link ParserATNSimulator} locks on the {@link //decisionToDFA} field when\n\t// it adds a new DFA object to that array. {@link //addDFAEdge}\n\t// locks on the DFA for the current decision when setting the\n\t// {@link DFAState//edges} field. {@link //addDFAState} locks on\n\t// the DFA for the current decision when looking up a DFA state to see if it\n\t// already exists. We must make sure that all requests to add DFA states that\n\t// are equivalent result in the same shared DFA object. This is because lots of\n\t// threads will be trying to update the DFA at once. The\n\t// {@link //addDFAState} method also locks inside the DFA lock\n\t// but this time on the shared context cache when it rebuilds the\n\t// configurations' {@link PredictionContext} objects using cached\n\t// subgraphs/nodes. No other locking occurs, even during DFA simulation. This is\n\t// safe as long as we can guarantee that all threads referencing\n\t// {@code s.edge[t]} get the same physical target {@link DFAState}, or\n\t// {@code null}. Once into the DFA, the DFA simulation does not reference the\n\t// {@link DFA//states} map. It follows the {@link DFAState//edges} field to new\n\t// targets. The DFA simulator will either find {@link DFAState//edges} to be\n\t// {@code null}, to be non-{@code null} and {@code dfa.edges[t]} null, or\n\t// {@code dfa.edges[t]} to be non-null. The\n\t// {@link //addDFAEdge} method could be racing to set the field\n\t// but in either case the DFA simulator works; if {@code null}, and requests ATN\n\t// simulation. It could also race trying to get {@code dfa.edges[t]}, but either\n\t// way it will work because it's not doing a test and set operation.</p>\n\t//\n\t// <p>\n\t// <strong>Starting with SLL then failing to combined SLL/LL (Two-Stage\n\t// Parsing)</strong></p>\n\t//\n\t// <p>\n\t// Sam pointed out that if SLL does not give a syntax error, then there is no\n\t// point in doing full LL, which is slower. We only have to try LL if we get a\n\t// syntax error. For maximum speed, Sam starts the parser set to pure SLL\n\t// mode with the {@link BailErrorStrategy}:</p>\n\t//\n\t// <pre>\n\t// parser.{@link Parser//getInterpreter() getInterpreter()}.{@link //setPredictionMode setPredictionMode}{@code (}{@link PredictionMode//SLL}{@code )};\n\t// parser.{@link Parser//setErrorHandler setErrorHandler}(new {@link BailErrorStrategy}());\n\t// </pre>\n\t//\n\t// <p>\n\t// If it does not get a syntax error, then we're done. If it does get a syntax\n\t// error, we need to retry with the combined SLL/LL strategy.</p>\n\t//\n\t// <p>\n\t// The reason this works is as follows. If there are no SLL conflicts, then the\n\t// grammar is SLL (at least for that input set). If there is an SLL conflict,\n\t// the full LL analysis must yield a set of viable alternatives which is a\n\t// subset of the alternatives reported by SLL. If the LL set is a singleton,\n\t// then the grammar is LL but not SLL. If the LL set is the same size as the SLL\n\t// set, the decision is SLL. If the LL set has size &gt; 1, then that decision\n\t// is truly ambiguous on the current input. If the LL set is smaller, then the\n\t// SLL conflict resolution might choose an alternative that the full LL would\n\t// rule out as a possibility based upon better context information. If that's\n\t// the case, then the SLL parse will definitely get an error because the full LL\n\t// analysis says it's not viable. If SLL conflict resolution chooses an\n\t// alternative within the LL set, them both SLL and LL would choose the same\n\t// alternative because they both choose the minimum of multiple conflicting\n\t// alternatives.</p>\n\t//\n\t// <p>\n\t// Let's say we have a set of SLL conflicting alternatives {@code {1, 2, 3}} and\n\t// a smaller LL set called <em>s</em>. If <em>s</em> is {@code {2, 3}}, then SLL\n\t// parsing will get an error because SLL will pursue alternative 1. If\n\t// <em>s</em> is {@code {1, 2}} or {@code {1, 3}} then both SLL and LL will\n\t// choose the same alternative because alternative one is the minimum of either\n\t// set. If <em>s</em> is {@code {2}} or {@code {3}} then SLL will get a syntax\n\t// error. If <em>s</em> is {@code {1}} then SLL will succeed.</p>\n\t//\n\t// <p>\n\t// Of course, if the input is invalid, then we will get an error for sure in\n\t// both SLL and LL parsing. Erroneous input will therefore require 2 passes over\n\t// the input.</p>\n\t//\n\t\n\tvar Utils = __webpack_require__(8);\n\tvar Set = Utils.Set;\n\tvar BitSet = Utils.BitSet;\n\tvar DoubleDict = Utils.DoubleDict;\n\tvar ATN = __webpack_require__(6).ATN;\n\tvar ATNConfig = __webpack_require__(10).ATNConfig;\n\tvar ATNConfigSet = __webpack_require__(32).ATNConfigSet;\n\tvar Token = __webpack_require__(9).Token;\n\tvar DFAState = __webpack_require__(31).DFAState;\n\tvar PredPrediction = __webpack_require__(31).PredPrediction;\n\tvar ATNSimulator = __webpack_require__(30).ATNSimulator;\n\tvar PredictionMode = __webpack_require__(35).PredictionMode;\n\tvar RuleContext = __webpack_require__(16).RuleContext;\n\tvar ParserRuleContext = __webpack_require__(19).ParserRuleContext;\n\tvar SemanticContext = __webpack_require__(12).SemanticContext;\n\tvar StarLoopEntryState = __webpack_require__(11).StarLoopEntryState;\n\tvar RuleStopState = __webpack_require__(11).RuleStopState;\n\tvar PredictionContext = __webpack_require__(15).PredictionContext;\n\tvar Interval = __webpack_require__(13).Interval;\n\tvar Transitions = __webpack_require__(14);\n\tvar Transition = Transitions.Transition;\n\tvar SetTransition = Transitions.SetTransition;\n\tvar NotSetTransition = Transitions.NotSetTransition;\n\tvar RuleTransition = Transitions.RuleTransition;\n\tvar ActionTransition = Transitions.ActionTransition;\n\tvar NoViableAltException = __webpack_require__(29).NoViableAltException;\n\t\n\tvar SingletonPredictionContext = __webpack_require__(15).SingletonPredictionContext;\n\tvar predictionContextFromRuleContext = __webpack_require__(15).predictionContextFromRuleContext;\n\t\n\tfunction ParserATNSimulator(parser, atn, decisionToDFA, sharedContextCache) {\n\t\tATNSimulator.call(this, atn, sharedContextCache);\n\t    this.parser = parser;\n\t    this.decisionToDFA = decisionToDFA;\n\t    // SLL, LL, or LL + exact ambig detection?//\n\t    this.predictionMode = PredictionMode.LL;\n\t    // LAME globals to avoid parameters!!!!! I need these down deep in predTransition\n\t    this._input = null;\n\t    this._startIndex = 0;\n\t    this._outerContext = null;\n\t    this._dfa = null;\n\t    // Each prediction operation uses a cache for merge of prediction contexts.\n\t    //  Don't keep around as it wastes huge amounts of memory. DoubleKeyMap\n\t    //  isn't synchronized but we're ok since two threads shouldn't reuse same\n\t    //  parser/atnsim object because it can only handle one input at a time.\n\t    //  This maps graphs a and b to merged result c. (a,b)&rarr;c. We can avoid\n\t    //  the merge if we ever see a and b again.  Note that (b,a)&rarr;c should\n\t    //  also be examined during cache lookup.\n\t    //\n\t    this.mergeCache = null;\n\t    return this;\n\t}\n\t\n\tParserATNSimulator.prototype = Object.create(ATNSimulator.prototype);\n\tParserATNSimulator.prototype.constructor = ParserATNSimulator;\n\t\n\tParserATNSimulator.prototype.debug = false;\n\tParserATNSimulator.prototype.debug_list_atn_decisions = false;\n\tParserATNSimulator.prototype.dfa_debug = false;\n\tParserATNSimulator.prototype.retry_debug = false;\n\t\n\t\n\tParserATNSimulator.prototype.reset = function() {\n\t};\n\t\n\tParserATNSimulator.prototype.adaptivePredict = function(input, decision, outerContext) {\n\t    if (this.debug || this.debug_list_atn_decisions) {\n\t        console.log(\"adaptivePredict decision \" + decision +\n\t                               \" exec LA(1)==\" + this.getLookaheadName(input) +\n\t                               \" line \" + input.LT(1).line + \":\" +\n\t                               input.LT(1).column);\n\t    }\n\t    this._input = input;\n\t    this._startIndex = input.index;\n\t    this._outerContext = outerContext;\n\t    \n\t    var dfa = this.decisionToDFA[decision];\n\t    this._dfa = dfa;\n\t    var m = input.mark();\n\t    var index = input.index;\n\t\n\t    // Now we are certain to have a specific decision's DFA\n\t    // But, do we still need an initial state?\n\t    try {\n\t        var s0;\n\t        if (dfa.precedenceDfa) {\n\t            // the start state for a precedence DFA depends on the current\n\t            // parser precedence, and is provided by a DFA method.\n\t            s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());\n\t        } else {\n\t            // the start state for a \"regular\" DFA is just s0\n\t            s0 = dfa.s0;\n\t        }\n\t        if (s0===null) {\n\t            if (outerContext===null) {\n\t                outerContext = RuleContext.EMPTY;\n\t            }\n\t            if (this.debug || this.debug_list_atn_decisions) {\n\t                console.log(\"predictATN decision \" + dfa.decision +\n\t                                   \" exec LA(1)==\" + this.getLookaheadName(input) +\n\t                                   \", outerContext=\" + outerContext.toString(this.parser.ruleNames));\n\t            }\n\t            // If this is not a precedence DFA, we check the ATN start state\n\t            // to determine if this ATN start state is the decision for the\n\t            // closure block that determines whether a precedence rule\n\t            // should continue or complete.\n\t            //\n\t            if (!dfa.precedenceDfa && (dfa.atnStartState instanceof StarLoopEntryState)) {\n\t                if (dfa.atnStartState.precedenceRuleDecision) {\n\t                    dfa.setPrecedenceDfa(true);\n\t                }\n\t            }\n\t            var fullCtx = false;\n\t            var s0_closure = this.computeStartState(dfa.atnStartState, RuleContext.EMPTY, fullCtx);\n\t\n\t            if( dfa.precedenceDfa) {\n\t                // If this is a precedence DFA, we use applyPrecedenceFilter\n\t                // to convert the computed start state to a precedence start\n\t                // state. We then use DFA.setPrecedenceStartState to set the\n\t                // appropriate start state for the precedence level rather\n\t                // than simply setting DFA.s0.\n\t                //\n\t                s0_closure = this.applyPrecedenceFilter(s0_closure);\n\t                s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n\t                dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);\n\t            } else {\n\t                s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n\t                dfa.s0 = s0;\n\t            }\n\t        }\n\t        var alt = this.execATN(dfa, s0, input, index, outerContext);\n\t        if (this.debug) {\n\t            console.log(\"DFA after predictATN: \" + dfa.toString(this.parser.literalNames));\n\t        }\n\t        return alt;\n\t    } finally {\n\t        this._dfa = null;\n\t        this.mergeCache = null; // wack cache after each prediction\n\t        input.seek(index);\n\t        input.release(m);\n\t    }\n\t};\n\t// Performs ATN simulation to compute a predicted alternative based\n\t//  upon the remaining input, but also updates the DFA cache to avoid\n\t//  having to traverse the ATN again for the same input sequence.\n\t\n\t// There are some key conditions we're looking for after computing a new\n\t// set of ATN configs (proposed DFA state):\n\t      // if the set is empty, there is no viable alternative for current symbol\n\t      // does the state uniquely predict an alternative?\n\t      // does the state have a conflict that would prevent us from\n\t      //   putting it on the work list?\n\t\n\t// We also have some key operations to do:\n\t      // add an edge from previous DFA state to potentially new DFA state, D,\n\t      //   upon current symbol but only if adding to work list, which means in all\n\t      //   cases except no viable alternative (and possibly non-greedy decisions?)\n\t      // collecting predicates and adding semantic context to DFA accept states\n\t      // adding rule context to context-sensitive DFA accept states\n\t      // consuming an input symbol\n\t      // reporting a conflict\n\t      // reporting an ambiguity\n\t      // reporting a context sensitivity\n\t      // reporting insufficient predicates\n\t\n\t// cover these cases:\n\t//    dead end\n\t//    single alt\n\t//    single alt + preds\n\t//    conflict\n\t//    conflict + preds\n\t//\n\tParserATNSimulator.prototype.execATN = function(dfa, s0, input, startIndex, outerContext ) {\n\t    if (this.debug || this.debug_list_atn_decisions) {\n\t        console.log(\"execATN decision \" + dfa.decision +\n\t                \" exec LA(1)==\" + this.getLookaheadName(input) +\n\t                \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n\t    }\n\t    var alt;\n\t    var previousD = s0;\n\t\n\t    if (this.debug) {\n\t        console.log(\"s0 = \" + s0);\n\t    }\n\t    var t = input.LA(1);\n\t    while(true) { // while more work\n\t        var D = this.getExistingTargetState(previousD, t);\n\t        if(D===null) {\n\t            D = this.computeTargetState(dfa, previousD, t);\n\t        }\n\t        if(D===ATNSimulator.ERROR) {\n\t            // if any configs in previous dipped into outer context, that\n\t            // means that input up to t actually finished entry rule\n\t            // at least for SLL decision. Full LL doesn't dip into outer\n\t            // so don't need special case.\n\t            // We will get an error no matter what so delay until after\n\t            // decision; better error message. Also, no reachable target\n\t            // ATN states in SLL implies LL will also get nowhere.\n\t            // If conflict in states that dip out, choose min since we\n\t            // will get error no matter what.\n\t            var e = this.noViableAlt(input, outerContext, previousD.configs, startIndex);\n\t            input.seek(startIndex);\n\t            alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);\n\t            if(alt!==ATN.INVALID_ALT_NUMBER) {\n\t                return alt;\n\t            } else {\n\t                throw e;\n\t            }\n\t        }\n\t        if(D.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {\n\t            // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)\n\t            var conflictingAlts = null;\n\t            if (D.predicates!==null) {\n\t                if (this.debug) {\n\t                    console.log(\"DFA state has preds in DFA sim LL failover\");\n\t                }\n\t                var conflictIndex = input.index;\n\t                if(conflictIndex !== startIndex) {\n\t                    input.seek(startIndex);\n\t                }\n\t                conflictingAlts = this.evalSemanticContext(D.predicates, outerContext, true);\n\t                if (conflictingAlts.length===1) {\n\t                    if(this.debug) {\n\t                        console.log(\"Full LL avoided\");\n\t                    }\n\t                    return conflictingAlts.minValue();\n\t                }\n\t                if (conflictIndex !== startIndex) {\n\t                    // restore the index so reporting the fallback to full\n\t                    // context occurs with the index at the correct spot\n\t                    input.seek(conflictIndex);\n\t                }\n\t            }\n\t            if (this.dfa_debug) {\n\t                console.log(\"ctx sensitive state \" + outerContext +\" in \" + D);\n\t            }\n\t            var fullCtx = true;\n\t            var s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);\n\t            this.reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index);\n\t            alt = this.execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);\n\t            return alt;\n\t        }\n\t        if (D.isAcceptState) {\n\t            if (D.predicates===null) {\n\t                return D.prediction;\n\t            }\n\t            var stopIndex = input.index;\n\t            input.seek(startIndex);\n\t            var alts = this.evalSemanticContext(D.predicates, outerContext, true);\n\t            if (alts.length===0) {\n\t                throw this.noViableAlt(input, outerContext, D.configs, startIndex);\n\t            } else if (alts.length===1) {\n\t                return alts.minValue();\n\t            } else {\n\t                // report ambiguity after predicate evaluation to make sure the correct set of ambig alts is reported.\n\t                this.reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);\n\t                return alts.minValue();\n\t            }\n\t        }\n\t        previousD = D;\n\t\n\t        if (t !== Token.EOF) {\n\t            input.consume();\n\t            t = input.LA(1);\n\t        }\n\t    }\n\t};\n\t//\n\t// Get an existing target state for an edge in the DFA. If the target state\n\t// for the edge has not yet been computed or is otherwise not available,\n\t// this method returns {@code null}.\n\t//\n\t// @param previousD The current DFA state\n\t// @param t The next input symbol\n\t// @return The existing target DFA state for the given input symbol\n\t// {@code t}, or {@code null} if the target state for this edge is not\n\t// already cached\n\t//\n\tParserATNSimulator.prototype.getExistingTargetState = function(previousD, t) {\n\t    var edges = previousD.edges;\n\t    if (edges===null) {\n\t        return null;\n\t    } else {\n\t        return edges[t + 1] || null;\n\t    }\n\t};\n\t//\n\t// Compute a target state for an edge in the DFA, and attempt to add the\n\t// computed state and corresponding edge to the DFA.\n\t//\n\t// @param dfa The DFA\n\t// @param previousD The current DFA state\n\t// @param t The next input symbol\n\t//\n\t// @return The computed target DFA state for the given input symbol\n\t// {@code t}. If {@code t} does not lead to a valid DFA state, this method\n\t// returns {@link //ERROR}.\n\t//\n\tParserATNSimulator.prototype.computeTargetState = function(dfa, previousD, t) {\n\t   var reach = this.computeReachSet(previousD.configs, t, false);\n\t    if(reach===null) {\n\t        this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);\n\t        return ATNSimulator.ERROR;\n\t    }\n\t    // create new target state; we'll add to DFA after it's complete\n\t    var D = new DFAState(null, reach);\n\t\n\t    var predictedAlt = this.getUniqueAlt(reach);\n\t\n\t    if (this.debug) {\n\t        var altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n\t        console.log(\"SLL altSubSets=\" + Utils.arrayToString(altSubSets) +\n\t                    \", previous=\" + previousD.configs +\n\t                    \", configs=\" + reach +\n\t                    \", predict=\" + predictedAlt +\n\t                    \", allSubsetsConflict=\" +\n\t                    PredictionMode.allSubsetsConflict(altSubSets) + \", conflictingAlts=\" +\n\t                    this.getConflictingAlts(reach));\n\t    }\n\t    if (predictedAlt!==ATN.INVALID_ALT_NUMBER) {\n\t        // NO CONFLICT, UNIQUELY PREDICTED ALT\n\t        D.isAcceptState = true;\n\t        D.configs.uniqueAlt = predictedAlt;\n\t        D.prediction = predictedAlt;\n\t    } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {\n\t        // MORE THAN ONE VIABLE ALTERNATIVE\n\t        D.configs.conflictingAlts = this.getConflictingAlts(reach);\n\t        D.requiresFullContext = true;\n\t        // in SLL-only mode, we will stop at this state and return the minimum alt\n\t        D.isAcceptState = true;\n\t        D.prediction = D.configs.conflictingAlts.minValue();\n\t    }\n\t    if (D.isAcceptState && D.configs.hasSemanticContext) {\n\t        this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));\n\t        if( D.predicates!==null) {\n\t            D.prediction = ATN.INVALID_ALT_NUMBER;\n\t        }\n\t    }\n\t    // all adds to dfa are done after we've created full D state\n\t    D = this.addDFAEdge(dfa, previousD, t, D);\n\t    return D;\n\t};\n\t\n\tParserATNSimulator.prototype.predicateDFAState = function(dfaState, decisionState) {\n\t    // We need to test all predicates, even in DFA states that\n\t    // uniquely predict alternative.\n\t    var nalts = decisionState.transitions.length;\n\t    // Update DFA so reach becomes accept state with (predicate,alt)\n\t    // pairs if preds found for conflicting alts\n\t    var altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);\n\t    var altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);\n\t    if (altToPred!==null) {\n\t        dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);\n\t        dfaState.prediction = ATN.INVALID_ALT_NUMBER; // make sure we use preds\n\t    } else {\n\t        // There are preds in configs but they might go away\n\t        // when OR'd together like {p}? || NONE == NONE. If neither\n\t        // alt has preds, resolve to min alt\n\t        dfaState.prediction = altsToCollectPredsFrom.minValue();\n\t    }\n\t};\n\t\n\t// comes back with reach.uniqueAlt set to a valid alt\n\tParserATNSimulator.prototype.execATNWithFullContext = function(dfa, D, // how far we got before failing over\n\t                                     s0,\n\t                                     input,\n\t                                     startIndex,\n\t                                     outerContext) {\n\t    if (this.debug || this.debug_list_atn_decisions) {\n\t        console.log(\"execATNWithFullContext \"+s0);\n\t    }\n\t    var fullCtx = true;\n\t    var foundExactAmbig = false;\n\t    var reach = null;\n\t    var previous = s0;\n\t    input.seek(startIndex);\n\t    var t = input.LA(1);\n\t    var predictedAlt = -1;\n\t    while (true) { // while more work\n\t        reach = this.computeReachSet(previous, t, fullCtx);\n\t        if (reach===null) {\n\t            // if any configs in previous dipped into outer context, that\n\t            // means that input up to t actually finished entry rule\n\t            // at least for LL decision. Full LL doesn't dip into outer\n\t            // so don't need special case.\n\t            // We will get an error no matter what so delay until after\n\t            // decision; better error message. Also, no reachable target\n\t            // ATN states in SLL implies LL will also get nowhere.\n\t            // If conflict in states that dip out, choose min since we\n\t            // will get error no matter what.\n\t            var e = this.noViableAlt(input, outerContext, previous, startIndex);\n\t            input.seek(startIndex);\n\t            var alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);\n\t            if(alt!==ATN.INVALID_ALT_NUMBER) {\n\t                return alt;\n\t            } else {\n\t                throw e;\n\t            }\n\t        }\n\t        var altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n\t        if(this.debug) {\n\t            console.log(\"LL altSubSets=\" + altSubSets + \", predict=\" +\n\t                  PredictionMode.getUniqueAlt(altSubSets) + \", resolvesToJustOneViableAlt=\" +\n\t                  PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n\t        }\n\t        reach.uniqueAlt = this.getUniqueAlt(reach);\n\t        // unique prediction?\n\t        if(reach.uniqueAlt!==ATN.INVALID_ALT_NUMBER) {\n\t            predictedAlt = reach.uniqueAlt;\n\t            break;\n\t        } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {\n\t            predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n\t            if(predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n\t                break;\n\t            }\n\t        } else {\n\t            // In exact ambiguity mode, we never try to terminate early.\n\t            // Just keeps scarfing until we know what the conflict is\n\t            if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {\n\t                foundExactAmbig = true;\n\t                predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n\t                break;\n\t            }\n\t            // else there are multiple non-conflicting subsets or\n\t            // we're not sure what the ambiguity is yet.\n\t            // So, keep going.\n\t        }\n\t        previous = reach;\n\t        if( t !== Token.EOF) {\n\t            input.consume();\n\t            t = input.LA(1);\n\t        }\n\t    }\n\t    // If the configuration set uniquely predicts an alternative,\n\t    // without conflict, then we know that it's a full LL decision\n\t    // not SLL.\n\t    if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER ) {\n\t        this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);\n\t        return predictedAlt;\n\t    }\n\t    // We do not check predicates here because we have checked them\n\t    // on-the-fly when doing full context prediction.\n\t\n\t    //\n\t    // In non-exact ambiguity detection mode, we might\tactually be able to\n\t    // detect an exact ambiguity, but I'm not going to spend the cycles\n\t    // needed to check. We only emit ambiguity warnings in exact ambiguity\n\t    // mode.\n\t    //\n\t    // For example, we might know that we have conflicting configurations.\n\t    // But, that does not mean that there is no way forward without a\n\t    // conflict. It's possible to have nonconflicting alt subsets as in:\n\t\n\t    // altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]\n\t\n\t    // from\n\t    //\n\t    //    [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),\n\t    //     (13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]\n\t    //\n\t    // In this case, (17,1,[5 $]) indicates there is some next sequence that\n\t    // would resolve this without conflict to alternative 1. Any other viable\n\t    // next sequence, however, is associated with a conflict.  We stop\n\t    // looking for input because no amount of further lookahead will alter\n\t    // the fact that we should predict alternative 1.  We just can't say for\n\t    // sure that there is an ambiguity without looking further.\n\t\n\t    this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, null, reach);\n\t\n\t    return predictedAlt;\n\t};\n\t\n\tParserATNSimulator.prototype.computeReachSet = function(closure, t, fullCtx) {\n\t    if (this.debug) {\n\t        console.log(\"in computeReachSet, starting closure: \" + closure);\n\t    }\n\t    if( this.mergeCache===null) {\n\t        this.mergeCache = new DoubleDict();\n\t    }\n\t    var intermediate = new ATNConfigSet(fullCtx);\n\t\n\t    // Configurations already in a rule stop state indicate reaching the end\n\t    // of the decision rule (local context) or end of the start rule (full\n\t    // context). Once reached, these configurations are never updated by a\n\t    // closure operation, so they are handled separately for the performance\n\t    // advantage of having a smaller intermediate set when calling closure.\n\t    //\n\t    // For full-context reach operations, separate handling is required to\n\t    // ensure that the alternative matching the longest overall sequence is\n\t    // chosen when multiple such configurations can match the input.\n\t    \n\t    var skippedStopStates = null;\n\t\n\t    // First figure out where we can reach on input t\n\t    for (var i=0; i<closure.items.length;i++) {\n\t        var c = closure.items[i];\n\t        if(this.debug) {\n\t            console.log(\"testing \" + this.getTokenName(t) + \" at \" + c);\n\t        }\n\t        if (c.state instanceof RuleStopState) {\n\t            if (fullCtx || t === Token.EOF) {\n\t                if (skippedStopStates===null) {\n\t                    skippedStopStates = [];\n\t                }\n\t                skippedStopStates.push(c);\n\t                if(this.debug) {\n\t                    console.log(\"added \" + c + \" to skippedStopStates\");\n\t                }\n\t            }\n\t            continue;\n\t        }\n\t        for(var j=0;j<c.state.transitions.length;j++) {\n\t            var trans = c.state.transitions[j];\n\t            var target = this.getReachableTarget(trans, t);\n\t            if (target!==null) {\n\t                var cfg = new ATNConfig({state:target}, c);\n\t                intermediate.add(cfg, this.mergeCache);\n\t                if(this.debug) {\n\t                    console.log(\"added \" + cfg + \" to intermediate\");\n\t                }\n\t            }\n\t        }\n\t    }\n\t    // Now figure out where the reach operation can take us...\n\t    var reach = null;\n\t\n\t    // This block optimizes the reach operation for intermediate sets which\n\t    // trivially indicate a termination state for the overall\n\t    // adaptivePredict operation.\n\t    //\n\t    // The conditions assume that intermediate\n\t    // contains all configurations relevant to the reach set, but this\n\t    // condition is not true when one or more configurations have been\n\t    // withheld in skippedStopStates, or when the current symbol is EOF.\n\t    //\n\t    if (skippedStopStates===null && t!==Token.EOF) {\n\t        if (intermediate.items.length===1) {\n\t            // Don't pursue the closure if there is just one state.\n\t            // It can only have one alternative; just add to result\n\t            // Also don't pursue the closure if there is unique alternative\n\t            // among the configurations.\n\t            reach = intermediate;\n\t        } else if (this.getUniqueAlt(intermediate)!==ATN.INVALID_ALT_NUMBER) {\n\t            // Also don't pursue the closure if there is unique alternative\n\t            // among the configurations.\n\t            reach = intermediate;\n\t        }\n\t    }\n\t    // If the reach set could not be trivially determined, perform a closure\n\t    // operation on the intermediate set to compute its initial value.\n\t    //\n\t    if (reach===null) {\n\t        reach = new ATNConfigSet(fullCtx);\n\t        var closureBusy = new Set();\n\t        var treatEofAsEpsilon = t === Token.EOF;\n\t        for (var k=0; k<intermediate.items.length;k++) {\n\t            this.closure(intermediate.items[k], reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n\t        }\n\t    }\n\t    if (t === Token.EOF) {\n\t        // After consuming EOF no additional input is possible, so we are\n\t        // only interested in configurations which reached the end of the\n\t        // decision rule (local context) or end of the start rule (full\n\t        // context). Update reach to contain only these configurations. This\n\t        // handles both explicit EOF transitions in the grammar and implicit\n\t        // EOF transitions following the end of the decision or start rule.\n\t        //\n\t        // When reach==intermediate, no closure operation was performed. In\n\t        // this case, removeAllConfigsNotInRuleStopState needs to check for\n\t        // reachable rule stop states as well as configurations already in\n\t        // a rule stop state.\n\t        //\n\t        // This is handled before the configurations in skippedStopStates,\n\t        // because any configurations potentially added from that list are\n\t        // already guaranteed to meet this condition whether or not it's\n\t        // required.\n\t        //\n\t        reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);\n\t    }\n\t    // If skippedStopStates!==null, then it contains at least one\n\t    // configuration. For full-context reach operations, these\n\t    // configurations reached the end of the start rule, in which case we\n\t    // only add them back to reach if no configuration during the current\n\t    // closure operation reached such a state. This ensures adaptivePredict\n\t    // chooses an alternative matching the longest overall sequence when\n\t    // multiple alternatives are viable.\n\t    //\n\t    if (skippedStopStates!==null && ( (! fullCtx) || (! PredictionMode.hasConfigInRuleStopState(reach)))) {\n\t        for (var l=0; l<skippedStopStates.length;l++) {\n\t            reach.add(skippedStopStates[l], this.mergeCache);\n\t        }\n\t    }\n\t    if (reach.items.length===0) {\n\t        return null;\n\t    } else {\n\t        return reach;\n\t    }\n\t};\n\t//\n\t// Return a configuration set containing only the configurations from\n\t// {@code configs} which are in a {@link RuleStopState}. If all\n\t// configurations in {@code configs} are already in a rule stop state, this\n\t// method simply returns {@code configs}.\n\t//\n\t// <p>When {@code lookToEndOfRule} is true, this method uses\n\t// {@link ATN//nextTokens} for each configuration in {@code configs} which is\n\t// not already in a rule stop state to see if a rule stop state is reachable\n\t// from the configuration via epsilon-only transitions.</p>\n\t//\n\t// @param configs the configuration set to update\n\t// @param lookToEndOfRule when true, this method checks for rule stop states\n\t// reachable by epsilon-only transitions from each configuration in\n\t// {@code configs}.\n\t//\n\t// @return {@code configs} if all configurations in {@code configs} are in a\n\t// rule stop state, otherwise return a new configuration set containing only\n\t// the configurations from {@code configs} which are in a rule stop state\n\t//\n\tParserATNSimulator.prototype.removeAllConfigsNotInRuleStopState = function(configs, lookToEndOfRule) {\n\t    if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n\t        return configs;\n\t    }\n\t    var result = new ATNConfigSet(configs.fullCtx);\n\t    for(var i=0; i<configs.items.length;i++) {\n\t        var config = configs.items[i];\n\t        if (config.state instanceof RuleStopState) {\n\t            result.add(config, this.mergeCache);\n\t            continue;\n\t        }\n\t        if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {\n\t            var nextTokens = this.atn.nextTokens(config.state);\n\t            if (nextTokens.contains(Token.EPSILON)) {\n\t                var endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];\n\t                result.add(new ATNConfig({state:endOfRuleState}, config), this.mergeCache);\n\t            }\n\t        }\n\t    }\n\t    return result;\n\t};\n\t\n\tParserATNSimulator.prototype.computeStartState = function(p, ctx, fullCtx) {\n\t    // always at least the implicit call to start rule\n\t    var initialContext = predictionContextFromRuleContext(this.atn, ctx);\n\t    var configs = new ATNConfigSet(fullCtx);\n\t    for(var i=0;i<p.transitions.length;i++) {\n\t        var target = p.transitions[i].target;\n\t        var c = new ATNConfig({ state:target, alt:i+1, context:initialContext }, null);\n\t        var closureBusy = new Set();\n\t        this.closure(c, configs, closureBusy, true, fullCtx, false);\n\t    }\n\t    return configs;\n\t};\n\t\n\t//\n\t// This method transforms the start state computed by\n\t// {@link //computeStartState} to the special start state used by a\n\t// precedence DFA for a particular precedence value. The transformation\n\t// process applies the following changes to the start state's configuration\n\t// set.\n\t//\n\t// <ol>\n\t// <li>Evaluate the precedence predicates for each configuration using\n\t// {@link SemanticContext//evalPrecedence}.</li>\n\t// <li>Remove all configurations which predict an alternative greater than\n\t// 1, for which another configuration that predicts alternative 1 is in the\n\t// same ATN state with the same prediction context. This transformation is\n\t// valid for the following reasons:\n\t// <ul>\n\t// <li>The closure block cannot contain any epsilon transitions which bypass\n\t// the body of the closure, so all states reachable via alternative 1 are\n\t// part of the precedence alternatives of the transformed left-recursive\n\t// rule.</li>\n\t// <li>The \"primary\" portion of a left recursive rule cannot contain an\n\t// epsilon transition, so the only way an alternative other than 1 can exist\n\t// in a state that is also reachable via alternative 1 is by nesting calls\n\t// to the left-recursive rule, with the outer calls not being at the\n\t// preferred precedence level.</li>\n\t// </ul>\n\t// </li>\n\t// </ol>\n\t//\n\t// <p>\n\t// The prediction context must be considered by this filter to address\n\t// situations like the following.\n\t// </p>\n\t// <code>\n\t// <pre>\n\t// grammar TA;\n\t// prog: statement* EOF;\n\t// statement: letterA | statement letterA 'b' ;\n\t// letterA: 'a';\n\t// </pre>\n\t// </code>\n\t// <p>\n\t// If the above grammar, the ATN state immediately before the token\n\t// reference {@code 'a'} in {@code letterA} is reachable from the left edge\n\t// of both the primary and closure blocks of the left-recursive rule\n\t// {@code statement}. The prediction context associated with each of these\n\t// configurations distinguishes between them, and prevents the alternative\n\t// which stepped out to {@code prog} (and then back in to {@code statement}\n\t// from being eliminated by the filter.\n\t// </p>\n\t//\n\t// @param configs The configuration set computed by\n\t// {@link //computeStartState} as the start state for the DFA.\n\t// @return The transformed configuration set representing the start state\n\t// for a precedence DFA at a particular precedence level (determined by\n\t// calling {@link Parser//getPrecedence}).\n\t//\n\tParserATNSimulator.prototype.applyPrecedenceFilter = function(configs) {\n\t\tvar config;\n\t\tvar statesFromAlt1 = [];\n\t    var configSet = new ATNConfigSet(configs.fullCtx);\n\t    for(var i=0; i<configs.items.length; i++) {\n\t        config = configs.items[i];\n\t        // handle alt 1 first\n\t        if (config.alt !== 1) {\n\t            continue;\n\t        }\n\t        var updatedContext = config.semanticContext.evalPrecedence(this.parser, this._outerContext);\n\t        if (updatedContext===null) {\n\t            // the configuration was eliminated\n\t            continue;\n\t        }\n\t        statesFromAlt1[config.state.stateNumber] = config.context;\n\t        if (updatedContext !== config.semanticContext) {\n\t            configSet.add(new ATNConfig({semanticContext:updatedContext}, config), this.mergeCache);\n\t        } else {\n\t            configSet.add(config, this.mergeCache);\n\t        }\n\t    }\n\t    for(i=0; i<configs.items.length; i++) {\n\t        config = configs.items[i];\n\t        if (config.alt === 1) {\n\t            // already handled\n\t            continue;\n\t        }\n\t        // In the future, this elimination step could be updated to also\n\t        // filter the prediction context for alternatives predicting alt>1\n\t        // (basically a graph subtraction algorithm).\n\t\t\tif (!config.precedenceFilterSuppressed) {\n\t            var context = statesFromAlt1[config.state.stateNumber] || null;\n\t            if (context!==null && context.equals(config.context)) {\n\t                // eliminated\n\t                continue;\n\t            }\n\t\t\t}\n\t        configSet.add(config, this.mergeCache);\n\t    }\n\t    return configSet;\n\t};\n\t\n\tParserATNSimulator.prototype.getReachableTarget = function(trans, ttype) {\n\t    if (trans.matches(ttype, 0, this.atn.maxTokenType)) {\n\t        return trans.target;\n\t    } else {\n\t        return null;\n\t    }\n\t};\n\t\n\tParserATNSimulator.prototype.getPredsForAmbigAlts = function(ambigAlts, configs, nalts) {\n\t    // REACH=[1|1|[]|0:0, 1|2|[]|0:1]\n\t    // altToPred starts as an array of all null contexts. The entry at index i\n\t    // corresponds to alternative i. altToPred[i] may have one of three values:\n\t    //   1. null: no ATNConfig c is found such that c.alt==i\n\t    //   2. SemanticContext.NONE: At least one ATNConfig c exists such that\n\t    //      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,\n\t    //      alt i has at least one unpredicated config.\n\t    //   3. Non-NONE Semantic Context: There exists at least one, and for all\n\t    //      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.\n\t    //\n\t    // From this, it is clear that NONE||anything==NONE.\n\t    //\n\t    var altToPred = [];\n\t    for(var i=0;i<configs.items.length;i++) {\n\t        var c = configs.items[i];\n\t        if(ambigAlts.contains( c.alt )) {\n\t            altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] || null, c.semanticContext);\n\t        }\n\t    }\n\t    var nPredAlts = 0;\n\t    for (i =1;i< nalts+1;i++) {\n\t        var pred = altToPred[i] || null;\n\t        if (pred===null) {\n\t            altToPred[i] = SemanticContext.NONE;\n\t        } else if (pred !== SemanticContext.NONE) {\n\t            nPredAlts += 1;\n\t        }\n\t    }\n\t    // nonambig alts are null in altToPred\n\t    if (nPredAlts===0) {\n\t        altToPred = null;\n\t    }\n\t    if (this.debug) {\n\t        console.log(\"getPredsForAmbigAlts result \" + Utils.arrayToString(altToPred));\n\t    }\n\t    return altToPred;\n\t};\n\t\n\tParserATNSimulator.prototype.getPredicatePredictions = function(ambigAlts, altToPred) {\n\t    var pairs = [];\n\t    var containsPredicate = false;\n\t    for (var i=1; i<altToPred.length;i++) {\n\t        var pred = altToPred[i];\n\t        // unpredicated is indicated by SemanticContext.NONE\n\t        if( ambigAlts!==null && ambigAlts.contains( i )) {\n\t            pairs.push(new PredPrediction(pred, i));\n\t        }\n\t        if (pred !== SemanticContext.NONE) {\n\t            containsPredicate = true;\n\t        }\n\t    }\n\t    if (! containsPredicate) {\n\t        return null;\n\t    }\n\t    return pairs;\n\t};\n\t\n\t//\n\t// This method is used to improve the localization of error messages by\n\t// choosing an alternative rather than throwing a\n\t// {@link NoViableAltException} in particular prediction scenarios where the\n\t// {@link //ERROR} state was reached during ATN simulation.\n\t//\n\t// <p>\n\t// The default implementation of this method uses the following\n\t// algorithm to identify an ATN configuration which successfully parsed the\n\t// decision entry rule. Choosing such an alternative ensures that the\n\t// {@link ParserRuleContext} returned by the calling rule will be complete\n\t// and valid, and the syntax error will be reported later at a more\n\t// localized location.</p>\n\t//\n\t// <ul>\n\t// <li>If a syntactically valid path or paths reach the end of the decision rule and\n\t// they are semantically valid if predicated, return the min associated alt.</li>\n\t// <li>Else, if a semantically invalid but syntactically valid path exist\n\t// or paths exist, return the minimum associated alt.\n\t// </li>\n\t// <li>Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.</li>\n\t// </ul>\n\t//\n\t// <p>\n\t// In some scenarios, the algorithm described above could predict an\n\t// alternative which will result in a {@link FailedPredicateException} in\n\t// the parser. Specifically, this could occur if the <em>only</em> configuration\n\t// capable of successfully parsing to the end of the decision rule is\n\t// blocked by a semantic predicate. By choosing this alternative within\n\t// {@link //adaptivePredict} instead of throwing a\n\t// {@link NoViableAltException}, the resulting\n\t// {@link FailedPredicateException} in the parser will identify the specific\n\t// predicate which is preventing the parser from successfully parsing the\n\t// decision rule, which helps developers identify and correct logic errors\n\t// in semantic predicates.\n\t// </p>\n\t//\n\t// @param configs The ATN configurations which were valid immediately before\n\t// the {@link //ERROR} state was reached\n\t// @param outerContext The is the \\gamma_0 initial parser context from the paper\n\t// or the parser stack at the instant before prediction commences.\n\t//\n\t// @return The value to return from {@link //adaptivePredict}, or\n\t// {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not\n\t// identified and {@link //adaptivePredict} should report an error instead.\n\t//\n\tParserATNSimulator.prototype.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule = function(configs, outerContext) {\n\t    var cfgs = this.splitAccordingToSemanticValidity(configs, outerContext);\n\t    var semValidConfigs = cfgs[0];\n\t    var semInvalidConfigs = cfgs[1];\n\t    var alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);\n\t    if (alt!==ATN.INVALID_ALT_NUMBER) { // semantically/syntactically viable path exists\n\t        return alt;\n\t    }\n\t    // Is there a syntactically valid path with a failed pred?\n\t    if (semInvalidConfigs.items.length>0) {\n\t        alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);\n\t        if (alt!==ATN.INVALID_ALT_NUMBER) { // syntactically viable path exists\n\t            return alt;\n\t        }\n\t    }\n\t    return ATN.INVALID_ALT_NUMBER;\n\t};\n\t    \n\tParserATNSimulator.prototype.getAltThatFinishedDecisionEntryRule = function(configs) {\n\t    var alts = [];\n\t    for(var i=0;i<configs.items.length; i++) {\n\t        var c = configs.items[i];\n\t        if (c.reachesIntoOuterContext>0 || ((c.state instanceof RuleStopState) && c.context.hasEmptyPath())) {\n\t            if(alts.indexOf(c.alt)<0) {\n\t                alts.push(c.alt);\n\t            }\n\t        }\n\t    }\n\t    if (alts.length===0) {\n\t        return ATN.INVALID_ALT_NUMBER;\n\t    } else {\n\t        return Math.min.apply(null, alts);\n\t    }\n\t};\n\t// Walk the list of configurations and split them according to\n\t//  those that have preds evaluating to true/false.  If no pred, assume\n\t//  true pred and include in succeeded set.  Returns Pair of sets.\n\t//\n\t//  Create a new set so as not to alter the incoming parameter.\n\t//\n\t//  Assumption: the input stream has been restored to the starting point\n\t//  prediction, which is where predicates need to evaluate.\n\t//\n\tParserATNSimulator.prototype.splitAccordingToSemanticValidity = function( configs, outerContext) {\n\t    var succeeded = new ATNConfigSet(configs.fullCtx);\n\t    var failed = new ATNConfigSet(configs.fullCtx);\n\t    for(var i=0;i<configs.items.length; i++) {\n\t        var c = configs.items[i];\n\t        if (c.semanticContext !== SemanticContext.NONE) {\n\t            var predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);\n\t            if (predicateEvaluationResult) {\n\t                succeeded.add(c);\n\t            } else {\n\t                failed.add(c);\n\t            }\n\t        } else {\n\t            succeeded.add(c);\n\t        }\n\t    }\n\t    return [succeeded, failed];\n\t};\n\t\n\t// Look through a list of predicate/alt pairs, returning alts for the\n\t//  pairs that win. A {@code NONE} predicate indicates an alt containing an\n\t//  unpredicated config which behaves as \"always true.\" If !complete\n\t//  then we stop at the first predicate that evaluates to true. This\n\t//  includes pairs with null predicates.\n\t//\n\tParserATNSimulator.prototype.evalSemanticContext = function(predPredictions, outerContext, complete) {\n\t    var predictions = new BitSet();\n\t    for(var i=0;i<predPredictions.length;i++) {\n\t    \tvar pair = predPredictions[i];\n\t        if (pair.pred === SemanticContext.NONE) {\n\t            predictions.add(pair.alt);\n\t            if (! complete) {\n\t                break;\n\t            }\n\t            continue;\n\t        }\n\t        var predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);\n\t        if (this.debug || this.dfa_debug) {\n\t            console.log(\"eval pred \" + pair + \"=\" + predicateEvaluationResult);\n\t        }\n\t        if (predicateEvaluationResult) {\n\t            if (this.debug || this.dfa_debug) {\n\t                console.log(\"PREDICT \" + pair.alt);\n\t            }\n\t            predictions.add(pair.alt);\n\t            if (! complete) {\n\t                break;\n\t            }\n\t        }\n\t    }\n\t    return predictions;\n\t};\n\t\n\t// TODO: If we are doing predicates, there is no point in pursuing\n\t//     closure operations if we reach a DFA state that uniquely predicts\n\t//     alternative. We will not be caching that DFA state and it is a\n\t//     waste to pursue the closure. Might have to advance when we do\n\t//     ambig detection thought :(\n\t//\n\t\n\tParserATNSimulator.prototype.closure = function(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {\n\t    var initialDepth = 0;\n\t    this.closureCheckingStopState(config, configs, closureBusy, collectPredicates,\n\t                             fullCtx, initialDepth, treatEofAsEpsilon);\n\t};\n\t\n\t\n\tParserATNSimulator.prototype.closureCheckingStopState = function(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n\t    if (this.debug) {\n\t        console.log(\"closure(\" + config.toString(this.parser,true) + \")\");\n\t        console.log(\"configs(\" + configs.toString() + \")\");\n\t        if(config.reachesIntoOuterContext>50) {\n\t            throw \"problem\";\n\t        }\n\t    }\n\t    if (config.state instanceof RuleStopState) {\n\t        // We hit rule end. If we have context info, use it\n\t        // run thru all possible stack tops in ctx\n\t        if (! config.context.isEmpty()) {\n\t            for ( var i =0; i<config.context.length; i++) {\n\t                if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {\n\t                    if (fullCtx) {\n\t                        configs.add(new ATNConfig({state:config.state, context:PredictionContext.EMPTY}, config), this.mergeCache);\n\t                        continue;\n\t                    } else {\n\t                        // we have no context info, just chase follow links (if greedy)\n\t                        if (this.debug) {\n\t                            console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n\t                        }\n\t                        this.closure_(config, configs, closureBusy, collectPredicates,\n\t                                 fullCtx, depth, treatEofAsEpsilon);\n\t                    }\n\t                    continue;\n\t                }\n\t                var returnState = this.atn.states[config.context.getReturnState(i)];\n\t                var newContext = config.context.getParent(i); // \"pop\" return state\n\t                var parms = {state:returnState, alt:config.alt, context:newContext, semanticContext:config.semanticContext};\n\t                var c = new ATNConfig(parms, null);\n\t                // While we have context to pop back from, we may have\n\t                // gotten that context AFTER having falling off a rule.\n\t                // Make sure we track that we are now out of context.\n\t                c.reachesIntoOuterContext = config.reachesIntoOuterContext;\n\t                this.closureCheckingStopState(c, configs, closureBusy, collectPredicates, fullCtx, depth - 1, treatEofAsEpsilon);\n\t            }\n\t            return;\n\t        } else if( fullCtx) {\n\t            // reached end of start rule\n\t            configs.add(config, this.mergeCache);\n\t            return;\n\t        } else {\n\t            // else if we have no context info, just chase follow links (if greedy)\n\t            if (this.debug) {\n\t                console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n\t            }\n\t        }\n\t    }\n\t    this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n\t};\n\t\n\t// Do the actual work of walking epsilon edges//\n\tParserATNSimulator.prototype.closure_ = function(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n\t    var p = config.state;\n\t    // optimization\n\t    if (! p.epsilonOnlyTransitions) {\n\t        configs.add(config, this.mergeCache);\n\t        // make sure to not return here, because EOF transitions can act as\n\t        // both epsilon transitions and non-epsilon transitions.\n\t    }\n\t    for(var i = 0;i<p.transitions.length; i++) {\n\t        var t = p.transitions[i];\n\t        var continueCollecting = collectPredicates && !(t instanceof ActionTransition);\n\t        var c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);\n\t        if (c!==null) {\n\t\t\t\tif (!t.isEpsilon && closureBusy.add(c)!==c){\n\t\t\t\t\t// avoid infinite recursion for EOF* and EOF+\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t            var newDepth = depth;\n\t            if ( config.state instanceof RuleStopState) {\n\t                // target fell off end of rule; mark resulting c as having dipped into outer context\n\t                // We can't get here if incoming config was rule stop and we had context\n\t                // track how far we dip into outer context.  Might\n\t                // come in handy and we avoid evaluating context dependent\n\t                // preds if this is > 0.\n\t\n\t                if (closureBusy.add(c)!==c) {\n\t                    // avoid infinite recursion for right-recursive rules\n\t                    continue;\n\t                }\n\t\n\t\t\t\t\tif (this._dfa !== null && this._dfa.precedenceDfa) {\n\t\t\t\t\t\tif (t.outermostPrecedenceReturn === this._dfa.atnStartState.ruleIndex) {\n\t\t\t\t\t\t\tc.precedenceFilterSuppressed = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\n\t                c.reachesIntoOuterContext += 1;\n\t                configs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n\t                newDepth -= 1;\n\t                if (this.debug) {\n\t                    console.log(\"dips into outer ctx: \" + c);\n\t                }\n\t            } else if (t instanceof RuleTransition) {\n\t                // latch when newDepth goes negative - once we step out of the entry context we can't return\n\t                if (newDepth >= 0) {\n\t                    newDepth += 1;\n\t                }\n\t            }\n\t            this.closureCheckingStopState(c, configs, closureBusy, continueCollecting, fullCtx, newDepth, treatEofAsEpsilon);\n\t        }\n\t    }\n\t};\n\t\n\tParserATNSimulator.prototype.getRuleName = function( index) {\n\t    if (this.parser!==null && index>=0) {\n\t        return this.parser.ruleNames[index];\n\t    } else {\n\t        return \"<rule \" + index + \">\";\n\t    }\n\t};\n\t\n\tParserATNSimulator.prototype.getEpsilonTarget = function(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {\n\t    switch(t.serializationType) {\n\t    case Transition.RULE:\n\t        return this.ruleTransition(config, t);\n\t    case Transition.PRECEDENCE:\n\t        return this.precedenceTransition(config, t, collectPredicates, inContext, fullCtx);\n\t    case Transition.PREDICATE:\n\t        return this.predTransition(config, t, collectPredicates, inContext, fullCtx);\n\t    case Transition.ACTION:\n\t        return this.actionTransition(config, t);\n\t    case Transition.EPSILON:\n\t        return new ATNConfig({state:t.target}, config);\n\t    case Transition.ATOM:\n\t    case Transition.RANGE:\n\t    case Transition.SET:\n\t        // EOF transitions act like epsilon transitions after the first EOF\n\t        // transition is traversed\n\t        if (treatEofAsEpsilon) {\n\t            if (t.matches(Token.EOF, 0, 1)) {\n\t                return new ATNConfig({state: t.target}, config);\n\t            }\n\t        }\n\t        return null;\n\t    default:\n\t    \treturn null;\n\t    }\n\t};\n\t\n\tParserATNSimulator.prototype.actionTransition = function(config, t) {\n\t    if (this.debug) {\n\t        console.log(\"ACTION edge \" + t.ruleIndex + \":\" + t.actionIndex);\n\t    }\n\t    return new ATNConfig({state:t.target}, config);\n\t};\n\t\n\tParserATNSimulator.prototype.precedenceTransition = function(config, pt,  collectPredicates, inContext, fullCtx) {\n\t    if (this.debug) {\n\t        console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" +\n\t                pt.precedence + \">=_p, ctx dependent=true\");\n\t        if (this.parser!==null) {\n\t        \tconsole.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n\t        }\n\t    }\n\t    var c = null;\n\t    if (collectPredicates && inContext) {\n\t        if (fullCtx) {\n\t            // In full context mode, we can evaluate predicates on-the-fly\n\t            // during closure, which dramatically reduces the size of\n\t            // the config sets. It also obviates the need to test predicates\n\t            // later during conflict resolution.\n\t            var currentPosition = this._input.index;\n\t            this._input.seek(this._startIndex);\n\t            var predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n\t            this._input.seek(currentPosition);\n\t            if (predSucceeds) {\n\t                c = new ATNConfig({state:pt.target}, config); // no pred context\n\t            }\n\t        } else {\n\t            newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n\t            c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n\t        }\n\t    } else {\n\t        c = new ATNConfig({state:pt.target}, config);\n\t    }\n\t    if (this.debug) {\n\t        console.log(\"config from pred transition=\" + c);\n\t    }\n\t    return c;\n\t};\n\t\n\tParserATNSimulator.prototype.predTransition = function(config, pt, collectPredicates, inContext, fullCtx) {\n\t    if (this.debug) {\n\t        console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.ruleIndex +\n\t                \":\" + pt.predIndex + \", ctx dependent=\" + pt.isCtxDependent);\n\t        if (this.parser!==null) {\n\t            console.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n\t        }\n\t    }\n\t    var c = null;\n\t    if (collectPredicates && ((pt.isCtxDependent && inContext) || ! pt.isCtxDependent)) {\n\t        if (fullCtx) {\n\t            // In full context mode, we can evaluate predicates on-the-fly\n\t            // during closure, which dramatically reduces the size of\n\t            // the config sets. It also obviates the need to test predicates\n\t            // later during conflict resolution.\n\t            var currentPosition = this._input.index;\n\t            this._input.seek(this._startIndex);\n\t            var predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n\t            this._input.seek(currentPosition);\n\t            if (predSucceeds) {\n\t                c = new ATNConfig({state:pt.target}, config); // no pred context\n\t            }\n\t        } else {\n\t            var newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n\t            c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n\t        }\n\t    } else {\n\t        c = new ATNConfig({state:pt.target}, config);\n\t    }\n\t    if (this.debug) {\n\t        console.log(\"config from pred transition=\" + c);\n\t    }\n\t    return c;\n\t};\n\t\n\tParserATNSimulator.prototype.ruleTransition = function(config, t) {\n\t    if (this.debug) {\n\t        console.log(\"CALL rule \" + this.getRuleName(t.target.ruleIndex) + \", ctx=\" + config.context);\n\t    }\n\t    var returnState = t.followState;\n\t    var newContext = SingletonPredictionContext.create(config.context, returnState.stateNumber);\n\t    return new ATNConfig({state:t.target, context:newContext}, config );\n\t};\n\t\n\tParserATNSimulator.prototype.getConflictingAlts = function(configs) {\n\t    var altsets = PredictionMode.getConflictingAltSubsets(configs);\n\t    return PredictionMode.getAlts(altsets);\n\t};\n\t\n\t // Sam pointed out a problem with the previous definition, v3, of\n\t // ambiguous states. If we have another state associated with conflicting\n\t // alternatives, we should keep going. For example, the following grammar\n\t //\n\t // s : (ID | ID ID?) ';' ;\n\t //\n\t // When the ATN simulation reaches the state before ';', it has a DFA\n\t // state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally\n\t // 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node\n\t // because alternative to has another way to continue, via [6|2|[]].\n\t // The key is that we have a single state that has config's only associated\n\t // with a single alternative, 2, and crucially the state transitions\n\t // among the configurations are all non-epsilon transitions. That means\n\t // we don't consider any conflicts that include alternative 2. So, we\n\t // ignore the conflict between alts 1 and 2. We ignore a set of\n\t // conflicting alts when there is an intersection with an alternative\n\t // associated with a single alt state in the state&rarr;config-list map.\n\t //\n\t // It's also the case that we might have two conflicting configurations but\n\t // also a 3rd nonconflicting configuration for a different alternative:\n\t // [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:\n\t //\n\t // a : A | A | A B ;\n\t //\n\t // After matching input A, we reach the stop state for rule A, state 1.\n\t // State 8 is the state right before B. Clearly alternatives 1 and 2\n\t // conflict and no amount of further lookahead will separate the two.\n\t // However, alternative 3 will be able to continue and so we do not\n\t // stop working on this state. In the previous example, we're concerned\n\t // with states associated with the conflicting alternatives. Here alt\n\t // 3 is not associated with the conflicting configs, but since we can continue\n\t // looking for input reasonably, I don't declare the state done. We\n\t // ignore a set of conflicting alts when we have an alternative\n\t // that we still need to pursue.\n\t//\n\t\n\tParserATNSimulator.prototype.getConflictingAltsOrUniqueAlt = function(configs) {\n\t    var conflictingAlts = null;\n\t    if (configs.uniqueAlt!== ATN.INVALID_ALT_NUMBER) {\n\t        conflictingAlts = new BitSet();\n\t        conflictingAlts.add(configs.uniqueAlt);\n\t    } else {\n\t        conflictingAlts = configs.conflictingAlts;\n\t    }\n\t    return conflictingAlts;\n\t};\n\t\n\tParserATNSimulator.prototype.getTokenName = function( t) {\n\t    if (t===Token.EOF) {\n\t        return \"EOF\";\n\t    }\n\t    if( this.parser!==null && this.parser.literalNames!==null) {\n\t        if (t >= this.parser.literalNames.length) {\n\t            console.log(\"\" + t + \" ttype out of range: \" + this.parser.literalNames);\n\t            console.log(\"\" + this.parser.getInputStream().getTokens());\n\t        } else {\n\t            return this.parser.literalNames[t] + \"<\" + t + \">\";\n\t        }\n\t    }\n\t    return \"\" + t;\n\t};\n\t\n\tParserATNSimulator.prototype.getLookaheadName = function(input) {\n\t    return this.getTokenName(input.LA(1));\n\t};\n\t\n\t// Used for debugging in adaptivePredict around execATN but I cut\n\t//  it out for clarity now that alg. works well. We can leave this\n\t//  \"dead\" code for a bit.\n\t//\n\tParserATNSimulator.prototype.dumpDeadEndConfigs = function(nvae) {\n\t    console.log(\"dead end configs: \");\n\t    var decs = nvae.getDeadEndConfigs();\n\t    for(var i=0; i<decs.length; i++) {\n\t    \tvar c = decs[i];\n\t        var trans = \"no edges\";\n\t        if (c.state.transitions.length>0) {\n\t            var t = c.state.transitions[0];\n\t            if (t instanceof AtomTransition) {\n\t                trans = \"Atom \"+ this.getTokenName(t.label);\n\t            } else if (t instanceof SetTransition) {\n\t                var neg = (t instanceof NotSetTransition);\n\t                trans = (neg ? \"~\" : \"\") + \"Set \" + t.set;\n\t            }\n\t        }\n\t        console.error(c.toString(this.parser, true) + \":\" + trans);\n\t    }\n\t};\n\t\n\tParserATNSimulator.prototype.noViableAlt = function(input, outerContext, configs, startIndex) {\n\t    return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);\n\t};\n\t\n\tParserATNSimulator.prototype.getUniqueAlt = function(configs) {\n\t    var alt = ATN.INVALID_ALT_NUMBER;\n\t    for(var i=0;i<configs.items.length;i++) {\n\t    \tvar c = configs.items[i];\n\t        if (alt === ATN.INVALID_ALT_NUMBER) {\n\t            alt = c.alt // found first alt\n\t        } else if( c.alt!==alt) {\n\t            return ATN.INVALID_ALT_NUMBER;\n\t        }\n\t    }\n\t    return alt;\n\t};\n\t\n\t//\n\t// Add an edge to the DFA, if possible. This method calls\n\t// {@link //addDFAState} to ensure the {@code to} state is present in the\n\t// DFA. If {@code from} is {@code null}, or if {@code t} is outside the\n\t// range of edges that can be represented in the DFA tables, this method\n\t// returns without adding the edge to the DFA.\n\t//\n\t// <p>If {@code to} is {@code null}, this method returns {@code null}.\n\t// Otherwise, this method returns the {@link DFAState} returned by calling\n\t// {@link //addDFAState} for the {@code to} state.</p>\n\t//\n\t// @param dfa The DFA\n\t// @param from The source state for the edge\n\t// @param t The input symbol\n\t// @param to The target state for the edge\n\t//\n\t// @return If {@code to} is {@code null}, this method returns {@code null};\n\t// otherwise this method returns the result of calling {@link //addDFAState}\n\t// on {@code to}\n\t//\n\tParserATNSimulator.prototype.addDFAEdge = function(dfa, from_, t, to) {\n\t    if( this.debug) {\n\t        console.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + this.getTokenName(t));\n\t    }\n\t    if (to===null) {\n\t        return null;\n\t    }\n\t    to = this.addDFAState(dfa, to); // used existing if possible not incoming\n\t    if (from_===null || t < -1 || t > this.atn.maxTokenType) {\n\t        return to;\n\t    }\n\t    if (from_.edges===null) {\n\t        from_.edges = [];\n\t    }\n\t    from_.edges[t+1] = to; // connect\n\t\n\t    if (this.debug) {\n\t        var names = this.parser===null ? null : this.parser.literalNames;\n\t        console.log(\"DFA=\\n\" + dfa.toString(names));\n\t    }\n\t    return to;\n\t};\n\t//\n\t// Add state {@code D} to the DFA if it is not already present, and return\n\t// the actual instance stored in the DFA. If a state equivalent to {@code D}\n\t// is already in the DFA, the existing state is returned. Otherwise this\n\t// method returns {@code D} after adding it to the DFA.\n\t//\n\t// <p>If {@code D} is {@link //ERROR}, this method returns {@link //ERROR} and\n\t// does not change the DFA.</p>\n\t//\n\t// @param dfa The dfa\n\t// @param D The DFA state to add\n\t// @return The state stored in the DFA. This will be either the existing\n\t// state if {@code D} is already in the DFA, or {@code D} itself if the\n\t// state was not already present.\n\t//\n\tParserATNSimulator.prototype.addDFAState = function(dfa, D) {\n\t    if (D == ATNSimulator.ERROR) {\n\t        return D;\n\t    }\n\t    var hash = D.hashString();\n\t    var existing = dfa.states[hash] || null;\n\t    if(existing!==null) {\n\t        return existing;\n\t    }\n\t    D.stateNumber = dfa.states.length;\n\t    if (! D.configs.readOnly) {\n\t        D.configs.optimizeConfigs(this);\n\t        D.configs.setReadonly(true);\n\t    }\n\t    dfa.states[hash] = D;\n\t    if (this.debug) {\n\t        console.log(\"adding new DFA state: \" + D);\n\t    }\n\t    return D;\n\t};\n\t\n\tParserATNSimulator.prototype.reportAttemptingFullContext = function(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n\t    if (this.debug || this.retry_debug) {\n\t        var interval = new Interval(startIndex, stopIndex + 1);\n\t        console.log(\"reportAttemptingFullContext decision=\" + dfa.decision + \":\" + configs +\n\t                           \", input=\" + this.parser.getTokenStream().getText(interval));\n\t    }\n\t    if (this.parser!==null) {\n\t        this.parser.getErrorListenerDispatch().reportAttemptingFullContext(this.parser, dfa, startIndex, stopIndex, conflictingAlts, configs);\n\t    }\n\t};\n\t\n\tParserATNSimulator.prototype.reportContextSensitivity = function(dfa, prediction, configs, startIndex, stopIndex) {\n\t    if (this.debug || this.retry_debug) {\n\t        var interval = new Interval(startIndex, stopIndex + 1);\n\t        console.log(\"reportContextSensitivity decision=\" + dfa.decision + \":\" + configs +\n\t                           \", input=\" + this.parser.getTokenStream().getText(interval));\n\t    }\n\t    if (this.parser!==null) {\n\t        this.parser.getErrorListenerDispatch().reportContextSensitivity(this.parser, dfa, startIndex, stopIndex, prediction, configs);\n\t    }\n\t};\n\t    \n\t// If context sensitive parsing, we know it's ambiguity not conflict//\n\tParserATNSimulator.prototype.reportAmbiguity = function(dfa, D, startIndex, stopIndex,\n\t                               exact, ambigAlts, configs ) {\n\t    if (this.debug || this.retry_debug) {\n\t        var interval = new Interval(startIndex, stopIndex + 1);\n\t        console.log(\"reportAmbiguity \" + ambigAlts + \":\" + configs +\n\t                           \", input=\" + this.parser.getTokenStream().getText(interval));\n\t    }\n\t    if (this.parser!==null) {\n\t        this.parser.getErrorListenerDispatch().reportAmbiguity(this.parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);\n\t    }\n\t};\n\t            \n\texports.ParserATNSimulator = ParserATNSimulator;\n\n/***/ },\n/* 35 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t//\n\t//\n\t// This enumeration defines the prediction modes available in ANTLR 4 along with\n\t// utility methods for analyzing configuration sets for conflicts and/or\n\t// ambiguities.\n\t\n\tvar Set = __webpack_require__(8).Set;\n\tvar BitSet = __webpack_require__(8).BitSet;\n\tvar AltDict = __webpack_require__(8).AltDict;\n\tvar ATN = __webpack_require__(6).ATN;\n\tvar RuleStopState = __webpack_require__(11).RuleStopState;\n\tvar ATNConfigSet = __webpack_require__(32).ATNConfigSet;\n\tvar ATNConfig = __webpack_require__(10).ATNConfig;\n\tvar SemanticContext = __webpack_require__(12).SemanticContext;\n\t\n\tfunction PredictionMode() {\n\t\treturn this;\n\t}\n\t\n\t//\n\t// The SLL(*) prediction mode. This prediction mode ignores the current\n\t// parser context when making predictions. This is the fastest prediction\n\t// mode, and provides correct results for many grammars. This prediction\n\t// mode is more powerful than the prediction mode provided by ANTLR 3, but\n\t// may result in syntax errors for grammar and input combinations which are\n\t// not SLL.\n\t//\n\t// <p>\n\t// When using this prediction mode, the parser will either return a correct\n\t// parse tree (i.e. the same parse tree that would be returned with the\n\t// {@link //LL} prediction mode), or it will report a syntax error. If a\n\t// syntax error is encountered when using the {@link //SLL} prediction mode,\n\t// it may be due to either an actual syntax error in the input or indicate\n\t// that the particular combination of grammar and input requires the more\n\t// powerful {@link //LL} prediction abilities to complete successfully.</p>\n\t//\n\t// <p>\n\t// This prediction mode does not provide any guarantees for prediction\n\t// behavior for syntactically-incorrect inputs.</p>\n\t//\n\tPredictionMode.SLL = 0;\n\t//\n\t// The LL(*) prediction mode. This prediction mode allows the current parser\n\t// context to be used for resolving SLL conflicts that occur during\n\t// prediction. This is the fastest prediction mode that guarantees correct\n\t// parse results for all combinations of grammars with syntactically correct\n\t// inputs.\n\t//\n\t// <p>\n\t// When using this prediction mode, the parser will make correct decisions\n\t// for all syntactically-correct grammar and input combinations. However, in\n\t// cases where the grammar is truly ambiguous this prediction mode might not\n\t// report a precise answer for <em>exactly which</em> alternatives are\n\t// ambiguous.</p>\n\t//\n\t// <p>\n\t// This prediction mode does not provide any guarantees for prediction\n\t// behavior for syntactically-incorrect inputs.</p>\n\t//\n\tPredictionMode.LL = 1;\n\t//\n\t// The LL(*) prediction mode with exact ambiguity detection. In addition to\n\t// the correctness guarantees provided by the {@link //LL} prediction mode,\n\t// this prediction mode instructs the prediction algorithm to determine the\n\t// complete and exact set of ambiguous alternatives for every ambiguous\n\t// decision encountered while parsing.\n\t//\n\t// <p>\n\t// This prediction mode may be used for diagnosing ambiguities during\n\t// grammar development. Due to the performance overhead of calculating sets\n\t// of ambiguous alternatives, this prediction mode should be avoided when\n\t// the exact results are not necessary.</p>\n\t//\n\t// <p>\n\t// This prediction mode does not provide any guarantees for prediction\n\t// behavior for syntactically-incorrect inputs.</p>\n\t//\n\tPredictionMode.LL_EXACT_AMBIG_DETECTION = 2;\n\t\n\t\n\t//\n\t// Computes the SLL prediction termination condition.\n\t//\n\t// <p>\n\t// This method computes the SLL prediction termination condition for both of\n\t// the following cases.</p>\n\t//\n\t// <ul>\n\t// <li>The usual SLL+LL fallback upon SLL conflict</li>\n\t// <li>Pure SLL without LL fallback</li>\n\t// </ul>\n\t//\n\t// <p><strong>COMBINED SLL+LL PARSING</strong></p>\n\t//\n\t// <p>When LL-fallback is enabled upon SLL conflict, correct predictions are\n\t// ensured regardless of how the termination condition is computed by this\n\t// method. Due to the substantially higher cost of LL prediction, the\n\t// prediction should only fall back to LL when the additional lookahead\n\t// cannot lead to a unique SLL prediction.</p>\n\t//\n\t// <p>Assuming combined SLL+LL parsing, an SLL configuration set with only\n\t// conflicting subsets should fall back to full LL, even if the\n\t// configuration sets don't resolve to the same alternative (e.g.\n\t// {@code {1,2}} and {@code {3,4}}. If there is at least one non-conflicting\n\t// configuration, SLL could continue with the hopes that more lookahead will\n\t// resolve via one of those non-conflicting configurations.</p>\n\t//\n\t// <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing)\n\t// stops when it sees only conflicting configuration subsets. In contrast,\n\t// full LL keeps going when there is uncertainty.</p>\n\t//\n\t// <p><strong>HEURISTIC</strong></p>\n\t//\n\t// <p>As a heuristic, we stop prediction when we see any conflicting subset\n\t// unless we see a state that only has one alternative associated with it.\n\t// The single-alt-state thing lets prediction continue upon rules like\n\t// (otherwise, it would admit defeat too soon):</p>\n\t//\n\t// <p>{@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}</p>\n\t//\n\t// <p>When the ATN simulation reaches the state before {@code ';'}, it has a\n\t// DFA state that looks like: {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally\n\t// {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stop\n\t// processing this node because alternative to has another way to continue,\n\t// via {@code [6|2|[]]}.</p>\n\t//\n\t// <p>It also let's us continue for this rule:</p>\n\t//\n\t// <p>{@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}</p>\n\t//\n\t// <p>After matching input A, we reach the stop state for rule A, state 1.\n\t// State 8 is the state right before B. Clearly alternatives 1 and 2\n\t// conflict and no amount of further lookahead will separate the two.\n\t// However, alternative 3 will be able to continue and so we do not stop\n\t// working on this state. In the previous example, we're concerned with\n\t// states associated with the conflicting alternatives. Here alt 3 is not\n\t// associated with the conflicting configs, but since we can continue\n\t// looking for input reasonably, don't declare the state done.</p>\n\t//\n\t// <p><strong>PURE SLL PARSING</strong></p>\n\t//\n\t// <p>To handle pure SLL parsing, all we have to do is make sure that we\n\t// combine stack contexts for configurations that differ only by semantic\n\t// predicate. From there, we can do the usual SLL termination heuristic.</p>\n\t//\n\t// <p><strong>PREDICATES IN SLL+LL PARSING</strong></p>\n\t//\n\t// <p>SLL decisions don't evaluate predicates until after they reach DFA stop\n\t// states because they need to create the DFA cache that works in all\n\t// semantic situations. In contrast, full LL evaluates predicates collected\n\t// during start state computation so it can ignore predicates thereafter.\n\t// This means that SLL termination detection can totally ignore semantic\n\t// predicates.</p>\n\t//\n\t// <p>Implementation-wise, {@link ATNConfigSet} combines stack contexts but not\n\t// semantic predicate contexts so we might see two configurations like the\n\t// following.</p>\n\t//\n\t// <p>{@code (s, 1, x, {}), (s, 1, x', {p})}</p>\n\t//\n\t// <p>Before testing these configurations against others, we have to merge\n\t// {@code x} and {@code x'} (without modifying the existing configurations).\n\t// For example, we test {@code (x+x')==x''} when looking for conflicts in\n\t// the following configurations.</p>\n\t//\n\t// <p>{@code (s, 1, x, {}), (s, 1, x', {p}), (s, 2, x'', {})}</p>\n\t//\n\t// <p>If the configuration set has predicates (as indicated by\n\t// {@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of\n\t// the configurations to strip out all of the predicates so that a standard\n\t// {@link ATNConfigSet} will merge everything ignoring predicates.</p>\n\t//\n\tPredictionMode.hasSLLConflictTerminatingPrediction = function( mode, configs) {\n\t    // Configs in rule stop states indicate reaching the end of the decision\n\t    // rule (local context) or end of start rule (full context). If all\n\t    // configs meet this condition, then none of the configurations is able\n\t    // to match additional input so we terminate prediction.\n\t    //\n\t    if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n\t        return true;\n\t    }\n\t    // pure SLL mode parsing\n\t    if (mode === PredictionMode.SLL) {\n\t        // Don't bother with combining configs from different semantic\n\t        // contexts if we can fail over to full LL; costs more time\n\t        // since we'll often fail over anyway.\n\t        if (configs.hasSemanticContext) {\n\t            // dup configs, tossing out semantic predicates\n\t            var dup = new ATNConfigSet();\n\t            for(var i=0;i<configs.items.length;i++) {\n\t            \tvar c = configs.items[i];\n\t                c = new ATNConfig({semanticContext:SemanticContext.NONE}, c);\n\t                dup.add(c);\n\t            }\n\t            configs = dup;\n\t        }\n\t        // now we have combined contexts for configs with dissimilar preds\n\t    }\n\t    // pure SLL or combined SLL+LL mode parsing\n\t    var altsets = PredictionMode.getConflictingAltSubsets(configs);\n\t    return PredictionMode.hasConflictingAltSet(altsets) && !PredictionMode.hasStateAssociatedWithOneAlt(configs);\n\t};\n\t\n\t// Checks if any configuration in {@code configs} is in a\n\t// {@link RuleStopState}. Configurations meeting this condition have reached\n\t// the end of the decision rule (local context) or end of start rule (full\n\t// context).\n\t//\n\t// @param configs the configuration set to test\n\t// @return {@code true} if any configuration in {@code configs} is in a\n\t// {@link RuleStopState}, otherwise {@code false}\n\tPredictionMode.hasConfigInRuleStopState = function(configs) {\n\t\tfor(var i=0;i<configs.items.length;i++) {\n\t\t\tvar c = configs.items[i];\n\t        if (c.state instanceof RuleStopState) {\n\t            return true;\n\t        }\n\t\t}\n\t    return false;\n\t};\n\t\n\t// Checks if all configurations in {@code configs} are in a\n\t// {@link RuleStopState}. Configurations meeting this condition have reached\n\t// the end of the decision rule (local context) or end of start rule (full\n\t// context).\n\t//\n\t// @param configs the configuration set to test\n\t// @return {@code true} if all configurations in {@code configs} are in a\n\t// {@link RuleStopState}, otherwise {@code false}\n\tPredictionMode.allConfigsInRuleStopStates = function(configs) {\n\t\tfor(var i=0;i<configs.items.length;i++) {\n\t\t\tvar c = configs.items[i];\n\t        if (!(c.state instanceof RuleStopState)) {\n\t            return false;\n\t        }\n\t\t}\n\t    return true;\n\t};\n\t\n\t//\n\t// Full LL prediction termination.\n\t//\n\t// <p>Can we stop looking ahead during ATN simulation or is there some\n\t// uncertainty as to which alternative we will ultimately pick, after\n\t// consuming more input? Even if there are partial conflicts, we might know\n\t// that everything is going to resolve to the same minimum alternative. That\n\t// means we can stop since no more lookahead will change that fact. On the\n\t// other hand, there might be multiple conflicts that resolve to different\n\t// minimums. That means we need more look ahead to decide which of those\n\t// alternatives we should predict.</p>\n\t//\n\t// <p>The basic idea is to split the set of configurations {@code C}, into\n\t// conflicting subsets {@code (s, _, ctx, _)} and singleton subsets with\n\t// non-conflicting configurations. Two configurations conflict if they have\n\t// identical {@link ATNConfig//state} and {@link ATNConfig//context} values\n\t// but different {@link ATNConfig//alt} value, e.g. {@code (s, i, ctx, _)}\n\t// and {@code (s, j, ctx, _)} for {@code i!=j}.</p>\n\t//\n\t// <p>Reduce these configuration subsets to the set of possible alternatives.\n\t// You can compute the alternative subsets in one pass as follows:</p>\n\t//\n\t// <p>{@code A_s,ctx = {i | (s, i, ctx, _)}} for each configuration in\n\t// {@code C} holding {@code s} and {@code ctx} fixed.</p>\n\t//\n\t// <p>Or in pseudo-code, for each configuration {@code c} in {@code C}:</p>\n\t//\n\t// <pre>\n\t// map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n\t// alt and not pred\n\t// </pre>\n\t//\n\t// <p>The values in {@code map} are the set of {@code A_s,ctx} sets.</p>\n\t//\n\t// <p>If {@code |A_s,ctx|=1} then there is no conflict associated with\n\t// {@code s} and {@code ctx}.</p>\n\t//\n\t// <p>Reduce the subsets to singletons by choosing a minimum of each subset. If\n\t// the union of these alternative subsets is a singleton, then no amount of\n\t// more lookahead will help us. We will always pick that alternative. If,\n\t// however, there is more than one alternative, then we are uncertain which\n\t// alternative to predict and must continue looking for resolution. We may\n\t// or may not discover an ambiguity in the future, even if there are no\n\t// conflicting subsets this round.</p>\n\t//\n\t// <p>The biggest sin is to terminate early because it means we've made a\n\t// decision but were uncertain as to the eventual outcome. We haven't used\n\t// enough lookahead. On the other hand, announcing a conflict too late is no\n\t// big deal; you will still have the conflict. It's just inefficient. It\n\t// might even look until the end of file.</p>\n\t//\n\t// <p>No special consideration for semantic predicates is required because\n\t// predicates are evaluated on-the-fly for full LL prediction, ensuring that\n\t// no configuration contains a semantic context during the termination\n\t// check.</p>\n\t//\n\t// <p><strong>CONFLICTING CONFIGS</strong></p>\n\t//\n\t// <p>Two configurations {@code (s, i, x)} and {@code (s, j, x')}, conflict\n\t// when {@code i!=j} but {@code x=x'}. Because we merge all\n\t// {@code (s, i, _)} configurations together, that means that there are at\n\t// most {@code n} configurations associated with state {@code s} for\n\t// {@code n} possible alternatives in the decision. The merged stacks\n\t// complicate the comparison of configuration contexts {@code x} and\n\t// {@code x'}. Sam checks to see if one is a subset of the other by calling\n\t// merge and checking to see if the merged result is either {@code x} or\n\t// {@code x'}. If the {@code x} associated with lowest alternative {@code i}\n\t// is the superset, then {@code i} is the only possible prediction since the\n\t// others resolve to {@code min(i)} as well. However, if {@code x} is\n\t// associated with {@code j>i} then at least one stack configuration for\n\t// {@code j} is not in conflict with alternative {@code i}. The algorithm\n\t// should keep going, looking for more lookahead due to the uncertainty.</p>\n\t//\n\t// <p>For simplicity, I'm doing a equality check between {@code x} and\n\t// {@code x'} that lets the algorithm continue to consume lookahead longer\n\t// than necessary. The reason I like the equality is of course the\n\t// simplicity but also because that is the test you need to detect the\n\t// alternatives that are actually in conflict.</p>\n\t//\n\t// <p><strong>CONTINUE/STOP RULE</strong></p>\n\t//\n\t// <p>Continue if union of resolved alternative sets from non-conflicting and\n\t// conflicting alternative subsets has more than one alternative. We are\n\t// uncertain about which alternative to predict.</p>\n\t//\n\t// <p>The complete set of alternatives, {@code [i for (_,i,_)]}, tells us which\n\t// alternatives are still in the running for the amount of input we've\n\t// consumed at this point. The conflicting sets let us to strip away\n\t// configurations that won't lead to more states because we resolve\n\t// conflicts to the configuration with a minimum alternate for the\n\t// conflicting set.</p>\n\t//\n\t// <p><strong>CASES</strong></p>\n\t//\n\t// <ul>\n\t//\n\t// <li>no conflicts and more than 1 alternative in set =&gt; continue</li>\n\t//\n\t// <li> {@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s, 3, z)},\n\t// {@code (s', 1, y)}, {@code (s', 2, y)} yields non-conflicting set\n\t// {@code {3}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n\t// {@code {1,3}} =&gt; continue\n\t// </li>\n\t//\n\t// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n\t// {@code (s', 2, y)}, {@code (s'', 1, z)} yields non-conflicting set\n\t// {@code {1}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n\t// {@code {1}} =&gt; stop and predict 1</li>\n\t//\n\t// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n\t// {@code (s', 2, y)} yields conflicting, reduced sets {@code {1}} U\n\t// {@code {1}} = {@code {1}} =&gt; stop and predict 1, can announce\n\t// ambiguity {@code {1,2}}</li>\n\t//\n\t// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 2, y)},\n\t// {@code (s', 3, y)} yields conflicting, reduced sets {@code {1}} U\n\t// {@code {2}} = {@code {1,2}} =&gt; continue</li>\n\t//\n\t// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 3, y)},\n\t// {@code (s', 4, y)} yields conflicting, reduced sets {@code {1}} U\n\t// {@code {3}} = {@code {1,3}} =&gt; continue</li>\n\t//\n\t// </ul>\n\t//\n\t// <p><strong>EXACT AMBIGUITY DETECTION</strong></p>\n\t//\n\t// <p>If all states report the same conflicting set of alternatives, then we\n\t// know we have the exact ambiguity set.</p>\n\t//\n\t// <p><code>|A_<em>i</em>|&gt;1</code> and\n\t// <code>A_<em>i</em> = A_<em>j</em></code> for all <em>i</em>, <em>j</em>.</p>\n\t//\n\t// <p>In other words, we continue examining lookahead until all {@code A_i}\n\t// have more than one alternative and all {@code A_i} are the same. If\n\t// {@code A={{1,2}, {1,3}}}, then regular LL prediction would terminate\n\t// because the resolved set is {@code {1}}. To determine what the real\n\t// ambiguity is, we have to know whether the ambiguity is between one and\n\t// two or one and three so we keep going. We can only stop prediction when\n\t// we need exact ambiguity detection when the sets look like\n\t// {@code A={{1,2}}} or {@code {{1,2},{1,2}}}, etc...</p>\n\t//\n\tPredictionMode.resolvesToJustOneViableAlt = function(altsets) {\n\t    return PredictionMode.getSingleViableAlt(altsets);\n\t};\n\t\n\t//\n\t// Determines if every alternative subset in {@code altsets} contains more\n\t// than one alternative.\n\t//\n\t// @param altsets a collection of alternative subsets\n\t// @return {@code true} if every {@link BitSet} in {@code altsets} has\n\t// {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n\t//\n\tPredictionMode.allSubsetsConflict = function(altsets) {\n\t    return ! PredictionMode.hasNonConflictingAltSet(altsets);\n\t};\n\t//\n\t// Determines if any single alternative subset in {@code altsets} contains\n\t// exactly one alternative.\n\t//\n\t// @param altsets a collection of alternative subsets\n\t// @return {@code true} if {@code altsets} contains a {@link BitSet} with\n\t// {@link BitSet//cardinality cardinality} 1, otherwise {@code false}\n\t//\n\tPredictionMode.hasNonConflictingAltSet = function(altsets) {\n\t\tfor(var i=0;i<altsets.length;i++) {\n\t\t\tvar alts = altsets[i];\n\t        if (alts.length===1) {\n\t            return true;\n\t        }\n\t\t}\n\t    return false;\n\t};\n\t\n\t//\n\t// Determines if any single alternative subset in {@code altsets} contains\n\t// more than one alternative.\n\t//\n\t// @param altsets a collection of alternative subsets\n\t// @return {@code true} if {@code altsets} contains a {@link BitSet} with\n\t// {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n\t//\n\tPredictionMode.hasConflictingAltSet = function(altsets) {\n\t\tfor(var i=0;i<altsets.length;i++) {\n\t\t\tvar alts = altsets[i];\n\t        if (alts.length>1) {\n\t            return true;\n\t        }\n\t\t}\n\t    return false;\n\t};\n\t\n\t//\n\t// Determines if every alternative subset in {@code altsets} is equivalent.\n\t//\n\t// @param altsets a collection of alternative subsets\n\t// @return {@code true} if every member of {@code altsets} is equal to the\n\t// others, otherwise {@code false}\n\t//\n\tPredictionMode.allSubsetsEqual = function(altsets) {\n\t    var first = null;\n\t\tfor(var i=0;i<altsets.length;i++) {\n\t\t\tvar alts = altsets[i];\n\t        if (first === null) {\n\t            first = alts;\n\t        } else if (alts!==first) {\n\t            return false;\n\t        }\n\t\t}\n\t    return true;\n\t};\n\t\n\t//\n\t// Returns the unique alternative predicted by all alternative subsets in\n\t// {@code altsets}. If no such alternative exists, this method returns\n\t// {@link ATN//INVALID_ALT_NUMBER}.\n\t//\n\t// @param altsets a collection of alternative subsets\n\t//\n\tPredictionMode.getUniqueAlt = function(altsets) {\n\t    var all = PredictionMode.getAlts(altsets);\n\t    if (all.length===1) {\n\t        return all.minValue();\n\t    } else {\n\t        return ATN.INVALID_ALT_NUMBER;\n\t    }\n\t};\n\t\n\t// Gets the complete set of represented alternatives for a collection of\n\t// alternative subsets. This method returns the union of each {@link BitSet}\n\t// in {@code altsets}.\n\t//\n\t// @param altsets a collection of alternative subsets\n\t// @return the set of represented alternatives in {@code altsets}\n\t//\n\tPredictionMode.getAlts = function(altsets) {\n\t    var all = new BitSet();\n\t    altsets.map( function(alts) { all.or(alts); });\n\t    return all;\n\t};\n\t\n\t//\n\t// This function gets the conflicting alt subsets from a configuration set.\n\t// For each configuration {@code c} in {@code configs}:\n\t//\n\t// <pre>\n\t// map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n\t// alt and not pred\n\t// </pre>\n\t//\n\tPredictionMode.getConflictingAltSubsets = function(configs) {\n\t    var configToAlts = {};\n\t\tfor(var i=0;i<configs.items.length;i++) {\n\t\t\tvar c = configs.items[i];\n\t        var key = \"key_\" + c.state.stateNumber + \"/\" + c.context;\n\t        var alts = configToAlts[key] || null;\n\t        if (alts === null) {\n\t            alts = new BitSet();\n\t            configToAlts[key] = alts;\n\t        }\n\t        alts.add(c.alt);\n\t\t}\n\t\tvar values = [];\n\t\tfor(var k in configToAlts) {\n\t\t\tif(k.indexOf(\"key_\")!==0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tvalues.push(configToAlts[k]);\n\t\t}\n\t    return values;\n\t};\n\t\n\t//\n\t// Get a map from state to alt subset from a configuration set. For each\n\t// configuration {@code c} in {@code configs}:\n\t//\n\t// <pre>\n\t// map[c.{@link ATNConfig//state state}] U= c.{@link ATNConfig//alt alt}\n\t// </pre>\n\t//\n\tPredictionMode.getStateToAltMap = function(configs) {\n\t    var m = new AltDict();\n\t    configs.items.map(function(c) {\n\t        var alts = m.get(c.state);\n\t        if (alts === null) {\n\t            alts = new BitSet();\n\t            m.put(c.state, alts);\n\t        }\n\t        alts.add(c.alt);\n\t    });\n\t    return m;\n\t};\n\t\n\tPredictionMode.hasStateAssociatedWithOneAlt = function(configs) {\n\t    var values = PredictionMode.getStateToAltMap(configs).values();\n\t    for(var i=0;i<values.length;i++) {\n\t        if (values[i].length===1) {\n\t            return true;\n\t        }\n\t    }\n\t    return false;\n\t};\n\t\n\tPredictionMode.getSingleViableAlt = function(altsets) {\n\t    var result = null;\n\t\tfor(var i=0;i<altsets.length;i++) {\n\t\t\tvar alts = altsets[i];\n\t        var minAlt = alts.minValue();\n\t        if(result===null) {\n\t            result = minAlt;\n\t        } else if(result!==minAlt) { // more than 1 viable alt\n\t            return ATN.INVALID_ALT_NUMBER;\n\t        }\n\t\t}\n\t    return result;\n\t};\n\t\n\texports.PredictionMode = PredictionMode;\n\n\n/***/ },\n/* 36 */\n/***/ function(module, exports, __webpack_require__) {\n\n\texports.DFA = __webpack_require__(37).DFA;\n\texports.DFASerializer = __webpack_require__(38).DFASerializer;\n\texports.LexerDFASerializer = __webpack_require__(38).LexerDFASerializer;\n\texports.PredPrediction = __webpack_require__(31).PredPrediction;\n\n\n/***/ },\n/* 37 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\tvar DFAState = __webpack_require__(31).DFAState;\n\tvar ATNConfigSet = __webpack_require__(32).ATNConfigSet;\n\tvar DFASerializer = __webpack_require__(38).DFASerializer;\n\tvar LexerDFASerializer = __webpack_require__(38).LexerDFASerializer;\n\t\n\tfunction DFAStatesSet() {\n\t\treturn this;\n\t}\n\t\n\tObject.defineProperty(DFAStatesSet.prototype, \"length\", {\n\t\tget : function() {\n\t\t\treturn Object.keys(this).length;\n\t\t}\n\t});\n\t\n\tfunction DFA(atnStartState, decision) {\n\t\tif (decision === undefined) {\n\t\t\tdecision = 0;\n\t\t}\n\t\t// From which ATN state did we create this DFA?\n\t\tthis.atnStartState = atnStartState;\n\t\tthis.decision = decision;\n\t\t// A set of all DFA states. Use {@link Map} so we can get old state back\n\t\t// ({@link Set} only allows you to see if it's there).\n\t\tthis._states = new DFAStatesSet();\n\t\tthis.s0 = null;\n\t\t// {@code true} if this DFA is for a precedence decision; otherwise,\n\t\t// {@code false}. This is the backing field for {@link //isPrecedenceDfa},\n\t\t// {@link //setPrecedenceDfa}.\n\t\tthis.precedenceDfa = false;\n\t\treturn this;\n\t}\n\t\n\t// Get the start state for a specific precedence value.\n\t//\n\t// @param precedence The current precedence.\n\t// @return The start state corresponding to the specified precedence, or\n\t// {@code null} if no start state exists for the specified precedence.\n\t//\n\t// @throws IllegalStateException if this is not a precedence DFA.\n\t// @see //isPrecedenceDfa()\n\t\n\tDFA.prototype.getPrecedenceStartState = function(precedence) {\n\t\tif (!(this.precedenceDfa)) {\n\t\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t\t}\n\t\t// s0.edges is never null for a precedence DFA\n\t\tif (precedence < 0 || precedence >= this.s0.edges.length) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.s0.edges[precedence] || null;\n\t};\n\t\n\t// Set the start state for a specific precedence value.\n\t//\n\t// @param precedence The current precedence.\n\t// @param startState The start state corresponding to the specified\n\t// precedence.\n\t//\n\t// @throws IllegalStateException if this is not a precedence DFA.\n\t// @see //isPrecedenceDfa()\n\t//\n\tDFA.prototype.setPrecedenceStartState = function(precedence, startState) {\n\t\tif (!(this.precedenceDfa)) {\n\t\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t\t}\n\t\tif (precedence < 0) {\n\t\t\treturn;\n\t\t}\n\t\n\t\t// synchronization on s0 here is ok. when the DFA is turned into a\n\t\t// precedence DFA, s0 will be initialized once and not updated again\n\t\t// s0.edges is never null for a precedence DFA\n\t\tthis.s0.edges[precedence] = startState;\n\t};\n\t\n\t//\n\t// Sets whether this is a precedence DFA. If the specified value differs\n\t// from the current DFA configuration, the following actions are taken;\n\t// otherwise no changes are made to the current DFA.\n\t//\n\t// <ul>\n\t// <li>The {@link //states} map is cleared</li>\n\t// <li>If {@code precedenceDfa} is {@code false}, the initial state\n\t// {@link //s0} is set to {@code null}; otherwise, it is initialized to a new\n\t// {@link DFAState} with an empty outgoing {@link DFAState//edges} array to\n\t// store the start states for individual precedence values.</li>\n\t// <li>The {@link //precedenceDfa} field is updated</li>\n\t// </ul>\n\t//\n\t// @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,\n\t// {@code false}\n\t\n\tDFA.prototype.setPrecedenceDfa = function(precedenceDfa) {\n\t\tif (this.precedenceDfa!==precedenceDfa) {\n\t\t\tthis._states = new DFAStatesSet();\n\t\t\tif (precedenceDfa) {\n\t\t\t\tvar precedenceState = new DFAState(new ATNConfigSet());\n\t\t\t\tprecedenceState.edges = [];\n\t\t\t\tprecedenceState.isAcceptState = false;\n\t\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\t\tthis.s0 = precedenceState;\n\t\t\t} else {\n\t\t\t\tthis.s0 = null;\n\t\t\t}\n\t\t\tthis.precedenceDfa = precedenceDfa;\n\t\t}\n\t};\n\t\n\tObject.defineProperty(DFA.prototype, \"states\", {\n\t\tget : function() {\n\t\t\treturn this._states;\n\t\t}\n\t});\n\t\n\t// Return a list of all states in this DFA, ordered by state number.\n\tDFA.prototype.sortedStates = function() {\n\t\t// states_ is a map of state/state, where key=value\n\t\tvar keys = Object.keys(this._states);\n\t\tvar list = [];\n\t\tfor(var i=0;i<keys.length;i++) {\n\t\t\tlist.push(this._states[keys[i]]);\n\t\t}\n\t\treturn list.sort(function(a, b) {\n\t\t\treturn a.stateNumber - b.stateNumber;\n\t\t});\n\t};\n\t\n\tDFA.prototype.toString = function(literalNames, symbolicNames) {\n\t\tliteralNames = literalNames || null;\n\t\tsymbolicNames = symbolicNames || null;\n\t\tif (this.s0 === null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tvar serializer = new DFASerializer(this, literalNames, symbolicNames);\n\t\treturn serializer.toString();\n\t};\n\t\n\tDFA.prototype.toLexerString = function() {\n\t\tif (this.s0 === null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tvar serializer = new LexerDFASerializer(this);\n\t\treturn serializer.toString();\n\t};\n\t\n\texports.DFA = DFA;\n\n\n/***/ },\n/* 38 */\n/***/ function(module, exports) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\t// A DFA walker that knows how to dump them to serialized strings.#/\n\t\n\t\n\tfunction DFASerializer(dfa, literalNames, symbolicNames) {\n\t\tthis.dfa = dfa;\n\t\tthis.literalNames = literalNames || [];\n\t\tthis.symbolicNames = symbolicNames || [];\n\t\treturn this;\n\t}\n\t\n\tDFASerializer.prototype.toString = function() {\n\t   if(this.dfa.s0 === null) {\n\t       return null;\n\t   }\n\t   var buf = \"\";\n\t   var states = this.dfa.sortedStates();\n\t   for(var i=0;i<states.length;i++) {\n\t       var s = states[i];\n\t       if(s.edges!==null) {\n\t            var n = s.edges.length;\n\t            for(var j=0;j<n;j++) {\n\t                var t = s.edges[j] || null;\n\t                if(t!==null && t.stateNumber !== 0x7FFFFFFF) {\n\t                    buf = buf.concat(this.getStateString(s));\n\t                    buf = buf.concat(\"-\");\n\t                    buf = buf.concat(this.getEdgeLabel(j));\n\t                    buf = buf.concat(\"->\");\n\t                    buf = buf.concat(this.getStateString(t));\n\t                    buf = buf.concat('\\n');\n\t                }\n\t            }\n\t       }\n\t   }\n\t   return buf.length===0 ? null : buf;\n\t};\n\t\n\tDFASerializer.prototype.getEdgeLabel = function(i) {\n\t    if (i===0) {\n\t        return \"EOF\";\n\t    } else if(this.literalNames !==null || this.symbolicNames!==null) {\n\t        return this.literalNames[i-1] || this.symbolicNames[i-1];\n\t    } else {\n\t        return String.fromCharCode(i-1);\n\t    }\n\t};\n\t\n\tDFASerializer.prototype.getStateString = function(s) {\n\t    var baseStateStr = ( s.isAcceptState ? \":\" : \"\") + \"s\" + s.stateNumber + ( s.requiresFullContext ? \"^\" : \"\");\n\t    if(s.isAcceptState) {\n\t        if (s.predicates !== null) {\n\t            return baseStateStr + \"=>\" + s.predicates.toString();\n\t        } else {\n\t            return baseStateStr + \"=>\" + s.prediction.toString();\n\t        }\n\t    } else {\n\t        return baseStateStr;\n\t    }\n\t};\n\t\n\tfunction LexerDFASerializer(dfa) {\n\t\tDFASerializer.call(this, dfa, null);\n\t\treturn this;\n\t}\n\t\n\tLexerDFASerializer.prototype = Object.create(DFASerializer.prototype);\n\tLexerDFASerializer.prototype.constructor = LexerDFASerializer;\n\t\n\tLexerDFASerializer.prototype.getEdgeLabel = function(i) {\n\t\treturn \"'\" + String.fromCharCode(i) + \"'\";\n\t};\n\t\n\texports.DFASerializer = DFASerializer;\n\texports.LexerDFASerializer = LexerDFASerializer;\n\t\n\n\n/***/ },\n/* 39 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar Tree = __webpack_require__(17);\n\texports.Trees = __webpack_require__(18).Trees;\n\texports.RuleNode = Tree.RuleNode;\n\texports.ParseTreeListener = Tree.ParseTreeListener;\n\texports.ParseTreeVisitor = Tree.ParseTreeVisitor;\n\texports.ParseTreeWalker = Tree.ParseTreeWalker;\n\n\n/***/ },\n/* 40 */\n/***/ function(module, exports, __webpack_require__) {\n\n\texports.RecognitionException = __webpack_require__(29).RecognitionException;\n\texports.NoViableAltException = __webpack_require__(29).NoViableAltException;\n\texports.LexerNoViableAltException = __webpack_require__(29).LexerNoViableAltException;\n\texports.InputMismatchException = __webpack_require__(29).InputMismatchException;\n\texports.FailedPredicateException = __webpack_require__(29).FailedPredicateException;\n\texports.DiagnosticErrorListener = __webpack_require__(41).DiagnosticErrorListener;\n\texports.BailErrorStrategy = __webpack_require__(42).BailErrorStrategy;\n\texports.ErrorListener = __webpack_require__(27).ErrorListener;\n\n/***/ },\n/* 41 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t//\n\t\n\t//\n\t// This implementation of {@link ANTLRErrorListener} can be used to identify\n\t// certain potential correctness and performance problems in grammars. \"Reports\"\n\t// are made by calling {@link Parser//notifyErrorListeners} with the appropriate\n\t// message.\n\t//\n\t// <ul>\n\t// <li><b>Ambiguities</b>: These are cases where more than one path through the\n\t// grammar can match the input.</li>\n\t// <li><b>Weak context sensitivity</b>: These are cases where full-context\n\t// prediction resolved an SLL conflict to a unique alternative which equaled the\n\t// minimum alternative of the SLL conflict.</li>\n\t// <li><b>Strong (forced) context sensitivity</b>: These are cases where the\n\t// full-context prediction resolved an SLL conflict to a unique alternative,\n\t// <em>and</em> the minimum alternative of the SLL conflict was found to not be\n\t// a truly viable alternative. Two-stage parsing cannot be used for inputs where\n\t// this situation occurs.</li>\n\t// </ul>\n\t\n\tvar BitSet = __webpack_require__(8).BitSet;\n\tvar ErrorListener = __webpack_require__(27).ErrorListener;\n\tvar Interval = __webpack_require__(13).Interval;\n\t\n\tfunction DiagnosticErrorListener(exactOnly) {\n\t\tErrorListener.call(this);\n\t\texactOnly = exactOnly || true;\n\t\t// whether all ambiguities or only exact ambiguities are reported.\n\t\tthis.exactOnly = exactOnly;\n\t\treturn this;\n\t}\n\t\n\tDiagnosticErrorListener.prototype = Object.create(ErrorListener.prototype);\n\tDiagnosticErrorListener.prototype.constructor = DiagnosticErrorListener;\n\t\n\tDiagnosticErrorListener.prototype.reportAmbiguity = function(recognizer, dfa,\n\t\t\tstartIndex, stopIndex, exact, ambigAlts, configs) {\n\t\tif (this.exactOnly && !exact) {\n\t\t\treturn;\n\t\t}\n\t\tvar msg = \"reportAmbiguity d=\" +\n\t\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\t\": ambigAlts=\" +\n\t\t\t\tthis.getConflictingAlts(ambigAlts, configs) +\n\t\t\t\t\", input='\" +\n\t\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\";\n\t\trecognizer.notifyErrorListeners(msg);\n\t};\n\t\n\tDiagnosticErrorListener.prototype.reportAttemptingFullContext = function(\n\t\t\trecognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\t\tvar msg = \"reportAttemptingFullContext d=\" +\n\t\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\t\", input='\" +\n\t\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\";\n\t\trecognizer.notifyErrorListeners(msg);\n\t};\n\t\n\tDiagnosticErrorListener.prototype.reportContextSensitivity = function(\n\t\t\trecognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\t\tvar msg = \"reportContextSensitivity d=\" +\n\t\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\t\", input='\" +\n\t\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\";\n\t\trecognizer.notifyErrorListeners(msg);\n\t};\n\t\n\tDiagnosticErrorListener.prototype.getDecisionDescription = function(recognizer, dfa) {\n\t\tvar decision = dfa.decision;\n\t\tvar ruleIndex = dfa.atnStartState.ruleIndex;\n\t\n\t\tvar ruleNames = recognizer.ruleNames;\n\t\tif (ruleIndex < 0 || ruleIndex >= ruleNames.length) {\n\t\t\treturn \"\" + decision;\n\t\t}\n\t\tvar ruleName = ruleNames[ruleIndex] || null;\n\t\tif (ruleName === null || ruleName.length === 0) {\n\t\t\treturn \"\" + decision;\n\t\t}\n\t\treturn \"\" + decision + \" (\" + ruleName + \")\";\n\t};\n\t\n\t//\n\t// Computes the set of conflicting or ambiguous alternatives from a\n\t// configuration set, if that information was not already provided by the\n\t// parser.\n\t//\n\t// @param reportedAlts The set of conflicting or ambiguous alternatives, as\n\t// reported by the parser.\n\t// @param configs The conflicting or ambiguous configuration set.\n\t// @return Returns {@code reportedAlts} if it is not {@code null}, otherwise\n\t// returns the set of alternatives represented in {@code configs}.\n\t//\n\tDiagnosticErrorListener.prototype.getConflictingAlts = function(reportedAlts, configs) {\n\t\tif (reportedAlts !== null) {\n\t\t\treturn reportedAlts;\n\t\t}\n\t\tvar result = new BitSet();\n\t\tfor (var i = 0; i < configs.items.length; i++) {\n\t\t\tresult.add(configs.items[i].alt);\n\t\t}\n\t\treturn \"{\" + result.values().join(\", \") + \"}\";\n\t};\n\t\n\texports.DiagnosticErrorListener = DiagnosticErrorListener;\n\n/***/ },\n/* 42 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t//\n\t\n\tvar Token = __webpack_require__(9).Token;\n\tvar Errors = __webpack_require__(29);\n\tvar NoViableAltException = Errors.NoViableAltException;\n\tvar InputMismatchException = Errors.InputMismatchException;\n\tvar FailedPredicateException = Errors.FailedPredicateException;\n\tvar ParseCancellationException = Errors.ParseCancellationException;\n\tvar ATNState = __webpack_require__(11).ATNState;\n\tvar Interval = __webpack_require__(13).Interval;\n\tvar IntervalSet = __webpack_require__(13).IntervalSet;\n\t\n\tfunction ErrorStrategy() {\n\t\t\n\t}\n\t\n\tErrorStrategy.prototype.reset = function(recognizer){\n\t};\n\t\n\tErrorStrategy.prototype.recoverInline = function(recognizer){\n\t};\n\t\n\tErrorStrategy.prototype.recover = function(recognizer, e){\n\t};\n\t\n\tErrorStrategy.prototype.sync = function(recognizer){\n\t};\n\t\n\tErrorStrategy.prototype.inErrorRecoveryMode = function(recognizer){\n\t};\n\t\n\tErrorStrategy.prototype.reportError = function(recognizer){\n\t};\n\t\n\t\n\t\n\t// This is the default implementation of {@link ANTLRErrorStrategy} used for\n\t// error reporting and recovery in ANTLR parsers.\n\t//\n\tfunction DefaultErrorStrategy() {\n\t\tErrorStrategy.call(this);\n\t    // Indicates whether the error strategy is currently \"recovering from an\n\t    // error\". This is used to suppress reporting multiple error messages while\n\t    // attempting to recover from a detected syntax error.\n\t    //\n\t    // @see //inErrorRecoveryMode\n\t    //\n\t    this.errorRecoveryMode = false;\n\t\n\t    // The index into the input stream where the last error occurred.\n\t    // This is used to prevent infinite loops where an error is found\n\t    // but no token is consumed during recovery...another error is found,\n\t    // ad nauseum. This is a failsafe mechanism to guarantee that at least\n\t    // one token/tree node is consumed for two errors.\n\t    //\n\t    this.lastErrorIndex = -1;\n\t    this.lastErrorStates = null;\n\t    return this;\n\t}\n\t\n\tDefaultErrorStrategy.prototype = Object.create(ErrorStrategy.prototype);\n\tDefaultErrorStrategy.prototype.constructor = DefaultErrorStrategy;\n\t\n\t// <p>The default implementation simply calls {@link //endErrorCondition} to\n\t// ensure that the handler is not in error recovery mode.</p>\n\tDefaultErrorStrategy.prototype.reset = function(recognizer) {\n\t    this.endErrorCondition(recognizer);\n\t};\n\t\n\t//\n\t// This method is called to enter error recovery mode when a recognition\n\t// exception is reported.\n\t//\n\t// @param recognizer the parser instance\n\t//\n\tDefaultErrorStrategy.prototype.beginErrorCondition = function(recognizer) {\n\t    this.errorRecoveryMode = true;\n\t};\n\t\n\tDefaultErrorStrategy.prototype.inErrorRecoveryMode = function(recognizer) {\n\t    return this.errorRecoveryMode;\n\t};\n\t\n\t//\n\t// This method is called to leave error recovery mode after recovering from\n\t// a recognition exception.\n\t//\n\t// @param recognizer\n\t//\n\tDefaultErrorStrategy.prototype.endErrorCondition = function(recognizer) {\n\t    this.errorRecoveryMode = false;\n\t    this.lastErrorStates = null;\n\t    this.lastErrorIndex = -1;\n\t};\n\t\n\t//\n\t// {@inheritDoc}\n\t//\n\t// <p>The default implementation simply calls {@link //endErrorCondition}.</p>\n\t//\n\tDefaultErrorStrategy.prototype.reportMatch = function(recognizer) {\n\t    this.endErrorCondition(recognizer);\n\t};\n\t\n\t//\n\t// {@inheritDoc}\n\t//\n\t// <p>The default implementation returns immediately if the handler is already\n\t// in error recovery mode. Otherwise, it calls {@link //beginErrorCondition}\n\t// and dispatches the reporting task based on the runtime type of {@code e}\n\t// according to the following table.</p>\n\t//\n\t// <ul>\n\t// <li>{@link NoViableAltException}: Dispatches the call to\n\t// {@link //reportNoViableAlternative}</li>\n\t// <li>{@link InputMismatchException}: Dispatches the call to\n\t// {@link //reportInputMismatch}</li>\n\t// <li>{@link FailedPredicateException}: Dispatches the call to\n\t// {@link //reportFailedPredicate}</li>\n\t// <li>All other types: calls {@link Parser//notifyErrorListeners} to report\n\t// the exception</li>\n\t// </ul>\n\t//\n\tDefaultErrorStrategy.prototype.reportError = function(recognizer, e) {\n\t   // if we've already reported an error and have not matched a token\n\t   // yet successfully, don't report any errors.\n\t    if(this.inErrorRecoveryMode(recognizer)) {\n\t        return; // don't report spurious errors\n\t    }\n\t    this.beginErrorCondition(recognizer);\n\t    if ( e instanceof NoViableAltException ) {\n\t        this.reportNoViableAlternative(recognizer, e);\n\t    } else if ( e instanceof InputMismatchException ) {\n\t        this.reportInputMismatch(recognizer, e);\n\t    } else if ( e instanceof FailedPredicateException ) {\n\t        this.reportFailedPredicate(recognizer, e);\n\t    } else {\n\t        console.log(\"unknown recognition error type: \" + e.constructor.name);\n\t        console.log(e.stack);\n\t        recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);\n\t    }\n\t};\n\t//\n\t// {@inheritDoc}\n\t//\n\t// <p>The default implementation resynchronizes the parser by consuming tokens\n\t// until we find one in the resynchronization set--loosely the set of tokens\n\t// that can follow the current rule.</p>\n\t//\n\tDefaultErrorStrategy.prototype.recover = function(recognizer, e) {\n\t    if (this.lastErrorIndex===recognizer.getInputStream().index &&\n\t        this.lastErrorStates !== null && this.lastErrorStates.indexOf(recognizer.state)>=0) {\n\t\t\t// uh oh, another error at same token index and previously-visited\n\t\t\t// state in ATN; must be a case where LT(1) is in the recovery\n\t\t\t// token set so nothing got consumed. Consume a single token\n\t\t\t// at least to prevent an infinite loop; this is a failsafe.\n\t\t\trecognizer.consume();\n\t    }\n\t    this.lastErrorIndex = recognizer._input.index;\n\t    if (this.lastErrorStates === null) {\n\t        this.lastErrorStates = [];\n\t    }\n\t    this.lastErrorStates.push(recognizer.state);\n\t    var followSet = this.getErrorRecoverySet(recognizer);\n\t    this.consumeUntil(recognizer, followSet);\n\t};\n\t\n\t// The default implementation of {@link ANTLRErrorStrategy//sync} makes sure\n\t// that the current lookahead symbol is consistent with what were expecting\n\t// at this point in the ATN. You can call this anytime but ANTLR only\n\t// generates code to check before subrules/loops and each iteration.\n\t//\n\t// <p>Implements Jim Idle's magic sync mechanism in closures and optional\n\t// subrules. E.g.,</p>\n\t//\n\t// <pre>\n\t// a : sync ( stuff sync )* ;\n\t// sync : {consume to what can follow sync} ;\n\t// </pre>\n\t//\n\t// At the start of a sub rule upon error, {@link //sync} performs single\n\t// token deletion, if possible. If it can't do that, it bails on the current\n\t// rule and uses the default error recovery, which consumes until the\n\t// resynchronization set of the current rule.\n\t//\n\t// <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block\n\t// with an empty alternative), then the expected set includes what follows\n\t// the subrule.</p>\n\t//\n\t// <p>During loop iteration, it consumes until it sees a token that can start a\n\t// sub rule or what follows loop. Yes, that is pretty aggressive. We opt to\n\t// stay in the loop as long as possible.</p>\n\t//\n\t// <p><strong>ORIGINS</strong></p>\n\t//\n\t// <p>Previous versions of ANTLR did a poor job of their recovery within loops.\n\t// A single mismatch token or missing token would force the parser to bail\n\t// out of the entire rules surrounding the loop. So, for rule</p>\n\t//\n\t// <pre>\n\t// classDef : 'class' ID '{' member* '}'\n\t// </pre>\n\t//\n\t// input with an extra token between members would force the parser to\n\t// consume until it found the next class definition rather than the next\n\t// member definition of the current class.\n\t//\n\t// <p>This functionality cost a little bit of effort because the parser has to\n\t// compare token set at the start of the loop and at each iteration. If for\n\t// some reason speed is suffering for you, you can turn off this\n\t// functionality by simply overriding this method as a blank { }.</p>\n\t//\n\tDefaultErrorStrategy.prototype.sync = function(recognizer) {\n\t    // If already recovering, don't try to sync\n\t    if (this.inErrorRecoveryMode(recognizer)) {\n\t        return;\n\t    }\n\t    var s = recognizer._interp.atn.states[recognizer.state];\n\t    var la = recognizer.getTokenStream().LA(1);\n\t    // try cheaper subset first; might get lucky. seems to shave a wee bit off\n\t    if (la===Token.EOF || recognizer.atn.nextTokens(s).contains(la)) {\n\t        return;\n\t    }\n\t    // Return but don't end recovery. only do that upon valid token match\n\t    if(recognizer.isExpectedToken(la)) {\n\t        return;\n\t    }\n\t    switch (s.stateType) {\n\t    case ATNState.BLOCK_START:\n\t    case ATNState.STAR_BLOCK_START:\n\t    case ATNState.PLUS_BLOCK_START:\n\t    case ATNState.STAR_LOOP_ENTRY:\n\t       // report error and recover if possible\n\t        if( this.singleTokenDeletion(recognizer) !== null) {\n\t            return;\n\t        } else {\n\t            throw new InputMismatchException(recognizer);\n\t        }\n\t        break;\n\t    case ATNState.PLUS_LOOP_BACK:\n\t    case ATNState.STAR_LOOP_BACK:\n\t        this.reportUnwantedToken(recognizer);\n\t        var expecting = new IntervalSet();\n\t        expecting.addSet(recognizer.getExpectedTokens());\n\t        var whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer));\n\t        this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);\n\t        break;\n\t    default:\n\t        // do nothing if we can't identify the exact kind of ATN state\n\t    }\n\t};\n\t\n\t// This is called by {@link //reportError} when the exception is a\n\t// {@link NoViableAltException}.\n\t//\n\t// @see //reportError\n\t//\n\t// @param recognizer the parser instance\n\t// @param e the recognition exception\n\t//\n\tDefaultErrorStrategy.prototype.reportNoViableAlternative = function(recognizer, e) {\n\t    var tokens = recognizer.getTokenStream();\n\t    var input;\n\t    if(tokens !== null) {\n\t        if (e.startToken.type===Token.EOF) {\n\t            input = \"<EOF>\";\n\t        } else {\n\t            input = tokens.getText(new Interval(e.startToken, e.offendingToken));\n\t        }\n\t    } else {\n\t        input = \"<unknown input>\";\n\t    }\n\t    var msg = \"no viable alternative at input \" + this.escapeWSAndQuote(input);\n\t    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n\t};\n\t\n\t//\n\t// This is called by {@link //reportError} when the exception is an\n\t// {@link InputMismatchException}.\n\t//\n\t// @see //reportError\n\t//\n\t// @param recognizer the parser instance\n\t// @param e the recognition exception\n\t//\n\tDefaultErrorStrategy.prototype.reportInputMismatch = function(recognizer, e) {\n\t    var msg = \"mismatched input \" + this.getTokenErrorDisplay(e.offendingToken) +\n\t          \" expecting \" + e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames);\n\t    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n\t};\n\t\n\t//\n\t// This is called by {@link //reportError} when the exception is a\n\t// {@link FailedPredicateException}.\n\t//\n\t// @see //reportError\n\t//\n\t// @param recognizer the parser instance\n\t// @param e the recognition exception\n\t//\n\tDefaultErrorStrategy.prototype.reportFailedPredicate = function(recognizer, e) {\n\t    var ruleName = recognizer.ruleNames[recognizer._ctx.ruleIndex];\n\t    var msg = \"rule \" + ruleName + \" \" + e.message;\n\t    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n\t};\n\t\n\t// This method is called to report a syntax error which requires the removal\n\t// of a token from the input stream. At the time this method is called, the\n\t// erroneous symbol is current {@code LT(1)} symbol and has not yet been\n\t// removed from the input stream. When this method returns,\n\t// {@code recognizer} is in error recovery mode.\n\t//\n\t// <p>This method is called when {@link //singleTokenDeletion} identifies\n\t// single-token deletion as a viable recovery strategy for a mismatched\n\t// input error.</p>\n\t//\n\t// <p>The default implementation simply returns if the handler is already in\n\t// error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n\t// enter error recovery mode, followed by calling\n\t// {@link Parser//notifyErrorListeners}.</p>\n\t//\n\t// @param recognizer the parser instance\n\t//\n\tDefaultErrorStrategy.prototype.reportUnwantedToken = function(recognizer) {\n\t    if (this.inErrorRecoveryMode(recognizer)) {\n\t        return;\n\t    }\n\t    this.beginErrorCondition(recognizer);\n\t    var t = recognizer.getCurrentToken();\n\t    var tokenName = this.getTokenErrorDisplay(t);\n\t    var expecting = this.getExpectedTokens(recognizer);\n\t    var msg = \"extraneous input \" + tokenName + \" expecting \" +\n\t        expecting.toString(recognizer.literalNames, recognizer.symbolicNames);\n\t    recognizer.notifyErrorListeners(msg, t, null);\n\t};\n\t// This method is called to report a syntax error which requires the\n\t// insertion of a missing token into the input stream. At the time this\n\t// method is called, the missing token has not yet been inserted. When this\n\t// method returns, {@code recognizer} is in error recovery mode.\n\t//\n\t// <p>This method is called when {@link //singleTokenInsertion} identifies\n\t// single-token insertion as a viable recovery strategy for a mismatched\n\t// input error.</p>\n\t//\n\t// <p>The default implementation simply returns if the handler is already in\n\t// error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n\t// enter error recovery mode, followed by calling\n\t// {@link Parser//notifyErrorListeners}.</p>\n\t//\n\t// @param recognizer the parser instance\n\t//\n\tDefaultErrorStrategy.prototype.reportMissingToken = function(recognizer) {\n\t    if ( this.inErrorRecoveryMode(recognizer)) {\n\t        return;\n\t    }\n\t    this.beginErrorCondition(recognizer);\n\t    var t = recognizer.getCurrentToken();\n\t    var expecting = this.getExpectedTokens(recognizer);\n\t    var msg = \"missing \" + expecting.toString(recognizer.literalNames, recognizer.symbolicNames) +\n\t          \" at \" + this.getTokenErrorDisplay(t);\n\t    recognizer.notifyErrorListeners(msg, t, null);\n\t};\n\t\n\t// <p>The default implementation attempts to recover from the mismatched input\n\t// by using single token insertion and deletion as described below. If the\n\t// recovery attempt fails, this method throws an\n\t// {@link InputMismatchException}.</p>\n\t//\n\t// <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>\n\t//\n\t// <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the\n\t// right token, however, then assume {@code LA(1)} is some extra spurious\n\t// token and delete it. Then consume and return the next token (which was\n\t// the {@code LA(2)} token) as the successful result of the match operation.</p>\n\t//\n\t// <p>This recovery strategy is implemented by {@link\n\t// //singleTokenDeletion}.</p>\n\t//\n\t// <p><strong>MISSING TOKEN</strong> (single token insertion)</p>\n\t//\n\t// <p>If current token (at {@code LA(1)}) is consistent with what could come\n\t// after the expected {@code LA(1)} token, then assume the token is missing\n\t// and use the parser's {@link TokenFactory} to create it on the fly. The\n\t// \"insertion\" is performed by returning the created token as the successful\n\t// result of the match operation.</p>\n\t//\n\t// <p>This recovery strategy is implemented by {@link\n\t// //singleTokenInsertion}.</p>\n\t//\n\t// <p><strong>EXAMPLE</strong></p>\n\t//\n\t// <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When\n\t// the parser returns from the nested call to {@code expr}, it will have\n\t// call chain:</p>\n\t//\n\t// <pre>\n\t// stat &rarr; expr &rarr; atom\n\t// </pre>\n\t//\n\t// and it will be trying to match the {@code ')'} at this point in the\n\t// derivation:\n\t//\n\t// <pre>\n\t// =&gt; ID '=' '(' INT ')' ('+' atom)* ';'\n\t// ^\n\t// </pre>\n\t//\n\t// The attempt to match {@code ')'} will fail when it sees {@code ';'} and\n\t// call {@link //recoverInline}. To recover, it sees that {@code LA(1)==';'}\n\t// is in the set of tokens that can follow the {@code ')'} token reference\n\t// in rule {@code atom}. It can assume that you forgot the {@code ')'}.\n\t//\n\tDefaultErrorStrategy.prototype.recoverInline = function(recognizer) {\n\t    // SINGLE TOKEN DELETION\n\t    var matchedSymbol = this.singleTokenDeletion(recognizer);\n\t    if (matchedSymbol !== null) {\n\t        // we have deleted the extra token.\n\t        // now, move past ttype token as if all were ok\n\t        recognizer.consume();\n\t        return matchedSymbol;\n\t    }\n\t    // SINGLE TOKEN INSERTION\n\t    if (this.singleTokenInsertion(recognizer)) {\n\t        return this.getMissingSymbol(recognizer);\n\t    }\n\t    // even that didn't work; must throw the exception\n\t    throw new InputMismatchException(recognizer);\n\t};\n\t\n\t//\n\t// This method implements the single-token insertion inline error recovery\n\t// strategy. It is called by {@link //recoverInline} if the single-token\n\t// deletion strategy fails to recover from the mismatched input. If this\n\t// method returns {@code true}, {@code recognizer} will be in error recovery\n\t// mode.\n\t//\n\t// <p>This method determines whether or not single-token insertion is viable by\n\t// checking if the {@code LA(1)} input symbol could be successfully matched\n\t// if it were instead the {@code LA(2)} symbol. If this method returns\n\t// {@code true}, the caller is responsible for creating and inserting a\n\t// token with the correct type to produce this behavior.</p>\n\t//\n\t// @param recognizer the parser instance\n\t// @return {@code true} if single-token insertion is a viable recovery\n\t// strategy for the current mismatched input, otherwise {@code false}\n\t//\n\tDefaultErrorStrategy.prototype.singleTokenInsertion = function(recognizer) {\n\t    var currentSymbolType = recognizer.getTokenStream().LA(1);\n\t    // if current token is consistent with what could come after current\n\t    // ATN state, then we know we're missing a token; error recovery\n\t    // is free to conjure up and insert the missing token\n\t    var atn = recognizer._interp.atn;\n\t    var currentState = atn.states[recognizer.state];\n\t    var next = currentState.transitions[0].target;\n\t    var expectingAtLL2 = atn.nextTokens(next, recognizer._ctx);\n\t    if (expectingAtLL2.contains(currentSymbolType) ){\n\t        this.reportMissingToken(recognizer);\n\t        return true;\n\t    } else {\n\t        return false;\n\t    }\n\t};\n\t\n\t// This method implements the single-token deletion inline error recovery\n\t// strategy. It is called by {@link //recoverInline} to attempt to recover\n\t// from mismatched input. If this method returns null, the parser and error\n\t// handler state will not have changed. If this method returns non-null,\n\t// {@code recognizer} will <em>not</em> be in error recovery mode since the\n\t// returned token was a successful match.\n\t//\n\t// <p>If the single-token deletion is successful, this method calls\n\t// {@link //reportUnwantedToken} to report the error, followed by\n\t// {@link Parser//consume} to actually \"delete\" the extraneous token. Then,\n\t// before returning {@link //reportMatch} is called to signal a successful\n\t// match.</p>\n\t//\n\t// @param recognizer the parser instance\n\t// @return the successfully matched {@link Token} instance if single-token\n\t// deletion successfully recovers from the mismatched input, otherwise\n\t// {@code null}\n\t//\n\tDefaultErrorStrategy.prototype.singleTokenDeletion = function(recognizer) {\n\t    var nextTokenType = recognizer.getTokenStream().LA(2);\n\t    var expecting = this.getExpectedTokens(recognizer);\n\t    if (expecting.contains(nextTokenType)) {\n\t        this.reportUnwantedToken(recognizer);\n\t        // print(\"recoverFromMismatchedToken deleting \" \\\n\t        // + str(recognizer.getTokenStream().LT(1)) \\\n\t        // + \" since \" + str(recognizer.getTokenStream().LT(2)) \\\n\t        // + \" is what we want\", file=sys.stderr)\n\t        recognizer.consume(); // simply delete extra token\n\t        // we want to return the token we're actually matching\n\t        var matchedSymbol = recognizer.getCurrentToken();\n\t        this.reportMatch(recognizer); // we know current token is correct\n\t        return matchedSymbol;\n\t    } else {\n\t        return null;\n\t    }\n\t};\n\t\n\t// Conjure up a missing token during error recovery.\n\t//\n\t// The recognizer attempts to recover from single missing\n\t// symbols. But, actions might refer to that missing symbol.\n\t// For example, x=ID {f($x);}. The action clearly assumes\n\t// that there has been an identifier matched previously and that\n\t// $x points at that token. If that token is missing, but\n\t// the next token in the stream is what we want we assume that\n\t// this token is missing and we keep going. Because we\n\t// have to return some token to replace the missing token,\n\t// we have to conjure one up. This method gives the user control\n\t// over the tokens returned for missing tokens. Mostly,\n\t// you will want to create something special for identifier\n\t// tokens. For literals such as '{' and ',', the default\n\t// action in the parser or tree parser works. It simply creates\n\t// a CommonToken of the appropriate type. The text will be the token.\n\t// If you change what tokens must be created by the lexer,\n\t// override this method to create the appropriate tokens.\n\t//\n\tDefaultErrorStrategy.prototype.getMissingSymbol = function(recognizer) {\n\t    var currentSymbol = recognizer.getCurrentToken();\n\t    var expecting = this.getExpectedTokens(recognizer);\n\t    var expectedTokenType = expecting.first(); // get any element\n\t    var tokenText;\n\t    if (expectedTokenType===Token.EOF) {\n\t        tokenText = \"<missing EOF>\";\n\t    } else {\n\t        tokenText = \"<missing \" + recognizer.literalNames[expectedTokenType] + \">\";\n\t    }\n\t    var current = currentSymbol;\n\t    var lookback = recognizer.getTokenStream().LT(-1);\n\t    if (current.type===Token.EOF && lookback !== null) {\n\t        current = lookback;\n\t    }\n\t    return recognizer.getTokenFactory().create(current.source,\n\t        expectedTokenType, tokenText, Token.DEFAULT_CHANNEL,\n\t        -1, -1, current.line, current.column);\n\t};\n\t\n\tDefaultErrorStrategy.prototype.getExpectedTokens = function(recognizer) {\n\t    return recognizer.getExpectedTokens();\n\t};\n\t\n\t// How should a token be displayed in an error message? The default\n\t// is to display just the text, but during development you might\n\t// want to have a lot of information spit out. Override in that case\n\t// to use t.toString() (which, for CommonToken, dumps everything about\n\t// the token). This is better than forcing you to override a method in\n\t// your token objects because you don't have to go modify your lexer\n\t// so that it creates a new Java type.\n\t//\n\tDefaultErrorStrategy.prototype.getTokenErrorDisplay = function(t) {\n\t    if (t === null) {\n\t        return \"<no token>\";\n\t    }\n\t    var s = t.text;\n\t    if (s === null) {\n\t        if (t.type===Token.EOF) {\n\t            s = \"<EOF>\";\n\t        } else {\n\t            s = \"<\" + t.type + \">\";\n\t        }\n\t    }\n\t    return this.escapeWSAndQuote(s);\n\t};\n\t\n\tDefaultErrorStrategy.prototype.escapeWSAndQuote = function(s) {\n\t    s = s.replace(/\\n/g,\"\\\\n\");\n\t    s = s.replace(/\\r/g,\"\\\\r\");\n\t    s = s.replace(/\\t/g,\"\\\\t\");\n\t    return \"'\" + s + \"'\";\n\t};\n\t\n\t// Compute the error recovery set for the current rule. During\n\t// rule invocation, the parser pushes the set of tokens that can\n\t// follow that rule reference on the stack; this amounts to\n\t// computing FIRST of what follows the rule reference in the\n\t// enclosing rule. See LinearApproximator.FIRST().\n\t// This local follow set only includes tokens\n\t// from within the rule; i.e., the FIRST computation done by\n\t// ANTLR stops at the end of a rule.\n\t//\n\t// EXAMPLE\n\t//\n\t// When you find a \"no viable alt exception\", the input is not\n\t// consistent with any of the alternatives for rule r. The best\n\t// thing to do is to consume tokens until you see something that\n\t// can legally follow a call to r//or* any rule that called r.\n\t// You don't want the exact set of viable next tokens because the\n\t// input might just be missing a token--you might consume the\n\t// rest of the input looking for one of the missing tokens.\n\t//\n\t// Consider grammar:\n\t//\n\t// a : '[' b ']'\n\t// | '(' b ')'\n\t// ;\n\t// b : c '^' INT ;\n\t// c : ID\n\t// | INT\n\t// ;\n\t//\n\t// At each rule invocation, the set of tokens that could follow\n\t// that rule is pushed on a stack. Here are the various\n\t// context-sensitive follow sets:\n\t//\n\t// FOLLOW(b1_in_a) = FIRST(']') = ']'\n\t// FOLLOW(b2_in_a) = FIRST(')') = ')'\n\t// FOLLOW(c_in_b) = FIRST('^') = '^'\n\t//\n\t// Upon erroneous input \"[]\", the call chain is\n\t//\n\t// a -> b -> c\n\t//\n\t// and, hence, the follow context stack is:\n\t//\n\t// depth follow set start of rule execution\n\t// 0 <EOF> a (from main())\n\t// 1 ']' b\n\t// 2 '^' c\n\t//\n\t// Notice that ')' is not included, because b would have to have\n\t// been called from a different context in rule a for ')' to be\n\t// included.\n\t//\n\t// For error recovery, we cannot consider FOLLOW(c)\n\t// (context-sensitive or otherwise). We need the combined set of\n\t// all context-sensitive FOLLOW sets--the set of all tokens that\n\t// could follow any reference in the call chain. We need to\n\t// resync to one of those tokens. Note that FOLLOW(c)='^' and if\n\t// we resync'd to that token, we'd consume until EOF. We need to\n\t// sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.\n\t// In this case, for input \"[]\", LA(1) is ']' and in the set, so we would\n\t// not consume anything. After printing an error, rule c would\n\t// return normally. Rule b would not find the required '^' though.\n\t// At this point, it gets a mismatched token error and throws an\n\t// exception (since LA(1) is not in the viable following token\n\t// set). The rule exception handler tries to recover, but finds\n\t// the same recovery set and doesn't consume anything. Rule b\n\t// exits normally returning to rule a. Now it finds the ']' (and\n\t// with the successful match exits errorRecovery mode).\n\t//\n\t// So, you can see that the parser walks up the call chain looking\n\t// for the token that was a member of the recovery set.\n\t//\n\t// Errors are not generated in errorRecovery mode.\n\t//\n\t// ANTLR's error recovery mechanism is based upon original ideas:\n\t//\n\t// \"Algorithms + Data Structures = Programs\" by Niklaus Wirth\n\t//\n\t// and\n\t//\n\t// \"A note on error recovery in recursive descent parsers\":\n\t// http://portal.acm.org/citation.cfm?id=947902.947905\n\t//\n\t// Later, Josef Grosch had some good ideas:\n\t//\n\t// \"Efficient and Comfortable Error Recovery in Recursive Descent\n\t// Parsers\":\n\t// ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip\n\t//\n\t// Like Grosch I implement context-sensitive FOLLOW sets that are combined\n\t// at run-time upon error to avoid overhead during parsing.\n\t//\n\tDefaultErrorStrategy.prototype.getErrorRecoverySet = function(recognizer) {\n\t    var atn = recognizer._interp.atn;\n\t    var ctx = recognizer._ctx;\n\t    var recoverSet = new IntervalSet();\n\t    while (ctx !== null && ctx.invokingState>=0) {\n\t        // compute what follows who invoked us\n\t        var invokingState = atn.states[ctx.invokingState];\n\t        var rt = invokingState.transitions[0];\n\t        var follow = atn.nextTokens(rt.followState);\n\t        recoverSet.addSet(follow);\n\t        ctx = ctx.parentCtx;\n\t    }\n\t    recoverSet.removeOne(Token.EPSILON);\n\t    return recoverSet;\n\t};\n\t\n\t// Consume tokens until one matches the given token set.//\n\tDefaultErrorStrategy.prototype.consumeUntil = function(recognizer, set) {\n\t    var ttype = recognizer.getTokenStream().LA(1);\n\t    while( ttype !== Token.EOF && !set.contains(ttype)) {\n\t        recognizer.consume();\n\t        ttype = recognizer.getTokenStream().LA(1);\n\t    }\n\t};\n\t\n\t//\n\t// This implementation of {@link ANTLRErrorStrategy} responds to syntax errors\n\t// by immediately canceling the parse operation with a\n\t// {@link ParseCancellationException}. The implementation ensures that the\n\t// {@link ParserRuleContext//exception} field is set for all parse tree nodes\n\t// that were not completed prior to encountering the error.\n\t//\n\t// <p>\n\t// This error strategy is useful in the following scenarios.</p>\n\t//\n\t// <ul>\n\t// <li><strong>Two-stage parsing:</strong> This error strategy allows the first\n\t// stage of two-stage parsing to immediately terminate if an error is\n\t// encountered, and immediately fall back to the second stage. In addition to\n\t// avoiding wasted work by attempting to recover from errors here, the empty\n\t// implementation of {@link BailErrorStrategy//sync} improves the performance of\n\t// the first stage.</li>\n\t// <li><strong>Silent validation:</strong> When syntax errors are not being\n\t// reported or logged, and the parse result is simply ignored if errors occur,\n\t// the {@link BailErrorStrategy} avoids wasting work on recovering from errors\n\t// when the result will be ignored either way.</li>\n\t// </ul>\n\t//\n\t// <p>\n\t// {@code myparser.setErrorHandler(new BailErrorStrategy());}</p>\n\t//\n\t// @see Parser//setErrorHandler(ANTLRErrorStrategy)\n\t//\n\tfunction BailErrorStrategy() {\n\t\tDefaultErrorStrategy.call(this);\n\t\treturn this;\n\t}\n\t\n\tBailErrorStrategy.prototype = Object.create(DefaultErrorStrategy.prototype);\n\tBailErrorStrategy.prototype.constructor = BailErrorStrategy;\n\t\n\t// Instead of recovering from exception {@code e}, re-throw it wrapped\n\t// in a {@link ParseCancellationException} so it is not caught by the\n\t// rule function catches. Use {@link Exception//getCause()} to get the\n\t// original {@link RecognitionException}.\n\t//\n\tBailErrorStrategy.prototype.recover = function(recognizer, e) {\n\t    var context = recognizer._ctx;\n\t    while (context !== null) {\n\t        context.exception = e;\n\t        context = context.parentCtx;\n\t    }\n\t    throw new ParseCancellationException(e);\n\t};\n\t    \n\t// Make sure we don't attempt to recover inline; if the parser\n\t// successfully recovers, it won't throw an exception.\n\t//\n\tBailErrorStrategy.prototype.recoverInline = function(recognizer) {\n\t    this.recover(recognizer, new InputMismatchException(recognizer));\n\t};\n\t\n\t// Make sure we don't attempt to recover from problems in subrules.//\n\tBailErrorStrategy.prototype.sync = function(recognizer) {\n\t    // pass\n\t};\n\t\n\texports.BailErrorStrategy = BailErrorStrategy;\n\texports.DefaultErrorStrategy = DefaultErrorStrategy;\n\n/***/ },\n/* 43 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// \n\t//  [The \"BSD license\"]\n\t//   Copyright (c) 2012 Terence Parr\n\t//   Copyright (c) 2012 Sam Harwell\n\t//   Copyright (c) 2014 Eric Vergnaud\n\t//   All rights reserved.\n\t// \n\t//   Redistribution and use in source and binary forms, with or without\n\t//   modification, are permitted provided that the following conditions\n\t//   are met:\n\t// \n\t//   1. Redistributions of source code must retain the above copyright\n\t//      notice, this list of conditions and the following disclaimer.\n\t//   2. Redistributions in binary form must reproduce the above copyright\n\t//      notice, this list of conditions and the following disclaimer in the\n\t//      documentation and/or other materials provided with the distribution.\n\t//   3. The name of the author may not be used to endorse or promote products\n\t//      derived from this software without specific prior written permission.\n\t// \n\t//   THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//   IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//   OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//   IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//   INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//   NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//   THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t// \n\t\n\tvar Token = __webpack_require__(9).Token;\n\t\n\t// Vacuum all input from a string and then treat it like a buffer.\n\t\n\tfunction _loadString(stream) {\n\t\tstream._index = 0;\n\t\tstream.data = [];\n\t\tfor (var i = 0; i < stream.strdata.length; i++) {\n\t\t\tstream.data.push(stream.strdata.charCodeAt(i));\n\t\t}\n\t\tstream._size = stream.data.length;\n\t}\n\t\n\tfunction InputStream(data) {\n\t\tthis.name = \"<empty>\";\n\t\tthis.strdata = data;\n\t\t_loadString(this);\n\t\treturn this;\n\t}\n\t\n\tObject.defineProperty(InputStream.prototype, \"index\", {\n\t\tget : function() {\n\t\t\treturn this._index;\n\t\t}\n\t});\n\t\n\tObject.defineProperty(InputStream.prototype, \"size\", {\n\t\tget : function() {\n\t\t\treturn this._size;\n\t\t}\n\t});\n\t\n\t// Reset the stream so that it's in the same state it was\n\t// when the object was created *except* the data array is not\n\t// touched.\n\t//\n\tInputStream.prototype.reset = function() {\n\t\tthis._index = 0;\n\t};\n\t\n\tInputStream.prototype.consume = function() {\n\t\tif (this._index >= this._size) {\n\t\t\t// assert this.LA(1) == Token.EOF\n\t\t\tthrow (\"cannot consume EOF\");\n\t\t}\n\t\tthis._index += 1;\n\t};\n\t\n\tInputStream.prototype.LA = function(offset) {\n\t\tif (offset === 0) {\n\t\t\treturn 0; // undefined\n\t\t}\n\t\tif (offset < 0) {\n\t\t\toffset += 1; // e.g., translate LA(-1) to use offset=0\n\t\t}\n\t\tvar pos = this._index + offset - 1;\n\t\tif (pos < 0 || pos >= this._size) { // invalid\n\t\t\treturn Token.EOF;\n\t\t}\n\t\treturn this.data[pos];\n\t};\n\t\n\tInputStream.prototype.LT = function(offset) {\n\t\treturn this.LA(offset);\n\t};\n\t\n\t// mark/release do nothing; we have entire buffer\n\tInputStream.prototype.mark = function() {\n\t\treturn -1;\n\t};\n\t\n\tInputStream.prototype.release = function(marker) {\n\t};\n\t\n\t// consume() ahead until p==_index; can't just set p=_index as we must\n\t// update line and column. If we seek backwards, just set p\n\t//\n\tInputStream.prototype.seek = function(_index) {\n\t\tif (_index <= this._index) {\n\t\t\tthis._index = _index; // just jump; don't update stream state (line,\n\t\t\t\t\t\t\t\t\t// ...)\n\t\t\treturn;\n\t\t}\n\t\t// seek forward\n\t\tthis._index = Math.min(_index, this._size);\n\t};\n\t\n\tInputStream.prototype.getText = function(start, stop) {\n\t\tif (stop >= this._size) {\n\t\t\tstop = this._size - 1;\n\t\t}\n\t\tif (start >= this._size) {\n\t\t\treturn \"\";\n\t\t} else {\n\t\t\treturn this.strdata.slice(start, stop + 1);\n\t\t}\n\t};\n\t\n\tInputStream.prototype.toString = function() {\n\t\treturn this.strdata;\n\t};\n\t\n\texports.InputStream = InputStream;\n\n\n/***/ },\n/* 44 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t//  [The \"BSD license\"]\n\t//   Copyright (c) 2012 Terence Parr\n\t//   Copyright (c) 2012 Sam Harwell\n\t//   Copyright (c) 2014 Eric Vergnaud\n\t//   All rights reserved.\n\t// \n\t//   Redistribution and use in source and binary forms, with or without\n\t//   modification, are permitted provided that the following conditions\n\t//   are met:\n\t// \n\t//   1. Redistributions of source code must retain the above copyright\n\t//      notice, this list of conditions and the following disclaimer.\n\t//   2. Redistributions in binary form must reproduce the above copyright\n\t//      notice, this list of conditions and the following disclaimer in the\n\t//      documentation and/or other materials provided with the distribution.\n\t//   3. The name of the author may not be used to endorse or promote products\n\t//      derived from this software without specific prior written permission.\n\t// \n\t//   THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//   IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//   OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//   IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//   INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//   NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//   THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t// \n\t\n\t//\n\t//  This is an InputStream that is loaded from a file all at once\n\t//  when you construct the object.\n\t// \n\tvar InputStream = __webpack_require__(43).InputStream;\n\tvar isNodeJs = typeof window === 'undefined' && typeof importScripts === 'undefined';\n\tvar fs = isNodeJs ? __webpack_require__(45) : null;\n\t\n\tfunction FileStream(fileName) {\n\t\tvar data = fs.readFileSync(fileName, \"utf8\");\n\t\tInputStream.call(this, data);\n\t\tthis.fileName = fileName;\n\t\treturn this;\n\t}\n\t\n\tFileStream.prototype = Object.create(InputStream.prototype);\n\tFileStream.prototype.constructor = FileStream;\n\t\n\texports.FileStream = FileStream;\n\n\n/***/ },\n/* 45 */\n/***/ function(module, exports) {\n\n\n\n/***/ },\n/* 46 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t///\n\t\n\t//\n\t// This class extends {@link BufferedTokenStream} with functionality to filter\n\t// token streams to tokens on a particular channel (tokens where\n\t// {@link Token//getChannel} returns a particular value).\n\t//\n\t// <p>\n\t// This token stream provides access to all tokens by index or when calling\n\t// methods like {@link //getText}. The channel filtering is only used for code\n\t// accessing tokens via the lookahead methods {@link //LA}, {@link //LT}, and\n\t// {@link //LB}.</p>\n\t//\n\t// <p>\n\t// By default, tokens are placed on the default channel\n\t// ({@link Token//DEFAULT_CHANNEL}), but may be reassigned by using the\n\t// {@code ->channel(HIDDEN)} lexer command, or by using an embedded action to\n\t// call {@link Lexer//setChannel}.\n\t// </p>\n\t//\n\t// <p>\n\t// Note: lexer rules which use the {@code ->skip} lexer command or call\n\t// {@link Lexer//skip} do not produce tokens at all, so input text matched by\n\t// such a rule will not be available as part of the token stream, regardless of\n\t// channel.</p>\n\t///\n\t\n\tvar Token = __webpack_require__(9).Token;\n\tvar BufferedTokenStream = __webpack_require__(47).BufferedTokenStream;\n\t\n\tfunction CommonTokenStream(lexer, channel) {\n\t\tBufferedTokenStream.call(this, lexer);\n\t    this.channel = channel===undefined ? Token.DEFAULT_CHANNEL : channel;\n\t    return this;\n\t}\n\t\n\tCommonTokenStream.prototype = Object.create(BufferedTokenStream.prototype);\n\tCommonTokenStream.prototype.constructor = CommonTokenStream;\n\t\n\tCommonTokenStream.prototype.adjustSeekIndex = function(i) {\n\t    return this.nextTokenOnChannel(i, this.channel);\n\t};\n\t\n\tCommonTokenStream.prototype.LB = function(k) {\n\t    if (k===0 || this.index-k<0) {\n\t        return null;\n\t    }\n\t    var i = this.index;\n\t    var n = 1;\n\t    // find k good tokens looking backwards\n\t    while (n <= k) {\n\t        // skip off-channel tokens\n\t        i = this.previousTokenOnChannel(i - 1, this.channel);\n\t        n += 1;\n\t    }\n\t    if (i < 0) {\n\t        return null;\n\t    }\n\t    return this.tokens[i];\n\t};\n\t\n\tCommonTokenStream.prototype.LT = function(k) {\n\t    this.lazyInit();\n\t    if (k === 0) {\n\t        return null;\n\t    }\n\t    if (k < 0) {\n\t        return this.LB(-k);\n\t    }\n\t    var i = this.index;\n\t    var n = 1; // we know tokens[pos] is a good one\n\t    // find k good tokens\n\t    while (n < k) {\n\t        // skip off-channel tokens, but make sure to not look past EOF\n\t        if (this.sync(i + 1)) {\n\t            i = this.nextTokenOnChannel(i + 1, this.channel);\n\t        }\n\t        n += 1;\n\t    }\n\t    return this.tokens[i];\n\t};\n\t\n\t// Count EOF just once.///\n\tCommonTokenStream.prototype.getNumberOfOnChannelTokens = function() {\n\t    var n = 0;\n\t    this.fill();\n\t    for (var i =0; i< this.tokens.length;i++) {\n\t        var t = this.tokens[i];\n\t        if( t.channel===this.channel) {\n\t            n += 1;\n\t        }\n\t        if( t.type===Token.EOF) {\n\t            break;\n\t        }\n\t    }\n\t    return n;\n\t};\n\t\n\texports.CommonTokenStream = CommonTokenStream;\n\n/***/ },\n/* 47 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t//\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\t// This implementation of {@link TokenStream} loads tokens from a\n\t// {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n\t// access to any previous token by index.\n\t//\n\t// <p>\n\t// This token stream ignores the value of {@link Token//getChannel}. If your\n\t// parser requires the token stream filter tokens to only those on a particular\n\t// channel, such as {@link Token//DEFAULT_CHANNEL} or\n\t// {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n\t// {@link CommonTokenStream}.</p>\n\t\n\tvar Token = __webpack_require__(9).Token;\n\tvar Lexer = __webpack_require__(25).Lexer;\n\tvar Interval = __webpack_require__(13).Interval;\n\t\n\t// this is just to keep meaningful parameter types to Parser\n\tfunction TokenStream() {\n\t\treturn this;\n\t}\n\t\n\tfunction BufferedTokenStream(tokenSource) {\n\t\n\t\tTokenStream.call(this);\n\t\t// The {@link TokenSource} from which tokens for this stream are fetched.\n\t\tthis.tokenSource = tokenSource;\n\t\n\t\t// A collection of all tokens fetched from the token source. The list is\n\t\t// considered a complete view of the input once {@link //fetchedEOF} is set\n\t\t// to {@code true}.\n\t\tthis.tokens = [];\n\t\n\t\t// The index into {@link //tokens} of the current token (next token to\n\t\t// {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n\t\t// be\n\t\t// {@link //LT LT(1)}.\n\t\t//\n\t\t// <p>This field is set to -1 when the stream is first constructed or when\n\t\t// {@link //setTokenSource} is called, indicating that the first token has\n\t\t// not yet been fetched from the token source. For additional information,\n\t\t// see the documentation of {@link IntStream} for a description of\n\t\t// Initializing Methods.</p>\n\t\tthis.index = -1;\n\t\n\t\t// Indicates whether the {@link Token//EOF} token has been fetched from\n\t\t// {@link //tokenSource} and added to {@link //tokens}. This field improves\n\t\t// performance for the following cases:\n\t\t//\n\t\t// <ul>\n\t\t// <li>{@link //consume}: The lookahead check in {@link //consume} to\n\t\t// prevent\n\t\t// consuming the EOF symbol is optimized by checking the values of\n\t\t// {@link //fetchedEOF} and {@link //p} instead of calling {@link\n\t\t// //LA}.</li>\n\t\t// <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n\t\t// into\n\t\t// {@link //tokens} is trivial with this field.</li>\n\t\t// <ul>\n\t\tthis.fetchedEOF = false;\n\t\treturn this;\n\t}\n\t\n\tBufferedTokenStream.prototype = Object.create(TokenStream.prototype);\n\tBufferedTokenStream.prototype.constructor = BufferedTokenStream;\n\t\n\tBufferedTokenStream.prototype.mark = function() {\n\t\treturn 0;\n\t};\n\t\n\tBufferedTokenStream.prototype.release = function(marker) {\n\t\t// no resources to release\n\t};\n\t\n\tBufferedTokenStream.prototype.reset = function() {\n\t\tthis.seek(0);\n\t};\n\t\n\tBufferedTokenStream.prototype.seek = function(index) {\n\t\tthis.lazyInit();\n\t\tthis.index = this.adjustSeekIndex(index);\n\t};\n\t\n\tBufferedTokenStream.prototype.get = function(index) {\n\t\tthis.lazyInit();\n\t\treturn this.tokens[index];\n\t};\n\t\n\tBufferedTokenStream.prototype.consume = function() {\n\t\tvar skipEofCheck = false;\n\t\tif (this.index >= 0) {\n\t\t\tif (this.fetchedEOF) {\n\t\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t\t// fetched token except the last.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length - 1;\n\t\t\t} else {\n\t\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length;\n\t\t\t}\n\t\t} else {\n\t\t\t// not yet initialized\n\t\t\tskipEofCheck = false;\n\t\t}\n\t\tif (!skipEofCheck && this.LA(1) === Token.EOF) {\n\t\t\tthrow \"cannot consume EOF\";\n\t\t}\n\t\tif (this.sync(this.index + 1)) {\n\t\t\tthis.index = this.adjustSeekIndex(this.index + 1);\n\t\t}\n\t};\n\t\n\t// Make sure index {@code i} in tokens has a token.\n\t//\n\t// @return {@code true} if a token is located at index {@code i}, otherwise\n\t// {@code false}.\n\t// @see //get(int i)\n\t// /\n\tBufferedTokenStream.prototype.sync = function(i) {\n\t\tvar n = i - this.tokens.length + 1; // how many more elements we need?\n\t\tif (n > 0) {\n\t\t\tvar fetched = this.fetch(n);\n\t\t\treturn fetched >= n;\n\t\t}\n\t\treturn true;\n\t};\n\t\n\t// Add {@code n} elements to buffer.\n\t//\n\t// @return The actual number of elements added to the buffer.\n\t// /\n\tBufferedTokenStream.prototype.fetch = function(n) {\n\t\tif (this.fetchedEOF) {\n\t\t\treturn 0;\n\t\t}\n\t\tfor (var i = 0; i < n; i++) {\n\t\t\tvar t = this.tokenSource.nextToken();\n\t\t\tt.tokenIndex = this.tokens.length;\n\t\t\tthis.tokens.push(t);\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tthis.fetchedEOF = true;\n\t\t\t\treturn i + 1;\n\t\t\t}\n\t\t}\n\t\treturn n;\n\t};\n\t\n\t// Get all tokens from start..stop inclusively///\n\tBufferedTokenStream.prototype.getTokens = function(start, stop, types) {\n\t\tif (types === undefined) {\n\t\t\ttypes = null;\n\t\t}\n\t\tif (start < 0 || stop < 0) {\n\t\t\treturn null;\n\t\t}\n\t\tthis.lazyInit();\n\t\tvar subset = [];\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tfor (var i = start; i < stop; i++) {\n\t\t\tvar t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (types === null || types.contains(t.type)) {\n\t\t\t\tsubset.push(t);\n\t\t\t}\n\t\t}\n\t\treturn subset;\n\t};\n\t\n\tBufferedTokenStream.prototype.LA = function(i) {\n\t\treturn this.LT(i).type;\n\t};\n\t\n\tBufferedTokenStream.prototype.LB = function(k) {\n\t\tif (this.index - k < 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.tokens[this.index - k];\n\t};\n\t\n\tBufferedTokenStream.prototype.LT = function(k) {\n\t\tthis.lazyInit();\n\t\tif (k === 0) {\n\t\t\treturn null;\n\t\t}\n\t\tif (k < 0) {\n\t\t\treturn this.LB(-k);\n\t\t}\n\t\tvar i = this.index + k - 1;\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) { // return EOF token\n\t\t\t// EOF must be last token\n\t\t\treturn this.tokens[this.tokens.length - 1];\n\t\t}\n\t\treturn this.tokens[i];\n\t};\n\t\n\t// Allowed derived classes to modify the behavior of operations which change\n\t// the current stream position by adjusting the target token index of a seek\n\t// operation. The default implementation simply returns {@code i}. If an\n\t// exception is thrown in this method, the current stream index should not be\n\t// changed.\n\t//\n\t// <p>For example, {@link CommonTokenStream} overrides this method to ensure\n\t// that\n\t// the seek target is always an on-channel token.</p>\n\t//\n\t// @param i The target token index.\n\t// @return The adjusted target token index.\n\t\n\tBufferedTokenStream.prototype.adjustSeekIndex = function(i) {\n\t\treturn i;\n\t};\n\t\n\tBufferedTokenStream.prototype.lazyInit = function() {\n\t\tif (this.index === -1) {\n\t\t\tthis.setup();\n\t\t}\n\t};\n\t\n\tBufferedTokenStream.prototype.setup = function() {\n\t\tthis.sync(0);\n\t\tthis.index = this.adjustSeekIndex(0);\n\t};\n\t\n\t// Reset this token stream by setting its token source.///\n\tBufferedTokenStream.prototype.setTokenSource = function(tokenSource) {\n\t\tthis.tokenSource = tokenSource;\n\t\tthis.tokens = [];\n\t\tthis.index = -1;\n\t};\n\t\n\t\n\t// Given a starting index, return the index of the next token on channel.\n\t// Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t// on channel between i and EOF.\n\t// /\n\tBufferedTokenStream.prototype.nextTokenOnChannel = function(i, channel) {\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) {\n\t\t\treturn -1;\n\t\t}\n\t\tvar token = this.tokens[i];\n\t\twhile (token.channel !== this.channel) {\n\t\t\tif (token.type === Token.EOF) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ti += 1;\n\t\t\tthis.sync(i);\n\t\t\ttoken = this.tokens[i];\n\t\t}\n\t\treturn i;\n\t};\n\t\n\t// Given a starting index, return the index of the previous token on channel.\n\t// Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t// on channel between i and 0.\n\tBufferedTokenStream.prototype.previousTokenOnChannel = function(i, channel) {\n\t\twhile (i >= 0 && this.tokens[i].channel !== channel) {\n\t\t\ti -= 1;\n\t\t}\n\t\treturn i;\n\t};\n\t\n\t// Collect all tokens on specified channel to the right of\n\t// the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n\t// EOF. If channel is -1, find any non default channel token.\n\tBufferedTokenStream.prototype.getHiddenTokensToRight = function(tokenIndex,\n\t\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tvar nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1,\n\t\t\t\tLexer.DEFAULT_TOKEN_CHANNEL);\n\t\tvar from_ = tokenIndex + 1;\n\t\t// if none onchannel to right, nextOnChannel=-1 so set to = last token\n\t\tvar to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t};\n\t\n\t// Collect all tokens on specified channel to the left of\n\t// the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n\t// If channel is -1, find any non default channel token.\n\tBufferedTokenStream.prototype.getHiddenTokensToLeft = function(tokenIndex,\n\t\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tvar prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1,\n\t\t\t\tLexer.DEFAULT_TOKEN_CHANNEL);\n\t\tif (prevOnChannel === tokenIndex - 1) {\n\t\t\treturn null;\n\t\t}\n\t\t// if none on channel to left, prevOnChannel=-1 then from=0\n\t\tvar from_ = prevOnChannel + 1;\n\t\tvar to = tokenIndex - 1;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t};\n\t\n\tBufferedTokenStream.prototype.filterForChannel = function(left, right, channel) {\n\t\tvar hidden = [];\n\t\tfor (var i = left; i < right + 1; i++) {\n\t\t\tvar t = this.tokens[i];\n\t\t\tif (channel === -1) {\n\t\t\t\tif (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n\t\t\t\t\thidden.push(t);\n\t\t\t\t}\n\t\t\t} else if (t.channel === channel) {\n\t\t\t\thidden.push(t);\n\t\t\t}\n\t\t}\n\t\tif (hidden.length === 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn hidden;\n\t};\n\t\n\tBufferedTokenStream.prototype.getSourceName = function() {\n\t\treturn this.tokenSource.getSourceName();\n\t};\n\t\n\t// Get the text of all tokens in this buffer.///\n\tBufferedTokenStream.prototype.getText = function(interval) {\n\t\tthis.lazyInit();\n\t\tthis.fill();\n\t\tif (interval === undefined || interval === null) {\n\t\t\tinterval = new Interval(0, this.tokens.length - 1);\n\t\t}\n\t\tvar start = interval.start;\n\t\tif (start instanceof Token) {\n\t\t\tstart = start.tokenIndex;\n\t\t}\n\t\tvar stop = interval.stop;\n\t\tif (stop instanceof Token) {\n\t\t\tstop = stop.tokenIndex;\n\t\t}\n\t\tif (start === null || stop === null || start < 0 || stop < 0) {\n\t\t\treturn \"\";\n\t\t}\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tvar s = \"\";\n\t\tfor (var i = start; i < stop + 1; i++) {\n\t\t\tvar t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ts = s + t.text;\n\t\t}\n\t\treturn s;\n\t};\n\t\n\t// Get all tokens from lexer until EOF///\n\tBufferedTokenStream.prototype.fill = function() {\n\t\tthis.lazyInit();\n\t\twhile (this.fetch(1000) === 1000) {\n\t\t\tcontinue;\n\t\t}\n\t};\n\t\n\texports.BufferedTokenStream = BufferedTokenStream;\n\n\n/***/ },\n/* 48 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// [The \"BSD license\"]\n\t//  Copyright (c) 2012 Terence Parr\n\t//  Copyright (c) 2012 Sam Harwell\n\t//  Copyright (c) 2014 Eric Vergnaud\n\t//  All rights reserved.\n\t//\n\t//  Redistribution and use in source and binary forms, with or without\n\t//  modification, are permitted provided that the following conditions\n\t//  are met:\n\t//\n\t//  1. Redistributions of source code must retain the above copyright\n\t//     notice, this list of conditions and the following disclaimer.\n\t//  2. Redistributions in binary form must reproduce the above copyright\n\t//     notice, this list of conditions and the following disclaimer in the\n\t//     documentation and/or other materials provided with the distribution.\n\t//  3. The name of the author may not be used to endorse or promote products\n\t//     derived from this software without specific prior written permission.\n\t//\n\t//  this SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n\t//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\t//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n\t//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n\t//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n\t//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n\t//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n\t//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n\t//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n\t//  this SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\n\tvar Token = __webpack_require__(9).Token;\n\tvar ParseTreeListener = __webpack_require__(17).ParseTreeListener;\n\tvar Recognizer = __webpack_require__(26).Recognizer;\n\tvar DefaultErrorStrategy = __webpack_require__(42).DefaultErrorStrategy;\n\tvar ATNDeserializer = __webpack_require__(20).ATNDeserializer;\n\tvar ATNDeserializationOptions = __webpack_require__(22).ATNDeserializationOptions;\n\t\n\tfunction TraceListener(parser) {\n\t\tParseTreeListener.call(this);\n\t    this.parser = parser;\n\t\treturn this;\n\t}\n\t\n\tTraceListener.prototype = Object.create(ParseTreeListener);\n\tTraceListener.prototype.constructor = TraceListener;\n\t\n\tTraceListener.prototype.enterEveryRule = function(ctx) {\n\t\tconsole.log(\"enter   \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n\t};\n\t\n\tTraceListener.prototype.visitTerminal = function( node) {\n\t\tconsole.log(\"consume \" + node.symbol + \" rule \" + this.parser.ruleNames[this.parser._ctx.ruleIndex]);\n\t};\n\t\n\tTraceListener.prototype.exitEveryRule = function(ctx) {\n\t\tconsole.log(\"exit    \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n\t};\n\t\n\t// this is all the parsing support code essentially; most of it is error\n\t// recovery stuff.//\n\tfunction Parser(input) {\n\t\tRecognizer.call(this);\n\t\t// The input stream.\n\t\tthis._input = null;\n\t\t// The error handling strategy for the parser. The default value is a new\n\t\t// instance of {@link DefaultErrorStrategy}.\n\t\tthis._errHandler = new DefaultErrorStrategy();\n\t\tthis._precedenceStack = [];\n\t\tthis._precedenceStack.push(0);\n\t\t// The {@link ParserRuleContext} object for the currently executing rule.\n\t\t// this is always non-null during the parsing process.\n\t\tthis._ctx = null;\n\t\t// Specifies whether or not the parser should construct a parse tree during\n\t\t// the parsing process. The default value is {@code true}.\n\t\tthis.buildParseTrees = true;\n\t\t// When {@link //setTrace}{@code (true)} is called, a reference to the\n\t\t// {@link TraceListener} is stored here so it can be easily removed in a\n\t\t// later call to {@link //setTrace}{@code (false)}. The listener itself is\n\t\t// implemented as a parser listener so this field is not directly used by\n\t\t// other parser methods.\n\t\tthis._tracer = null;\n\t\t// The list of {@link ParseTreeListener} listeners registered to receive\n\t\t// events during the parse.\n\t\tthis._parseListeners = null;\n\t\t// The number of syntax errors reported during parsing. this value is\n\t\t// incremented each time {@link //notifyErrorListeners} is called.\n\t\tthis._syntaxErrors = 0;\n\t\tthis.setInputStream(input);\n\t\treturn this;\n\t}\n\t\n\tParser.prototype = Object.create(Recognizer.prototype);\n\tParser.prototype.contructor = Parser;\n\t\n\t// this field maps from the serialized ATN string to the deserialized {@link\n\t// ATN} with\n\t// bypass alternatives.\n\t//\n\t// @see ATNDeserializationOptions//isGenerateRuleBypassTransitions()\n\t//\n\tParser.bypassAltsAtnCache = {};\n\t\n\t// reset the parser's state//\n\tParser.prototype.reset = function() {\n\t\tif (this._input !== null) {\n\t\t\tthis._input.seek(0);\n\t\t}\n\t\tthis._errHandler.reset(this);\n\t\tthis._ctx = null;\n\t\tthis._syntaxErrors = 0;\n\t\tthis.setTrace(false);\n\t\tthis._precedenceStack = [];\n\t\tthis._precedenceStack.push(0);\n\t\tif (this._interp !== null) {\n\t\t\tthis._interp.reset();\n\t\t}\n\t};\n\t\n\t// Match current input symbol against {@code ttype}. If the symbol type\n\t// matches, {@link ANTLRErrorStrategy//reportMatch} and {@link //consume} are\n\t// called to complete the match process.\n\t//\n\t// <p>If the symbol type does not match,\n\t// {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n\t// strategy to attempt recovery. If {@link //getBuildParseTree} is\n\t// {@code true} and the token index of the symbol returned by\n\t// {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n\t// the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n\t//\n\t// @param ttype the token type to match\n\t// @return the matched symbol\n\t// @throws RecognitionException if the current input symbol did not match\n\t// {@code ttype} and the error strategy could not recover from the\n\t// mismatched symbol\n\t\n\tParser.prototype.match = function(ttype) {\n\t\tvar t = this.getCurrentToken();\n\t\tif (t.type === ttype) {\n\t\t\tthis._errHandler.reportMatch(this);\n\t\t\tthis.consume();\n\t\t} else {\n\t\t\tt = this._errHandler.recoverInline(this);\n\t\t\tif (this.buildParseTrees && t.tokenIndex === -1) {\n\t\t\t\t// we must have conjured up a new token during single token\n\t\t\t\t// insertion\n\t\t\t\t// if it's not the current symbol\n\t\t\t\tthis._ctx.addErrorNode(t);\n\t\t\t}\n\t\t}\n\t\treturn t;\n\t};\n\t// Match current input symbol as a wildcard. If the symbol type matches\n\t// (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}\n\t// and {@link //consume} are called to complete the match process.\n\t//\n\t// <p>If the symbol type does not match,\n\t// {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n\t// strategy to attempt recovery. If {@link //getBuildParseTree} is\n\t// {@code true} and the token index of the symbol returned by\n\t// {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n\t// the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n\t//\n\t// @return the matched symbol\n\t// @throws RecognitionException if the current input symbol did not match\n\t// a wildcard and the error strategy could not recover from the mismatched\n\t// symbol\n\t\n\tParser.prototype.matchWildcard = function() {\n\t\tvar t = this.getCurrentToken();\n\t\tif (t.type > 0) {\n\t\t\tthis._errHandler.reportMatch(this);\n\t\t\tthis.consume();\n\t\t} else {\n\t\t\tt = this._errHandler.recoverInline(this);\n\t\t\tif (this._buildParseTrees && t.tokenIndex === -1) {\n\t\t\t\t// we must have conjured up a new token during single token\n\t\t\t\t// insertion\n\t\t\t\t// if it's not the current symbol\n\t\t\t\tthis._ctx.addErrorNode(t);\n\t\t\t}\n\t\t}\n\t\treturn t;\n\t};\n\t\n\tParser.prototype.getParseListeners = function() {\n\t\treturn this._parseListeners || [];\n\t};\n\t\n\t// Registers {@code listener} to receive events during the parsing process.\n\t//\n\t// <p>To support output-preserving grammar transformations (including but not\n\t// limited to left-recursion removal, automated left-factoring, and\n\t// optimized code generation), calls to listener methods during the parse\n\t// may differ substantially from calls made by\n\t// {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In\n\t// particular, rule entry and exit events may occur in a different order\n\t// during the parse than after the parser. In addition, calls to certain\n\t// rule entry methods may be omitted.</p>\n\t//\n\t// <p>With the following specific exceptions, calls to listener events are\n\t// <em>deterministic</em>, i.e. for identical input the calls to listener\n\t// methods will be the same.</p>\n\t//\n\t// <ul>\n\t// <li>Alterations to the grammar used to generate code may change the\n\t// behavior of the listener calls.</li>\n\t// <li>Alterations to the command line options passed to ANTLR 4 when\n\t// generating the parser may change the behavior of the listener calls.</li>\n\t// <li>Changing the version of the ANTLR Tool used to generate the parser\n\t// may change the behavior of the listener calls.</li>\n\t// </ul>\n\t//\n\t// @param listener the listener to add\n\t//\n\t// @throws NullPointerException if {@code} listener is {@code null}\n\t//\n\tParser.prototype.addParseListener = function(listener) {\n\t\tif (listener === null) {\n\t\t\tthrow \"listener\";\n\t\t}\n\t\tif (this._parseListeners === null) {\n\t\t\tthis._parseListeners = [];\n\t\t}\n\t\tthis._parseListeners.push(listener);\n\t};\n\t\n\t//\n\t// Remove {@code listener} from the list of parse listeners.\n\t//\n\t// <p>If {@code listener} is {@code null} or has not been added as a parse\n\t// listener, this method does nothing.</p>\n\t// @param listener the listener to remove\n\t//\n\tParser.prototype.removeParseListener = function(listener) {\n\t\tif (this._parseListeners !== null) {\n\t\t\tvar idx = this._parseListeners.indexOf(listener);\n\t\t\tif (idx >= 0) {\n\t\t\t\tthis._parseListeners.splice(idx, 1);\n\t\t\t}\n\t\t\tif (this._parseListeners.length === 0) {\n\t\t\t\tthis._parseListeners = null;\n\t\t\t}\n\t\t}\n\t};\n\t\n\t// Remove all parse listeners.\n\tParser.prototype.removeParseListeners = function() {\n\t\tthis._parseListeners = null;\n\t};\n\t\n\t// Notify any parse listeners of an enter rule event.\n\tParser.prototype.triggerEnterRuleEvent = function() {\n\t\tif (this._parseListeners !== null) {\n\t        var ctx = this._ctx;\n\t\t\tthis._parseListeners.map(function(listener) {\n\t\t\t\tlistener.enterEveryRule(ctx);\n\t\t\t\tctx.enterRule(listener);\n\t\t\t});\n\t\t}\n\t};\n\t\n\t//\n\t// Notify any parse listeners of an exit rule event.\n\t//\n\t// @see //addParseListener\n\t//\n\tParser.prototype.triggerExitRuleEvent = function() {\n\t\tif (this._parseListeners !== null) {\n\t\t\t// reverse order walk of listeners\n\t        var ctx = this._ctx;\n\t\t\tthis._parseListeners.slice(0).reverse().map(function(listener) {\n\t\t\t\tctx.exitRule(listener);\n\t\t\t\tlistener.exitEveryRule(ctx);\n\t\t\t});\n\t\t}\n\t};\n\t\n\tParser.prototype.getTokenFactory = function() {\n\t\treturn this._input.tokenSource._factory;\n\t};\n\t\n\t// Tell our token source and error strategy about a new way to create tokens.//\n\tParser.prototype.setTokenFactory = function(factory) {\n\t\tthis._input.tokenSource._factory = factory;\n\t};\n\t\n\t// The ATN with bypass alternatives is expensive to create so we create it\n\t// lazily.\n\t//\n\t// @throws UnsupportedOperationException if the current parser does not\n\t// implement the {@link //getSerializedATN()} method.\n\t//\n\tParser.prototype.getATNWithBypassAlts = function() {\n\t\tvar serializedAtn = this.getSerializedATN();\n\t\tif (serializedAtn === null) {\n\t\t\tthrow \"The current parser does not support an ATN with bypass alternatives.\";\n\t\t}\n\t\tvar result = this.bypassAltsAtnCache[serializedAtn];\n\t\tif (result === null) {\n\t\t\tvar deserializationOptions = new ATNDeserializationOptions();\n\t\t\tdeserializationOptions.generateRuleBypassTransitions = true;\n\t\t\tresult = new ATNDeserializer(deserializationOptions)\n\t\t\t\t\t.deserialize(serializedAtn);\n\t\t\tthis.bypassAltsAtnCache[serializedAtn] = result;\n\t\t}\n\t\treturn result;\n\t};\n\t\n\t// The preferred method of getting a tree pattern. For example, here's a\n\t// sample use:\n\t//\n\t// <pre>\n\t// ParseTree t = parser.expr();\n\t// ParseTreePattern p = parser.compileParseTreePattern(\"&lt;ID&gt;+0\",\n\t// MyParser.RULE_expr);\n\t// ParseTreeMatch m = p.match(t);\n\t// String id = m.get(\"ID\");\n\t// </pre>\n\t\n\tvar Lexer = __webpack_require__(25).Lexer;\n\t\n\tParser.prototype.compileParseTreePattern = function(pattern, patternRuleIndex, lexer) {\n\t\tlexer = lexer || null;\n\t\tif (lexer === null) {\n\t\t\tif (this.getTokenStream() !== null) {\n\t\t\t\tvar tokenSource = this.getTokenStream().tokenSource;\n\t\t\t\tif (tokenSource instanceof Lexer) {\n\t\t\t\t\tlexer = tokenSource;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (lexer === null) {\n\t\t\tthrow \"Parser can't discover a lexer to use\";\n\t\t}\n\t\tvar m = new ParseTreePatternMatcher(lexer, this);\n\t\treturn m.compile(pattern, patternRuleIndex);\n\t};\n\t\n\tParser.prototype.getInputStream = function() {\n\t\treturn this.getTokenStream();\n\t};\n\t\n\tParser.prototype.setInputStream = function(input) {\n\t\tthis.setTokenStream(input);\n\t};\n\t\n\tParser.prototype.getTokenStream = function() {\n\t\treturn this._input;\n\t};\n\t\n\t// Set the token stream and reset the parser.//\n\tParser.prototype.setTokenStream = function(input) {\n\t\tthis._input = null;\n\t\tthis.reset();\n\t\tthis._input = input;\n\t};\n\t\n\t// Match needs to return the current input symbol, which gets put\n\t// into the label for the associated token ref; e.g., x=ID.\n\t//\n\tParser.prototype.getCurrentToken = function() {\n\t\treturn this._input.LT(1);\n\t};\n\t\n\tParser.prototype.notifyErrorListeners = function(msg, offendingToken, err) {\n\t\toffendingToken = offendingToken || null;\n\t\terr = err || null;\n\t\tif (offendingToken === null) {\n\t\t\toffendingToken = this.getCurrentToken();\n\t\t}\n\t\tthis._syntaxErrors += 1;\n\t\tvar line = offendingToken.line;\n\t\tvar column = offendingToken.column;\n\t\tvar listener = this.getErrorListenerDispatch();\n\t\tlistener.syntaxError(this, offendingToken, line, column, msg, err);\n\t};\n\t\n\t//\n\t// Consume and return the {@linkplain //getCurrentToken current symbol}.\n\t//\n\t// <p>E.g., given the following input with {@code A} being the current\n\t// lookahead symbol, this function moves the cursor to {@code B} and returns\n\t// {@code A}.</p>\n\t//\n\t// <pre>\n\t// A B\n\t// ^\n\t// </pre>\n\t//\n\t// If the parser is not in error recovery mode, the consumed symbol is added\n\t// to the parse tree using {@link ParserRuleContext//addChild(Token)}, and\n\t// {@link ParseTreeListener//visitTerminal} is called on any parse listeners.\n\t// If the parser <em>is</em> in error recovery mode, the consumed symbol is\n\t// added to the parse tree using\n\t// {@link ParserRuleContext//addErrorNode(Token)}, and\n\t// {@link ParseTreeListener//visitErrorNode} is called on any parse\n\t// listeners.\n\t//\n\tParser.prototype.consume = function() {\n\t\tvar o = this.getCurrentToken();\n\t\tif (o.type !== Token.EOF) {\n\t\t\tthis.getInputStream().consume();\n\t\t}\n\t\tvar hasListener = this._parseListeners !== null && this._parseListeners.length > 0;\n\t\tif (this.buildParseTrees || hasListener) {\n\t\t\tvar node;\n\t\t\tif (this._errHandler.inErrorRecoveryMode(this)) {\n\t\t\t\tnode = this._ctx.addErrorNode(o);\n\t\t\t} else {\n\t\t\t\tnode = this._ctx.addTokenNode(o);\n\t\t\t}\n\t        node.invokingState = this.state;\n\t\t\tif (hasListener) {\n\t\t\t\tthis._parseListeners.map(function(listener) {\n\t\t\t\t\tlistener.visitTerminal(node);\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\treturn o;\n\t};\n\t\n\tParser.prototype.addContextToParseTree = function() {\n\t\t// add current context to parent if we have a parent\n\t\tif (this._ctx.parentCtx !== null) {\n\t\t\tthis._ctx.parentCtx.addChild(this._ctx);\n\t\t}\n\t};\n\t\n\t// Always called by generated parsers upon entry to a rule. Access field\n\t// {@link //_ctx} get the current context.\n\t\n\tParser.prototype.enterRule = function(localctx, state, ruleIndex) {\n\t\tthis.state = state;\n\t\tthis._ctx = localctx;\n\t\tthis._ctx.start = this._input.LT(1);\n\t\tif (this.buildParseTrees) {\n\t\t\tthis.addContextToParseTree();\n\t\t}\n\t\tif (this._parseListeners !== null) {\n\t\t\tthis.triggerEnterRuleEvent();\n\t\t}\n\t};\n\t\n\tParser.prototype.exitRule = function() {\n\t\tthis._ctx.stop = this._input.LT(-1);\n\t\t// trigger event on _ctx, before it reverts to parent\n\t\tif (this._parseListeners !== null) {\n\t\t\tthis.triggerExitRuleEvent();\n\t\t}\n\t\tthis.state = this._ctx.invokingState;\n\t\tthis._ctx = this._ctx.parentCtx;\n\t};\n\t\n\tParser.prototype.enterOuterAlt = function(localctx, altNum) {\n\t   \tlocalctx.setAltNumber(altNum);\n\t\t// if we have new localctx, make sure we replace existing ctx\n\t\t// that is previous child of parse tree\n\t\tif (this.buildParseTrees && this._ctx !== localctx) {\n\t\t\tif (this._ctx.parentCtx !== null) {\n\t\t\t\tthis._ctx.parentCtx.removeLastChild();\n\t\t\t\tthis._ctx.parentCtx.addChild(localctx);\n\t\t\t}\n\t\t}\n\t\tthis._ctx = localctx;\n\t};\n\t\n\t// Get the precedence level for the top-most precedence rule.\n\t//\n\t// @return The precedence level for the top-most precedence rule, or -1 if\n\t// the parser context is not nested within a precedence rule.\n\t\n\tParser.prototype.getPrecedence = function() {\n\t\tif (this._precedenceStack.length === 0) {\n\t\t\treturn -1;\n\t\t} else {\n\t\t\treturn this._precedenceStack[this._precedenceStack.length-1];\n\t\t}\n\t};\n\t\n\tParser.prototype.enterRecursionRule = function(localctx, state, ruleIndex,\n\t\t\tprecedence) {\n\t\tthis.state = state;\n\t\tthis._precedenceStack.push(precedence);\n\t\tthis._ctx = localctx;\n\t\tthis._ctx.start = this._input.LT(1);\n\t\tif (this._parseListeners !== null) {\n\t\t\tthis.triggerEnterRuleEvent(); // simulates rule entry for\n\t\t\t\t\t\t\t\t\t\t\t// left-recursive rules\n\t\t}\n\t};\n\t\n\t//\n\t// Like {@link //enterRule} but for recursive rules.\n\t\n\tParser.prototype.pushNewRecursionContext = function(localctx, state, ruleIndex) {\n\t\tvar previous = this._ctx;\n\t\tprevious.parentCtx = localctx;\n\t\tprevious.invokingState = state;\n\t\tprevious.stop = this._input.LT(-1);\n\t\n\t\tthis._ctx = localctx;\n\t\tthis._ctx.start = previous.start;\n\t\tif (this.buildParseTrees) {\n\t\t\tthis._ctx.addChild(previous);\n\t\t}\n\t\tif (this._parseListeners !== null) {\n\t\t\tthis.triggerEnterRuleEvent(); // simulates rule entry for\n\t\t\t\t\t\t\t\t\t\t\t// left-recursive rules\n\t\t}\n\t};\n\t\n\tParser.prototype.unrollRecursionContexts = function(parentCtx) {\n\t\tthis._precedenceStack.pop();\n\t\tthis._ctx.stop = this._input.LT(-1);\n\t\tvar retCtx = this._ctx; // save current ctx (return value)\n\t\t// unroll so _ctx is as it was before call to recursive method\n\t\tif (this._parseListeners !== null) {\n\t\t\twhile (this._ctx !== parentCtx) {\n\t\t\t\tthis.triggerExitRuleEvent();\n\t\t\t\tthis._ctx = this._ctx.parentCtx;\n\t\t\t}\n\t\t} else {\n\t\t\tthis._ctx = parentCtx;\n\t\t}\n\t\t// hook into tree\n\t\tretCtx.parentCtx = parentCtx;\n\t\tif (this.buildParseTrees && parentCtx !== null) {\n\t\t\t// add return ctx into invoking rule's tree\n\t\t\tparentCtx.addChild(retCtx);\n\t\t}\n\t};\n\t\n\tParser.prototype.getInvokingContext = function(ruleIndex) {\n\t\tvar ctx = this._ctx;\n\t\twhile (ctx !== null) {\n\t\t\tif (ctx.ruleIndex === ruleIndex) {\n\t\t\t\treturn ctx;\n\t\t\t}\n\t\t\tctx = ctx.parentCtx;\n\t\t}\n\t\treturn null;\n\t};\n\t\n\tParser.prototype.precpred = function(localctx, precedence) {\n\t\treturn precedence >= this._precedenceStack[this._precedenceStack.length-1];\n\t};\n\t\n\tParser.prototype.inContext = function(context) {\n\t\t// TODO: useful in parser?\n\t\treturn false;\n\t};\n\t\n\t//\n\t// Checks whether or not {@code symbol} can follow the current state in the\n\t// ATN. The behavior of this method is equivalent to the following, but is\n\t// implemented such that the complete context-sensitive follow set does not\n\t// need to be explicitly constructed.\n\t//\n\t// <pre>\n\t// return getExpectedTokens().contains(symbol);\n\t// </pre>\n\t//\n\t// @param symbol the symbol type to check\n\t// @return {@code true} if {@code symbol} can follow the current state in\n\t// the ATN, otherwise {@code false}.\n\t\n\tParser.prototype.isExpectedToken = function(symbol) {\n\t\tvar atn = this._interp.atn;\n\t\tvar ctx = this._ctx;\n\t\tvar s = atn.states[this.state];\n\t\tvar following = atn.nextTokens(s);\n\t\tif (following.contains(symbol)) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!following.contains(Token.EPSILON)) {\n\t\t\treturn false;\n\t\t}\n\t\twhile (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n\t\t\tvar invokingState = atn.states[ctx.invokingState];\n\t\t\tvar rt = invokingState.transitions[0];\n\t\t\tfollowing = atn.nextTokens(rt.followState);\n\t\t\tif (following.contains(symbol)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tctx = ctx.parentCtx;\n\t\t}\n\t\tif (following.contains(Token.EPSILON) && symbol === Token.EOF) {\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t};\n\t\n\t// Computes the set of input symbols which could follow the current parser\n\t// state and context, as given by {@link //getState} and {@link //getContext},\n\t// respectively.\n\t//\n\t// @see ATN//getExpectedTokens(int, RuleContext)\n\t//\n\tParser.prototype.getExpectedTokens = function() {\n\t\treturn this._interp.atn.getExpectedTokens(this.state, this._ctx);\n\t};\n\t\n\tParser.prototype.getExpectedTokensWithinCurrentRule = function() {\n\t\tvar atn = this._interp.atn;\n\t\tvar s = atn.states[this.state];\n\t\treturn atn.nextTokens(s);\n\t};\n\t\n\t// Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.//\n\tParser.prototype.getRuleIndex = function(ruleName) {\n\t\tvar ruleIndex = this.getRuleIndexMap()[ruleName];\n\t\tif (ruleIndex !== null) {\n\t\t\treturn ruleIndex;\n\t\t} else {\n\t\t\treturn -1;\n\t\t}\n\t};\n\t\n\t// Return List&lt;String&gt; of the rule names in your parser instance\n\t// leading up to a call to the current rule. You could override if\n\t// you want more details such as the file/line info of where\n\t// in the ATN a rule is invoked.\n\t//\n\t// this is very useful for error messages.\n\t//\n\tParser.prototype.getRuleInvocationStack = function(p) {\n\t\tp = p || null;\n\t\tif (p === null) {\n\t\t\tp = this._ctx;\n\t\t}\n\t\tvar stack = [];\n\t\twhile (p !== null) {\n\t\t\t// compute what follows who invoked us\n\t\t\tvar ruleIndex = p.ruleIndex;\n\t\t\tif (ruleIndex < 0) {\n\t\t\t\tstack.push(\"n/a\");\n\t\t\t} else {\n\t\t\t\tstack.push(this.ruleNames[ruleIndex]);\n\t\t\t}\n\t\t\tp = p.parentCtx;\n\t\t}\n\t\treturn stack;\n\t};\n\t\n\t// For debugging and other purposes.//\n\tParser.prototype.getDFAStrings = function() {\n\t\treturn this._interp.decisionToDFA.toString();\n\t};\n\t// For debugging and other purposes.//\n\tParser.prototype.dumpDFA = function() {\n\t\tvar seenOne = false;\n\t\tfor (var i = 0; i < this._interp.decisionToDFA.length; i++) {\n\t\t\tvar dfa = this._interp.decisionToDFA[i];\n\t\t\tif (dfa.states.length > 0) {\n\t\t\t\tif (seenOne) {\n\t\t\t\t\tconsole.log();\n\t\t\t\t}\n\t\t\t\tthis.printer.println(\"Decision \" + dfa.decision + \":\");\n\t\t\t\tthis.printer.print(dfa.toString(this.literalNames, this.symbolicNames));\n\t\t\t\tseenOne = true;\n\t\t\t}\n\t\t}\n\t};\n\t\n\t/*\n\t\"\t\t\tprinter = function() {\\r\\n\" +\n\t\"\t\t\t\tthis.println = function(s) { document.getElementById('output') += s + '\\\\n'; }\\r\\n\" +\n\t\"\t\t\t\tthis.print = function(s) { document.getElementById('output') += s; }\\r\\n\" +\n\t\"\t\t\t};\\r\\n\" +\n\t*/\n\t\n\tParser.prototype.getSourceName = function() {\n\t\treturn this._input.sourceName;\n\t};\n\t\n\t// During a parse is sometimes useful to listen in on the rule entry and exit\n\t// events as well as token matches. this is for quick and dirty debugging.\n\t//\n\tParser.prototype.setTrace = function(trace) {\n\t\tif (!trace) {\n\t\t\tthis.removeParseListener(this._tracer);\n\t\t\tthis._tracer = null;\n\t\t} else {\n\t\t\tif (this._tracer !== null) {\n\t\t\t\tthis.removeParseListener(this._tracer);\n\t\t\t}\n\t\t\tthis._tracer = new TraceListener(this);\n\t\t\tthis.addParseListener(this._tracer);\n\t\t}\n\t};\n\t\n\texports.Parser = Parser;\n\n/***/ },\n/* 49 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// Generated from Calculator.g4 by ANTLR 4.5.2\r\n\t// jshint ignore: start\r\n\tvar antlr4 = __webpack_require__(4);\r\n\tvar CalculatorVisitor = __webpack_require__(50).CalculatorVisitor;\r\n\t\r\n\tvar grammarFileName = \"Calculator.g4\";\r\n\t\r\n\tvar serializedATN = [\"\\u0003\\u0430\\ud6d1\\u8206\\uad2d\\u4417\\uaef1\\u8d80\\uaadd\",\r\n\t    \"\\u00035{\\u0004\\u0002\\t\\u0002\\u0004\\u0003\\t\\u0003\\u0004\\u0004\\t\\u0004\",\r\n\t    \"\\u0003\\u0002\\u0003\\u0002\\u0005\\u0002\\u000b\\n\\u0002\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0005\\u0003W\\n\\u0003\\u0003\\u0003\\u0005\\u0003Z\\n\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n\t    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0007\\u0003\",\r\n\t    \"t\\n\\u0003\\f\\u0003\\u000e\\u0003w\\u000b\\u0003\\u0003\\u0004\\u0003\\u0004\\u0003\",\r\n\t    \"\\u0004\\u0002\\u0003\\u0004\\u0005\\u0002\\u0004\\u0006\\u0002\\u0007\\u0003\\u0002\",\r\n\t    \"\\u0006\\u0007\\u0004\\u0002\\b\\b\\u000f\\u000f\\u0003\\u0002\\t\\n\\u0003\\u0002\",\r\n\t    \"\\u0011\\u0012\\u0003\\u0002\\u0013\\u0014\\u00a0\\u0002\\b\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002\\u0004Y\\u0003\\u0002\\u0002\\u0002\\u0006x\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"\\b\\n\\u0005\\u0004\\u0003\\u0002\\t\\u000b\\u0005\\u0006\\u0004\\u0002\\n\\t\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\n\\u000b\\u0003\\u0002\\u0002\\u0002\\u000b\\u0003\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002\\f\\r\\b\\u0003\\u0001\\u0002\\r\\u000e\\u0007\\u001b\\u0002\",\r\n\t    \"\\u0002\\u000eZ\\u0005\\u0004\\u0003*\\u000f\\u0010\\u0007\\u001c\\u0002\\u0002\",\r\n\t    \"\\u0010Z\\u0005\\u0004\\u0003)\\u0011\\u0012\\u0007\\u001d\\u0002\\u0002\\u0012\",\r\n\t    \"Z\\u0005\\u0004\\u0003(\\u0013\\u0014\\u0007\\u001f\\u0002\\u0002\\u0014Z\\u0005\",\r\n\t    \"\\u0004\\u0003&\\u0015\\u0016\\u0007 \\u0002\\u0002\\u0016Z\\u0005\\u0004\\u0003\",\r\n\t    \"%\\u0017\\u0018\\u0007!\\u0002\\u0002\\u0018Z\\u0005\\u0004\\u0003$\\u0019\\u001a\",\r\n\t    \"\\u0007\\\"\\u0002\\u0002\\u001aZ\\u0005\\u0004\\u0003#\\u001b\\u001c\\u0007#\\u0002\",\r\n\t    \"\\u0002\\u001cZ\\u0005\\u0004\\u0003\\\"\\u001d\\u001e\\u0007$\\u0002\\u0002\\u001e\",\r\n\t    \"Z\\u0005\\u0004\\u0003!\\u001f \\u0007%\\u0002\\u0002 Z\\u0005\\u0004\\u0003 \",\r\n\t    \"!\\\"\\u0007&\\u0002\\u0002\\\"Z\\u0005\\u0004\\u0003\\u001f#$\\u0007\\'\\u0002\\u0002\",\r\n\t    \"$Z\\u0005\\u0004\\u0003\\u001e%&\\u0007(\\u0002\\u0002&Z\\u0005\\u0004\\u0003\",\r\n\t    \"\\u001d\\'(\\u0007)\\u0002\\u0002(Z\\u0005\\u0004\\u0003\\u001c)*\\u0007*\\u0002\",\r\n\t    \"\\u0002*Z\\u0005\\u0004\\u0003\\u001b+,\\u0007,\\u0002\\u0002,Z\\u0005\\u0004\",\r\n\t    \"\\u0003\\u0019-.\\u0007-\\u0002\\u0002.Z\\u0005\\u0004\\u0003\\u0018/0\\u0007\",\r\n\t    \".\\u0002\\u00020Z\\u0005\\u0004\\u0003\\u001712\\u0007/\\u0002\\u00022Z\\u0005\",\r\n\t    \"\\u0004\\u0003\\u001634\\u00070\\u0002\\u00024Z\\u0005\\u0004\\u0003\\u001556\",\r\n\t    \"\\u00071\\u0002\\u00026Z\\u0005\\u0004\\u0003\\u001478\\u00072\\u0002\\u00028\",\r\n\t    \"Z\\u0005\\u0004\\u0003\\u00139:\\u0007\\u0019\\u0002\\u0002:Z\\u0005\\u0004\\u0003\",\r\n\t    \"\\u0012;<\\u0007\\u001a\\u0002\\u0002<Z\\u0005\\u0004\\u0003\\u0011=>\\u0007\\u0014\",\r\n\t    \"\\u0002\\u0002>Z\\u0005\\u0004\\u0003\\u0004?@\\u0007\\u0013\\u0002\\u0002@Z\\u0005\",\r\n\t    \"\\u0004\\u0003\\u0003AB\\u0007\\u001e\\u0002\\u0002BC\\u0007\\u0003\\u0002\\u0002\",\r\n\t    \"CD\\u0005\\u0004\\u0003\\u0002DE\\u0007\\u0004\\u0002\\u0002EF\\u0005\\u0004\\u0003\",\r\n\t    \"\\u0002FG\\u0007\\u0005\\u0002\\u0002GZ\\u0003\\u0002\\u0002\\u0002HI\\u0007+\",\r\n\t    \"\\u0002\\u0002IJ\\u0007\\u0003\\u0002\\u0002JK\\u0005\\u0004\\u0003\\u0002KL\\u0007\",\r\n\t    \"\\u0004\\u0002\\u0002LM\\u0005\\u0004\\u0003\\u0002MN\\u0007\\u0005\\u0002\\u0002\",\r\n\t    \"NZ\\u0003\\u0002\\u0002\\u0002OZ\\u0007\\f\\u0002\\u0002PQ\\u0007\\u0003\\u0002\",\r\n\t    \"\\u0002QR\\u0005\\u0004\\u0003\\u0002RS\\u0007\\u0005\\u0002\\u0002SZ\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002TV\\u0007\\u0015\\u0002\\u0002UW\\u0007\\u000b\\u0002\\u0002VU\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002VW\\u0003\\u0002\\u0002\\u0002WZ\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"XZ\\u0007\\u0018\\u0002\\u0002Y\\f\\u0003\\u0002\\u0002\\u0002Y\\u000f\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002Y\\u0011\\u0003\\u0002\\u0002\\u0002Y\\u0013\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002Y\\u0015\\u0003\\u0002\\u0002\\u0002Y\\u0017\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"Y\\u0019\\u0003\\u0002\\u0002\\u0002Y\\u001b\\u0003\\u0002\\u0002\\u0002Y\\u001d\",\r\n\t    \"\\u0003\\u0002\\u0002\\u0002Y\\u001f\\u0003\\u0002\\u0002\\u0002Y!\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002Y#\\u0003\\u0002\\u0002\\u0002Y%\\u0003\\u0002\\u0002\\u0002Y\\'\",\r\n\t    \"\\u0003\\u0002\\u0002\\u0002Y)\\u0003\\u0002\\u0002\\u0002Y+\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002Y-\\u0003\\u0002\\u0002\\u0002Y/\\u0003\\u0002\\u0002\\u0002Y1\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002Y3\\u0003\\u0002\\u0002\\u0002Y5\\u0003\\u0002\\u0002\\u0002Y7\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002Y9\\u0003\\u0002\\u0002\\u0002Y;\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"Y=\\u0003\\u0002\\u0002\\u0002Y?\\u0003\\u0002\\u0002\\u0002YA\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002YH\\u0003\\u0002\\u0002\\u0002YO\\u0003\\u0002\\u0002\\u0002YP\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002YT\\u0003\\u0002\\u0002\\u0002YX\\u0003\\u0002\\u0002\\u0002Zu\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002[\\\\\\f\\u0010\\u0002\\u0002\\\\]\\t\\u0002\\u0002\\u0002]t\\u0005\",\r\n\t    \"\\u0004\\u0003\\u0011^_\\f\\u000f\\u0002\\u0002_`\\t\\u0003\\u0002\\u0002`t\\u0005\",\r\n\t    \"\\u0004\\u0003\\u0010ab\\f\\u000e\\u0002\\u0002bc\\u0007\\u0010\\u0002\\u0002c\",\r\n\t    \"t\\u0005\\u0004\\u0003\\u000fde\\f\\r\\u0002\\u0002ef\\t\\u0004\\u0002\\u0002ft\",\r\n\t    \"\\u0005\\u0004\\u0003\\u000egh\\f\\f\\u0002\\u0002hi\\t\\u0005\\u0002\\u0002it\\u0005\",\r\n\t    \"\\u0004\\u0003\\rjk\\f\\u000b\\u0002\\u0002kl\\t\\u0006\\u0002\\u0002lt\\u0005\\u0004\",\r\n\t    \"\\u0003\\fmn\\f\\u0007\\u0002\\u0002no\\u0007\\u0016\\u0002\\u0002ot\\u0005\\u0004\",\r\n\t    \"\\u0003\\bpq\\f\\u0006\\u0002\\u0002qr\\u0007\\u0017\\u0002\\u0002rt\\u0005\\u0004\",\r\n\t    \"\\u0003\\u0007s[\\u0003\\u0002\\u0002\\u0002s^\\u0003\\u0002\\u0002\\u0002sa\\u0003\",\r\n\t    \"\\u0002\\u0002\\u0002sd\\u0003\\u0002\\u0002\\u0002sg\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"sj\\u0003\\u0002\\u0002\\u0002sm\\u0003\\u0002\\u0002\\u0002sp\\u0003\\u0002\\u0002\",\r\n\t    \"\\u0002tw\\u0003\\u0002\\u0002\\u0002us\\u0003\\u0002\\u0002\\u0002uv\\u0003\\u0002\",\r\n\t    \"\\u0002\\u0002v\\u0005\\u0003\\u0002\\u0002\\u0002wu\\u0003\\u0002\\u0002\\u0002\",\r\n\t    \"xy\\u0007\\u0002\\u0002\\u0003y\\u0007\\u0003\\u0002\\u0002\\u0002\\u0007\\nVY\",\r\n\t    \"su\"].join(\"\");\r\n\t\r\n\t\r\n\tvar atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);\r\n\t\r\n\tvar decisionsToDFA = atn.decisionToState.map( function(ds, index) { return new antlr4.dfa.DFA(ds, index); });\r\n\t\r\n\tvar sharedContextCache = new antlr4.PredictionContextCache();\r\n\t\r\n\tvar literalNames = [ null, \"'('\", \"';'\", \"')'\", \"'^'\", \"'**'\", \"'%'\", \"'~'\", \r\n\t                     \"'//'\", \"'()'\", null, null, null, null, null, \"'*'\", \r\n\t                     \"'/'\", \"'+'\", \"'-'\" ];\r\n\t\r\n\tvar symbolicNames = [ null, null, null, null, null, null, null, null, null, \r\n\t                      null, \"NUMBER\", \"FLOAT\", \"DIGIT\", \"MOD\", \"WHOLE\", \r\n\t                      \"MUL\", \"DIV\", \"ADD\", \"SUB\", \"PI\", \"EXPONENT\", \"NEGEXPONENT\", \r\n\t                      \"EULER\", \"SQRT\", \"SQR\", \"FLOOR\", \"CEIL\", \"ABS\", \"ROUNDK\", \r\n\t                      \"ROUND\", \"TRUNC\", \"SIN\", \"COS\", \"TAN\", \"COT\", \"SINH\", \r\n\t                      \"COSH\", \"TANH\", \"ARCSIN\", \"ARCCOS\", \"ARCTAN\", \"ARCTAN2\", \r\n\t                      \"ARCCOT\", \"EXP\", \"LN\", \"EEX\", \"LOG\", \"RAD\", \"DEG\", \r\n\t                      \"WS\", \"COM\", \"INVALID\" ];\r\n\t\r\n\tvar ruleNames =  [ \"calculator\", \"expression\", \"compileUnit\" ];\r\n\t\r\n\tfunction CalculatorParser (input) {\r\n\t\tantlr4.Parser.call(this, input);\r\n\t    this._interp = new antlr4.atn.ParserATNSimulator(this, atn, decisionsToDFA, sharedContextCache);\r\n\t    this.ruleNames = ruleNames;\r\n\t    this.literalNames = literalNames;\r\n\t    this.symbolicNames = symbolicNames;\r\n\t    return this;\r\n\t}\r\n\t\r\n\tCalculatorParser.prototype = Object.create(antlr4.Parser.prototype);\r\n\tCalculatorParser.prototype.constructor = CalculatorParser;\r\n\t\r\n\tObject.defineProperty(CalculatorParser.prototype, \"atn\", {\r\n\t\tget : function() {\r\n\t\t\treturn atn;\r\n\t\t}\r\n\t});\r\n\t\r\n\tCalculatorParser.EOF = antlr4.Token.EOF;\r\n\tCalculatorParser.T__0 = 1;\r\n\tCalculatorParser.T__1 = 2;\r\n\tCalculatorParser.T__2 = 3;\r\n\tCalculatorParser.T__3 = 4;\r\n\tCalculatorParser.T__4 = 5;\r\n\tCalculatorParser.T__5 = 6;\r\n\tCalculatorParser.T__6 = 7;\r\n\tCalculatorParser.T__7 = 8;\r\n\tCalculatorParser.T__8 = 9;\r\n\tCalculatorParser.NUMBER = 10;\r\n\tCalculatorParser.FLOAT = 11;\r\n\tCalculatorParser.DIGIT = 12;\r\n\tCalculatorParser.MOD = 13;\r\n\tCalculatorParser.WHOLE = 14;\r\n\tCalculatorParser.MUL = 15;\r\n\tCalculatorParser.DIV = 16;\r\n\tCalculatorParser.ADD = 17;\r\n\tCalculatorParser.SUB = 18;\r\n\tCalculatorParser.PI = 19;\r\n\tCalculatorParser.EXPONENT = 20;\r\n\tCalculatorParser.NEGEXPONENT = 21;\r\n\tCalculatorParser.EULER = 22;\r\n\tCalculatorParser.SQRT = 23;\r\n\tCalculatorParser.SQR = 24;\r\n\tCalculatorParser.FLOOR = 25;\r\n\tCalculatorParser.CEIL = 26;\r\n\tCalculatorParser.ABS = 27;\r\n\tCalculatorParser.ROUNDK = 28;\r\n\tCalculatorParser.ROUND = 29;\r\n\tCalculatorParser.TRUNC = 30;\r\n\tCalculatorParser.SIN = 31;\r\n\tCalculatorParser.COS = 32;\r\n\tCalculatorParser.TAN = 33;\r\n\tCalculatorParser.COT = 34;\r\n\tCalculatorParser.SINH = 35;\r\n\tCalculatorParser.COSH = 36;\r\n\tCalculatorParser.TANH = 37;\r\n\tCalculatorParser.ARCSIN = 38;\r\n\tCalculatorParser.ARCCOS = 39;\r\n\tCalculatorParser.ARCTAN = 40;\r\n\tCalculatorParser.ARCTAN2 = 41;\r\n\tCalculatorParser.ARCCOT = 42;\r\n\tCalculatorParser.EXP = 43;\r\n\tCalculatorParser.LN = 44;\r\n\tCalculatorParser.EEX = 45;\r\n\tCalculatorParser.LOG = 46;\r\n\tCalculatorParser.RAD = 47;\r\n\tCalculatorParser.DEG = 48;\r\n\tCalculatorParser.WS = 49;\r\n\tCalculatorParser.COM = 50;\r\n\tCalculatorParser.INVALID = 51;\r\n\t\r\n\tCalculatorParser.RULE_calculator = 0;\r\n\tCalculatorParser.RULE_expression = 1;\r\n\tCalculatorParser.RULE_compileUnit = 2;\r\n\t\r\n\tfunction CalculatorContext(parser, parent, invokingState) {\r\n\t\tif(parent===undefined) {\r\n\t\t    parent = null;\r\n\t\t}\r\n\t\tif(invokingState===undefined || invokingState===null) {\r\n\t\t\tinvokingState = -1;\r\n\t\t}\r\n\t\tantlr4.ParserRuleContext.call(this, parent, invokingState);\r\n\t    this.parser = parser;\r\n\t    this.ruleIndex = CalculatorParser.RULE_calculator;\r\n\t    return this;\r\n\t}\r\n\t\r\n\tCalculatorContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\r\n\tCalculatorContext.prototype.constructor = CalculatorContext;\r\n\t\r\n\tCalculatorContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\t\r\n\tCalculatorContext.prototype.compileUnit = function() {\r\n\t    return this.getTypedRuleContext(CompileUnitContext,0);\r\n\t};\r\n\t\r\n\tCalculatorContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitCalculator(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tCalculatorParser.CalculatorContext = CalculatorContext;\r\n\t\r\n\tCalculatorParser.prototype.calculator = function() {\r\n\t\r\n\t    var localctx = new CalculatorContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 0, CalculatorParser.RULE_calculator);\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 6;\r\n\t        this.expression(0);\r\n\t        this.state = 8;\r\n\t        this._errHandler.sync(this);\r\n\t        var la_ = this._interp.adaptivePredict(this._input,0,this._ctx);\r\n\t        if(la_===1) {\r\n\t            this.state = 7;\r\n\t            this.compileUnit();\r\n\t\r\n\t        }\r\n\t    } catch (re) {\r\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n\t};\r\n\t\r\n\tfunction ExpressionContext(parser, parent, invokingState) {\r\n\t\tif(parent===undefined) {\r\n\t\t    parent = null;\r\n\t\t}\r\n\t\tif(invokingState===undefined || invokingState===null) {\r\n\t\t\tinvokingState = -1;\r\n\t\t}\r\n\t\tantlr4.ParserRuleContext.call(this, parent, invokingState);\r\n\t    this.parser = parser;\r\n\t    this.ruleIndex = CalculatorParser.RULE_expression;\r\n\t    return this;\r\n\t}\r\n\t\r\n\tExpressionContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\r\n\tExpressionContext.prototype.constructor = ExpressionContext;\r\n\t\r\n\t\r\n\t \r\n\tExpressionContext.prototype.copyFrom = function(ctx) {\r\n\t    antlr4.ParserRuleContext.prototype.copyFrom.call(this, ctx);\r\n\t};\r\n\t\r\n\tfunction TanContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tTanContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tTanContext.prototype.constructor = TanContext;\r\n\t\r\n\tCalculatorParser.TanContext = TanContext;\r\n\t\r\n\tTanContext.prototype.TAN = function() {\r\n\t    return this.getToken(CalculatorParser.TAN, 0);\r\n\t};\r\n\t\r\n\tTanContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tTanContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitTan(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction CoshContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tCoshContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tCoshContext.prototype.constructor = CoshContext;\r\n\t\r\n\tCalculatorParser.CoshContext = CoshContext;\r\n\t\r\n\tCoshContext.prototype.COSH = function() {\r\n\t    return this.getToken(CalculatorParser.COSH, 0);\r\n\t};\r\n\t\r\n\tCoshContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tCoshContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitCosh(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction SqRootContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    this.op = null; // Token;\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tSqRootContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tSqRootContext.prototype.constructor = SqRootContext;\r\n\t\r\n\tCalculatorParser.SqRootContext = SqRootContext;\r\n\t\r\n\tSqRootContext.prototype.expression = function(i) {\r\n\t    if(i===undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if(i===null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    } else {\r\n\t        return this.getTypedRuleContext(ExpressionContext,i);\r\n\t    }\r\n\t};\r\n\tSqRootContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitSqRoot(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction NegExponentContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tNegExponentContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tNegExponentContext.prototype.constructor = NegExponentContext;\r\n\t\r\n\tCalculatorParser.NegExponentContext = NegExponentContext;\r\n\t\r\n\tNegExponentContext.prototype.expression = function(i) {\r\n\t    if(i===undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if(i===null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    } else {\r\n\t        return this.getTypedRuleContext(ExpressionContext,i);\r\n\t    }\r\n\t};\r\n\t\r\n\tNegExponentContext.prototype.NEGEXPONENT = function() {\r\n\t    return this.getToken(CalculatorParser.NEGEXPONENT, 0);\r\n\t};\r\n\tNegExponentContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitNegExponent(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction ExponentContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tExponentContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tExponentContext.prototype.constructor = ExponentContext;\r\n\t\r\n\tCalculatorParser.ExponentContext = ExponentContext;\r\n\t\r\n\tExponentContext.prototype.expression = function(i) {\r\n\t    if(i===undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if(i===null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    } else {\r\n\t        return this.getTypedRuleContext(ExpressionContext,i);\r\n\t    }\r\n\t};\r\n\t\r\n\tExponentContext.prototype.EXPONENT = function() {\r\n\t    return this.getToken(CalculatorParser.EXPONENT, 0);\r\n\t};\r\n\tExponentContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitExponent(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction Arctan2Context(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tArctan2Context.prototype = Object.create(ExpressionContext.prototype);\r\n\tArctan2Context.prototype.constructor = Arctan2Context;\r\n\t\r\n\tCalculatorParser.Arctan2Context = Arctan2Context;\r\n\t\r\n\tArctan2Context.prototype.ARCTAN2 = function() {\r\n\t    return this.getToken(CalculatorParser.ARCTAN2, 0);\r\n\t};\r\n\t\r\n\tArctan2Context.prototype.expression = function(i) {\r\n\t    if(i===undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if(i===null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    } else {\r\n\t        return this.getTypedRuleContext(ExpressionContext,i);\r\n\t    }\r\n\t};\r\n\tArctan2Context.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitArctan2(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction MulDivContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    this.op = null; // Token;\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tMulDivContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tMulDivContext.prototype.constructor = MulDivContext;\r\n\t\r\n\tCalculatorParser.MulDivContext = MulDivContext;\r\n\t\r\n\tMulDivContext.prototype.expression = function(i) {\r\n\t    if(i===undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if(i===null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    } else {\r\n\t        return this.getTypedRuleContext(ExpressionContext,i);\r\n\t    }\r\n\t};\r\n\tMulDivContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitMulDiv(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction ArcsinContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tArcsinContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tArcsinContext.prototype.constructor = ArcsinContext;\r\n\t\r\n\tCalculatorParser.ArcsinContext = ArcsinContext;\r\n\t\r\n\tArcsinContext.prototype.ARCSIN = function() {\r\n\t    return this.getToken(CalculatorParser.ARCSIN, 0);\r\n\t};\r\n\t\r\n\tArcsinContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tArcsinContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitArcsin(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction UnaryPlusContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tUnaryPlusContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tUnaryPlusContext.prototype.constructor = UnaryPlusContext;\r\n\t\r\n\tCalculatorParser.UnaryPlusContext = UnaryPlusContext;\r\n\t\r\n\tUnaryPlusContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tUnaryPlusContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitUnaryPlus(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction ArccotContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tArccotContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tArccotContext.prototype.constructor = ArccotContext;\r\n\t\r\n\tCalculatorParser.ArccotContext = ArccotContext;\r\n\t\r\n\tArccotContext.prototype.ARCCOT = function() {\r\n\t    return this.getToken(CalculatorParser.ARCCOT, 0);\r\n\t};\r\n\t\r\n\tArccotContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tArccotContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitArccot(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction ArccosContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tArccosContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tArccosContext.prototype.constructor = ArccosContext;\r\n\t\r\n\tCalculatorParser.ArccosContext = ArccosContext;\r\n\t\r\n\tArccosContext.prototype.ARCCOS = function() {\r\n\t    return this.getToken(CalculatorParser.ARCCOS, 0);\r\n\t};\r\n\t\r\n\tArccosContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tArccosContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitArccos(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction EulerContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tEulerContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tEulerContext.prototype.constructor = EulerContext;\r\n\t\r\n\tCalculatorParser.EulerContext = EulerContext;\r\n\t\r\n\tEulerContext.prototype.EULER = function() {\r\n\t    return this.getToken(CalculatorParser.EULER, 0);\r\n\t};\r\n\tEulerContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitEuler(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction ArctanContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tArctanContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tArctanContext.prototype.constructor = ArctanContext;\r\n\t\r\n\tCalculatorParser.ArctanContext = ArctanContext;\r\n\t\r\n\tArctanContext.prototype.ARCTAN = function() {\r\n\t    return this.getToken(CalculatorParser.ARCTAN, 0);\r\n\t};\r\n\t\r\n\tArctanContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tArctanContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitArctan(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction ParenthesisContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tParenthesisContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tParenthesisContext.prototype.constructor = ParenthesisContext;\r\n\t\r\n\tCalculatorParser.ParenthesisContext = ParenthesisContext;\r\n\t\r\n\tParenthesisContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tParenthesisContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitParenthesis(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction AbsContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tAbsContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tAbsContext.prototype.constructor = AbsContext;\r\n\t\r\n\tCalculatorParser.AbsContext = AbsContext;\r\n\t\r\n\tAbsContext.prototype.ABS = function() {\r\n\t    return this.getToken(CalculatorParser.ABS, 0);\r\n\t};\r\n\t\r\n\tAbsContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tAbsContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitAbs(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction NumberContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tNumberContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tNumberContext.prototype.constructor = NumberContext;\r\n\t\r\n\tCalculatorParser.NumberContext = NumberContext;\r\n\t\r\n\tNumberContext.prototype.NUMBER = function() {\r\n\t    return this.getToken(CalculatorParser.NUMBER, 0);\r\n\t};\r\n\tNumberContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitNumber(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction SinhContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tSinhContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tSinhContext.prototype.constructor = SinhContext;\r\n\t\r\n\tCalculatorParser.SinhContext = SinhContext;\r\n\t\r\n\tSinhContext.prototype.SINH = function() {\r\n\t    return this.getToken(CalculatorParser.SINH, 0);\r\n\t};\r\n\t\r\n\tSinhContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tSinhContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitSinh(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction RoundContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tRoundContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tRoundContext.prototype.constructor = RoundContext;\r\n\t\r\n\tCalculatorParser.RoundContext = RoundContext;\r\n\t\r\n\tRoundContext.prototype.ROUND = function() {\r\n\t    return this.getToken(CalculatorParser.ROUND, 0);\r\n\t};\r\n\t\r\n\tRoundContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tRoundContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitRound(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction TruncContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tTruncContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tTruncContext.prototype.constructor = TruncContext;\r\n\t\r\n\tCalculatorParser.TruncContext = TruncContext;\r\n\t\r\n\tTruncContext.prototype.TRUNC = function() {\r\n\t    return this.getToken(CalculatorParser.TRUNC, 0);\r\n\t};\r\n\t\r\n\tTruncContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tTruncContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitTrunc(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction PiContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tPiContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tPiContext.prototype.constructor = PiContext;\r\n\t\r\n\tCalculatorParser.PiContext = PiContext;\r\n\t\r\n\tPiContext.prototype.PI = function() {\r\n\t    return this.getToken(CalculatorParser.PI, 0);\r\n\t};\r\n\tPiContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitPi(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction TanhContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tTanhContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tTanhContext.prototype.constructor = TanhContext;\r\n\t\r\n\tCalculatorParser.TanhContext = TanhContext;\r\n\t\r\n\tTanhContext.prototype.TANH = function() {\r\n\t    return this.getToken(CalculatorParser.TANH, 0);\r\n\t};\r\n\t\r\n\tTanhContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tTanhContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitTanh(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction FloorContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tFloorContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tFloorContext.prototype.constructor = FloorContext;\r\n\t\r\n\tCalculatorParser.FloorContext = FloorContext;\r\n\t\r\n\tFloorContext.prototype.FLOOR = function() {\r\n\t    return this.getToken(CalculatorParser.FLOOR, 0);\r\n\t};\r\n\t\r\n\tFloorContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tFloorContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitFloor(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction LnContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tLnContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tLnContext.prototype.constructor = LnContext;\r\n\t\r\n\tCalculatorParser.LnContext = LnContext;\r\n\t\r\n\tLnContext.prototype.LN = function() {\r\n\t    return this.getToken(CalculatorParser.LN, 0);\r\n\t};\r\n\t\r\n\tLnContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tLnContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitLn(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction ModContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tModContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tModContext.prototype.constructor = ModContext;\r\n\t\r\n\tCalculatorParser.ModContext = ModContext;\r\n\t\r\n\tModContext.prototype.expression = function(i) {\r\n\t    if(i===undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if(i===null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    } else {\r\n\t        return this.getTypedRuleContext(ExpressionContext,i);\r\n\t    }\r\n\t};\r\n\t\r\n\tModContext.prototype.MOD = function() {\r\n\t    return this.getToken(CalculatorParser.MOD, 0);\r\n\t};\r\n\tModContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitMod(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction LogContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tLogContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tLogContext.prototype.constructor = LogContext;\r\n\t\r\n\tCalculatorParser.LogContext = LogContext;\r\n\t\r\n\tLogContext.prototype.LOG = function() {\r\n\t    return this.getToken(CalculatorParser.LOG, 0);\r\n\t};\r\n\t\r\n\tLogContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tLogContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitLog(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction AddSubContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    this.op = null; // Token;\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tAddSubContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tAddSubContext.prototype.constructor = AddSubContext;\r\n\t\r\n\tCalculatorParser.AddSubContext = AddSubContext;\r\n\t\r\n\tAddSubContext.prototype.expression = function(i) {\r\n\t    if(i===undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if(i===null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    } else {\r\n\t        return this.getTypedRuleContext(ExpressionContext,i);\r\n\t    }\r\n\t};\r\n\tAddSubContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitAddSub(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction CosContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tCosContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tCosContext.prototype.constructor = CosContext;\r\n\t\r\n\tCalculatorParser.CosContext = CosContext;\r\n\t\r\n\tCosContext.prototype.COS = function() {\r\n\t    return this.getToken(CalculatorParser.COS, 0);\r\n\t};\r\n\t\r\n\tCosContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tCosContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitCos(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction DegContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tDegContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tDegContext.prototype.constructor = DegContext;\r\n\t\r\n\tCalculatorParser.DegContext = DegContext;\r\n\t\r\n\tDegContext.prototype.DEG = function() {\r\n\t    return this.getToken(CalculatorParser.DEG, 0);\r\n\t};\r\n\t\r\n\tDegContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tDegContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitDeg(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction SqrtContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tSqrtContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tSqrtContext.prototype.constructor = SqrtContext;\r\n\t\r\n\tCalculatorParser.SqrtContext = SqrtContext;\r\n\t\r\n\tSqrtContext.prototype.SQRT = function() {\r\n\t    return this.getToken(CalculatorParser.SQRT, 0);\r\n\t};\r\n\t\r\n\tSqrtContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tSqrtContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitSqrt(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction CotContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tCotContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tCotContext.prototype.constructor = CotContext;\r\n\t\r\n\tCalculatorParser.CotContext = CotContext;\r\n\t\r\n\tCotContext.prototype.COT = function() {\r\n\t    return this.getToken(CalculatorParser.COT, 0);\r\n\t};\r\n\t\r\n\tCotContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tCotContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitCot(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction WholeContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tWholeContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tWholeContext.prototype.constructor = WholeContext;\r\n\t\r\n\tCalculatorParser.WholeContext = WholeContext;\r\n\t\r\n\tWholeContext.prototype.expression = function(i) {\r\n\t    if(i===undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if(i===null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    } else {\r\n\t        return this.getTypedRuleContext(ExpressionContext,i);\r\n\t    }\r\n\t};\r\n\t\r\n\tWholeContext.prototype.WHOLE = function() {\r\n\t    return this.getToken(CalculatorParser.WHOLE, 0);\r\n\t};\r\n\tWholeContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitWhole(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction UnaryContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tUnaryContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tUnaryContext.prototype.constructor = UnaryContext;\r\n\t\r\n\tCalculatorParser.UnaryContext = UnaryContext;\r\n\t\r\n\tUnaryContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tUnaryContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitUnary(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction RadContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tRadContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tRadContext.prototype.constructor = RadContext;\r\n\t\r\n\tCalculatorParser.RadContext = RadContext;\r\n\t\r\n\tRadContext.prototype.RAD = function() {\r\n\t    return this.getToken(CalculatorParser.RAD, 0);\r\n\t};\r\n\t\r\n\tRadContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tRadContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitRad(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction SqrContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tSqrContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tSqrContext.prototype.constructor = SqrContext;\r\n\t\r\n\tCalculatorParser.SqrContext = SqrContext;\r\n\t\r\n\tSqrContext.prototype.SQR = function() {\r\n\t    return this.getToken(CalculatorParser.SQR, 0);\r\n\t};\r\n\t\r\n\tSqrContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tSqrContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitSqr(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction SinContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tSinContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tSinContext.prototype.constructor = SinContext;\r\n\t\r\n\tCalculatorParser.SinContext = SinContext;\r\n\t\r\n\tSinContext.prototype.SIN = function() {\r\n\t    return this.getToken(CalculatorParser.SIN, 0);\r\n\t};\r\n\t\r\n\tSinContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tSinContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitSin(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction EexContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tEexContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tEexContext.prototype.constructor = EexContext;\r\n\t\r\n\tCalculatorParser.EexContext = EexContext;\r\n\t\r\n\tEexContext.prototype.EEX = function() {\r\n\t    return this.getToken(CalculatorParser.EEX, 0);\r\n\t};\r\n\t\r\n\tEexContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tEexContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitEex(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction PowContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    this.op = null; // Token;\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tPowContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tPowContext.prototype.constructor = PowContext;\r\n\t\r\n\tCalculatorParser.PowContext = PowContext;\r\n\t\r\n\tPowContext.prototype.expression = function(i) {\r\n\t    if(i===undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if(i===null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    } else {\r\n\t        return this.getTypedRuleContext(ExpressionContext,i);\r\n\t    }\r\n\t};\r\n\tPowContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitPow(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction CeilContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tCeilContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tCeilContext.prototype.constructor = CeilContext;\r\n\t\r\n\tCalculatorParser.CeilContext = CeilContext;\r\n\t\r\n\tCeilContext.prototype.CEIL = function() {\r\n\t    return this.getToken(CalculatorParser.CEIL, 0);\r\n\t};\r\n\t\r\n\tCeilContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tCeilContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitCeil(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction ExpContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tExpContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tExpContext.prototype.constructor = ExpContext;\r\n\t\r\n\tCalculatorParser.ExpContext = ExpContext;\r\n\t\r\n\tExpContext.prototype.EXP = function() {\r\n\t    return this.getToken(CalculatorParser.EXP, 0);\r\n\t};\r\n\t\r\n\tExpContext.prototype.expression = function() {\r\n\t    return this.getTypedRuleContext(ExpressionContext,0);\r\n\t};\r\n\tExpContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitExp(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\tfunction RoundkContext(parser, ctx) {\r\n\t\tExpressionContext.call(this, parser);\r\n\t    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n\t    return this;\r\n\t}\r\n\t\r\n\tRoundkContext.prototype = Object.create(ExpressionContext.prototype);\r\n\tRoundkContext.prototype.constructor = RoundkContext;\r\n\t\r\n\tCalculatorParser.RoundkContext = RoundkContext;\r\n\t\r\n\tRoundkContext.prototype.ROUNDK = function() {\r\n\t    return this.getToken(CalculatorParser.ROUNDK, 0);\r\n\t};\r\n\t\r\n\tRoundkContext.prototype.expression = function(i) {\r\n\t    if(i===undefined) {\r\n\t        i = null;\r\n\t    }\r\n\t    if(i===null) {\r\n\t        return this.getTypedRuleContexts(ExpressionContext);\r\n\t    } else {\r\n\t        return this.getTypedRuleContext(ExpressionContext,i);\r\n\t    }\r\n\t};\r\n\tRoundkContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitRoundk(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\t\r\n\tCalculatorParser.prototype.expression = function(_p) {\r\n\t\tif(_p===undefined) {\r\n\t\t    _p = 0;\r\n\t\t}\r\n\t    var _parentctx = this._ctx;\r\n\t    var _parentState = this.state;\r\n\t    var localctx = new ExpressionContext(this, this._ctx, _parentState);\r\n\t    var _prevctx = localctx;\r\n\t    var _startState = 2;\r\n\t    this.enterRecursionRule(localctx, 2, CalculatorParser.RULE_expression, _p);\r\n\t    var _la = 0; // Token type\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 87;\r\n\t        switch(this._input.LA(1)) {\r\n\t        case CalculatorParser.FLOOR:\r\n\t            localctx = new FloorContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t\r\n\t            this.state = 11;\r\n\t            this.match(CalculatorParser.FLOOR);\r\n\t            this.state = 12;\r\n\t            this.expression(40);\r\n\t            break;\r\n\t        case CalculatorParser.CEIL:\r\n\t            localctx = new CeilContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 13;\r\n\t            this.match(CalculatorParser.CEIL);\r\n\t            this.state = 14;\r\n\t            this.expression(39);\r\n\t            break;\r\n\t        case CalculatorParser.ABS:\r\n\t            localctx = new AbsContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 15;\r\n\t            this.match(CalculatorParser.ABS);\r\n\t            this.state = 16;\r\n\t            this.expression(38);\r\n\t            break;\r\n\t        case CalculatorParser.ROUND:\r\n\t            localctx = new RoundContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 17;\r\n\t            this.match(CalculatorParser.ROUND);\r\n\t            this.state = 18;\r\n\t            this.expression(36);\r\n\t            break;\r\n\t        case CalculatorParser.TRUNC:\r\n\t            localctx = new TruncContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 19;\r\n\t            this.match(CalculatorParser.TRUNC);\r\n\t            this.state = 20;\r\n\t            this.expression(35);\r\n\t            break;\r\n\t        case CalculatorParser.SIN:\r\n\t            localctx = new SinContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 21;\r\n\t            this.match(CalculatorParser.SIN);\r\n\t            this.state = 22;\r\n\t            this.expression(34);\r\n\t            break;\r\n\t        case CalculatorParser.COS:\r\n\t            localctx = new CosContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 23;\r\n\t            this.match(CalculatorParser.COS);\r\n\t            this.state = 24;\r\n\t            this.expression(33);\r\n\t            break;\r\n\t        case CalculatorParser.TAN:\r\n\t            localctx = new TanContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 25;\r\n\t            this.match(CalculatorParser.TAN);\r\n\t            this.state = 26;\r\n\t            this.expression(32);\r\n\t            break;\r\n\t        case CalculatorParser.COT:\r\n\t            localctx = new CotContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 27;\r\n\t            this.match(CalculatorParser.COT);\r\n\t            this.state = 28;\r\n\t            this.expression(31);\r\n\t            break;\r\n\t        case CalculatorParser.SINH:\r\n\t            localctx = new SinhContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 29;\r\n\t            this.match(CalculatorParser.SINH);\r\n\t            this.state = 30;\r\n\t            this.expression(30);\r\n\t            break;\r\n\t        case CalculatorParser.COSH:\r\n\t            localctx = new CoshContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 31;\r\n\t            this.match(CalculatorParser.COSH);\r\n\t            this.state = 32;\r\n\t            this.expression(29);\r\n\t            break;\r\n\t        case CalculatorParser.TANH:\r\n\t            localctx = new TanhContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 33;\r\n\t            this.match(CalculatorParser.TANH);\r\n\t            this.state = 34;\r\n\t            this.expression(28);\r\n\t            break;\r\n\t        case CalculatorParser.ARCSIN:\r\n\t            localctx = new ArcsinContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 35;\r\n\t            this.match(CalculatorParser.ARCSIN);\r\n\t            this.state = 36;\r\n\t            this.expression(27);\r\n\t            break;\r\n\t        case CalculatorParser.ARCCOS:\r\n\t            localctx = new ArccosContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 37;\r\n\t            this.match(CalculatorParser.ARCCOS);\r\n\t            this.state = 38;\r\n\t            this.expression(26);\r\n\t            break;\r\n\t        case CalculatorParser.ARCTAN:\r\n\t            localctx = new ArctanContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 39;\r\n\t            this.match(CalculatorParser.ARCTAN);\r\n\t            this.state = 40;\r\n\t            this.expression(25);\r\n\t            break;\r\n\t        case CalculatorParser.ARCCOT:\r\n\t            localctx = new ArccotContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 41;\r\n\t            this.match(CalculatorParser.ARCCOT);\r\n\t            this.state = 42;\r\n\t            this.expression(23);\r\n\t            break;\r\n\t        case CalculatorParser.EXP:\r\n\t            localctx = new ExpContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 43;\r\n\t            this.match(CalculatorParser.EXP);\r\n\t            this.state = 44;\r\n\t            this.expression(22);\r\n\t            break;\r\n\t        case CalculatorParser.LN:\r\n\t            localctx = new LnContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 45;\r\n\t            this.match(CalculatorParser.LN);\r\n\t            this.state = 46;\r\n\t            this.expression(21);\r\n\t            break;\r\n\t        case CalculatorParser.EEX:\r\n\t            localctx = new EexContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 47;\r\n\t            this.match(CalculatorParser.EEX);\r\n\t            this.state = 48;\r\n\t            this.expression(20);\r\n\t            break;\r\n\t        case CalculatorParser.LOG:\r\n\t            localctx = new LogContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 49;\r\n\t            this.match(CalculatorParser.LOG);\r\n\t            this.state = 50;\r\n\t            this.expression(19);\r\n\t            break;\r\n\t        case CalculatorParser.RAD:\r\n\t            localctx = new RadContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 51;\r\n\t            this.match(CalculatorParser.RAD);\r\n\t            this.state = 52;\r\n\t            this.expression(18);\r\n\t            break;\r\n\t        case CalculatorParser.DEG:\r\n\t            localctx = new DegContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 53;\r\n\t            this.match(CalculatorParser.DEG);\r\n\t            this.state = 54;\r\n\t            this.expression(17);\r\n\t            break;\r\n\t        case CalculatorParser.SQRT:\r\n\t            localctx = new SqrtContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 55;\r\n\t            this.match(CalculatorParser.SQRT);\r\n\t            this.state = 56;\r\n\t            this.expression(16);\r\n\t            break;\r\n\t        case CalculatorParser.SQR:\r\n\t            localctx = new SqrContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 57;\r\n\t            this.match(CalculatorParser.SQR);\r\n\t            this.state = 58;\r\n\t            this.expression(15);\r\n\t            break;\r\n\t        case CalculatorParser.SUB:\r\n\t            localctx = new UnaryContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 59;\r\n\t            this.match(CalculatorParser.SUB);\r\n\t            this.state = 60;\r\n\t            this.expression(2);\r\n\t            break;\r\n\t        case CalculatorParser.ADD:\r\n\t            localctx = new UnaryPlusContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 61;\r\n\t            this.match(CalculatorParser.ADD);\r\n\t            this.state = 62;\r\n\t            this.expression(1);\r\n\t            break;\r\n\t        case CalculatorParser.ROUNDK:\r\n\t            localctx = new RoundkContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 63;\r\n\t            this.match(CalculatorParser.ROUNDK);\r\n\t            this.state = 64;\r\n\t            this.match(CalculatorParser.T__0);\r\n\t            this.state = 65;\r\n\t            this.expression(0);\r\n\t            this.state = 66;\r\n\t            this.match(CalculatorParser.T__1);\r\n\t            this.state = 67;\r\n\t            this.expression(0);\r\n\t            this.state = 68;\r\n\t            this.match(CalculatorParser.T__2);\r\n\t            break;\r\n\t        case CalculatorParser.ARCTAN2:\r\n\t            localctx = new Arctan2Context(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 70;\r\n\t            this.match(CalculatorParser.ARCTAN2);\r\n\t            this.state = 71;\r\n\t            this.match(CalculatorParser.T__0);\r\n\t            this.state = 72;\r\n\t            this.expression(0);\r\n\t            this.state = 73;\r\n\t            this.match(CalculatorParser.T__1);\r\n\t            this.state = 74;\r\n\t            this.expression(0);\r\n\t            this.state = 75;\r\n\t            this.match(CalculatorParser.T__2);\r\n\t            break;\r\n\t        case CalculatorParser.NUMBER:\r\n\t            localctx = new NumberContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 77;\r\n\t            this.match(CalculatorParser.NUMBER);\r\n\t            break;\r\n\t        case CalculatorParser.T__0:\r\n\t            localctx = new ParenthesisContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 78;\r\n\t            this.match(CalculatorParser.T__0);\r\n\t            this.state = 79;\r\n\t            this.expression(0);\r\n\t            this.state = 80;\r\n\t            this.match(CalculatorParser.T__2);\r\n\t            break;\r\n\t        case CalculatorParser.PI:\r\n\t            localctx = new PiContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 82;\r\n\t            this.match(CalculatorParser.PI);\r\n\t            this.state = 84;\r\n\t            this._errHandler.sync(this);\r\n\t            var la_ = this._interp.adaptivePredict(this._input,1,this._ctx);\r\n\t            if(la_===1) {\r\n\t                this.state = 83;\r\n\t                this.match(CalculatorParser.T__8);\r\n\t\r\n\t            }\r\n\t            break;\r\n\t        case CalculatorParser.EULER:\r\n\t            localctx = new EulerContext(this, localctx);\r\n\t            this._ctx = localctx;\r\n\t            _prevctx = localctx;\r\n\t            this.state = 86;\r\n\t            this.match(CalculatorParser.EULER);\r\n\t            break;\r\n\t        default:\r\n\t            throw new antlr4.error.NoViableAltException(this);\r\n\t        }\r\n\t        this._ctx.stop = this._input.LT(-1);\r\n\t        this.state = 115;\r\n\t        this._errHandler.sync(this);\r\n\t        var _alt = this._interp.adaptivePredict(this._input,4,this._ctx)\r\n\t        while(_alt!=2 && _alt!=antlr4.atn.ATN.INVALID_ALT_NUMBER) {\r\n\t            if(_alt===1) {\r\n\t                if(this._parseListeners!==null) {\r\n\t                    this.triggerExitRuleEvent();\r\n\t                }\r\n\t                _prevctx = localctx;\r\n\t                this.state = 113;\r\n\t                this._errHandler.sync(this);\r\n\t                var la_ = this._interp.adaptivePredict(this._input,3,this._ctx);\r\n\t                switch(la_) {\r\n\t                case 1:\r\n\t                    localctx = new PowContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n\t                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n\t                    this.state = 89;\r\n\t                    if (!( this.precpred(this._ctx, 14))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 14)\");\r\n\t                    }\r\n\t                    this.state = 90;\r\n\t                    localctx.op = this._input.LT(1);\r\n\t                    _la = this._input.LA(1);\r\n\t                    if(!(_la===CalculatorParser.T__3 || _la===CalculatorParser.T__4)) {\r\n\t                        localctx.op = this._errHandler.recoverInline(this);\r\n\t                    }\r\n\t                    else {\r\n\t                        this.consume();\r\n\t                    }\r\n\t                    this.state = 91;\r\n\t                    this.expression(15);\r\n\t                    break;\r\n\t\r\n\t                case 2:\r\n\t                    localctx = new ModContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n\t                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n\t                    this.state = 92;\r\n\t                    if (!( this.precpred(this._ctx, 13))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 13)\");\r\n\t                    }\r\n\t                    this.state = 93;\r\n\t                    _la = this._input.LA(1);\r\n\t                    if(!(_la===CalculatorParser.T__5 || _la===CalculatorParser.MOD)) {\r\n\t                    this._errHandler.recoverInline(this);\r\n\t                    }\r\n\t                    else {\r\n\t                        this.consume();\r\n\t                    }\r\n\t                    this.state = 94;\r\n\t                    this.expression(14);\r\n\t                    break;\r\n\t\r\n\t                case 3:\r\n\t                    localctx = new WholeContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n\t                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n\t                    this.state = 95;\r\n\t                    if (!( this.precpred(this._ctx, 12))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 12)\");\r\n\t                    }\r\n\t                    this.state = 96;\r\n\t                    this.match(CalculatorParser.WHOLE);\r\n\t                    this.state = 97;\r\n\t                    this.expression(13);\r\n\t                    break;\r\n\t\r\n\t                case 4:\r\n\t                    localctx = new SqRootContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n\t                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n\t                    this.state = 98;\r\n\t                    if (!( this.precpred(this._ctx, 11))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 11)\");\r\n\t                    }\r\n\t                    this.state = 99;\r\n\t                    localctx.op = this._input.LT(1);\r\n\t                    _la = this._input.LA(1);\r\n\t                    if(!(_la===CalculatorParser.T__6 || _la===CalculatorParser.T__7)) {\r\n\t                        localctx.op = this._errHandler.recoverInline(this);\r\n\t                    }\r\n\t                    else {\r\n\t                        this.consume();\r\n\t                    }\r\n\t                    this.state = 100;\r\n\t                    this.expression(12);\r\n\t                    break;\r\n\t\r\n\t                case 5:\r\n\t                    localctx = new MulDivContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n\t                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n\t                    this.state = 101;\r\n\t                    if (!( this.precpred(this._ctx, 10))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 10)\");\r\n\t                    }\r\n\t                    this.state = 102;\r\n\t                    localctx.op = this._input.LT(1);\r\n\t                    _la = this._input.LA(1);\r\n\t                    if(!(_la===CalculatorParser.MUL || _la===CalculatorParser.DIV)) {\r\n\t                        localctx.op = this._errHandler.recoverInline(this);\r\n\t                    }\r\n\t                    else {\r\n\t                        this.consume();\r\n\t                    }\r\n\t                    this.state = 103;\r\n\t                    this.expression(11);\r\n\t                    break;\r\n\t\r\n\t                case 6:\r\n\t                    localctx = new AddSubContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n\t                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n\t                    this.state = 104;\r\n\t                    if (!( this.precpred(this._ctx, 9))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 9)\");\r\n\t                    }\r\n\t                    this.state = 105;\r\n\t                    localctx.op = this._input.LT(1);\r\n\t                    _la = this._input.LA(1);\r\n\t                    if(!(_la===CalculatorParser.ADD || _la===CalculatorParser.SUB)) {\r\n\t                        localctx.op = this._errHandler.recoverInline(this);\r\n\t                    }\r\n\t                    else {\r\n\t                        this.consume();\r\n\t                    }\r\n\t                    this.state = 106;\r\n\t                    this.expression(10);\r\n\t                    break;\r\n\t\r\n\t                case 7:\r\n\t                    localctx = new ExponentContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n\t                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n\t                    this.state = 107;\r\n\t                    if (!( this.precpred(this._ctx, 5))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 5)\");\r\n\t                    }\r\n\t                    this.state = 108;\r\n\t                    this.match(CalculatorParser.EXPONENT);\r\n\t                    this.state = 109;\r\n\t                    this.expression(6);\r\n\t                    break;\r\n\t\r\n\t                case 8:\r\n\t                    localctx = new NegExponentContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n\t                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n\t                    this.state = 110;\r\n\t                    if (!( this.precpred(this._ctx, 4))) {\r\n\t                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 4)\");\r\n\t                    }\r\n\t                    this.state = 111;\r\n\t                    this.match(CalculatorParser.NEGEXPONENT);\r\n\t                    this.state = 112;\r\n\t                    this.expression(5);\r\n\t                    break;\r\n\t\r\n\t                } \r\n\t            }\r\n\t            this.state = 117;\r\n\t            this._errHandler.sync(this);\r\n\t            _alt = this._interp.adaptivePredict(this._input,4,this._ctx);\r\n\t        }\r\n\t\r\n\t    } catch( error) {\r\n\t        if(error instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = error;\r\n\t\t        this._errHandler.reportError(this, error);\r\n\t\t        this._errHandler.recover(this, error);\r\n\t\t    } else {\r\n\t\t    \tthrow error;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.unrollRecursionContexts(_parentctx)\r\n\t    }\r\n\t    return localctx;\r\n\t};\r\n\t\r\n\tfunction CompileUnitContext(parser, parent, invokingState) {\r\n\t\tif(parent===undefined) {\r\n\t\t    parent = null;\r\n\t\t}\r\n\t\tif(invokingState===undefined || invokingState===null) {\r\n\t\t\tinvokingState = -1;\r\n\t\t}\r\n\t\tantlr4.ParserRuleContext.call(this, parent, invokingState);\r\n\t    this.parser = parser;\r\n\t    this.ruleIndex = CalculatorParser.RULE_compileUnit;\r\n\t    return this;\r\n\t}\r\n\t\r\n\tCompileUnitContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\r\n\tCompileUnitContext.prototype.constructor = CompileUnitContext;\r\n\t\r\n\tCompileUnitContext.prototype.EOF = function() {\r\n\t    return this.getToken(CalculatorParser.EOF, 0);\r\n\t};\r\n\t\r\n\tCompileUnitContext.prototype.accept = function(visitor) {\r\n\t    if ( visitor instanceof CalculatorVisitor ) {\r\n\t        return visitor.visitCompileUnit(this);\r\n\t    } else {\r\n\t        return visitor.visitChildren(this);\r\n\t    }\r\n\t};\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tCalculatorParser.CompileUnitContext = CompileUnitContext;\r\n\t\r\n\tCalculatorParser.prototype.compileUnit = function() {\r\n\t\r\n\t    var localctx = new CompileUnitContext(this, this._ctx, this.state);\r\n\t    this.enterRule(localctx, 4, CalculatorParser.RULE_compileUnit);\r\n\t    try {\r\n\t        this.enterOuterAlt(localctx, 1);\r\n\t        this.state = 118;\r\n\t        this.match(CalculatorParser.EOF);\r\n\t    } catch (re) {\r\n\t    \tif(re instanceof antlr4.error.RecognitionException) {\r\n\t\t        localctx.exception = re;\r\n\t\t        this._errHandler.reportError(this, re);\r\n\t\t        this._errHandler.recover(this, re);\r\n\t\t    } else {\r\n\t\t    \tthrow re;\r\n\t\t    }\r\n\t    } finally {\r\n\t        this.exitRule();\r\n\t    }\r\n\t    return localctx;\r\n\t};\r\n\t\r\n\t\r\n\tCalculatorParser.prototype.sempred = function(localctx, ruleIndex, predIndex) {\r\n\t\tswitch(ruleIndex) {\r\n\t\tcase 1:\r\n\t\t\t\treturn this.expression_sempred(localctx, predIndex);\r\n\t    default:\r\n\t        throw \"No predicate with index:\" + ruleIndex;\r\n\t   }\r\n\t};\r\n\t\r\n\tCalculatorParser.prototype.expression_sempred = function(localctx, predIndex) {\r\n\t\tswitch(predIndex) {\r\n\t\t\tcase 0:\r\n\t\t\t\treturn this.precpred(this._ctx, 14);\r\n\t\t\tcase 1:\r\n\t\t\t\treturn this.precpred(this._ctx, 13);\r\n\t\t\tcase 2:\r\n\t\t\t\treturn this.precpred(this._ctx, 12);\r\n\t\t\tcase 3:\r\n\t\t\t\treturn this.precpred(this._ctx, 11);\r\n\t\t\tcase 4:\r\n\t\t\t\treturn this.precpred(this._ctx, 10);\r\n\t\t\tcase 5:\r\n\t\t\t\treturn this.precpred(this._ctx, 9);\r\n\t\t\tcase 6:\r\n\t\t\t\treturn this.precpred(this._ctx, 5);\r\n\t\t\tcase 7:\r\n\t\t\t\treturn this.precpred(this._ctx, 4);\r\n\t\t\tdefault:\r\n\t\t\t\tthrow \"No predicate with index:\" + predIndex;\r\n\t\t}\r\n\t};\r\n\t\r\n\t\r\n\texports.CalculatorParser = CalculatorParser;\r\n\n\n/***/ },\n/* 50 */\n/***/ function(module, exports, __webpack_require__) {\n\n\t// Generated from Calculator.g4 by ANTLR 4.5.2\r\n\t// jshint ignore: start\r\n\tvar antlr4 = __webpack_require__(4);\r\n\t\r\n\t// This class defines a complete generic visitor for a parse tree produced by CalculatorParser.\r\n\t\r\n\tfunction CalculatorVisitor() {\r\n\t\tantlr4.tree.ParseTreeVisitor.call(this);\r\n\t\treturn this;\r\n\t}\r\n\t\r\n\tCalculatorVisitor.prototype = Object.create(antlr4.tree.ParseTreeVisitor.prototype);\r\n\tCalculatorVisitor.prototype.constructor = CalculatorVisitor;\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#calculator.\r\n\tCalculatorVisitor.prototype.visitCalculator = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Tan.\r\n\tCalculatorVisitor.prototype.visitTan = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Cosh.\r\n\tCalculatorVisitor.prototype.visitCosh = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#SqRoot.\r\n\tCalculatorVisitor.prototype.visitSqRoot = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#NegExponent.\r\n\tCalculatorVisitor.prototype.visitNegExponent = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Exponent.\r\n\tCalculatorVisitor.prototype.visitExponent = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Arctan2.\r\n\tCalculatorVisitor.prototype.visitArctan2 = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#MulDiv.\r\n\tCalculatorVisitor.prototype.visitMulDiv = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Arcsin.\r\n\tCalculatorVisitor.prototype.visitArcsin = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#UnaryPlus.\r\n\tCalculatorVisitor.prototype.visitUnaryPlus = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Arccot.\r\n\tCalculatorVisitor.prototype.visitArccot = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Arccos.\r\n\tCalculatorVisitor.prototype.visitArccos = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Euler.\r\n\tCalculatorVisitor.prototype.visitEuler = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Arctan.\r\n\tCalculatorVisitor.prototype.visitArctan = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Parenthesis.\r\n\tCalculatorVisitor.prototype.visitParenthesis = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Abs.\r\n\tCalculatorVisitor.prototype.visitAbs = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Number.\r\n\tCalculatorVisitor.prototype.visitNumber = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Sinh.\r\n\tCalculatorVisitor.prototype.visitSinh = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Round.\r\n\tCalculatorVisitor.prototype.visitRound = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Trunc.\r\n\tCalculatorVisitor.prototype.visitTrunc = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Pi.\r\n\tCalculatorVisitor.prototype.visitPi = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Tanh.\r\n\tCalculatorVisitor.prototype.visitTanh = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Floor.\r\n\tCalculatorVisitor.prototype.visitFloor = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Ln.\r\n\tCalculatorVisitor.prototype.visitLn = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Mod.\r\n\tCalculatorVisitor.prototype.visitMod = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Log.\r\n\tCalculatorVisitor.prototype.visitLog = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#AddSub.\r\n\tCalculatorVisitor.prototype.visitAddSub = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Cos.\r\n\tCalculatorVisitor.prototype.visitCos = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Deg.\r\n\tCalculatorVisitor.prototype.visitDeg = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Sqrt.\r\n\tCalculatorVisitor.prototype.visitSqrt = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Cot.\r\n\tCalculatorVisitor.prototype.visitCot = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Whole.\r\n\tCalculatorVisitor.prototype.visitWhole = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Unary.\r\n\tCalculatorVisitor.prototype.visitUnary = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Rad.\r\n\tCalculatorVisitor.prototype.visitRad = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Sqr.\r\n\tCalculatorVisitor.prototype.visitSqr = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Sin.\r\n\tCalculatorVisitor.prototype.visitSin = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Eex.\r\n\tCalculatorVisitor.prototype.visitEex = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Pow.\r\n\tCalculatorVisitor.prototype.visitPow = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Ceil.\r\n\tCalculatorVisitor.prototype.visitCeil = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Exp.\r\n\tCalculatorVisitor.prototype.visitExp = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#Roundk.\r\n\tCalculatorVisitor.prototype.visitRoundk = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t// Visit a parse tree produced by CalculatorParser#compileUnit.\r\n\tCalculatorVisitor.prototype.visitCompileUnit = function(ctx) {\r\n\t};\r\n\t\r\n\t\r\n\t\r\n\texports.CalculatorVisitor = CalculatorVisitor;\n\n/***/ },\n/* 51 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__, exports], __WEBPACK_AMD_DEFINE_RESULT__ = function (require, exports) {\r\n\t    \"use strict\";\r\n\t    var CalculationResult = (function () {\r\n\t        function CalculationResult() {\r\n\t            this.isValid = false;\r\n\t            this.errorPosition = null;\r\n\t            this.errorMessage = null;\r\n\t            this.result = NaN;\r\n\t        }\r\n\t        return CalculationResult;\r\n\t    }());\r\n\t    exports.CalculationResult = CalculationResult;\r\n\t}.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__), __WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\r\n\n\n/***/ },\n/* 52 */\n/***/ function(module, exports, __webpack_require__) {\n\n\tvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__, exports], __WEBPACK_AMD_DEFINE_RESULT__ = function (require, exports) {\r\n\t    \"use strict\";\r\n\t    var FormulaErrorListener = (function () {\r\n\t        function FormulaErrorListener() {\r\n\t            this._isValid = true;\r\n\t            this._errorLocation = null;\r\n\t        }\r\n\t        Object.defineProperty(FormulaErrorListener.prototype, \"isValid\", {\r\n\t            get: function () {\r\n\t                return this._isValid;\r\n\t            },\r\n\t            enumerable: true,\r\n\t            configurable: true\r\n\t        });\r\n\t        Object.defineProperty(FormulaErrorListener.prototype, \"errorLocation\", {\r\n\t            get: function () {\r\n\t                return this._errorLocation;\r\n\t            },\r\n\t            enumerable: true,\r\n\t            configurable: true\r\n\t        });\r\n\t        Object.defineProperty(FormulaErrorListener.prototype, \"errorMessage\", {\r\n\t            get: function () {\r\n\t                return this._errorMessage;\r\n\t            },\r\n\t            enumerable: true,\r\n\t            configurable: true\r\n\t        });\r\n\t        FormulaErrorListener.prototype.syntaxError = function (recognizer, offendingSymbol, line, column, msg, e) {\r\n\t            this._isValid = false;\r\n\t            this._errorLocation = column;\r\n\t            this._errorMessage = msg;\r\n\t        };\r\n\t        /**\r\n\t         * Method stub - does nothing\r\n\t         * @param recognizer\r\n\t         * @param dfa\r\n\t         * @param startIndex\r\n\t         * @param stopIndex\r\n\t         * @param exact\r\n\t         * @param ambigAlts\r\n\t         * @param configs\r\n\t         */\r\n\t        FormulaErrorListener.prototype.reportAmbiguity = function (recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\r\n\t        };\r\n\t        ;\r\n\t        /**\r\n\t         * Method stub - does nothing\r\n\t         * @param recognizer\r\n\t         * @param dfa\r\n\t         * @param startIndex\r\n\t         * @param stopIndex\r\n\t         * @param conflictingAlts\r\n\t         * @param configs\r\n\t         */\r\n\t        FormulaErrorListener.prototype.reportAttemptingFullContext = function (recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\r\n\t        };\r\n\t        ;\r\n\t        /**\r\n\t         * Method stub - does nothing\r\n\t         * @param recognizer\r\n\t         * @param dfa\r\n\t         * @param startIndex\r\n\t         * @param stopIndex\r\n\t         * @param prediction\r\n\t         * @param configs\r\n\t         */\r\n\t        FormulaErrorListener.prototype.reportContextSensitivity = function (recognizer, dfa, startIndex, stopIndex, prediction, configs) {\r\n\t        };\r\n\t        ;\r\n\t        return FormulaErrorListener;\r\n\t    }());\r\n\t    exports.FormulaErrorListener = FormulaErrorListener;\r\n\t}.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__), __WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\r\n\n\n/***/ }\n/******/ ]);\n\n\n/** WEBPACK FOOTER **\n ** dist/bundle.js\n **/"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId])\n \t\t\treturn installedModules[moduleId].exports;\n\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\texports: {},\n \t\t\tid: moduleId,\n \t\t\tloaded: false\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.loaded = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(0);\n\n\n\n/** WEBPACK FOOTER **\n ** webpack/bootstrap 942a5966cbc125448730\n **/","import { FormulaVisitor } from './FormulaVisitor';\r\nimport { CalculationResult } from './CalculationResult';\r\nimport { FormulaErrorListener } from './FormulaErrorListener';\r\n\r\nimport { BaseError } from 'make-error-cause';\r\n\r\nimport { InputStream, CommonTokenStream } from 'antlr4';\r\n\r\nimport { CalculatorLexer, CalculatorParser } from './GeneratedAntlr';\r\n\r\nexport class Calculator {\r\n    public static calculate(formula: string): CalculationResult {\r\n        var result = new CalculationResult();\r\n        if (formula === null || formula.match(/^\\s*$/) !== null) {\r\n            result.result = 0;\r\n            result.isValid = true;\r\n            return result;\r\n        }\r\n        var inputStream = new InputStream(formula);\r\n        var lexer = new CalculatorLexer(inputStream);\r\n        var commonTokenStream = new CommonTokenStream(lexer);\r\n        var parser = new CalculatorParser(commonTokenStream);\r\n        var errorListener = new FormulaErrorListener();\r\n        parser._listeners = [errorListener];\r\n        var visitor = new FormulaVisitor();\r\n        var parseTree = parser.calculator();\r\n        if (errorListener.isValid) {\r\n            var visitorResult = visitor.visitCalculator(parseTree);\r\n            if (isNaN(visitorResult)) {\r\n                result.isValid = false;\r\n                result.result = NaN;\r\n            } else {\r\n                result.isValid = true;\r\n                result.result = visitorResult;\r\n            }\r\n            return result;\r\n        }\r\n        result.isValid = false;\r\n        result.errorPosition = errorListener.errorLocation;\r\n        result.errorMessage = errorListener.errorMessage;\r\n        result.result = NaN;\r\n        return result;\r\n    }\r\n}\n\n\n/** WEBPACK FOOTER **\n ** ./Calculator.ts\n **/","import { tree } from 'antlr4';\r\nimport { CalculatorVisitor } from './GeneratedAntlr'\r\n\r\n// This class defines a complete visitor for a parse tree produced by the CalculatorParser.\r\nexport class FormulaVisitor extends CalculatorVisitor {\r\n\r\n    // Visit a parse tree produced by calculatorParser#calculator.\r\n    public visitCalculator(context): number {\r\n        return context.expression(0).accept(this);\r\n    };\r\n\r\n    public visitExpression(context): number {\r\n        return context.accept(this);\r\n    };\r\n\r\n    // Visit a parse tree produced by calculatorParser#Tan.\r\n    public visitTan(context): number {\r\n        return Math.tan(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Cosh.\r\n    public visitCosh(context): number {\r\n        return Math.cosh(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#SqRoot.\r\n    public visitSqRoot(context): number {\r\n        var nthRoot = this.visitExpression(context.expression(0));\r\n        if (nthRoot === 0) {\r\n            return NaN;\r\n        }\r\n        return Math.pow(this.visitExpression(context.expression(1)), 1 / nthRoot);\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#NegExponent.\r\n    public visitNegExponent(context): number {\r\n        return this.visitExpression(context.expression(0)) * Math.pow(10, -1 * this.visitExpression(context.expression(1)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Exponent.\r\n    public visitExponent(context): number {\r\n        return this.visitExpression(context.expression(0)) * Math.pow(10, this.visitExpression(context.expression(1)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Arctan2.\r\n    public visitArctan2(context): number {\r\n        return Math.atan2(this.visitExpression(context.expression(0)), this.visitExpression(context.expression(1)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#MulDiv.\r\n    public visitMulDiv(context): number {\r\n        if (context.op.text === '*') {\r\n            return this.visitExpression(context.expression(0)) * this.visitExpression(context.expression(1));\r\n        } else {\r\n            var divisor = this.visitExpression(context.expression(1));\r\n            if (divisor !== 0) {\r\n                return this.visitExpression(context.expression(0)) / divisor;\r\n            }\r\n            return NaN;\r\n        }\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Arcsin.\r\n    public visitArcsin(context): number {\r\n        return Math.asin(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Arccot.\r\n    public visitArccot(context): number {\r\n        return Math.PI * 0.5 - Math.atan(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Arccos.\r\n    public visitArccos(context): number {\r\n        return Math.acos(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Euler.\r\n    public visitEuler(context): number {\r\n        return Math.E;\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Arctan.\r\n    public visitArctan(context): number {\r\n        return Math.atan(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Parenthesis.\r\n    public visitParenthesis(context): number {\r\n        return this.visitExpression(context.expression(0));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Abs.\r\n    public visitAbs(context): number {\r\n        return Math.abs(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Number.\r\n    public visitNumber(context): number {\r\n        return Number(context.getText().replace(',', '.'));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Sinh.\r\n    public visitSinh(context): number {\r\n        return Math.sinh(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Round.\r\n    public visitRound(context): number {\r\n        return Math.round(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Trunc.\r\n    public visitTrunc(context): number {\r\n        return Math.trunc(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Pi.\r\n    public visitPi(context): number {\r\n        return Math.PI;\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Tanh.\r\n    public visitTanh(context): number {\r\n        return Math.tanh(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Floor.\r\n    public visitFloor(context): number {\r\n        return Math.floor(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Ln.\r\n    public visitLn(context): number {\r\n        return Math.log(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Mod.\r\n    public visitMod(context): number {\r\n        return this.visitExpression(context.expression(0)) % this.visitExpression(context.expression(1));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Log.\r\n    public visitLog(context): number {\r\n        return Math.log10(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#AddSub.\r\n    public visitAddSub(context): number {\r\n        return context.op.text === '+'\r\n            ? (this.visitExpression(context.expression(0)) + this.visitExpression(context.expression(1)))\r\n            : (this.visitExpression(context.expression(0)) - this.visitExpression(context.expression(1)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Cos.\r\n    public visitCos(context): number {\r\n        return Math.cos(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Deg.\r\n    public visitDeg(context): number {\r\n        return this.visitExpression(context.expression(0)) * 180 / Math.PI;\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Sqrt.\r\n    public visitSqrt(context): number {\r\n        return Math.sqrt(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Cot.\r\n    public visitCot(context): number {\r\n        return 1 / Math.tan(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Whole.\r\n    public visitWhole(context): number {\r\n        return Math.trunc(this.visitExpression(context.expression(0)) / this.visitExpression(context.expression(1)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Unary.\r\n    public visitUnary(context): number {\r\n        return -1 * this.visitExpression(context.expression(0));\r\n    };\r\n\r\n    // Visit a parse tree produced by calculatorParser#UnaryPlus.\r\n    public visitUnaryPlus(context): number {\r\n        return this.visitExpression(context.expression(0));\r\n    }\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Rad.\r\n    public visitRad(context): number {\r\n        return this.visitExpression(context.expression(0)) * Math.PI / 180;\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Sqr.\r\n    public visitSqr(context): number {\r\n        return this.visitExpression(context.expression(0)) * this.visitExpression(context.expression(0));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Sin.\r\n    public visitSin(context): number {\r\n        return Math.sin(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Eex.\r\n    public visitEex(context): number {\r\n        return Math.pow(10, this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Pow.\r\n    public visitPow(context): number {\r\n        return Math.pow(this.visitExpression(context.expression(0)), this.visitExpression(context.expression(1)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Ceil.\r\n    public visitCeil(context): number {\r\n        return Math.ceil(this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Exp.\r\n    public visitExp(context): number {\r\n        return Math.pow(Math.E, this.visitExpression(context.expression(0)));\r\n    };\r\n\r\n\r\n    // Visit a parse tree produced by calculatorParser#Roundk.\r\n    public visitRoundk(context): number {\r\n        return Math.round(this.visitExpression(context.expression(0)) * Math.pow(10, this.visitExpression(context.expression(1)))) /\r\n            Math.pow(10, this.visitExpression(context.expression(1)));\r\n    };\r\n}\n\n\n/** WEBPACK FOOTER **\n ** ./FormulaVisitor.ts\n **/","exports.CalculatorLexer = require('./CalculatorLexer.js').CalculatorLexer;\r\nexports.CalculatorParser = require('./CalculatorParser.js').CalculatorParser;\r\nexports.CalculatorVisitor = require('./CalculatorVisitor.js').CalculatorVisitor;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./GeneratedAntlr/index.js\n ** module id = 2\n ** module chunks = 0\n **/","// Generated from Calculator.g4 by ANTLR 4.5.2\r\n// jshint ignore: start\r\nvar antlr4 = require('antlr4/index');\r\n\r\n\r\nvar serializedATN = [\"\\u0003\\u0430\\ud6d1\\u8206\\uad2d\\u4417\\uaef1\\u8d80\\uaadd\",\r\n    \"\\u00025\\u0165\\b\\u0001\\u0004\\u0002\\t\\u0002\\u0004\\u0003\\t\\u0003\\u0004\",\r\n    \"\\u0004\\t\\u0004\\u0004\\u0005\\t\\u0005\\u0004\\u0006\\t\\u0006\\u0004\\u0007\\t\",\r\n    \"\\u0007\\u0004\\b\\t\\b\\u0004\\t\\t\\t\\u0004\\n\\t\\n\\u0004\\u000b\\t\\u000b\\u0004\",\r\n    \"\\f\\t\\f\\u0004\\r\\t\\r\\u0004\\u000e\\t\\u000e\\u0004\\u000f\\t\\u000f\\u0004\\u0010\",\r\n    \"\\t\\u0010\\u0004\\u0011\\t\\u0011\\u0004\\u0012\\t\\u0012\\u0004\\u0013\\t\\u0013\",\r\n    \"\\u0004\\u0014\\t\\u0014\\u0004\\u0015\\t\\u0015\\u0004\\u0016\\t\\u0016\\u0004\\u0017\",\r\n    \"\\t\\u0017\\u0004\\u0018\\t\\u0018\\u0004\\u0019\\t\\u0019\\u0004\\u001a\\t\\u001a\",\r\n    \"\\u0004\\u001b\\t\\u001b\\u0004\\u001c\\t\\u001c\\u0004\\u001d\\t\\u001d\\u0004\\u001e\",\r\n    \"\\t\\u001e\\u0004\\u001f\\t\\u001f\\u0004 \\t \\u0004!\\t!\\u0004\\\"\\t\\\"\\u0004#\",\r\n    \"\\t#\\u0004$\\t$\\u0004%\\t%\\u0004&\\t&\\u0004\\'\\t\\'\\u0004(\\t(\\u0004)\\t)\\u0004\",\r\n    \"*\\t*\\u0004+\\t+\\u0004,\\t,\\u0004-\\t-\\u0004.\\t.\\u0004/\\t/\\u00040\\t0\\u0004\",\r\n    \"1\\t1\\u00042\\t2\\u00043\\t3\\u00044\\t4\\u00045\\t5\\u0003\\u0002\\u0003\\u0002\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0004\\u0003\\u0004\\u0003\\u0005\\u0003\\u0005\",\r\n    \"\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0007\\u0003\\u0007\\u0003\\b\",\r\n    \"\\u0003\\b\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\n\\u0003\\n\\u0003\\n\\u0003\\u000b\",\r\n    \"\\u0003\\u000b\\u0006\\u000b\\u0083\\n\\u000b\\r\\u000b\\u000e\\u000b\\u0084\\u0005\",\r\n    \"\\u000b\\u0087\\n\\u000b\\u0003\\f\\u0006\\f\\u008a\\n\\f\\r\\f\\u000e\\f\\u008b\\u0003\",\r\n    \"\\f\\u0003\\f\\u0007\\f\\u0090\\n\\f\\f\\f\\u000e\\f\\u0093\\u000b\\f\\u0003\\f\\u0003\",\r\n    \"\\f\\u0006\\f\\u0097\\n\\f\\r\\f\\u000e\\f\\u0098\\u0005\\f\\u009b\\n\\f\\u0003\\r\\u0003\",\r\n    \"\\r\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000f\\u0003\",\r\n    \"\\u000f\\u0003\\u000f\\u0003\\u000f\\u0003\\u0010\\u0003\\u0010\\u0003\\u0011\\u0003\",\r\n    \"\\u0011\\u0003\\u0012\\u0003\\u0012\\u0003\\u0013\\u0003\\u0013\\u0003\\u0014\\u0003\",\r\n    \"\\u0014\\u0003\\u0014\\u0003\\u0015\\u0003\\u0015\\u0003\\u0015\\u0003\\u0016\\u0003\",\r\n    \"\\u0016\\u0003\\u0016\\u0003\\u0017\\u0003\\u0017\\u0003\\u0018\\u0003\\u0018\\u0003\",\r\n    \"\\u0018\\u0003\\u0018\\u0003\\u0018\\u0003\\u0019\\u0003\\u0019\\u0003\\u0019\\u0003\",\r\n    \"\\u0019\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a\\u0003\\u001a\\u0003\",\r\n    \"\\u001a\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\\u001b\\u0003\",\r\n    \"\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001c\\u0003\\u001d\\u0003\\u001d\\u0003\",\r\n    \"\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001d\\u0003\\u001e\\u0003\",\r\n    \"\\u001e\\u0003\\u001e\\u0003\\u001e\\u0003\\u001e\\u0003\\u001e\\u0003\\u001f\\u0003\",\r\n    \"\\u001f\\u0003\\u001f\\u0003\\u001f\\u0003\\u001f\\u0003\\u001f\\u0003 \\u0003\",\r\n    \" \\u0003 \\u0003 \\u0003!\\u0003!\\u0003!\\u0003!\\u0003\\\"\\u0003\\\"\\u0003\\\"\",\r\n    \"\\u0003\\\"\\u0003#\\u0003#\\u0003#\\u0003#\\u0003$\\u0003$\\u0003$\\u0003$\\u0003\",\r\n    \"$\\u0003%\\u0003%\\u0003%\\u0003%\\u0003%\\u0003&\\u0003&\\u0003&\\u0003&\\u0003\",\r\n    \"&\\u0003\\'\\u0003\\'\\u0003\\'\\u0003\\'\\u0003\\'\\u0003\\'\\u0003\\'\\u0003(\\u0003\",\r\n    \"(\\u0003(\\u0003(\\u0003(\\u0003(\\u0003(\\u0003)\\u0003)\\u0003)\\u0003)\\u0003\",\r\n    \")\\u0003)\\u0003)\\u0003*\\u0003*\\u0003*\\u0003*\\u0003*\\u0003*\\u0003*\\u0003\",\r\n    \"*\\u0003+\\u0003+\\u0003+\\u0003+\\u0003+\\u0003+\\u0003+\\u0003,\\u0003,\\u0003\",\r\n    \",\\u0003,\\u0003-\\u0003-\\u0003-\\u0003.\\u0003.\\u0003.\\u0003.\\u0003/\\u0003\",\r\n    \"/\\u0003/\\u0003/\\u00030\\u00030\\u00030\\u00030\\u00031\\u00031\\u00031\\u0003\",\r\n    \"1\\u00032\\u00032\\u00032\\u00032\\u00033\\u00033\\u00033\\u00033\\u00034\\u0003\",\r\n    \"4\\u00035\\u00035\\u00035\\u00035\\u00075\\u014d\\n5\\f5\\u000e5\\u0150\\u000b\",\r\n    \"5\\u00035\\u00035\\u00035\\u00035\\u00075\\u0156\\n5\\f5\\u000e5\\u0159\\u000b\",\r\n    \"5\\u00035\\u00035\\u00035\\u00075\\u015e\\n5\\f5\\u000e5\\u0161\\u000b5\\u0003\",\r\n    \"5\\u00055\\u0164\\n5\\u0005\\u014e\\u0157\\u015f\\u00026\\u0003\\u0003\\u0005\\u0004\",\r\n    \"\\u0007\\u0005\\t\\u0006\\u000b\\u0007\\r\\b\\u000f\\t\\u0011\\n\\u0013\\u000b\\u0015\",\r\n    \"\\f\\u0017\\r\\u0019\\u000e\\u001b\\u000f\\u001d\\u0010\\u001f\\u0011!\\u0012#\\u0013\",\r\n    \"%\\u0014\\'\\u0015)\\u0016+\\u0017-\\u0018/\\u00191\\u001a3\\u001b5\\u001c7\\u001d\",\r\n    \"9\\u001e;\\u001f= ?!A\\\"C#E$G%I&K\\'M(O)Q*S+U,W-Y.[/]0_1a2c3e4g5i\\u0002\",\r\n    \"\\u0003\\u0002\\u001c\\u0004\\u0002..00\\u0003\\u00022;\\u0004\\u0002OOoo\\u0004\",\r\n    \"\\u0002QQqq\\u0004\\u0002FFff\\u0004\\u0002KKkk\\u0004\\u0002XXxx\\u0004\\u0002\",\r\n    \"RRrr\\u0004\\u0002GGgg\\u0004\\u0002UUuu\\u0004\\u0002SSss\\u0004\\u0002TTt\",\r\n    \"t\\u0004\\u0002VVvv\\u0004\\u0002HHhh\\u0004\\u0002NNnn\\u0004\\u0002EEee\\u0004\",\r\n    \"\\u0002CCcc\\u0004\\u0002DDdd\\u0004\\u0002WWww\\u0004\\u0002PPpp\\u0004\\u0002\",\r\n    \"MMmm\\u0004\\u0002JJjj\\u0003\\u000244\\u0004\\u0002ZZzz\\u0004\\u0002IIii\\u0005\",\r\n    \"\\u0002\\u000b\\f\\u000f\\u000f\\\"\\\"\\u016e\\u0002\\u0003\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0002\\u0005\\u0003\\u0002\\u0002\\u0002\\u0002\\u0007\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0002\\t\\u0003\\u0002\\u0002\\u0002\\u0002\\u000b\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0002\\r\\u0003\\u0002\\u0002\\u0002\\u0002\\u000f\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0002\\u0011\\u0003\\u0002\\u0002\\u0002\\u0002\\u0013\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0002\\u0015\\u0003\\u0002\\u0002\\u0002\\u0002\\u0017\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0002\\u0019\\u0003\\u0002\\u0002\\u0002\\u0002\\u001b\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0002\\u001d\\u0003\\u0002\\u0002\\u0002\\u0002\\u001f\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0002!\\u0003\\u0002\\u0002\\u0002\\u0002#\\u0003\\u0002\\u0002\\u0002\\u0002\",\r\n    \"%\\u0003\\u0002\\u0002\\u0002\\u0002\\'\\u0003\\u0002\\u0002\\u0002\\u0002)\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0002+\\u0003\\u0002\\u0002\\u0002\\u0002-\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u0002/\\u0003\\u0002\\u0002\\u0002\\u00021\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u00023\\u0003\\u0002\\u0002\\u0002\\u00025\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u00027\\u0003\\u0002\\u0002\\u0002\\u00029\\u0003\\u0002\\u0002\\u0002\\u0002\",\r\n    \";\\u0003\\u0002\\u0002\\u0002\\u0002=\\u0003\\u0002\\u0002\\u0002\\u0002?\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0002A\\u0003\\u0002\\u0002\\u0002\\u0002C\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u0002E\\u0003\\u0002\\u0002\\u0002\\u0002G\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u0002I\\u0003\\u0002\\u0002\\u0002\\u0002K\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0002M\\u0003\\u0002\\u0002\\u0002\\u0002O\\u0003\\u0002\\u0002\\u0002\\u0002\",\r\n    \"Q\\u0003\\u0002\\u0002\\u0002\\u0002S\\u0003\\u0002\\u0002\\u0002\\u0002U\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0002W\\u0003\\u0002\\u0002\\u0002\\u0002Y\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u0002[\\u0003\\u0002\\u0002\\u0002\\u0002]\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u0002_\\u0003\\u0002\\u0002\\u0002\\u0002a\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0002c\\u0003\\u0002\\u0002\\u0002\\u0002e\\u0003\\u0002\\u0002\\u0002\\u0002\",\r\n    \"g\\u0003\\u0002\\u0002\\u0002\\u0003k\\u0003\\u0002\\u0002\\u0002\\u0005m\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0007o\\u0003\\u0002\\u0002\\u0002\\tq\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u000bs\\u0003\\u0002\\u0002\\u0002\\rv\\u0003\\u0002\\u0002\\u0002\\u000f\",\r\n    \"x\\u0003\\u0002\\u0002\\u0002\\u0011z\\u0003\\u0002\\u0002\\u0002\\u0013}\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0015\\u0086\\u0003\\u0002\\u0002\\u0002\\u0017\\u009a\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0019\\u009c\\u0003\\u0002\\u0002\\u0002\\u001b\\u009e\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u001d\\u00a2\\u0003\\u0002\\u0002\\u0002\\u001f\\u00a6\\u0003\",\r\n    \"\\u0002\\u0002\\u0002!\\u00a8\\u0003\\u0002\\u0002\\u0002#\\u00aa\\u0003\\u0002\",\r\n    \"\\u0002\\u0002%\\u00ac\\u0003\\u0002\\u0002\\u0002\\'\\u00ae\\u0003\\u0002\\u0002\",\r\n    \"\\u0002)\\u00b1\\u0003\\u0002\\u0002\\u0002+\\u00b4\\u0003\\u0002\\u0002\\u0002\",\r\n    \"-\\u00b7\\u0003\\u0002\\u0002\\u0002/\\u00b9\\u0003\\u0002\\u0002\\u00021\\u00be\",\r\n    \"\\u0003\\u0002\\u0002\\u00023\\u00c2\\u0003\\u0002\\u0002\\u00025\\u00c8\\u0003\",\r\n    \"\\u0002\\u0002\\u00027\\u00cd\\u0003\\u0002\\u0002\\u00029\\u00d1\\u0003\\u0002\",\r\n    \"\\u0002\\u0002;\\u00d8\\u0003\\u0002\\u0002\\u0002=\\u00de\\u0003\\u0002\\u0002\",\r\n    \"\\u0002?\\u00e4\\u0003\\u0002\\u0002\\u0002A\\u00e8\\u0003\\u0002\\u0002\\u0002\",\r\n    \"C\\u00ec\\u0003\\u0002\\u0002\\u0002E\\u00f0\\u0003\\u0002\\u0002\\u0002G\\u00f4\",\r\n    \"\\u0003\\u0002\\u0002\\u0002I\\u00f9\\u0003\\u0002\\u0002\\u0002K\\u00fe\\u0003\",\r\n    \"\\u0002\\u0002\\u0002M\\u0103\\u0003\\u0002\\u0002\\u0002O\\u010a\\u0003\\u0002\",\r\n    \"\\u0002\\u0002Q\\u0111\\u0003\\u0002\\u0002\\u0002S\\u0118\\u0003\\u0002\\u0002\",\r\n    \"\\u0002U\\u0120\\u0003\\u0002\\u0002\\u0002W\\u0127\\u0003\\u0002\\u0002\\u0002\",\r\n    \"Y\\u012b\\u0003\\u0002\\u0002\\u0002[\\u012e\\u0003\\u0002\\u0002\\u0002]\\u0132\",\r\n    \"\\u0003\\u0002\\u0002\\u0002_\\u0136\\u0003\\u0002\\u0002\\u0002a\\u013a\\u0003\",\r\n    \"\\u0002\\u0002\\u0002c\\u013e\\u0003\\u0002\\u0002\\u0002e\\u0142\\u0003\\u0002\",\r\n    \"\\u0002\\u0002g\\u0146\\u0003\\u0002\\u0002\\u0002i\\u0163\\u0003\\u0002\\u0002\",\r\n    \"\\u0002kl\\u0007*\\u0002\\u0002l\\u0004\\u0003\\u0002\\u0002\\u0002mn\\u0007=\",\r\n    \"\\u0002\\u0002n\\u0006\\u0003\\u0002\\u0002\\u0002op\\u0007+\\u0002\\u0002p\\b\",\r\n    \"\\u0003\\u0002\\u0002\\u0002qr\\u0007`\\u0002\\u0002r\\n\\u0003\\u0002\\u0002\\u0002\",\r\n    \"st\\u0007,\\u0002\\u0002tu\\u0007,\\u0002\\u0002u\\f\\u0003\\u0002\\u0002\\u0002\",\r\n    \"vw\\u0007\\'\\u0002\\u0002w\\u000e\\u0003\\u0002\\u0002\\u0002xy\\u0007\\u0080\",\r\n    \"\\u0002\\u0002y\\u0010\\u0003\\u0002\\u0002\\u0002z{\\u00071\\u0002\\u0002{|\\u0007\",\r\n    \"1\\u0002\\u0002|\\u0012\\u0003\\u0002\\u0002\\u0002}~\\u0007*\\u0002\\u0002~\\u007f\",\r\n    \"\\u0007+\\u0002\\u0002\\u007f\\u0014\\u0003\\u0002\\u0002\\u0002\\u0080\\u0087\",\r\n    \"\\u0005\\u0017\\f\\u0002\\u0081\\u0083\\u0005\\u0019\\r\\u0002\\u0082\\u0081\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0083\\u0084\\u0003\\u0002\\u0002\\u0002\\u0084\\u0082\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0084\\u0085\\u0003\\u0002\\u0002\\u0002\\u0085\\u0087\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0086\\u0080\\u0003\\u0002\\u0002\\u0002\\u0086\\u0082\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0087\\u0016\\u0003\\u0002\\u0002\\u0002\\u0088\\u008a\\u0005\",\r\n    \"\\u0019\\r\\u0002\\u0089\\u0088\\u0003\\u0002\\u0002\\u0002\\u008a\\u008b\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u008b\\u0089\\u0003\\u0002\\u0002\\u0002\\u008b\\u008c\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u008c\\u008d\\u0003\\u0002\\u0002\\u0002\\u008d\\u0091\\t\",\r\n    \"\\u0002\\u0002\\u0002\\u008e\\u0090\\u0005\\u0019\\r\\u0002\\u008f\\u008e\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0090\\u0093\\u0003\\u0002\\u0002\\u0002\\u0091\\u008f\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0091\\u0092\\u0003\\u0002\\u0002\\u0002\\u0092\\u009b\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0093\\u0091\\u0003\\u0002\\u0002\\u0002\\u0094\\u0096\\t\",\r\n    \"\\u0002\\u0002\\u0002\\u0095\\u0097\\u0005\\u0019\\r\\u0002\\u0096\\u0095\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0097\\u0098\\u0003\\u0002\\u0002\\u0002\\u0098\\u0096\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0098\\u0099\\u0003\\u0002\\u0002\\u0002\\u0099\\u009b\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u009a\\u0089\\u0003\\u0002\\u0002\\u0002\\u009a\\u0094\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u009b\\u0018\\u0003\\u0002\\u0002\\u0002\\u009c\\u009d\\t\",\r\n    \"\\u0003\\u0002\\u0002\\u009d\\u001a\\u0003\\u0002\\u0002\\u0002\\u009e\\u009f\\t\",\r\n    \"\\u0004\\u0002\\u0002\\u009f\\u00a0\\t\\u0005\\u0002\\u0002\\u00a0\\u00a1\\t\\u0006\",\r\n    \"\\u0002\\u0002\\u00a1\\u001c\\u0003\\u0002\\u0002\\u0002\\u00a2\\u00a3\\t\\u0006\",\r\n    \"\\u0002\\u0002\\u00a3\\u00a4\\t\\u0007\\u0002\\u0002\\u00a4\\u00a5\\t\\b\\u0002\\u0002\",\r\n    \"\\u00a5\\u001e\\u0003\\u0002\\u0002\\u0002\\u00a6\\u00a7\\u0007,\\u0002\\u0002\",\r\n    \"\\u00a7 \\u0003\\u0002\\u0002\\u0002\\u00a8\\u00a9\\u00071\\u0002\\u0002\\u00a9\",\r\n    \"\\\"\\u0003\\u0002\\u0002\\u0002\\u00aa\\u00ab\\u0007-\\u0002\\u0002\\u00ab$\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u00ac\\u00ad\\u0007/\\u0002\\u0002\\u00ad&\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u00ae\\u00af\\t\\t\\u0002\\u0002\\u00af\\u00b0\\t\\u0007\\u0002\\u0002\",\r\n    \"\\u00b0(\\u0003\\u0002\\u0002\\u0002\\u00b1\\u00b2\\t\\n\\u0002\\u0002\\u00b2\\u00b3\",\r\n    \"\\u0007-\\u0002\\u0002\\u00b3*\\u0003\\u0002\\u0002\\u0002\\u00b4\\u00b5\\t\\n\\u0002\",\r\n    \"\\u0002\\u00b5\\u00b6\\u0007/\\u0002\\u0002\\u00b6,\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u00b7\\u00b8\\t\\n\\u0002\\u0002\\u00b8.\\u0003\\u0002\\u0002\\u0002\\u00b9\\u00ba\",\r\n    \"\\t\\u000b\\u0002\\u0002\\u00ba\\u00bb\\t\\f\\u0002\\u0002\\u00bb\\u00bc\\t\\r\\u0002\",\r\n    \"\\u0002\\u00bc\\u00bd\\t\\u000e\\u0002\\u0002\\u00bd0\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u00be\\u00bf\\t\\u000b\\u0002\\u0002\\u00bf\\u00c0\\t\\f\\u0002\\u0002\\u00c0\\u00c1\",\r\n    \"\\t\\r\\u0002\\u0002\\u00c12\\u0003\\u0002\\u0002\\u0002\\u00c2\\u00c3\\t\\u000f\",\r\n    \"\\u0002\\u0002\\u00c3\\u00c4\\t\\u0010\\u0002\\u0002\\u00c4\\u00c5\\t\\u0005\\u0002\",\r\n    \"\\u0002\\u00c5\\u00c6\\t\\u0005\\u0002\\u0002\\u00c6\\u00c7\\t\\r\\u0002\\u0002\\u00c7\",\r\n    \"4\\u0003\\u0002\\u0002\\u0002\\u00c8\\u00c9\\t\\u0011\\u0002\\u0002\\u00c9\\u00ca\",\r\n    \"\\t\\n\\u0002\\u0002\\u00ca\\u00cb\\t\\u0007\\u0002\\u0002\\u00cb\\u00cc\\t\\u0010\",\r\n    \"\\u0002\\u0002\\u00cc6\\u0003\\u0002\\u0002\\u0002\\u00cd\\u00ce\\t\\u0012\\u0002\",\r\n    \"\\u0002\\u00ce\\u00cf\\t\\u0013\\u0002\\u0002\\u00cf\\u00d0\\t\\u000b\\u0002\\u0002\",\r\n    \"\\u00d08\\u0003\\u0002\\u0002\\u0002\\u00d1\\u00d2\\t\\r\\u0002\\u0002\\u00d2\\u00d3\",\r\n    \"\\t\\u0005\\u0002\\u0002\\u00d3\\u00d4\\t\\u0014\\u0002\\u0002\\u00d4\\u00d5\\t\\u0015\",\r\n    \"\\u0002\\u0002\\u00d5\\u00d6\\t\\u0006\\u0002\\u0002\\u00d6\\u00d7\\t\\u0016\\u0002\",\r\n    \"\\u0002\\u00d7:\\u0003\\u0002\\u0002\\u0002\\u00d8\\u00d9\\t\\r\\u0002\\u0002\\u00d9\",\r\n    \"\\u00da\\t\\u0005\\u0002\\u0002\\u00da\\u00db\\t\\u0014\\u0002\\u0002\\u00db\\u00dc\",\r\n    \"\\t\\u0015\\u0002\\u0002\\u00dc\\u00dd\\t\\u0006\\u0002\\u0002\\u00dd<\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u00de\\u00df\\t\\u000e\\u0002\\u0002\\u00df\\u00e0\\t\\r\\u0002\\u0002\",\r\n    \"\\u00e0\\u00e1\\t\\u0014\\u0002\\u0002\\u00e1\\u00e2\\t\\u0015\\u0002\\u0002\\u00e2\",\r\n    \"\\u00e3\\t\\u0011\\u0002\\u0002\\u00e3>\\u0003\\u0002\\u0002\\u0002\\u00e4\\u00e5\",\r\n    \"\\t\\u000b\\u0002\\u0002\\u00e5\\u00e6\\t\\u0007\\u0002\\u0002\\u00e6\\u00e7\\t\\u0015\",\r\n    \"\\u0002\\u0002\\u00e7@\\u0003\\u0002\\u0002\\u0002\\u00e8\\u00e9\\t\\u0011\\u0002\",\r\n    \"\\u0002\\u00e9\\u00ea\\t\\u0005\\u0002\\u0002\\u00ea\\u00eb\\t\\u000b\\u0002\\u0002\",\r\n    \"\\u00ebB\\u0003\\u0002\\u0002\\u0002\\u00ec\\u00ed\\t\\u000e\\u0002\\u0002\\u00ed\",\r\n    \"\\u00ee\\t\\u0012\\u0002\\u0002\\u00ee\\u00ef\\t\\u0015\\u0002\\u0002\\u00efD\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u00f0\\u00f1\\t\\u0011\\u0002\\u0002\\u00f1\\u00f2\\t\\u0005\",\r\n    \"\\u0002\\u0002\\u00f2\\u00f3\\t\\u000e\\u0002\\u0002\\u00f3F\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u00f4\\u00f5\\t\\u000b\\u0002\\u0002\\u00f5\\u00f6\\t\\u0007\\u0002\\u0002\",\r\n    \"\\u00f6\\u00f7\\t\\u0015\\u0002\\u0002\\u00f7\\u00f8\\t\\u0017\\u0002\\u0002\\u00f8\",\r\n    \"H\\u0003\\u0002\\u0002\\u0002\\u00f9\\u00fa\\t\\u0011\\u0002\\u0002\\u00fa\\u00fb\",\r\n    \"\\t\\u0005\\u0002\\u0002\\u00fb\\u00fc\\t\\u000b\\u0002\\u0002\\u00fc\\u00fd\\t\\u0017\",\r\n    \"\\u0002\\u0002\\u00fdJ\\u0003\\u0002\\u0002\\u0002\\u00fe\\u00ff\\t\\u000e\\u0002\",\r\n    \"\\u0002\\u00ff\\u0100\\t\\u0012\\u0002\\u0002\\u0100\\u0101\\t\\u0015\\u0002\\u0002\",\r\n    \"\\u0101\\u0102\\t\\u0017\\u0002\\u0002\\u0102L\\u0003\\u0002\\u0002\\u0002\\u0103\",\r\n    \"\\u0104\\t\\u0012\\u0002\\u0002\\u0104\\u0105\\t\\r\\u0002\\u0002\\u0105\\u0106\\t\",\r\n    \"\\u0011\\u0002\\u0002\\u0106\\u0107\\t\\u000b\\u0002\\u0002\\u0107\\u0108\\t\\u0007\",\r\n    \"\\u0002\\u0002\\u0108\\u0109\\t\\u0015\\u0002\\u0002\\u0109N\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u010a\\u010b\\t\\u0012\\u0002\\u0002\\u010b\\u010c\\t\\r\\u0002\\u0002\\u010c\",\r\n    \"\\u010d\\t\\u0011\\u0002\\u0002\\u010d\\u010e\\t\\u0011\\u0002\\u0002\\u010e\\u010f\",\r\n    \"\\t\\u0005\\u0002\\u0002\\u010f\\u0110\\t\\u000b\\u0002\\u0002\\u0110P\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u0111\\u0112\\t\\u0012\\u0002\\u0002\\u0112\\u0113\\t\\r\\u0002\\u0002\",\r\n    \"\\u0113\\u0114\\t\\u0011\\u0002\\u0002\\u0114\\u0115\\t\\u000e\\u0002\\u0002\\u0115\",\r\n    \"\\u0116\\t\\u0012\\u0002\\u0002\\u0116\\u0117\\t\\u0015\\u0002\\u0002\\u0117R\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\u0118\\u0119\\t\\u0012\\u0002\\u0002\\u0119\\u011a\\t\\r\\u0002\",\r\n    \"\\u0002\\u011a\\u011b\\t\\u0011\\u0002\\u0002\\u011b\\u011c\\t\\u000e\\u0002\\u0002\",\r\n    \"\\u011c\\u011d\\t\\u0012\\u0002\\u0002\\u011d\\u011e\\t\\u0015\\u0002\\u0002\\u011e\",\r\n    \"\\u011f\\t\\u0018\\u0002\\u0002\\u011fT\\u0003\\u0002\\u0002\\u0002\\u0120\\u0121\",\r\n    \"\\t\\u0012\\u0002\\u0002\\u0121\\u0122\\t\\r\\u0002\\u0002\\u0122\\u0123\\t\\u0011\",\r\n    \"\\u0002\\u0002\\u0123\\u0124\\t\\u0011\\u0002\\u0002\\u0124\\u0125\\t\\u0005\\u0002\",\r\n    \"\\u0002\\u0125\\u0126\\t\\u000e\\u0002\\u0002\\u0126V\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0127\\u0128\\t\\n\\u0002\\u0002\\u0128\\u0129\\t\\u0019\\u0002\\u0002\\u0129\\u012a\",\r\n    \"\\t\\t\\u0002\\u0002\\u012aX\\u0003\\u0002\\u0002\\u0002\\u012b\\u012c\\t\\u0010\",\r\n    \"\\u0002\\u0002\\u012c\\u012d\\t\\u0015\\u0002\\u0002\\u012dZ\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u012e\\u012f\\t\\n\\u0002\\u0002\\u012f\\u0130\\t\\n\\u0002\\u0002\\u0130\",\r\n    \"\\u0131\\t\\u0019\\u0002\\u0002\\u0131\\\\\\u0003\\u0002\\u0002\\u0002\\u0132\\u0133\",\r\n    \"\\t\\u0010\\u0002\\u0002\\u0133\\u0134\\t\\u0005\\u0002\\u0002\\u0134\\u0135\\t\\u001a\",\r\n    \"\\u0002\\u0002\\u0135^\\u0003\\u0002\\u0002\\u0002\\u0136\\u0137\\t\\r\\u0002\\u0002\",\r\n    \"\\u0137\\u0138\\t\\u0012\\u0002\\u0002\\u0138\\u0139\\t\\u0006\\u0002\\u0002\\u0139\",\r\n    \"`\\u0003\\u0002\\u0002\\u0002\\u013a\\u013b\\t\\u0006\\u0002\\u0002\\u013b\\u013c\",\r\n    \"\\t\\n\\u0002\\u0002\\u013c\\u013d\\t\\u001a\\u0002\\u0002\\u013db\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u013e\\u013f\\t\\u001b\\u0002\\u0002\\u013f\\u0140\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u0140\\u0141\\b2\\u0002\\u0002\\u0141d\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\u0142\\u0143\\u0005i5\\u0002\\u0143\\u0144\\u0003\\u0002\\u0002\\u0002\\u0144\",\r\n    \"\\u0145\\b3\\u0002\\u0002\\u0145f\\u0003\\u0002\\u0002\\u0002\\u0146\\u0147\\u000b\",\r\n    \"\\u0002\\u0002\\u0002\\u0147h\\u0003\\u0002\\u0002\\u0002\\u0148\\u0149\\u0007\",\r\n    \"1\\u0002\\u0002\\u0149\\u014a\\u0007,\\u0002\\u0002\\u014a\\u014e\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u014b\\u014d\\u000b\\u0002\\u0002\\u0002\\u014c\\u014b\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u014d\\u0150\\u0003\\u0002\\u0002\\u0002\\u014e\\u014f\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u014e\\u014c\\u0003\\u0002\\u0002\\u0002\\u014f\\u0151\\u0003\\u0002\",\r\n    \"\\u0002\\u0002\\u0150\\u014e\\u0003\\u0002\\u0002\\u0002\\u0151\\u0152\\u0007,\",\r\n    \"\\u0002\\u0002\\u0152\\u0164\\u00071\\u0002\\u0002\\u0153\\u0157\\u0007)\\u0002\",\r\n    \"\\u0002\\u0154\\u0156\\u000b\\u0002\\u0002\\u0002\\u0155\\u0154\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u0156\\u0159\\u0003\\u0002\\u0002\\u0002\\u0157\\u0158\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u0157\\u0155\\u0003\\u0002\\u0002\\u0002\\u0158\\u015a\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u0159\\u0157\\u0003\\u0002\\u0002\\u0002\\u015a\\u0164\\u0007)\\u0002\",\r\n    \"\\u0002\\u015b\\u015f\\u0007$\\u0002\\u0002\\u015c\\u015e\\u000b\\u0002\\u0002\",\r\n    \"\\u0002\\u015d\\u015c\\u0003\\u0002\\u0002\\u0002\\u015e\\u0161\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u015f\\u0160\\u0003\\u0002\\u0002\\u0002\\u015f\\u015d\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u0160\\u0162\\u0003\\u0002\\u0002\\u0002\\u0161\\u015f\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u0162\\u0164\\u0007$\\u0002\\u0002\\u0163\\u0148\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u0163\\u0153\\u0003\\u0002\\u0002\\u0002\\u0163\\u015b\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u0164j\\u0003\\u0002\\u0002\\u0002\\r\\u0002\\u0084\\u0086\\u008b\\u0091\",\r\n    \"\\u0098\\u009a\\u014e\\u0157\\u015f\\u0163\\u0003\\b\\u0002\\u0002\"].join(\"\");\r\n\r\n\r\nvar atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);\r\n\r\nvar decisionsToDFA = atn.decisionToState.map( function(ds, index) { return new antlr4.dfa.DFA(ds, index); });\r\n\r\nfunction CalculatorLexer(input) {\r\n\tantlr4.Lexer.call(this, input);\r\n    this._interp = new antlr4.atn.LexerATNSimulator(this, atn, decisionsToDFA, new antlr4.PredictionContextCache());\r\n    return this;\r\n}\r\n\r\nCalculatorLexer.prototype = Object.create(antlr4.Lexer.prototype);\r\nCalculatorLexer.prototype.constructor = CalculatorLexer;\r\n\r\nCalculatorLexer.EOF = antlr4.Token.EOF;\r\nCalculatorLexer.T__0 = 1;\r\nCalculatorLexer.T__1 = 2;\r\nCalculatorLexer.T__2 = 3;\r\nCalculatorLexer.T__3 = 4;\r\nCalculatorLexer.T__4 = 5;\r\nCalculatorLexer.T__5 = 6;\r\nCalculatorLexer.T__6 = 7;\r\nCalculatorLexer.T__7 = 8;\r\nCalculatorLexer.T__8 = 9;\r\nCalculatorLexer.NUMBER = 10;\r\nCalculatorLexer.FLOAT = 11;\r\nCalculatorLexer.DIGIT = 12;\r\nCalculatorLexer.MOD = 13;\r\nCalculatorLexer.WHOLE = 14;\r\nCalculatorLexer.MUL = 15;\r\nCalculatorLexer.DIV = 16;\r\nCalculatorLexer.ADD = 17;\r\nCalculatorLexer.SUB = 18;\r\nCalculatorLexer.PI = 19;\r\nCalculatorLexer.EXPONENT = 20;\r\nCalculatorLexer.NEGEXPONENT = 21;\r\nCalculatorLexer.EULER = 22;\r\nCalculatorLexer.SQRT = 23;\r\nCalculatorLexer.SQR = 24;\r\nCalculatorLexer.FLOOR = 25;\r\nCalculatorLexer.CEIL = 26;\r\nCalculatorLexer.ABS = 27;\r\nCalculatorLexer.ROUNDK = 28;\r\nCalculatorLexer.ROUND = 29;\r\nCalculatorLexer.TRUNC = 30;\r\nCalculatorLexer.SIN = 31;\r\nCalculatorLexer.COS = 32;\r\nCalculatorLexer.TAN = 33;\r\nCalculatorLexer.COT = 34;\r\nCalculatorLexer.SINH = 35;\r\nCalculatorLexer.COSH = 36;\r\nCalculatorLexer.TANH = 37;\r\nCalculatorLexer.ARCSIN = 38;\r\nCalculatorLexer.ARCCOS = 39;\r\nCalculatorLexer.ARCTAN = 40;\r\nCalculatorLexer.ARCTAN2 = 41;\r\nCalculatorLexer.ARCCOT = 42;\r\nCalculatorLexer.EXP = 43;\r\nCalculatorLexer.LN = 44;\r\nCalculatorLexer.EEX = 45;\r\nCalculatorLexer.LOG = 46;\r\nCalculatorLexer.RAD = 47;\r\nCalculatorLexer.DEG = 48;\r\nCalculatorLexer.WS = 49;\r\nCalculatorLexer.COM = 50;\r\nCalculatorLexer.INVALID = 51;\r\n\r\n\r\nCalculatorLexer.modeNames = [ \"DEFAULT_MODE\" ];\r\n\r\nCalculatorLexer.literalNames = [ null, \"'('\", \"';'\", \"')'\", \"'^'\", \"'**'\", \r\n                                 \"'%'\", \"'~'\", \"'//'\", \"'()'\", null, null, \r\n                                 null, null, null, \"'*'\", \"'/'\", \"'+'\", \r\n                                 \"'-'\" ];\r\n\r\nCalculatorLexer.symbolicNames = [ null, null, null, null, null, null, null, \r\n                                  null, null, null, \"NUMBER\", \"FLOAT\", \"DIGIT\", \r\n                                  \"MOD\", \"WHOLE\", \"MUL\", \"DIV\", \"ADD\", \"SUB\", \r\n                                  \"PI\", \"EXPONENT\", \"NEGEXPONENT\", \"EULER\", \r\n                                  \"SQRT\", \"SQR\", \"FLOOR\", \"CEIL\", \"ABS\", \r\n                                  \"ROUNDK\", \"ROUND\", \"TRUNC\", \"SIN\", \"COS\", \r\n                                  \"TAN\", \"COT\", \"SINH\", \"COSH\", \"TANH\", \r\n                                  \"ARCSIN\", \"ARCCOS\", \"ARCTAN\", \"ARCTAN2\", \r\n                                  \"ARCCOT\", \"EXP\", \"LN\", \"EEX\", \"LOG\", \"RAD\", \r\n                                  \"DEG\", \"WS\", \"COM\", \"INVALID\" ];\r\n\r\nCalculatorLexer.ruleNames = [ \"T__0\", \"T__1\", \"T__2\", \"T__3\", \"T__4\", \"T__5\", \r\n                              \"T__6\", \"T__7\", \"T__8\", \"NUMBER\", \"FLOAT\", \r\n                              \"DIGIT\", \"MOD\", \"WHOLE\", \"MUL\", \"DIV\", \"ADD\", \r\n                              \"SUB\", \"PI\", \"EXPONENT\", \"NEGEXPONENT\", \"EULER\", \r\n                              \"SQRT\", \"SQR\", \"FLOOR\", \"CEIL\", \"ABS\", \"ROUNDK\", \r\n                              \"ROUND\", \"TRUNC\", \"SIN\", \"COS\", \"TAN\", \"COT\", \r\n                              \"SINH\", \"COSH\", \"TANH\", \"ARCSIN\", \"ARCCOS\", \r\n                              \"ARCTAN\", \"ARCTAN2\", \"ARCCOT\", \"EXP\", \"LN\", \r\n                              \"EEX\", \"LOG\", \"RAD\", \"DEG\", \"WS\", \"COM\", \"INVALID\", \r\n                              \"COMMENT\" ];\r\n\r\nCalculatorLexer.grammarFileName = \"Calculator.g4\";\r\n\r\n\r\n\r\nexports.CalculatorLexer = CalculatorLexer;\r\n\r\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./GeneratedAntlr/CalculatorLexer.js\n ** module id = 3\n ** module chunks = 0\n **/","exports.atn = require('./atn/index');\nexports.dfa = require('./dfa/index');\nexports.tree = require('./tree/index');\nexports.error = require('./error/index');\nexports.Token = require('./Token').Token;\nexports.CommonToken = require('./Token').CommonToken;\nexports.InputStream = require('./InputStream').InputStream;\nexports.FileStream = require('./FileStream').FileStream;\nexports.CommonTokenStream = require('./CommonTokenStream').CommonTokenStream;\nexports.Lexer = require('./Lexer').Lexer;\nexports.Parser = require('./Parser').Parser;\nvar pc = require('./PredictionContext');\nexports.PredictionContextCache = pc.PredictionContextCache;\nexports.ParserRuleContext = require('./ParserRuleContext').ParserRuleContext;\nexports.Interval = require('./IntervalSet').Interval;\nexports.Utils = require('./Utils');\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/index.js\n ** module id = 4\n ** module chunks = 0\n **/","exports.ATN = require('./ATN').ATN;\nexports.ATNDeserializer = require('./ATNDeserializer').ATNDeserializer;\nexports.LexerATNSimulator = require('./LexerATNSimulator').LexerATNSimulator;\nexports.ParserATNSimulator = require('./ParserATNSimulator').ParserATNSimulator;\nexports.PredictionMode = require('./PredictionMode').PredictionMode;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/index.js\n ** module id = 5\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2013 Terence Parr\n//  Copyright (c) 2013 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nvar LL1Analyzer = require('./../LL1Analyzer').LL1Analyzer;\nvar IntervalSet = require('./../IntervalSet').IntervalSet;\n\nfunction ATN(grammarType , maxTokenType) {\n\n    // Used for runtime deserialization of ATNs from strings///\n    // The type of the ATN.\n    this.grammarType = grammarType;\n    // The maximum value for any symbol recognized by a transition in the ATN.\n    this.maxTokenType = maxTokenType;\n    this.states = [];\n    // Each subrule/rule is a decision point and we must track them so we\n    //  can go back later and build DFA predictors for them.  This includes\n    //  all the rules, subrules, optional blocks, ()+, ()* etc...\n    this.decisionToState = [];\n    // Maps from rule index to starting state number.\n    this.ruleToStartState = [];\n    // Maps from rule index to stop state number.\n    this.ruleToStopState = null;\n    this.modeNameToStartState = {};\n    // For lexer ATNs, this maps the rule index to the resulting token type.\n    // For parser ATNs, this maps the rule index to the generated bypass token\n    // type if the\n    // {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}\n    // deserialization option was specified; otherwise, this is {@code null}.\n    this.ruleToTokenType = null;\n    // For lexer ATNs, this is an array of {@link LexerAction} objects which may\n    // be referenced by action transitions in the ATN.\n    this.lexerActions = null;\n    this.modeToStartState = [];\n\n    return this;\n}\n\t\n// Compute the set of valid tokens that can occur starting in state {@code s}.\n//  If {@code ctx} is null, the set of tokens will not include what can follow\n//  the rule surrounding {@code s}. In other words, the set will be\n//  restricted to tokens reachable staying within {@code s}'s rule.\nATN.prototype.nextTokensInContext = function(s, ctx) {\n    var anal = new LL1Analyzer(this);\n    return anal.LOOK(s, null, ctx);\n};\n\n// Compute the set of valid tokens that can occur starting in {@code s} and\n// staying in same rule. {@link Token//EPSILON} is in set if we reach end of\n// rule.\nATN.prototype.nextTokensNoContext = function(s) {\n    if (s.nextTokenWithinRule !== null ) {\n        return s.nextTokenWithinRule;\n    }\n    s.nextTokenWithinRule = this.nextTokensInContext(s, null);\n    s.nextTokenWithinRule.readOnly = true;\n    return s.nextTokenWithinRule;\n};\n\nATN.prototype.nextTokens = function(s, ctx) {\n    if ( ctx===undefined ) {\n        return this.nextTokensNoContext(s);\n    } else {\n        return this.nextTokensInContext(s, ctx);\n    }\n};\n\nATN.prototype.addState = function( state) {\n    if ( state !== null ) {\n        state.atn = this;\n        state.stateNumber = this.states.length;\n    }\n    this.states.push(state);\n};\n\nATN.prototype.removeState = function( state) {\n    this.states[state.stateNumber] = null; // just free mem, don't shift states in list\n};\n\nATN.prototype.defineDecisionState = function( s) {\n    this.decisionToState.push(s);\n    s.decision = this.decisionToState.length-1;\n    return s.decision;\n};\n\nATN.prototype.getDecisionState = function( decision) {\n    if (this.decisionToState.length===0) {\n        return null;\n    } else {\n        return this.decisionToState[decision];\n    }\n};\n\n// Computes the set of input symbols which could follow ATN state number\n// {@code stateNumber} in the specified full {@code context}. This method\n// considers the complete parser context, but does not evaluate semantic\n// predicates (i.e. all predicates encountered during the calculation are\n// assumed true). If a path in the ATN exists from the starting state to the\n// {@link RuleStopState} of the outermost context without matching any\n// symbols, {@link Token//EOF} is added to the returned set.\n//\n// <p>If {@code context} is {@code null}, it is treated as\n// {@link ParserRuleContext//EMPTY}.</p>\n//\n// @param stateNumber the ATN state number\n// @param context the full parse context\n// @return The set of potentially valid input symbols which could follow the\n// specified state in the specified context.\n// @throws IllegalArgumentException if the ATN does not contain a state with\n// number {@code stateNumber}\nvar Token = require('./../Token').Token;\n\nATN.prototype.getExpectedTokens = function( stateNumber, ctx ) {\n    if ( stateNumber < 0 || stateNumber >= this.states.length ) {\n        throw(\"Invalid state number.\");\n    }\n    var s = this.states[stateNumber];\n    var following = this.nextTokens(s);\n    if (!following.contains(Token.EPSILON)) {\n        return following;\n    }\n    var expected = new IntervalSet();\n    expected.addSet(following);\n    expected.removeOne(Token.EPSILON);\n    while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n        var invokingState = this.states[ctx.invokingState];\n        var rt = invokingState.transitions[0];\n        following = this.nextTokens(rt.followState);\n        expected.addSet(following);\n        expected.removeOne(Token.EPSILON);\n        ctx = ctx.parentCtx;\n    }\n    if (following.contains(Token.EPSILON)) {\n        expected.addOne(Token.EOF);\n    }\n    return expected;\n};\n\nATN.INVALID_ALT_NUMBER = 0;\n\nexports.ATN = ATN;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/ATN.js\n ** module id = 6\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\nvar Set = require('./Utils').Set;\nvar BitSet = require('./Utils').BitSet;\nvar Token = require('./Token').Token;\nvar ATNConfig = require('./atn/ATNConfig').ATNConfig;\nvar Interval = require('./IntervalSet').Interval;\nvar IntervalSet = require('./IntervalSet').IntervalSet;\nvar RuleStopState = require('./atn/ATNState').RuleStopState;\nvar RuleTransition = require('./atn/Transition').RuleTransition;\nvar NotSetTransition = require('./atn/Transition').NotSetTransition;\nvar WildcardTransition = require('./atn/Transition').WildcardTransition;\nvar AbstractPredicateTransition = require('./atn/Transition').AbstractPredicateTransition;\n\nvar pc = require('./PredictionContext');\nvar predictionContextFromRuleContext = pc.predictionContextFromRuleContext;\nvar PredictionContext = pc.PredictionContext;\nvar SingletonPredictionContext = pc.SingletonPredictionContext;\n\nfunction LL1Analyzer (atn) {\n    this.atn = atn;\n}\n\n//* Special value added to the lookahead sets to indicate that we hit\n//  a predicate during analysis if {@code seeThruPreds==false}.\n///\nLL1Analyzer.HIT_PRED = Token.INVALID_TYPE;\n\n\n//*\n// Calculates the SLL(1) expected lookahead set for each outgoing transition\n// of an {@link ATNState}. The returned array has one element for each\n// outgoing transition in {@code s}. If the closure from transition\n// <em>i</em> leads to a semantic predicate before matching a symbol, the\n// element at index <em>i</em> of the result will be {@code null}.\n//\n// @param s the ATN state\n// @return the expected symbols for each outgoing transition of {@code s}.\n///\nLL1Analyzer.prototype.getDecisionLookahead = function(s) {\n    if (s === null) {\n        return null;\n    }\n    var count = s.transitions.length;\n    var look = [];\n    for(var alt=0; alt< count; alt++) {\n        look[alt] = new IntervalSet();\n        var lookBusy = new Set();\n        var seeThruPreds = false; // fail to get lookahead upon pred\n        this._LOOK(s.transition(alt).target, null, PredictionContext.EMPTY,\n              look[alt], lookBusy, new BitSet(), seeThruPreds, false);\n        // Wipe out lookahead for this alternative if we found nothing\n        // or we had a predicate when we !seeThruPreds\n        if (look[alt].length===0 || look[alt].contains(LL1Analyzer.HIT_PRED)) {\n            look[alt] = null;\n        }\n    }\n    return look;\n};\n\n//*\n// Compute set of tokens that can follow {@code s} in the ATN in the\n// specified {@code ctx}.\n//\n// <p>If {@code ctx} is {@code null} and the end of the rule containing\n// {@code s} is reached, {@link Token//EPSILON} is added to the result set.\n// If {@code ctx} is not {@code null} and the end of the outermost rule is\n// reached, {@link Token//EOF} is added to the result set.</p>\n//\n// @param s the ATN state\n// @param stopState the ATN state to stop at. This can be a\n// {@link BlockEndState} to detect epsilon paths through a closure.\n// @param ctx the complete parser context, or {@code null} if the context\n// should be ignored\n//\n// @return The set of tokens that can follow {@code s} in the ATN in the\n// specified {@code ctx}.\n///\nLL1Analyzer.prototype.LOOK = function(s, stopState, ctx) {\n    var r = new IntervalSet();\n    var seeThruPreds = true; // ignore preds; get all lookahead\n\tctx = ctx || null;\n    var lookContext = ctx!==null ? predictionContextFromRuleContext(s.atn, ctx) : null;\n    this._LOOK(s, stopState, lookContext, r, new Set(), new BitSet(), seeThruPreds, true);\n    return r;\n};\n    \n//*\n// Compute set of tokens that can follow {@code s} in the ATN in the\n// specified {@code ctx}.\n//\n// <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the\n// rule containing {@code s} is reached, {@link Token//EPSILON} is added to\n// the result set. If {@code ctx} is not {@code null} and {@code addEOF} is\n// {@code true} and {@code stopState} or the end of the outermost rule is\n// reached, {@link Token//EOF} is added to the result set.</p>\n//\n// @param s the ATN state.\n// @param stopState the ATN state to stop at. This can be a\n// {@link BlockEndState} to detect epsilon paths through a closure.\n// @param ctx The outer context, or {@code null} if the outer context should\n// not be used.\n// @param look The result lookahead set.\n// @param lookBusy A set used for preventing epsilon closures in the ATN\n// from causing a stack overflow. Outside code should pass\n// {@code new Set<ATNConfig>} for this argument.\n// @param calledRuleStack A set used for preventing left recursion in the\n// ATN from causing a stack overflow. Outside code should pass\n// {@code new BitSet()} for this argument.\n// @param seeThruPreds {@code true} to true semantic predicates as\n// implicitly {@code true} and \"see through them\", otherwise {@code false}\n// to treat semantic predicates as opaque and add {@link //HIT_PRED} to the\n// result if one is encountered.\n// @param addEOF Add {@link Token//EOF} to the result if the end of the\n// outermost context is reached. This parameter has no effect if {@code ctx}\n// is {@code null}.\n///\nLL1Analyzer.prototype._LOOK = function(s, stopState , ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {\n    var c = new ATNConfig({state:s, alt:0, context: ctx}, null);\n    if (lookBusy.contains(c)) {\n        return;\n    }\n    lookBusy.add(c);\n    if (s === stopState) {\n        if (ctx ===null) {\n            look.addOne(Token.EPSILON);\n            return;\n        } else if (ctx.isEmpty() && addEOF) {\n            look.addOne(Token.EOF);\n            return;\n        }\n    }\n    if (s instanceof RuleStopState ) {\n        if (ctx ===null) {\n            look.addOne(Token.EPSILON);\n            return;\n        } else if (ctx.isEmpty() && addEOF) {\n            look.addOne(Token.EOF);\n            return;\n        }\n        if (ctx !== PredictionContext.EMPTY) {\n            // run thru all possible stack tops in ctx\n            for(var i=0; i<ctx.length; i++) {\n                var returnState = this.atn.states[ctx.getReturnState(i)];\n                var removed = calledRuleStack.contains(returnState.ruleIndex);\n                try {\n                    calledRuleStack.remove(returnState.ruleIndex);\n                    this._LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                } finally {\n                    if (removed) {\n                        calledRuleStack.add(returnState.ruleIndex);\n                    }\n                }\n            }\n            return;\n        }\n    }\n    for(var j=0; j<s.transitions.length; j++) {\n        var t = s.transitions[j];\n        if (t.constructor === RuleTransition) {\n            if (calledRuleStack.contains(t.target.ruleIndex)) {\n                continue;\n            }\n            var newContext = SingletonPredictionContext.create(ctx, t.followState.stateNumber);\n            try {\n                calledRuleStack.add(t.target.ruleIndex);\n                this._LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n            } finally {\n                calledRuleStack.remove(t.target.ruleIndex);\n            }\n        } else if (t instanceof AbstractPredicateTransition ) {\n            if (seeThruPreds) {\n                this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n            } else {\n                look.addOne(LL1Analyzer.HIT_PRED);\n            }\n        } else if( t.isEpsilon) {\n            this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n        } else if (t.constructor === WildcardTransition) {\n            look.addRange( Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType );\n        } else {\n            var set = t.label;\n            if (set !== null) {\n                if (t instanceof NotSetTransition) {\n                    set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);\n                }\n                look.addSet(set);\n            }\n        }\n    }\n};\n\nexports.LL1Analyzer = LL1Analyzer;\n\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/LL1Analyzer.js\n ** module id = 7\n ** module chunks = 0\n **/","function arrayToString(a) {\n\treturn \"[\" + a.join(\", \") + \"]\";\n}\n\nString.prototype.hashCode = function(s) {\n\tvar hash = 0;\n\tif (this.length === 0) {\n\t\treturn hash;\n\t}\n\tfor (var i = 0; i < this.length; i++) {\n\t\tvar character = this.charCodeAt(i);\n\t\thash = ((hash << 5) - hash) + character;\n\t\thash = hash & hash; // Convert to 32bit integer\n\t}\n\treturn hash;\n};\n\nfunction standardEqualsFunction(a,b) {\n\treturn a.equals(b);\n}\n\nfunction standardHashFunction(a) {\n\treturn a.hashString();\n}\n\nfunction Set(hashFunction, equalsFunction) {\n\tthis.data = {};\n\tthis.hashFunction = hashFunction || standardHashFunction;\n\tthis.equalsFunction = equalsFunction || standardEqualsFunction;\n\treturn this;\n}\n\nObject.defineProperty(Set.prototype, \"length\", {\n\tget : function() {\n\t\treturn this.values().length;\n\t}\n});\n\nSet.prototype.add = function(value) {\n\tvar hash = this.hashFunction(value);\n\tvar key = \"hash_\" + hash.hashCode();\n\tif(key in this.data) {\n\t\tvar i;\n\t\tvar values = this.data[key];\n\t\tfor(i=0;i<values.length; i++) {\n\t\t\tif(this.equalsFunction(value, values[i])) {\n\t\t\t\treturn values[i];\n\t\t\t}\n\t\t}\n\t\tvalues.push(value);\n\t\treturn value;\n\t} else {\n\t\tthis.data[key] = [ value ];\n\t\treturn value;\n\t}\n};\n\nSet.prototype.contains = function(value) {\n\tvar hash = this.hashFunction(value);\n\tvar key = hash.hashCode();\n\tif(key in this.data) {\n\t\tvar i;\n\t\tvar values = this.data[key];\n\t\tfor(i=0;i<values.length; i++) {\n\t\t\tif(this.equalsFunction(value, values[i])) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t}\n\treturn false;\n};\n\nSet.prototype.values = function() {\n\tvar l = [];\n\tfor(var key in this.data) {\n\t\tif(key.indexOf(\"hash_\")===0) {\n\t\t\tl = l.concat(this.data[key]);\n\t\t}\n\t}\n\treturn l;\n};\n\nSet.prototype.toString = function() {\n\treturn arrayToString(this.values());\n};\n\nfunction BitSet() {\n\tthis.data = [];\n\treturn this;\n}\n\nBitSet.prototype.add = function(value) {\n\tthis.data[value] = true;\n};\n\nBitSet.prototype.or = function(set) {\n\tvar bits = this;\n\tObject.keys(set.data).map( function(alt) { bits.add(alt); });\n};\n\nBitSet.prototype.remove = function(value) {\n\tdelete this.data[value];\n};\n\nBitSet.prototype.contains = function(value) {\n\treturn this.data[value] === true;\n};\n\nBitSet.prototype.values = function() {\n\treturn Object.keys(this.data);\n};\n\nBitSet.prototype.minValue = function() {\n\treturn Math.min.apply(null, this.values());\n};\n\nBitSet.prototype.hashString = function() {\n\treturn this.values().toString();\n};\n\nBitSet.prototype.equals = function(other) {\n\tif(!(other instanceof BitSet)) {\n\t\treturn false;\n\t}\n\treturn this.hashString()===other.hashString();\n};\n\nObject.defineProperty(BitSet.prototype, \"length\", {\n\tget : function() {\n\t\treturn this.values().length;\n\t}\n});\n\nBitSet.prototype.toString = function() {\n\treturn \"{\" + this.values().join(\", \") + \"}\";\n};\n\nfunction AltDict() {\n\tthis.data = {};\n\treturn this;\n}\n\nAltDict.prototype.get = function(key) {\n\tkey = \"k-\" + key;\n\tif(key in this.data){\n\t\treturn this.data[key];\n\t} else {\n\t\treturn null;\n\t}\n};\n\nAltDict.prototype.put = function(key, value) {\n\tkey = \"k-\" + key;\n\tthis.data[key] = value;\n};\n\nAltDict.prototype.values = function() {\n\tvar data = this.data;\n\tvar keys = Object.keys(this.data);\n\treturn keys.map(function(key) {\n\t\treturn data[key];\n\t});\n};\n\nfunction DoubleDict() {\n\treturn this;\n}\n\nDoubleDict.prototype.get = function(a, b) {\n\tvar d = this[a] || null;\n\treturn d===null ? null : (d[b] || null);\n};\n\nDoubleDict.prototype.set = function(a, b, o) {\n\tvar d = this[a] || null;\n\tif(d===null) {\n\t\td = {};\n\t\tthis[a] = d;\n\t}\n\td[b] = o;\n};\n\n\nfunction escapeWhitespace(s, escapeSpaces) {\n\ts = s.replace(\"\\t\",\"\\\\t\");\n\ts = s.replace(\"\\n\",\"\\\\n\");\n\ts = s.replace(\"\\r\",\"\\\\r\");\n\tif(escapeSpaces) {\n\t\ts = s.replace(\" \",\"\\u00B7\");\n\t}\n\treturn s;\n}\n\nexports.isArray = function (entity) {\n\treturn Object.prototype.toString.call( entity ) === '[object Array]'\n};\n\nexports.titleCase = function(str) {\n\treturn str.replace(/\\w\\S*/g, function(txt){return txt.charAt(0).toUpperCase() + txt.substr(1);});\n};\n\nexports.Set = Set;\nexports.BitSet = BitSet;\nexports.AltDict = AltDict;\nexports.DoubleDict = DoubleDict;\nexports.escapeWhitespace = escapeWhitespace;\nexports.arrayToString = arrayToString;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/Utils.js\n ** module id = 8\n ** module chunks = 0\n **/","//[The \"BSD license\"]\n// Copyright (c) 2012 Terence Parr\n// Copyright (c) 2012 Sam Harwell\n// Copyright (c) 2014 Eric Vergnaud\n// All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions\n// are met:\n//\n// 1. Redistributions of source code must retain the above copyright\n//    notice, this list of conditions and the following disclaimer.\n// 2. Redistributions in binary form must reproduce the above copyright\n//    notice, this list of conditions and the following disclaimer in the\n//    documentation and/or other materials provided with the distribution.\n// 3. The name of the author may not be used to endorse or promote products\n//    derived from this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n// IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n// INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n// NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n// THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n\n// A token has properties: text, type, line, character position in the line\n// (so we can ignore tabs), token channel, index, and source from which\n// we obtained this token.\n\nfunction Token() {\n\tthis.source = null;\n\tthis.type = null; // token type of the token\n\tthis.channel = null; // The parser ignores everything not on DEFAULT_CHANNEL\n\tthis.start = null; // optional; return -1 if not implemented.\n\tthis.stop = null; // optional; return -1 if not implemented.\n\tthis.tokenIndex = null; // from 0..n-1 of the token object in the input stream\n\tthis.line = null; // line=1..n of the 1st character\n\tthis.column = null; // beginning of the line at which it occurs, 0..n-1\n\tthis._text = null; // text of the token.\n\treturn this;\n}\n\nToken.INVALID_TYPE = 0;\n\n// During lookahead operations, this \"token\" signifies we hit rule end ATN state\n// and did not follow it despite needing to.\nToken.EPSILON = -2;\n\nToken.MIN_USER_TOKEN_TYPE = 1;\n\nToken.EOF = -1;\n\n// All tokens go to the parser (unless skip() is called in that rule)\n// on a particular \"channel\". The parser tunes to a particular channel\n// so that whitespace etc... can go to the parser on a \"hidden\" channel.\n\nToken.DEFAULT_CHANNEL = 0;\n\n// Anything on different channel than DEFAULT_CHANNEL is not parsed\n// by parser.\n\nToken.HIDDEN_CHANNEL = 1;\n\n// Explicitly set the text for this token. If {code text} is not\n// {@code null}, then {@link //getText} will return this value rather than\n// extracting the text from the input.\n//\n// @param text The explicit text of the token, or {@code null} if the text\n// should be obtained from the input along with the start and stop indexes\n// of the token.\n\nObject.defineProperty(Token.prototype, \"text\", {\n\tget : function() {\n\t\treturn this._text;\n\t},\n\tset : function(text) {\n\t\tthis._text = text;\n\t}\n});\n\nToken.prototype.getTokenSource = function() {\n\treturn this.source[0];\n};\n\nToken.prototype.getInputStream = function() {\n\treturn this.source[1];\n};\n\nfunction CommonToken(source, type, channel, start, stop) {\n\tToken.call(this);\n\tthis.source = source !== undefined ? source : CommonToken.EMPTY_SOURCE;\n\tthis.type = type !== undefined ? type : null;\n\tthis.channel = channel !== undefined ? channel : Token.DEFAULT_CHANNEL;\n\tthis.start = start !== undefined ? start : -1;\n\tthis.stop = stop !== undefined ? stop : -1;\n\tthis.tokenIndex = -1;\n\tif (this.source[0] !== null) {\n\t\tthis.line = source[0].line;\n\t\tthis.column = source[0].column;\n\t} else {\n\t\tthis.column = -1;\n\t}\n\treturn this;\n}\n\nCommonToken.prototype = Object.create(Token.prototype);\nCommonToken.prototype.constructor = CommonToken;\n\n// An empty {@link Pair} which is used as the default value of\n// {@link //source} for tokens that do not have a source.\nCommonToken.EMPTY_SOURCE = [ null, null ];\n\n// Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n//\n// <p>\n// If {@code oldToken} is also a {@link CommonToken} instance, the newly\n// constructed token will share a reference to the {@link //text} field and\n// the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will\n// be assigned the result of calling {@link //getText}, and {@link //source}\n// will be constructed from the result of {@link Token//getTokenSource} and\n// {@link Token//getInputStream}.</p>\n//\n// @param oldToken The token to copy.\n//\nCommonToken.prototype.clone = function() {\n\tvar t = new CommonToken(this.source, this.type, this.channel, this.start,\n\t\t\tthis.stop);\n\tt.tokenIndex = this.tokenIndex;\n\tt.line = this.line;\n\tt.column = this.column;\n\tt.text = this.text;\n\treturn t;\n};\n\nObject.defineProperty(CommonToken.prototype, \"text\", {\n\tget : function() {\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t}\n\t\tvar input = this.getInputStream();\n\t\tif (input === null) {\n\t\t\treturn null;\n\t\t}\n\t\tvar n = input.size;\n\t\tif (this.start < n && this.stop < n) {\n\t\t\treturn input.getText(this.start, this.stop);\n\t\t} else {\n\t\t\treturn \"<EOF>\";\n\t\t}\n\t},\n\tset : function(text) {\n\t\tthis._text = text;\n\t}\n});\n\nCommonToken.prototype.toString = function() {\n\tvar txt = this.text;\n\tif (txt !== null) {\n\t\ttxt = txt.replace(/\\n/g, \"\\\\n\").replace(/\\r/g, \"\\\\r\").replace(/\\t/g, \"\\\\t\");\n\t} else {\n\t\ttxt = \"<no text>\";\n\t}\n\treturn \"[@\" + this.tokenIndex + \",\" + this.start + \":\" + this.stop + \"='\" +\n\t\t\ttxt + \"',<\" + this.type + \">\" +\n\t\t\t(this.channel > 0 ? \",channel=\" + this.channel : \"\") + \",\" +\n\t\t\tthis.line + \":\" + this.column + \"]\";\n};\n\nexports.Token = Token;\nexports.CommonToken = CommonToken;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/Token.js\n ** module id = 9\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\n// A tuple: (ATN state, predicted alt, syntactic, semantic context).\n//  The syntactic context is a graph-structured stack node whose\n//  path(s) to the root is the rule invocation(s)\n//  chain used to arrive at the state.  The semantic context is\n//  the tree of semantic predicates encountered before reaching\n//  an ATN state.\n///\n\nvar DecisionState = require('./ATNState').DecisionState;\nvar SemanticContext = require('./SemanticContext').SemanticContext;\n\nfunction checkParams(params, isCfg) {\n\tif(params===null) {\n\t\tvar result = { state:null, alt:null, context:null, semanticContext:null };\n\t\tif(isCfg) {\n\t\t\tresult.reachesIntoOuterContext = 0;\n\t\t}\n\t\treturn result;\n\t} else {\n\t\tvar props = {};\n\t\tprops.state = params.state || null;\n\t\tprops.alt = (params.alt === undefined) ? null : params.alt;\n\t\tprops.context = params.context || null;\n\t\tprops.semanticContext = params.semanticContext || null;\n\t\tif(isCfg) {\n\t\t\tprops.reachesIntoOuterContext = params.reachesIntoOuterContext || 0;\n\t\t\tprops.precedenceFilterSuppressed = params.precedenceFilterSuppressed || false;\n\t\t}\n\t\treturn props;\n\t}\n}\n\nfunction ATNConfig(params, config) {\n\tthis.checkContext(params, config);\n\tparams = checkParams(params);\n\tconfig = checkParams(config, true);\n    // The ATN state associated with this configuration///\n    this.state = params.state!==null ? params.state : config.state;\n    // What alt (or lexer rule) is predicted by this configuration///\n    this.alt = params.alt!==null ? params.alt : config.alt;\n    // The stack of invoking states leading to the rule/states associated\n    //  with this config.  We track only those contexts pushed during\n    //  execution of the ATN simulator.\n    this.context = params.context!==null ? params.context : config.context;\n    this.semanticContext = params.semanticContext!==null ? params.semanticContext :\n        (config.semanticContext!==null ? config.semanticContext : SemanticContext.NONE);\n    // We cannot execute predicates dependent upon local context unless\n    // we know for sure we are in the correct context. Because there is\n    // no way to do this efficiently, we simply cannot evaluate\n    // dependent predicates unless we are in the rule that initially\n    // invokes the ATN simulator.\n    //\n    // closure() tracks the depth of how far we dip into the\n    // outer context: depth &gt; 0.  Note that it may not be totally\n    // accurate depth since I don't ever decrement. TODO: make it a boolean then\n    this.reachesIntoOuterContext = config.reachesIntoOuterContext;\n    this.precedenceFilterSuppressed = config.precedenceFilterSuppressed;\n    return this;\n}\n\nATNConfig.prototype.checkContext = function(params, config) {\n\tif((params.context===null || params.context===undefined) &&\n\t\t\t(config===null || config.context===null || config.context===undefined)) {\n\t\tthis.context = null;\n\t}\n};\n\n// An ATN configuration is equal to another if both have\n//  the same state, they predict the same alternative, and\n//  syntactic/semantic contexts are the same.\n///\nATNConfig.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof ATNConfig)) {\n        return false;\n    } else {\n        return this.state.stateNumber===other.state.stateNumber &&\n            this.alt===other.alt &&\n            (this.context===null ? other.context===null : this.context.equals(other.context)) &&\n            this.semanticContext.equals(other.semanticContext) &&\n            this.precedenceFilterSuppressed===other.precedenceFilterSuppressed;\n    }\n};\n\nATNConfig.prototype.shortHashString = function() {\n    return \"\" + this.state.stateNumber + \"/\" + this.alt + \"/\" + this.semanticContext;\n};\n\nATNConfig.prototype.hashString = function() {\n    return \"\" + this.state.stateNumber + \"/\" + this.alt + \"/\" +\n             (this.context===null ? \"\" : this.context.hashString()) +\n             \"/\" + this.semanticContext.hashString();\n};\n\nATNConfig.prototype.toString = function() {\n    return \"(\" + this.state + \",\" + this.alt +\n        (this.context!==null ? \",[\" + this.context.toString() + \"]\" : \"\") +\n        (this.semanticContext !== SemanticContext.NONE ?\n                (\",\" + this.semanticContext.toString())\n                : \"\") +\n        (this.reachesIntoOuterContext>0 ?\n                (\",up=\" + this.reachesIntoOuterContext)\n                : \"\") + \")\";\n};\n\n\nfunction LexerATNConfig(params, config) {\n\tATNConfig.call(this, params, config);\n    \n    // This is the backing field for {@link //getLexerActionExecutor}.\n\tvar lexerActionExecutor = params.lexerActionExecutor || null;\n    this.lexerActionExecutor = lexerActionExecutor || (config!==null ? config.lexerActionExecutor : null);\n    this.passedThroughNonGreedyDecision = config!==null ? this.checkNonGreedyDecision(config, this.state) : false;\n    return this;\n}\n\nLexerATNConfig.prototype = Object.create(ATNConfig.prototype);\nLexerATNConfig.prototype.constructor = LexerATNConfig;\n\nLexerATNConfig.prototype.hashString = function() {\n    return \"\" + this.state.stateNumber + this.alt + this.context +\n            this.semanticContext + (this.passedThroughNonGreedyDecision ? 1 : 0) +\n            this.lexerActionExecutor;\n};\n\nLexerATNConfig.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (!(other instanceof LexerATNConfig)) {\n        return false;\n    } else if (this.passedThroughNonGreedyDecision !== other.passedThroughNonGreedyDecision) {\n        return false;\n    } else if (this.lexerActionExecutor ?\n            !this.lexerActionExecutor.equals(other.lexerActionExecutor)\n            : !other.lexerActionExecutor) {\n        return false;\n    } else {\n        return ATNConfig.prototype.equals.call(this, other);\n    }\n};\n\nLexerATNConfig.prototype.checkNonGreedyDecision = function(source, target) {\n    return source.passedThroughNonGreedyDecision ||\n        (target instanceof DecisionState) && target.nonGreedy;\n};\n\nexports.ATNConfig = ATNConfig;\nexports.LexerATNConfig = LexerATNConfig;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/ATNConfig.js\n ** module id = 10\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n\n// The following images show the relation of states and\n// {@link ATNState//transitions} for various grammar constructs.\n//\n// <ul>\n//\n// <li>Solid edges marked with an &//0949; indicate a required\n// {@link EpsilonTransition}.</li>\n//\n// <li>Dashed edges indicate locations where any transition derived from\n// {@link Transition} might appear.</li>\n//\n// <li>Dashed nodes are place holders for either a sequence of linked\n// {@link BasicState} states or the inclusion of a block representing a nested\n// construct in one of the forms below.</li>\n//\n// <li>Nodes showing multiple outgoing alternatives with a {@code ...} support\n// any number of alternatives (one or more). Nodes without the {@code ...} only\n// support the exact number of alternatives shown in the diagram.</li>\n//\n// </ul>\n//\n// <h2>Basic Blocks</h2>\n//\n// <h3>Rule</h3>\n//\n// <embed src=\"images/Rule.svg\" type=\"image/svg+xml\"/>\n//\n// <h3>Block of 1 or more alternatives</h3>\n//\n// <embed src=\"images/Block.svg\" type=\"image/svg+xml\"/>\n//\n// <h2>Greedy Loops</h2>\n//\n// <h3>Greedy Closure: {@code (...)*}</h3>\n//\n// <embed src=\"images/ClosureGreedy.svg\" type=\"image/svg+xml\"/>\n//\n// <h3>Greedy Positive Closure: {@code (...)+}</h3>\n//\n// <embed src=\"images/PositiveClosureGreedy.svg\" type=\"image/svg+xml\"/>\n//\n// <h3>Greedy Optional: {@code (...)?}</h3>\n//\n// <embed src=\"images/OptionalGreedy.svg\" type=\"image/svg+xml\"/>\n//\n// <h2>Non-Greedy Loops</h2>\n//\n// <h3>Non-Greedy Closure: {@code (...)*?}</h3>\n//\n// <embed src=\"images/ClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n//\n// <h3>Non-Greedy Positive Closure: {@code (...)+?}</h3>\n//\n// <embed src=\"images/PositiveClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n//\n// <h3>Non-Greedy Optional: {@code (...)??}</h3>\n//\n// <embed src=\"images/OptionalNonGreedy.svg\" type=\"image/svg+xml\"/>\n//\n\nvar INITIAL_NUM_TRANSITIONS = 4;\n\nfunction ATNState() {\n    // Which ATN are we in?\n    this.atn = null;\n    this.stateNumber = ATNState.INVALID_STATE_NUMBER;\n    this.stateType = null;\n    this.ruleIndex = 0; // at runtime, we don't have Rule objects\n    this.epsilonOnlyTransitions = false;\n    // Track the transitions emanating from this ATN state.\n    this.transitions = [];\n    // Used to cache lookahead during parsing, not used during construction\n    this.nextTokenWithinRule = null;\n    return this;\n}\n\n// constants for serialization\nATNState.INVALID_TYPE = 0;\nATNState.BASIC = 1;\nATNState.RULE_START = 2;\nATNState.BLOCK_START = 3;\nATNState.PLUS_BLOCK_START = 4;\nATNState.STAR_BLOCK_START = 5;\nATNState.TOKEN_START = 6;\nATNState.RULE_STOP = 7;\nATNState.BLOCK_END = 8;\nATNState.STAR_LOOP_BACK = 9;\nATNState.STAR_LOOP_ENTRY = 10;\nATNState.PLUS_LOOP_BACK = 11;\nATNState.LOOP_END = 12;\n\nATNState.serializationNames = [\n            \"INVALID\",\n            \"BASIC\",\n            \"RULE_START\",\n            \"BLOCK_START\",\n            \"PLUS_BLOCK_START\",\n            \"STAR_BLOCK_START\",\n            \"TOKEN_START\",\n            \"RULE_STOP\",\n            \"BLOCK_END\",\n            \"STAR_LOOP_BACK\",\n            \"STAR_LOOP_ENTRY\",\n            \"PLUS_LOOP_BACK\",\n            \"LOOP_END\" ];\n\nATNState.INVALID_STATE_NUMBER = -1;\n\nATNState.prototype.toString = function() {\n\treturn this.stateNumber;\n};\n\nATNState.prototype.equals = function(other) {\n    if (other instanceof ATNState) {\n        return this.stateNumber===other.stateNumber;\n    } else {\n        return false;\n    }\n};\n\nATNState.prototype.isNonGreedyExitState = function() {\n    return false;\n};\n\n\nATNState.prototype.addTransition = function(trans, index) {\n\tif(index===undefined) {\n\t\tindex = -1;\n\t}\n    if (this.transitions.length===0) {\n        this.epsilonOnlyTransitions = trans.isEpsilon;\n    } else if(this.epsilonOnlyTransitions !== trans.isEpsilon) {\n        this.epsilonOnlyTransitions = false;\n    }\n    if (index===-1) {\n        this.transitions.push(trans);\n    } else {\n        this.transitions.splice(index, 1, trans);\n    }\n};\n\nfunction BasicState() {\n\tATNState.call(this);\n    this.stateType = ATNState.BASIC;\n    return this;\n}\n\nBasicState.prototype = Object.create(ATNState.prototype);\nBasicState.prototype.constructor = BasicState;\n\n\nfunction DecisionState() {\n\tATNState.call(this);\n    this.decision = -1;\n    this.nonGreedy = false;\n    return this;\n}\n\nDecisionState.prototype = Object.create(ATNState.prototype);\nDecisionState.prototype.constructor = DecisionState;\n\n\n//  The start of a regular {@code (...)} block.\nfunction BlockStartState() {\n\tDecisionState.call(this);\n\tthis.endState = null;\n\treturn this;\n}\n\nBlockStartState.prototype = Object.create(DecisionState.prototype);\nBlockStartState.prototype.constructor = BlockStartState;\n\n\nfunction BasicBlockStartState() {\n\tBlockStartState.call(this);\n\tthis.stateType = ATNState.BLOCK_START;\n\treturn this;\n}\n\nBasicBlockStartState.prototype = Object.create(BlockStartState.prototype);\nBasicBlockStartState.prototype.constructor = BasicBlockStartState;\n\n\n// Terminal node of a simple {@code (a|b|c)} block.\nfunction BlockEndState() {\n\tATNState.call(this);\n\tthis.stateType = ATNState.BLOCK_END;\n    this.startState = null;\n    return this;\n}\n\nBlockEndState.prototype = Object.create(ATNState.prototype);\nBlockEndState.prototype.constructor = BlockEndState;\n\n\n// The last node in the ATN for a rule, unless that rule is the start symbol.\n//  In that case, there is one transition to EOF. Later, we might encode\n//  references to all calls to this rule to compute FOLLOW sets for\n//  error handling.\n//\nfunction RuleStopState() {\n\tATNState.call(this);\n    this.stateType = ATNState.RULE_STOP;\n    return this;\n}\n\nRuleStopState.prototype = Object.create(ATNState.prototype);\nRuleStopState.prototype.constructor = RuleStopState;\n\nfunction RuleStartState() {\n\tATNState.call(this);\n\tthis.stateType = ATNState.RULE_START;\n\tthis.stopState = null;\n\tthis.isPrecedenceRule = false;\n\treturn this;\n}\n\nRuleStartState.prototype = Object.create(ATNState.prototype);\nRuleStartState.prototype.constructor = RuleStartState;\n\n// Decision state for {@code A+} and {@code (A|B)+}.  It has two transitions:\n//  one to the loop back to start of the block and one to exit.\n//\nfunction PlusLoopbackState() {\n\tDecisionState.call(this);\n\tthis.stateType = ATNState.PLUS_LOOP_BACK;\n\treturn this;\n}\n\nPlusLoopbackState.prototype = Object.create(DecisionState.prototype);\nPlusLoopbackState.prototype.constructor = PlusLoopbackState;\n        \n\n// Start of {@code (A|B|...)+} loop. Technically a decision state, but\n//  we don't use for code generation; somebody might need it, so I'm defining\n//  it for completeness. In reality, the {@link PlusLoopbackState} node is the\n//  real decision-making note for {@code A+}.\n//\nfunction PlusBlockStartState() {\n\tBlockStartState.call(this);\n\tthis.stateType = ATNState.PLUS_BLOCK_START;\n    this.loopBackState = null;\n    return this;\n}\n\nPlusBlockStartState.prototype = Object.create(BlockStartState.prototype);\nPlusBlockStartState.prototype.constructor = PlusBlockStartState;\n\n// The block that begins a closure loop.\nfunction StarBlockStartState() {\n\tBlockStartState.call(this);\n\tthis.stateType = ATNState.STAR_BLOCK_START;\n\treturn this;\n}\n\nStarBlockStartState.prototype = Object.create(BlockStartState.prototype);\nStarBlockStartState.prototype.constructor = StarBlockStartState;\n\n\nfunction StarLoopbackState() {\n\tATNState.call(this);\n\tthis.stateType = ATNState.STAR_LOOP_BACK;\n\treturn this;\n}\n\nStarLoopbackState.prototype = Object.create(ATNState.prototype);\nStarLoopbackState.prototype.constructor = StarLoopbackState;\n\n\nfunction StarLoopEntryState() {\n\tDecisionState.call(this);\n\tthis.stateType = ATNState.STAR_LOOP_ENTRY;\n    this.loopBackState = null;\n    // Indicates whether this state can benefit from a precedence DFA during SLL decision making.\n    this.precedenceRuleDecision = null;\n    return this;\n}\n\nStarLoopEntryState.prototype = Object.create(DecisionState.prototype);\nStarLoopEntryState.prototype.constructor = StarLoopEntryState;\n\n\n// Mark the end of a * or + loop.\nfunction LoopEndState() {\n\tATNState.call(this);\n\tthis.stateType = ATNState.LOOP_END;\n\tthis.loopBackState = null;\n\treturn this;\n}\n\nLoopEndState.prototype = Object.create(ATNState.prototype);\nLoopEndState.prototype.constructor = LoopEndState;\n\n\n// The Tokens rule start state linking to each lexer rule start state */\nfunction TokensStartState() {\n\tDecisionState.call(this);\n\tthis.stateType = ATNState.TOKEN_START;\n\treturn this;\n}\n\nTokensStartState.prototype = Object.create(DecisionState.prototype);\nTokensStartState.prototype.constructor = TokensStartState;\n\nexports.ATNState = ATNState;\nexports.BasicState = BasicState;\nexports.DecisionState = DecisionState;\nexports.BlockStartState = BlockStartState;\nexports.BlockEndState = BlockEndState;\nexports.LoopEndState = LoopEndState;\nexports.RuleStartState = RuleStartState;\nexports.RuleStopState = RuleStopState;\nexports.TokensStartState = TokensStartState;\nexports.PlusLoopbackState = PlusLoopbackState;\nexports.StarLoopbackState = StarLoopbackState;\nexports.StarLoopEntryState = StarLoopEntryState;\nexports.PlusBlockStartState = PlusBlockStartState;\nexports.StarBlockStartState = StarBlockStartState;\nexports.BasicBlockStartState = BasicBlockStartState;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/ATNState.js\n ** module id = 11\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n\n// A tree structure used to record the semantic context in which\n//  an ATN configuration is valid.  It's either a single predicate,\n//  a conjunction {@code p1&&p2}, or a sum of products {@code p1||p2}.\n//\n//  <p>I have scoped the {@link AND}, {@link OR}, and {@link Predicate} subclasses of\n//  {@link SemanticContext} within the scope of this outer class.</p>\n//\n\nvar Set = require('./../Utils').Set;\n\nfunction SemanticContext() {\n\treturn this;\n}\n\n// For context independent predicates, we evaluate them without a local\n// context (i.e., null context). That way, we can evaluate them without\n// having to create proper rule-specific context during prediction (as\n// opposed to the parser, which creates them naturally). In a practical\n// sense, this avoids a cast exception from RuleContext to myruleContext.\n//\n// <p>For context dependent predicates, we must pass in a local context so that\n// references such as $arg evaluate properly as _localctx.arg. We only\n// capture context dependent predicates in the context in which we begin\n// prediction, so we passed in the outer context here in case of context\n// dependent predicate evaluation.</p>\n//\nSemanticContext.prototype.evaluate = function(parser, outerContext) {\n};\n\n//\n// Evaluate the precedence predicates for the context and reduce the result.\n//\n// @param parser The parser instance.\n// @param outerContext The current parser context object.\n// @return The simplified semantic context after precedence predicates are\n// evaluated, which will be one of the following values.\n// <ul>\n// <li>{@link //NONE}: if the predicate simplifies to {@code true} after\n// precedence predicates are evaluated.</li>\n// <li>{@code null}: if the predicate simplifies to {@code false} after\n// precedence predicates are evaluated.</li>\n// <li>{@code this}: if the semantic context is not changed as a result of\n// precedence predicate evaluation.</li>\n// <li>A non-{@code null} {@link SemanticContext}: the new simplified\n// semantic context after precedence predicates are evaluated.</li>\n// </ul>\n//\nSemanticContext.prototype.evalPrecedence = function(parser, outerContext) {\n\treturn this;\n};\n\nSemanticContext.andContext = function(a, b) {\n\tif (a === null || a === SemanticContext.NONE) {\n\t\treturn b;\n\t}\n\tif (b === null || b === SemanticContext.NONE) {\n\t\treturn a;\n\t}\n\tvar result = new AND(a, b);\n\tif (result.opnds.length === 1) {\n\t\treturn result.opnds[0];\n\t} else {\n\t\treturn result;\n\t}\n};\n\nSemanticContext.orContext = function(a, b) {\n\tif (a === null) {\n\t\treturn b;\n\t}\n\tif (b === null) {\n\t\treturn a;\n\t}\n\tif (a === SemanticContext.NONE || b === SemanticContext.NONE) {\n\t\treturn SemanticContext.NONE;\n\t}\n\tvar result = new OR(a, b);\n\tif (result.opnds.length === 1) {\n\t\treturn result.opnds[0];\n\t} else {\n\t\treturn result;\n\t}\n};\n\nfunction Predicate(ruleIndex, predIndex, isCtxDependent) {\n\tSemanticContext.call(this);\n\tthis.ruleIndex = ruleIndex === undefined ? -1 : ruleIndex;\n\tthis.predIndex = predIndex === undefined ? -1 : predIndex;\n\tthis.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred\n\treturn this;\n}\n\nPredicate.prototype = Object.create(SemanticContext.prototype);\nPredicate.prototype.constructor = Predicate;\n\n//The default {@link SemanticContext}, which is semantically equivalent to\n//a predicate of the form {@code {true}?}.\n//\nSemanticContext.NONE = new Predicate();\n\n\nPredicate.prototype.evaluate = function(parser, outerContext) {\n\tvar localctx = this.isCtxDependent ? outerContext : null;\n\treturn parser.sempred(localctx, this.ruleIndex, this.predIndex);\n};\n\nPredicate.prototype.hashString = function() {\n\treturn \"\" + this.ruleIndex + \"/\" + this.predIndex + \"/\" + this.isCtxDependent;\n};\n\nPredicate.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof Predicate)) {\n\t\treturn false;\n\t} else {\n\t\treturn this.ruleIndex === other.ruleIndex &&\n\t\t\t\tthis.predIndex === other.predIndex &&\n\t\t\t\tthis.isCtxDependent === other.isCtxDependent;\n\t}\n};\n\nPredicate.prototype.toString = function() {\n\treturn \"{\" + this.ruleIndex + \":\" + this.predIndex + \"}?\";\n};\n\nfunction PrecedencePredicate(precedence) {\n\tSemanticContext.call(this);\n\tthis.precedence = precedence === undefined ? 0 : precedence;\n}\n\nPrecedencePredicate.prototype = Object.create(SemanticContext.prototype);\nPrecedencePredicate.prototype.constructor = PrecedencePredicate;\n\nPrecedencePredicate.prototype.evaluate = function(parser, outerContext) {\n\treturn parser.precpred(outerContext, this.precedence);\n};\n\nPrecedencePredicate.prototype.evalPrecedence = function(parser, outerContext) {\n\tif (parser.precpred(outerContext, this.precedence)) {\n\t\treturn SemanticContext.NONE;\n\t} else {\n\t\treturn null;\n\t}\n};\n\nPrecedencePredicate.prototype.compareTo = function(other) {\n\treturn this.precedence - other.precedence;\n};\n\nPrecedencePredicate.prototype.hashString = function() {\n\treturn \"31\";\n};\n\nPrecedencePredicate.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof PrecedencePredicate)) {\n\t\treturn false;\n\t} else {\n\t\treturn this.precedence === other.precedence;\n\t}\n};\n\nPrecedencePredicate.prototype.toString = function() {\n\treturn \"{\"+this.precedence+\">=prec}?\";\n};\n\n\n\nPrecedencePredicate.filterPrecedencePredicates = function(set) {\n\tvar result = [];\n\tset.values().map( function(context) {\n\t\tif (context instanceof PrecedencePredicate) {\n\t\t\tresult.push(context);\n\t\t}\n\t});\n\treturn result;\n};\n\n\n// A semantic context which is true whenever none of the contained contexts\n// is false.\n//\nfunction AND(a, b) {\n\tSemanticContext.call(this);\n\tvar operands = new Set();\n\tif (a instanceof AND) {\n\t\ta.opnds.map(function(o) {\n\t\t\toperands.add(o);\n\t\t});\n\t} else {\n\t\toperands.add(a);\n\t}\n\tif (b instanceof AND) {\n\t\tb.opnds.map(function(o) {\n\t\t\toperands.add(o);\n\t\t});\n\t} else {\n\t\toperands.add(b);\n\t}\n\tvar precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\tif (precedencePredicates.length > 0) {\n\t\t// interested in the transition with the lowest precedence\n\t\tvar reduced = null;\n\t\tprecedencePredicates.map( function(p) {\n\t\t\tif(reduced===null || p.precedence<reduced.precedence) {\n\t\t\t\treduced = p;\n\t\t\t}\n\t\t});\n\t\toperands.add(reduced);\n\t}\n\tthis.opnds = operands.values();\n\treturn this;\n}\n\nAND.prototype = Object.create(SemanticContext.prototype);\nAND.prototype.constructor = AND;\n\nAND.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof AND)) {\n\t\treturn false;\n\t} else {\n\t\treturn this.opnds === other.opnds;\n\t}\n};\n\nAND.prototype.hashString = function() {\n\treturn \"\" + this.opnds + \"/AND\";\n};\n//\n// {@inheritDoc}\n//\n// <p>\n// The evaluation of predicates by this context is short-circuiting, but\n// unordered.</p>\n//\nAND.prototype.evaluate = function(parser, outerContext) {\n\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\tif (!this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n};\n\nAND.prototype.evalPrecedence = function(parser, outerContext) {\n\tvar differs = false;\n\tvar operands = [];\n\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\tvar context = this.opnds[i];\n\t\tvar evaluated = context.evalPrecedence(parser, outerContext);\n\t\tdiffers |= (evaluated !== context);\n\t\tif (evaluated === null) {\n\t\t\t// The AND context is false if any element is false\n\t\t\treturn null;\n\t\t} else if (evaluated !== SemanticContext.NONE) {\n\t\t\t// Reduce the result by skipping true elements\n\t\t\toperands.push(evaluated);\n\t\t}\n\t}\n\tif (!differs) {\n\t\treturn this;\n\t}\n\tif (operands.length === 0) {\n\t\t// all elements were true, so the AND context is true\n\t\treturn SemanticContext.NONE;\n\t}\n\tvar result = null;\n\toperands.map(function(o) {\n\t\tresult = result === null ? o : SemanticContext.andContext(result, o);\n\t});\n\treturn result;\n};\n\nAND.prototype.toString = function() {\n\tvar s = \"\";\n\tthis.opnds.map(function(o) {\n\t\ts += \"&& \" + o.toString();\n\t});\n\treturn s.length > 3 ? s.slice(3) : s;\n};\n\n//\n// A semantic context which is true whenever at least one of the contained\n// contexts is true.\n//\nfunction OR(a, b) {\n\tSemanticContext.call(this);\n\tvar operands = new Set();\n\tif (a instanceof OR) {\n\t\ta.opnds.map(function(o) {\n\t\t\toperands.add(o);\n\t\t});\n\t} else {\n\t\toperands.add(a);\n\t}\n\tif (b instanceof OR) {\n\t\tb.opnds.map(function(o) {\n\t\t\toperands.add(o);\n\t\t});\n\t} else {\n\t\toperands.add(b);\n\t}\n\n\tvar precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\tif (precedencePredicates.length > 0) {\n\t\t// interested in the transition with the highest precedence\n\t\tvar s = precedencePredicates.sort(function(a, b) {\n\t\t\treturn a.compareTo(b);\n\t\t});\n\t\tvar reduced = s[s.length-1];\n\t\toperands.add(reduced);\n\t}\n\tthis.opnds = operands.values();\n\treturn this;\n}\n\nOR.prototype = Object.create(SemanticContext.prototype);\nOR.prototype.constructor = OR;\n\nOR.prototype.constructor = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof OR)) {\n\t\treturn false;\n\t} else {\n\t\treturn this.opnds === other.opnds;\n\t}\n};\n\nOR.prototype.hashString = function() {\n\treturn \"\" + this.opnds + \"/OR\"; \n};\n\n// <p>\n// The evaluation of predicates by this context is short-circuiting, but\n// unordered.</p>\n//\nOR.prototype.evaluate = function(parser, outerContext) {\n\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\tif (this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n};\n\nOR.prototype.evalPrecedence = function(parser, outerContext) {\n\tvar differs = false;\n\tvar operands = [];\n\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\tvar context = this.opnds[i];\n\t\tvar evaluated = context.evalPrecedence(parser, outerContext);\n\t\tdiffers |= (evaluated !== context);\n\t\tif (evaluated === SemanticContext.NONE) {\n\t\t\t// The OR context is true if any element is true\n\t\t\treturn SemanticContext.NONE;\n\t\t} else if (evaluated !== null) {\n\t\t\t// Reduce the result by skipping false elements\n\t\t\toperands.push(evaluated);\n\t\t}\n\t}\n\tif (!differs) {\n\t\treturn this;\n\t}\n\tif (operands.length === 0) {\n\t\t// all elements were false, so the OR context is false\n\t\treturn null;\n\t}\n\tvar result = null;\n\toperands.map(function(o) {\n\t\treturn result === null ? o : SemanticContext.orContext(result, o);\n\t});\n\treturn result;\n};\n\nOR.prototype.toString = function() {\n\tvar s = \"\";\n\tthis.opnds.map(function(o) {\n\t\ts += \"|| \" + o.toString();\n\t});\n\treturn s.length > 3 ? s.slice(3) : s;\n};\n\nexports.SemanticContext = SemanticContext;\nexports.PrecedencePredicate = PrecedencePredicate;\nexports.Predicate = Predicate;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/SemanticContext.js\n ** module id = 12\n ** module chunks = 0\n **/","/*jslint smarttabs:true */\n\nvar Token = require('./Token').Token;\n\n/* stop is not included! */\nfunction Interval(start, stop) {\n\tthis.start = start;\n\tthis.stop = stop;\n\treturn this;\n}\n\nInterval.prototype.contains = function(item) {\n\treturn item >= this.start && item < this.stop;\n};\n\nInterval.prototype.toString = function() {\n\tif(this.start===this.stop-1) {\n\t\treturn this.start.toString();\n\t} else {\n\t\treturn this.start.toString() + \"..\" + (this.stop-1).toString();\n\t}\n};\n\n\nObject.defineProperty(Interval.prototype, \"length\", {\n\tget : function() {\n\t\treturn this.stop - this.start;\n\t}\n});\n\nfunction IntervalSet() {\n\tthis.intervals = null;\n\tthis.readOnly = false;\n}\n\nIntervalSet.prototype.first = function(v) {\n\tif (this.intervals === null || this.intervals.length===0) {\n\t\treturn Token.INVALID_TYPE;\n\t} else {\n\t\treturn this.intervals[0].start;\n\t}\n};\n\nIntervalSet.prototype.addOne = function(v) {\n\tthis.addInterval(new Interval(v, v + 1));\n};\n\nIntervalSet.prototype.addRange = function(l, h) {\n\tthis.addInterval(new Interval(l, h + 1));\n};\n\nIntervalSet.prototype.addInterval = function(v) {\n\tif (this.intervals === null) {\n\t\tthis.intervals = [];\n\t\tthis.intervals.push(v);\n\t} else {\n\t\t// find insert pos\n\t\tfor (var k = 0; k < this.intervals.length; k++) {\n\t\t\tvar i = this.intervals[k];\n\t\t\t// distinct range -> insert\n\t\t\tif (v.stop < i.start) {\n\t\t\t\tthis.intervals.splice(k, 0, v);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// contiguous range -> adjust\n\t\t\telse if (v.stop === i.start) {\n\t\t\t\tthis.intervals[k].start = v.start;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// overlapping range -> adjust and reduce\n\t\t\telse if (v.start <= i.stop) {\n\t\t\t\tthis.intervals[k] = new Interval(Math.min(i.start, v.start), Math.max(i.stop, v.stop));\n\t\t\t\tthis.reduce(k);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\t// greater than any existing\n\t\tthis.intervals.push(v);\n\t}\n};\n\nIntervalSet.prototype.addSet = function(other) {\n\tif (other.intervals !== null) {\n\t\tfor (var k = 0; k < other.intervals.length; k++) {\n\t\t\tvar i = other.intervals[k];\n\t\t\tthis.addInterval(new Interval(i.start, i.stop));\n\t\t}\n\t}\n\treturn this;\n};\n\nIntervalSet.prototype.reduce = function(k) {\n\t// only need to reduce if k is not the last\n\tif (k < this.intervalslength - 1) {\n\t\tvar l = this.intervals[k];\n\t\tvar r = this.intervals[k + 1];\n\t\t// if r contained in l\n\t\tif (l.stop >= r.stop) {\n\t\t\tthis.intervals.pop(k + 1);\n\t\t\tthis.reduce(k);\n\t\t} else if (l.stop >= r.start) {\n\t\t\tthis.intervals[k] = new Interval(l.start, r.stop);\n\t\t\tthis.intervals.pop(k + 1);\n\t\t}\n\t}\n};\n\nIntervalSet.prototype.complement = function(start, stop) {\n    var result = new IntervalSet();\n    result.addInterval(new Interval(start,stop+1));\n    for(var i=0; i<this.intervals.length; i++) {\n        result.removeRange(this.intervals[i]);\n    }\n    return result;\n};\n\nIntervalSet.prototype.contains = function(item) {\n\tif (this.intervals === null) {\n\t\treturn false;\n\t} else {\n\t\tfor (var k = 0; k < this.intervals.length; k++) {\n\t\t\tif(this.intervals[k].contains(item)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n};\n\nObject.defineProperty(IntervalSet.prototype, \"length\", {\n\tget : function() {\n\t\tvar len = 0;\n\t\tthis.intervals.map(function(i) {len += i.length;});\n\t\treturn len;\n\t}\n});\n\nIntervalSet.prototype.removeRange = function(v) {\n    if(v.start===v.stop-1) {\n        this.removeOne(v.start);\n    } else if (this.intervals!==null) {\n        var k = 0;\n        for(var n=0; n<this.intervals.length; n++) {\n            var i = this.intervals[k];\n            // intervals are ordered\n            if (v.stop<=i.start) {\n                return;\n            }\n            // check for including range, split it\n            else if(v.start>i.start && v.stop<i.stop) {\n                this.intervals[k] = new Interval(i.start, v.start);\n                var x = new Interval(v.stop, i.stop);\n                this.intervals.splice(k, 0, x);\n                return;\n            }\n            // check for included range, remove it\n            else if(v.start<=i.start && v.stop>=i.stop) {\n                this.intervals.splice(k, 1);\n                k = k - 1; // need another pass\n            }\n            // check for lower boundary\n            else if(v.start<i.stop) {\n                this.intervals[k] = new Interval(i.start, v.start);\n            }\n            // check for upper boundary\n            else if(v.stop<i.stop) {\n                this.intervals[k] = new Interval(v.stop, i.stop);\n            }\n            k += 1;\n        }\n    }\n};\n\nIntervalSet.prototype.removeOne = function(v) {\n\tif (this.intervals !== null) {\n\t\tfor (var k = 0; k < this.intervals.length; k++) {\n\t\t\tvar i = this.intervals[k];\n\t\t\t// intervals is ordered\n\t\t\tif (v < i.start) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// check for single value range\n\t\t\telse if (v === i.start && v === i.stop - 1) {\n\t\t\t\tthis.intervals.splice(k, 1);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// check for lower boundary\n\t\t\telse if (v === i.start) {\n\t\t\t\tthis.intervals[k] = new Interval(i.start + 1, i.stop);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// check for upper boundary\n\t\t\telse if (v === i.stop - 1) {\n\t\t\t\tthis.intervals[k] = new Interval(i.start, i.stop - 1);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// split existing range\n\t\t\telse if (v < i.stop - 1) {\n\t\t\t\tvar x = new Interval(i.start, v);\n\t\t\t\ti.start = v + 1;\n\t\t\t\tthis.intervals.splice(k, 0, x);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n};\n\nIntervalSet.prototype.toString = function(literalNames, symbolicNames, elemsAreChar) {\n\tliteralNames = literalNames || null;\n\tsymbolicNames = symbolicNames || null;\n\telemsAreChar = elemsAreChar || false;\n\tif (this.intervals === null) {\n\t\treturn \"{}\";\n\t} else if(literalNames!==null || symbolicNames!==null) {\n\t\treturn this.toTokenString(literalNames, symbolicNames);\n\t} else if(elemsAreChar) {\n\t\treturn this.toCharString();\n\t} else {\n\t\treturn this.toIndexString();\n\t}\n};\n\nIntervalSet.prototype.toCharString = function() {\n\tvar names = [];\n\tfor (var i = 0; i < this.intervals.length; i++) {\n\t\tvar v = this.intervals[i];\n\t\tif(v.stop===v.start+1) {\n\t\t\tif ( v.start===Token.EOF ) {\n\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t} else {\n\t\t\t\tnames.push(\"'\" + String.fromCharCode(v.start) + \"'\");\n\t\t\t}\n\t\t} else {\n\t\t\tnames.push(\"'\" + String.fromCharCode(v.start) + \"'..'\" + String.fromCharCode(v.stop-1) + \"'\");\n\t\t}\n\t}\n\tif (names.length > 1) {\n\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t} else {\n\t\treturn names[0];\n\t}\n};\n\n\nIntervalSet.prototype.toIndexString = function() {\n\tvar names = [];\n\tfor (var i = 0; i < this.intervals.length; i++) {\n\t\tvar v = this.intervals[i];\n\t\tif(v.stop===v.start+1) {\n\t\t\tif ( v.start===Token.EOF ) {\n\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t} else {\n\t\t\t\tnames.push(v.start.toString());\n\t\t\t}\n\t\t} else {\n\t\t\tnames.push(v.start.toString() + \"..\" + (v.stop-1).toString());\n\t\t}\n\t}\n\tif (names.length > 1) {\n\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t} else {\n\t\treturn names[0];\n\t}\n};\n\n\nIntervalSet.prototype.toTokenString = function(literalNames, symbolicNames) {\n\tvar names = [];\n\tfor (var i = 0; i < this.intervals.length; i++) {\n\t\tvar v = this.intervals[i];\n\t\tfor (var j = v.start; j < v.stop; j++) {\n\t\t\tnames.push(this.elementName(literalNames, symbolicNames, j));\n\t\t}\n\t}\n\tif (names.length > 1) {\n\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t} else {\n\t\treturn names[0];\n\t}\n};\n\nIntervalSet.prototype.elementName = function(literalNames, symbolicNames, a) {\n\tif (a === Token.EOF) {\n\t\treturn \"<EOF>\";\n\t} else if (a === Token.EPSILON) {\n\t\treturn \"<EPSILON>\";\n\t} else {\n\t\treturn literalNames[a] || symbolicNames[a];\n\t}\n};\n\nexports.Interval = Interval;\nexports.IntervalSet = IntervalSet;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/IntervalSet.js\n ** module id = 13\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n\n//  An ATN transition between any two ATN states.  Subclasses define\n//  atom, set, epsilon, action, predicate, rule transitions.\n//\n//  <p>This is a one way link.  It emanates from a state (usually via a list of\n//  transitions) and has a target state.</p>\n//\n//  <p>Since we never have to change the ATN transitions once we construct it,\n//  we can fix these transitions as specific classes. The DFA transitions\n//  on the other hand need to update the labels as it adds transitions to\n//  the states. We'll use the term Edge for the DFA to distinguish them from\n//  ATN transitions.</p>\n\nvar Token = require('./../Token').Token;\nvar Interval = require('./../IntervalSet').Interval;\nvar IntervalSet = require('./../IntervalSet').IntervalSet;\nvar Predicate = require('./SemanticContext').Predicate;\nvar PrecedencePredicate = require('./SemanticContext').PrecedencePredicate;\n\nfunction Transition (target) {\n    // The target of this transition.\n    if (target===undefined || target===null) {\n        throw \"target cannot be null.\";\n    }\n    this.target = target;\n    // Are we epsilon, action, sempred?\n    this.isEpsilon = false;\n    this.label = null;\n    return this;\n}\n    // constants for serialization\nTransition.EPSILON = 1;\nTransition.RANGE = 2;\nTransition.RULE = 3;\nTransition.PREDICATE = 4; // e.g., {isType(input.LT(1))}?\nTransition.ATOM = 5;\nTransition.ACTION = 6;\nTransition.SET = 7; // ~(A|B) or ~atom, wildcard, which convert to next 2\nTransition.NOT_SET = 8;\nTransition.WILDCARD = 9;\nTransition.PRECEDENCE = 10;\n\nTransition.serializationNames = [\n            \"INVALID\",\n            \"EPSILON\",\n            \"RANGE\",\n            \"RULE\",\n            \"PREDICATE\",\n            \"ATOM\",\n            \"ACTION\",\n            \"SET\",\n            \"NOT_SET\",\n            \"WILDCARD\",\n            \"PRECEDENCE\"\n        ];\n\nTransition.serializationTypes = {\n        EpsilonTransition: Transition.EPSILON,\n        RangeTransition: Transition.RANGE,\n        RuleTransition: Transition.RULE,\n        PredicateTransition: Transition.PREDICATE,\n        AtomTransition: Transition.ATOM,\n        ActionTransition: Transition.ACTION,\n        SetTransition: Transition.SET,\n        NotSetTransition: Transition.NOT_SET,\n        WildcardTransition: Transition.WILDCARD,\n        PrecedencePredicateTransition: Transition.PRECEDENCE\n    };\n\n\n// TODO: make all transitions sets? no, should remove set edges\nfunction AtomTransition(target, label) {\n\tTransition.call(this, target);\n\tthis.label_ = label; // The token type or character value; or, signifies special label.\n    this.label = this.makeLabel();\n    this.serializationType = Transition.ATOM;\n    return this;\n}\n\nAtomTransition.prototype = Object.create(Transition.prototype);\nAtomTransition.prototype.constructor = AtomTransition;\n\nAtomTransition.prototype.makeLabel = function() {\n\tvar s = new IntervalSet();\n    s.addOne(this.label_);\n    return s;\n};\n\nAtomTransition.prototype.matches = function( symbol, minVocabSymbol,  maxVocabSymbol) {\n    return this.label_ === symbol;\n};\n\nAtomTransition.prototype.toString = function() {\n\treturn this.label_;\n};\n\nfunction RuleTransition(ruleStart, ruleIndex, precedence, followState) {\n\tTransition.call(this, ruleStart);\n    this.ruleIndex = ruleIndex; // ptr to the rule definition object for this rule ref\n    this.precedence = precedence;\n    this.followState = followState; // what node to begin computations following ref to rule\n    this.serializationType = Transition.RULE;\n    this.isEpsilon = true;\n    return this;\n}\n\nRuleTransition.prototype = Object.create(Transition.prototype);\nRuleTransition.prototype.constructor = RuleTransition;\n\nRuleTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn false;\n};\n\n\nfunction EpsilonTransition(target, outermostPrecedenceReturn) {\n\tTransition.call(this, target);\n    this.serializationType = Transition.EPSILON;\n    this.isEpsilon = true;\n    this.outermostPrecedenceReturn = outermostPrecedenceReturn;\n    return this;\n}\n\nEpsilonTransition.prototype = Object.create(Transition.prototype);\nEpsilonTransition.prototype.constructor = EpsilonTransition;\n\nEpsilonTransition.prototype.matches = function( symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn false;\n};\n\nEpsilonTransition.prototype.toString = function() {\n\treturn \"epsilon\";\n};\n\nfunction RangeTransition(target, start, stop) {\n\tTransition.call(this, target);\n\tthis.serializationType = Transition.RANGE;\n    this.start = start;\n    this.stop = stop;\n    this.label = this.makeLabel();\n    return this;\n}\n\nRangeTransition.prototype = Object.create(Transition.prototype);\nRangeTransition.prototype.constructor = RangeTransition;\n\nRangeTransition.prototype.makeLabel = function() {\n    var s = new IntervalSet();\n    s.addRange(this.start, this.stop);\n    return s;\n};\n\nRangeTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn symbol >= this.start && symbol <= this.stop;\n};\n\nRangeTransition.prototype.toString = function() {\n\treturn \"'\" + String.fromCharCode(this.start) + \"'..'\" + String.fromCharCode(this.stop) + \"'\";\n};\n\nfunction AbstractPredicateTransition(target) {\n\tTransition.call(this, target);\n\treturn this;\n}\n\nAbstractPredicateTransition.prototype = Object.create(Transition.prototype);\nAbstractPredicateTransition.prototype.constructor = AbstractPredicateTransition;\n\nfunction PredicateTransition(target, ruleIndex, predIndex, isCtxDependent) {\n\tAbstractPredicateTransition.call(this, target);\n    this.serializationType = Transition.PREDICATE;\n    this.ruleIndex = ruleIndex;\n    this.predIndex = predIndex;\n    this.isCtxDependent = isCtxDependent; // e.g., $i ref in pred\n    this.isEpsilon = true;\n    return this;\n}\n\nPredicateTransition.prototype = Object.create(AbstractPredicateTransition.prototype);\nPredicateTransition.prototype.constructor = PredicateTransition;\n\nPredicateTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn false;\n};\n\nPredicateTransition.prototype.getPredicate = function() {\n\treturn new Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);\n};\n\nPredicateTransition.prototype.toString = function() {\n\treturn \"pred_\" + this.ruleIndex + \":\" + this.predIndex;\n};\n\nfunction ActionTransition(target, ruleIndex, actionIndex, isCtxDependent) {\n\tTransition.call(this, target);\n    this.serializationType = Transition.ACTION;\n    this.ruleIndex = ruleIndex;\n    this.actionIndex = actionIndex===undefined ? -1 : actionIndex;\n    this.isCtxDependent = isCtxDependent===undefined ? false : isCtxDependent; // e.g., $i ref in pred\n    this.isEpsilon = true;\n    return this;\n}\n\nActionTransition.prototype = Object.create(Transition.prototype);\nActionTransition.prototype.constructor = ActionTransition;\n\n\nActionTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn false;\n};\n\nActionTransition.prototype.toString = function() {\n\treturn \"action_\" + this.ruleIndex + \":\" + this.actionIndex;\n};\n        \n\n// A transition containing a set of values.\nfunction SetTransition(target, set) {\n\tTransition.call(this, target);\n\tthis.serializationType = Transition.SET;\n    if (set !==undefined && set !==null) {\n        this.label = set;\n    } else {\n        this.label = new IntervalSet();\n        this.label.addOne(Token.INVALID_TYPE);\n    }\n    return this;\n}\n\nSetTransition.prototype = Object.create(Transition.prototype);\nSetTransition.prototype.constructor = SetTransition;\n\nSetTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn this.label.contains(symbol);\n};\n        \n\nSetTransition.prototype.toString = function() {\n\treturn this.label.toString();\n};\n\nfunction NotSetTransition(target, set) {\n\tSetTransition.call(this, target, set);\n\tthis.serializationType = Transition.NOT_SET;\n\treturn this;\n}\n\nNotSetTransition.prototype = Object.create(SetTransition.prototype);\nNotSetTransition.prototype.constructor = NotSetTransition;\n\nNotSetTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn symbol >= minVocabSymbol && symbol <= maxVocabSymbol &&\n\t\t\t!SetTransition.prototype.matches.call(this, symbol, minVocabSymbol, maxVocabSymbol);\n};\n\nNotSetTransition.prototype.toString = function() {\n\treturn '~' + SetTransition.prototype.toString.call(this);\n};\n\nfunction WildcardTransition(target) {\n\tTransition.call(this, target);\n\tthis.serializationType = Transition.WILDCARD;\n\treturn this;\n}\n\nWildcardTransition.prototype = Object.create(Transition.prototype);\nWildcardTransition.prototype.constructor = WildcardTransition;\n\n\nWildcardTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn symbol >= minVocabSymbol && symbol <= maxVocabSymbol;\n};\n\nWildcardTransition.prototype.toString = function() {\n\treturn \".\";\n};\n\nfunction PrecedencePredicateTransition(target, precedence) {\n\tAbstractPredicateTransition.call(this, target);\n    this.serializationType = Transition.PRECEDENCE;\n    this.precedence = precedence;\n    this.isEpsilon = true;\n    return this;\n}\n\nPrecedencePredicateTransition.prototype = Object.create(AbstractPredicateTransition.prototype);\nPrecedencePredicateTransition.prototype.constructor = PrecedencePredicateTransition;\n\nPrecedencePredicateTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn false;\n};\n\nPrecedencePredicateTransition.prototype.getPredicate = function() {\n\treturn new PrecedencePredicate(this.precedence);\n};\n\nPrecedencePredicateTransition.prototype.toString = function() {\n\treturn this.precedence + \" >= _p\";\n};\n        \nexports.Transition = Transition;\nexports.AtomTransition = AtomTransition;\nexports.SetTransition = SetTransition;\nexports.NotSetTransition = NotSetTransition;\nexports.RuleTransition = RuleTransition;\nexports.ActionTransition = ActionTransition;\nexports.EpsilonTransition = EpsilonTransition;\nexports.RangeTransition = RangeTransition;\nexports.WildcardTransition = WildcardTransition;\nexports.PredicateTransition = PredicateTransition;\nexports.PrecedencePredicateTransition = PrecedencePredicateTransition;\nexports.AbstractPredicateTransition = AbstractPredicateTransition;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/Transition.js\n ** module id = 14\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\nvar RuleContext = require('./RuleContext').RuleContext;\n\nfunction PredictionContext(cachedHashString) {\n\tthis.cachedHashString = cachedHashString;\n}\n\n// Represents {@code $} in local context prediction, which means wildcard.\n// {@code//+x =//}.\n// /\nPredictionContext.EMPTY = null;\n\n// Represents {@code $} in an array in full context mode, when {@code $}\n// doesn't mean wildcard: {@code $ + x = [$,x]}. Here,\n// {@code $} = {@link //EMPTY_RETURN_STATE}.\n// /\nPredictionContext.EMPTY_RETURN_STATE = 0x7FFFFFFF;\n\nPredictionContext.globalNodeCount = 1;\nPredictionContext.id = PredictionContext.globalNodeCount;\n\n// Stores the computed hash code of this {@link PredictionContext}. The hash\n// code is computed in parts to match the following reference algorithm.\n//\n// <pre>\n// private int referenceHashCode() {\n// int hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link\n// //INITIAL_HASH});\n//\n// for (int i = 0; i &lt; {@link //size()}; i++) {\n// hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //getParent\n// getParent}(i));\n// }\n//\n// for (int i = 0; i &lt; {@link //size()}; i++) {\n// hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link\n// //getReturnState getReturnState}(i));\n// }\n//\n// hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link\n// //size()});\n// return hash;\n// }\n// </pre>\n// /\n\n// This means only the {@link //EMPTY} context is in set.\nPredictionContext.prototype.isEmpty = function() {\n\treturn this === PredictionContext.EMPTY;\n};\n\nPredictionContext.prototype.hasEmptyPath = function() {\n\treturn this.getReturnState(this.length - 1) === PredictionContext.EMPTY_RETURN_STATE;\n};\n\nPredictionContext.prototype.hashString = function() {\n\treturn this.cachedHashString;\n};\n\nfunction calculateHashString(parent, returnState) {\n\treturn \"\" + parent + returnState;\n}\n\nfunction calculateEmptyHashString() {\n\treturn \"\";\n}\n\n// Used to cache {@link PredictionContext} objects. Its used for the shared\n// context cash associated with contexts in DFA states. This cache\n// can be used for both lexers and parsers.\n\nfunction PredictionContextCache() {\n\tthis.cache = {};\n\treturn this;\n}\n\n// Add a context to the cache and return it. If the context already exists,\n// return that one instead and do not add a new context to the cache.\n// Protect shared cache from unsafe thread access.\n//\nPredictionContextCache.prototype.add = function(ctx) {\n\tif (ctx === PredictionContext.EMPTY) {\n\t\treturn PredictionContext.EMPTY;\n\t}\n\tvar existing = this.cache[ctx] || null;\n\tif (existing !== null) {\n\t\treturn existing;\n\t}\n\tthis.cache[ctx] = ctx;\n\treturn ctx;\n};\n\nPredictionContextCache.prototype.get = function(ctx) {\n\treturn this.cache[ctx] || null;\n};\n\nObject.defineProperty(PredictionContextCache.prototype, \"length\", {\n\tget : function() {\n\t\treturn this.cache.length;\n\t}\n});\n\nfunction SingletonPredictionContext(parent, returnState) {\n\tvar hashString = parent !== null ? calculateHashString(parent, returnState)\n\t\t\t: calculateEmptyHashString();\n\tPredictionContext.call(this, hashString);\n\tthis.parentCtx = parent;\n\tthis.returnState = returnState;\n}\n\nSingletonPredictionContext.prototype = Object.create(PredictionContext.prototype);\nSingletonPredictionContext.prototype.contructor = SingletonPredictionContext;\n\nSingletonPredictionContext.create = function(parent, returnState) {\n\tif (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {\n\t\t// someone can pass in the bits of an array ctx that mean $\n\t\treturn PredictionContext.EMPTY;\n\t} else {\n\t\treturn new SingletonPredictionContext(parent, returnState);\n\t}\n};\n\nObject.defineProperty(SingletonPredictionContext.prototype, \"length\", {\n\tget : function() {\n\t\treturn 1;\n\t}\n});\n\nSingletonPredictionContext.prototype.getParent = function(index) {\n\treturn this.parentCtx;\n};\n\nSingletonPredictionContext.prototype.getReturnState = function(index) {\n\treturn this.returnState;\n};\n\nSingletonPredictionContext.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof SingletonPredictionContext)) {\n\t\treturn false;\n\t} else if (this.hashString() !== other.hashString()) {\n\t\treturn false; // can't be same if hash is different\n\t} else {\n\t\tif(this.returnState !== other.returnState)\n            return false;\n        else if(this.parentCtx==null)\n            return other.parentCtx==null\n\t\telse\n            return this.parentCtx.equals(other.parentCtx);\n\t}\n};\n\nSingletonPredictionContext.prototype.hashString = function() {\n\treturn this.cachedHashString;\n};\n\nSingletonPredictionContext.prototype.toString = function() {\n\tvar up = this.parentCtx === null ? \"\" : this.parentCtx.toString();\n\tif (up.length === 0) {\n\t\tif (this.returnState === this.EMPTY_RETURN_STATE) {\n\t\t\treturn \"$\";\n\t\t} else {\n\t\t\treturn \"\" + this.returnState;\n\t\t}\n\t} else {\n\t\treturn \"\" + this.returnState + \" \" + up;\n\t}\n};\n\nfunction EmptyPredictionContext() {\n\tSingletonPredictionContext.call(this, null, PredictionContext.EMPTY_RETURN_STATE);\n\treturn this;\n}\n\nEmptyPredictionContext.prototype = Object.create(SingletonPredictionContext.prototype);\nEmptyPredictionContext.prototype.constructor = EmptyPredictionContext;\n\nEmptyPredictionContext.prototype.isEmpty = function() {\n\treturn true;\n};\n\nEmptyPredictionContext.prototype.getParent = function(index) {\n\treturn null;\n};\n\nEmptyPredictionContext.prototype.getReturnState = function(index) {\n\treturn this.returnState;\n};\n\nEmptyPredictionContext.prototype.equals = function(other) {\n\treturn this === other;\n};\n\nEmptyPredictionContext.prototype.toString = function() {\n\treturn \"$\";\n};\n\nPredictionContext.EMPTY = new EmptyPredictionContext();\n\nfunction ArrayPredictionContext(parents, returnStates) {\n\t// Parent can be null only if full ctx mode and we make an array\n\t// from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using\n\t// null parent and\n\t// returnState == {@link //EMPTY_RETURN_STATE}.\n\tvar hash = calculateHashString(parents, returnStates);\n\tPredictionContext.call(this, hash);\n\tthis.parents = parents;\n\tthis.returnStates = returnStates;\n\treturn this;\n}\n\nArrayPredictionContext.prototype = Object.create(PredictionContext.prototype);\nArrayPredictionContext.prototype.constructor = ArrayPredictionContext;\n\nArrayPredictionContext.prototype.isEmpty = function() {\n\t// since EMPTY_RETURN_STATE can only appear in the last position, we\n\t// don't need to verify that size==1\n\treturn this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;\n};\n\nObject.defineProperty(ArrayPredictionContext.prototype, \"length\", {\n\tget : function() {\n\t\treturn this.returnStates.length;\n\t}\n});\n\nArrayPredictionContext.prototype.getParent = function(index) {\n\treturn this.parents[index];\n};\n\nArrayPredictionContext.prototype.getReturnState = function(index) {\n\treturn this.returnStates[index];\n};\n\nArrayPredictionContext.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof ArrayPredictionContext)) {\n\t\treturn false;\n\t} else if (this.hashString !== other.hashString()) {\n\t\treturn false; // can't be same if hash is different\n\t} else {\n\t\treturn this.returnStates === other.returnStates &&\n\t\t\t\tthis.parents === other.parents;\n\t}\n};\n\nArrayPredictionContext.prototype.toString = function() {\n\tif (this.isEmpty()) {\n\t\treturn \"[]\";\n\t} else {\n\t\tvar s = \"[\";\n\t\tfor (var i = 0; i < this.returnStates.length; i++) {\n\t\t\tif (i > 0) {\n\t\t\t\ts = s + \", \";\n\t\t\t}\n\t\t\tif (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\ts = s + \"$\";\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ts = s + this.returnStates[i];\n\t\t\tif (this.parents[i] !== null) {\n\t\t\t\ts = s + \" \" + this.parents[i];\n\t\t\t} else {\n\t\t\t\ts = s + \"null\";\n\t\t\t}\n\t\t}\n\t\treturn s + \"]\";\n\t}\n};\n\n// Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.\n// Return {@link //EMPTY} if {@code outerContext} is empty or null.\n// /\nfunction predictionContextFromRuleContext(atn, outerContext) {\n\tif (outerContext === undefined || outerContext === null) {\n\t\touterContext = RuleContext.EMPTY;\n\t}\n\t// if we are in RuleContext of start rule, s, then PredictionContext\n\t// is EMPTY. Nobody called us. (if we are empty, return empty)\n\tif (outerContext.parentCtx === null || outerContext === RuleContext.EMPTY) {\n\t\treturn PredictionContext.EMPTY;\n\t}\n\t// If we have a parent, convert it to a PredictionContext graph\n\tvar parent = predictionContextFromRuleContext(atn, outerContext.parentCtx);\n\tvar state = atn.states[outerContext.invokingState];\n\tvar transition = state.transitions[0];\n\treturn SingletonPredictionContext.create(parent, transition.followState.stateNumber);\n}\n\nfunction calculateListsHashString(parents, returnStates) {\n\tvar s = \"\";\n\tparents.map(function(p) {\n\t\ts = s + p;\n\t});\n\treturnStates.map(function(r) {\n\t\ts = s + r;\n\t});\n\treturn s;\n}\n\nfunction merge(a, b, rootIsWildcard, mergeCache) {\n\t// share same graph if both same\n\tif (a === b) {\n\t\treturn a;\n\t}\n\tif (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n\t\treturn mergeSingletons(a, b, rootIsWildcard, mergeCache);\n\t}\n\t// At least one of a or b is array\n\t// If one is $ and rootIsWildcard, return $ as// wildcard\n\tif (rootIsWildcard) {\n\t\tif (a instanceof EmptyPredictionContext) {\n\t\t\treturn a;\n\t\t}\n\t\tif (b instanceof EmptyPredictionContext) {\n\t\t\treturn b;\n\t\t}\n\t}\n\t// convert singleton so both are arrays to normalize\n\tif (a instanceof SingletonPredictionContext) {\n\t\ta = new ArrayPredictionContext([a.getParent()], [a.returnState]);\n\t}\n\tif (b instanceof SingletonPredictionContext) {\n\t\tb = new ArrayPredictionContext([b.getParent()], [b.returnState]);\n\t}\n\treturn mergeArrays(a, b, rootIsWildcard, mergeCache);\n}\n\n//\n// Merge two {@link SingletonPredictionContext} instances.\n//\n// <p>Stack tops equal, parents merge is same; return left graph.<br>\n// <embed src=\"images/SingletonMerge_SameRootSamePar.svg\"\n// type=\"image/svg+xml\"/></p>\n//\n// <p>Same stack top, parents differ; merge parents giving array node, then\n// remainders of those graphs. A new root node is created to point to the\n// merged parents.<br>\n// <embed src=\"images/SingletonMerge_SameRootDiffPar.svg\"\n// type=\"image/svg+xml\"/></p>\n//\n// <p>Different stack tops pointing to same parent. Make array node for the\n// root where both element in the root point to the same (original)\n// parent.<br>\n// <embed src=\"images/SingletonMerge_DiffRootSamePar.svg\"\n// type=\"image/svg+xml\"/></p>\n//\n// <p>Different stack tops pointing to different parents. Make array node for\n// the root where each element points to the corresponding original\n// parent.<br>\n// <embed src=\"images/SingletonMerge_DiffRootDiffPar.svg\"\n// type=\"image/svg+xml\"/></p>\n//\n// @param a the first {@link SingletonPredictionContext}\n// @param b the second {@link SingletonPredictionContext}\n// @param rootIsWildcard {@code true} if this is a local-context merge,\n// otherwise false to indicate a full-context merge\n// @param mergeCache\n// /\nfunction mergeSingletons(a, b, rootIsWildcard, mergeCache) {\n\tif (mergeCache !== null) {\n\t\tvar previous = mergeCache.get(a, b);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t\tprevious = mergeCache.get(b, a);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t}\n\n\tvar rootMerge = mergeRoot(a, b, rootIsWildcard);\n\tif (rootMerge !== null) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, rootMerge);\n\t\t}\n\t\treturn rootMerge;\n\t}\n\tif (a.returnState === b.returnState) {\n\t\tvar parent = merge(a.parentCtx, b.parentCtx, rootIsWildcard, mergeCache);\n\t\t// if parent is same as existing a or b parent or reduced to a parent,\n\t\t// return it\n\t\tif (parent === a.parentCtx) {\n\t\t\treturn a; // ax + bx = ax, if a=b\n\t\t}\n\t\tif (parent === b.parentCtx) {\n\t\t\treturn b; // ax + bx = bx, if a=b\n\t\t}\n\t\t// else: ax + ay = a'[x,y]\n\t\t// merge parents x and y, giving array node with x,y then remainders\n\t\t// of those graphs. dup a, a' points at merged array\n\t\t// new joined parent so create new singleton pointing to it, a'\n\t\tvar spc = SingletonPredictionContext.create(parent, a.returnState);\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, spc);\n\t\t}\n\t\treturn spc;\n\t} else { // a != b payloads differ\n\t\t// see if we can collapse parents due to $+x parents if local ctx\n\t\tvar singleParent = null;\n\t\tif (a === b || (a.parentCtx !== null && a.parentCtx === b.parentCtx)) { // ax +\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// bx =\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// [a,b]x\n\t\t\tsingleParent = a.parentCtx;\n\t\t}\n\t\tif (singleParent !== null) { // parents are same\n\t\t\t// sort payloads and use same parent\n\t\t\tvar payloads = [ a.returnState, b.returnState ];\n\t\t\tif (a.returnState > b.returnState) {\n\t\t\t\tpayloads[0] = b.returnState;\n\t\t\t\tpayloads[1] = a.returnState;\n\t\t\t}\n\t\t\tvar parents = [ singleParent, singleParent ];\n\t\t\tvar apc = new ArrayPredictionContext(parents, payloads);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, apc);\n\t\t\t}\n\t\t\treturn apc;\n\t\t}\n\t\t// parents differ and can't merge them. Just pack together\n\t\t// into array; can't merge.\n\t\t// ax + by = [ax,by]\n\t\tvar payloads = [ a.returnState, b.returnState ];\n\t\tvar parents = [ a.parentCtx, b.parentCtx ];\n\t\tif (a.returnState > b.returnState) { // sort by payload\n\t\t\tpayloads[0] = b.returnState;\n\t\t\tpayloads[1] = a.returnState;\n\t\t\tparents = [ b.parentCtx, a.parentCtx ];\n\t\t}\n\t\tvar a_ = new ArrayPredictionContext(parents, payloads);\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, a_);\n\t\t}\n\t\treturn a_;\n\t}\n}\n\n//\n// Handle case where at least one of {@code a} or {@code b} is\n// {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used\n// to represent {@link //EMPTY}.\n//\n// <h2>Local-Context Merges</h2>\n//\n// <p>These local-context merge operations are used when {@code rootIsWildcard}\n// is true.</p>\n//\n// <p>{@link //EMPTY} is superset of any graph; return {@link //EMPTY}.<br>\n// <embed src=\"images/LocalMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is\n// {@code //EMPTY}; return left graph.<br>\n// <embed src=\"images/LocalMerge_EmptyParent.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>Special case of last merge if local context.<br>\n// <embed src=\"images/LocalMerge_DiffRoots.svg\" type=\"image/svg+xml\"/></p>\n//\n// <h2>Full-Context Merges</h2>\n//\n// <p>These full-context merge operations are used when {@code rootIsWildcard}\n// is false.</p>\n//\n// <p><embed src=\"images/FullMerge_EmptyRoots.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>Must keep all contexts; {@link //EMPTY} in array is a special value (and\n// null parent).<br>\n// <embed src=\"images/FullMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p><embed src=\"images/FullMerge_SameRoot.svg\" type=\"image/svg+xml\"/></p>\n//\n// @param a the first {@link SingletonPredictionContext}\n// @param b the second {@link SingletonPredictionContext}\n// @param rootIsWildcard {@code true} if this is a local-context merge,\n// otherwise false to indicate a full-context merge\n// /\nfunction mergeRoot(a, b, rootIsWildcard) {\n\tif (rootIsWildcard) {\n\t\tif (a === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // // + b =//\n\t\t}\n\t\tif (b === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // a +// =//\n\t\t}\n\t} else {\n\t\tif (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // $ + $ = $\n\t\t} else if (a === PredictionContext.EMPTY) { // $ + x = [$,x]\n\t\t\tvar payloads = [ b.returnState,\n\t\t\t\t\tPredictionContext.EMPTY_RETURN_STATE ];\n\t\t\tvar parents = [ b.parentCtx, null ];\n\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t} else if (b === PredictionContext.EMPTY) { // x + $ = [$,x] ($ is always first if present)\n\t\t\tvar payloads = [ a.returnState, PredictionContext.EMPTY_RETURN_STATE ];\n\t\t\tvar parents = [ a.parentCtx, null ];\n\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t}\n\t}\n\treturn null;\n}\n\n//\n// Merge two {@link ArrayPredictionContext} instances.\n//\n// <p>Different tops, different parents.<br>\n// <embed src=\"images/ArrayMerge_DiffTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>Shared top, same parents.<br>\n// <embed src=\"images/ArrayMerge_ShareTopSamePar.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>Shared top, different parents.<br>\n// <embed src=\"images/ArrayMerge_ShareTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>Shared top, all shared parents.<br>\n// <embed src=\"images/ArrayMerge_ShareTopSharePar.svg\"\n// type=\"image/svg+xml\"/></p>\n//\n// <p>Equal tops, merge parents and reduce top to\n// {@link SingletonPredictionContext}.<br>\n// <embed src=\"images/ArrayMerge_EqualTop.svg\" type=\"image/svg+xml\"/></p>\n// /\nfunction mergeArrays(a, b, rootIsWildcard, mergeCache) {\n\tif (mergeCache !== null) {\n\t\tvar previous = mergeCache.get(a, b);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t\tprevious = mergeCache.get(b, a);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t}\n\t// merge sorted payloads a + b => M\n\tvar i = 0; // walks a\n\tvar j = 0; // walks b\n\tvar k = 0; // walks target M array\n\n\tvar mergedReturnStates = [];\n\tvar mergedParents = [];\n\t// walk and merge to yield mergedParents, mergedReturnStates\n\twhile (i < a.returnStates.length && j < b.returnStates.length) {\n\t\tvar a_parent = a.parents[i];\n\t\tvar b_parent = b.parents[j];\n\t\tif (a.returnStates[i] === b.returnStates[j]) {\n\t\t\t// same payload (stack tops are equal), must yield merged singleton\n\t\t\tvar payload = a.returnStates[i];\n\t\t\t// $+$ = $\n\t\t\tvar bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE &&\n\t\t\t\t\ta_parent === null && b_parent === null;\n\t\t\tvar ax_ax = (a_parent !== null && b_parent !== null && a_parent === b_parent); // ax+ax\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ->\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ax\n\t\t\tif (bothDollars || ax_ax) {\n\t\t\t\tmergedParents[k] = a_parent; // choose left\n\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t} else { // ax+ay -> a'[x,y]\n\t\t\t\tvar mergedParent = merge(a_parent, b_parent, rootIsWildcard, mergeCache);\n\t\t\t\tmergedParents[k] = mergedParent;\n\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t}\n\t\t\ti += 1; // hop over left one as usual\n\t\t\tj += 1; // but also skip one in right side since we merge\n\t\t} else if (a.returnStates[i] < b.returnStates[j]) { // copy a[i] to M\n\t\t\tmergedParents[k] = a_parent;\n\t\t\tmergedReturnStates[k] = a.returnStates[i];\n\t\t\ti += 1;\n\t\t} else { // b > a, copy b[j] to M\n\t\t\tmergedParents[k] = b_parent;\n\t\t\tmergedReturnStates[k] = b.returnStates[j];\n\t\t\tj += 1;\n\t\t}\n\t\tk += 1;\n\t}\n\t// copy over any payloads remaining in either array\n\tif (i < a.returnStates.length) {\n\t\tfor (var p = i; p < a.returnStates.length; p++) {\n\t\t\tmergedParents[k] = a.parents[p];\n\t\t\tmergedReturnStates[k] = a.returnStates[p];\n\t\t\tk += 1;\n\t\t}\n\t} else {\n\t\tfor (var p = j; p < b.returnStates.length; p++) {\n\t\t\tmergedParents[k] = b.parents[p];\n\t\t\tmergedReturnStates[k] = b.returnStates[p];\n\t\t\tk += 1;\n\t\t}\n\t}\n\t// trim merged if we combined a few that had same stack tops\n\tif (k < mergedParents.length) { // write index < last position; trim\n\t\tif (k === 1) { // for just one merged element, return singleton top\n\t\t\tvar a_ = SingletonPredictionContext.create(mergedParents[0],\n\t\t\t\t\tmergedReturnStates[0]);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, a_);\n\t\t\t}\n\t\t\treturn a_;\n\t\t}\n\t\tmergedParents = mergedParents.slice(0, k);\n\t\tmergedReturnStates = mergedReturnStates.slice(0, k);\n\t}\n\n\tvar M = new ArrayPredictionContext(mergedParents, mergedReturnStates);\n\n\t// if we created same array as a or b, return that instead\n\t// TODO: track whether this is possible above during merge sort for speed\n\tif (M === a) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, a);\n\t\t}\n\t\treturn a;\n\t}\n\tif (M === b) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, b);\n\t\t}\n\t\treturn b;\n\t}\n\tcombineCommonParents(mergedParents);\n\n\tif (mergeCache !== null) {\n\t\tmergeCache.set(a, b, M);\n\t}\n\treturn M;\n}\n\n//\n// Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}\n// ones.\n// /\nfunction combineCommonParents(parents) {\n\tvar uniqueParents = {};\n\n\tfor (var p = 0; p < parents.length; p++) {\n\t\tvar parent = parents[p];\n\t\tif (!(parent in uniqueParents)) {\n\t\t\tuniqueParents[parent] = parent;\n\t\t}\n\t}\n\tfor (var q = 0; q < parents.length; q++) {\n\t\tparents[q] = uniqueParents[parents[q]];\n\t}\n}\n\nfunction getCachedPredictionContext(context, contextCache, visited) {\n\tif (context.isEmpty()) {\n\t\treturn context;\n\t}\n\tvar existing = visited[context] || null;\n\tif (existing !== null) {\n\t\treturn existing;\n\t}\n\texisting = contextCache.get(context);\n\tif (existing !== null) {\n\t\tvisited[context] = existing;\n\t\treturn existing;\n\t}\n\tvar changed = false;\n\tvar parents = [];\n\tfor (var i = 0; i < parents.length; i++) {\n\t\tvar parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);\n\t\tif (changed || parent !== context.getParent(i)) {\n\t\t\tif (!changed) {\n\t\t\t\tparents = [];\n\t\t\t\tfor (var j = 0; j < context.length; j++) {\n\t\t\t\t\tparents[j] = context.getParent(j);\n\t\t\t\t}\n\t\t\t\tchanged = true;\n\t\t\t}\n\t\t\tparents[i] = parent;\n\t\t}\n\t}\n\tif (!changed) {\n\t\tcontextCache.add(context);\n\t\tvisited[context] = context;\n\t\treturn context;\n\t}\n\tvar updated = null;\n\tif (parents.length === 0) {\n\t\tupdated = PredictionContext.EMPTY;\n\t} else if (parents.length === 1) {\n\t\tupdated = SingletonPredictionContext.create(parents[0], context\n\t\t\t\t.getReturnState(0));\n\t} else {\n\t\tupdated = new ArrayPredictionContext(parents, context.returnStates);\n\t}\n\tcontextCache.add(updated);\n\tvisited[updated] = updated;\n\tvisited[context] = updated;\n\n\treturn updated;\n}\n\n// ter's recursive version of Sam's getAllNodes()\nfunction getAllContextNodes(context, nodes, visited) {\n\tif (nodes === null) {\n\t\tnodes = [];\n\t\treturn getAllContextNodes(context, nodes, visited);\n\t} else if (visited === null) {\n\t\tvisited = {};\n\t\treturn getAllContextNodes(context, nodes, visited);\n\t} else {\n\t\tif (context === null || visited[context] !== null) {\n\t\t\treturn nodes;\n\t\t}\n\t\tvisited[context] = context;\n\t\tnodes.push(context);\n\t\tfor (var i = 0; i < context.length; i++) {\n\t\t\tgetAllContextNodes(context.getParent(i), nodes, visited);\n\t\t}\n\t\treturn nodes;\n\t}\n}\n\nexports.merge = merge;\nexports.PredictionContext = PredictionContext;\nexports.PredictionContextCache = PredictionContextCache;\nexports.SingletonPredictionContext = SingletonPredictionContext;\nexports.predictionContextFromRuleContext = predictionContextFromRuleContext;\nexports.getCachedPredictionContext = getCachedPredictionContext;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/PredictionContext.js\n ** module id = 15\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2013 Terence Parr\n//  Copyright (c) 2013 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\n//  A rule context is a record of a single rule invocation. It knows\n//  which context invoked it, if any. If there is no parent context, then\n//  naturally the invoking state is not valid.  The parent link\n//  provides a chain upwards from the current rule invocation to the root\n//  of the invocation tree, forming a stack. We actually carry no\n//  information about the rule associated with this context (except\n//  when parsing). We keep only the state number of the invoking state from\n//  the ATN submachine that invoked this. Contrast this with the s\n//  pointer inside ParserRuleContext that tracks the current state\n//  being \"executed\" for the current rule.\n//\n//  The parent contexts are useful for computing lookahead sets and\n//  getting error information.\n//\n//  These objects are used during parsing and prediction.\n//  For the special case of parsers, we use the subclass\n//  ParserRuleContext.\n//\n//  @see ParserRuleContext\n///\n\nvar RuleNode = require('./tree/Tree').RuleNode;\nvar INVALID_INTERVAL = require('./tree/Tree').INVALID_INTERVAL;\nvar INVALID_ALT_NUMBER = require('./atn/ATN').INVALID_ALT_NUMBER;\n\nfunction RuleContext(parent, invokingState) {\n\tRuleNode.call(this);\n\t// What context invoked this rule?\n\tthis.parentCtx = parent || null;\n\t// What state invoked the rule associated with this context?\n\t// The \"return address\" is the followState of invokingState\n\t// If parent is null, this should be -1.\n\tthis.invokingState = invokingState || -1;\n\treturn this;\n}\n\nRuleContext.prototype = Object.create(RuleNode.prototype);\nRuleContext.prototype.constructor = RuleContext;\n\nRuleContext.prototype.depth = function() {\n\tvar n = 0;\n\tvar p = this;\n\twhile (p !== null) {\n\t\tp = p.parentCtx;\n\t\tn += 1;\n\t}\n\treturn n;\n};\n\n// A context is empty if there is no invoking state; meaning nobody call\n// current context.\nRuleContext.prototype.isEmpty = function() {\n\treturn this.invokingState === -1;\n};\n\n// satisfy the ParseTree / SyntaxTree interface\n\nRuleContext.prototype.getSourceInterval = function() {\n\treturn INVALID_INTERVAL;\n};\n\nRuleContext.prototype.getRuleContext = function() {\n\treturn this;\n};\n\nRuleContext.prototype.getPayload = function() {\n\treturn this;\n};\n\n// Return the combined text of all child nodes. This method only considers\n// tokens which have been added to the parse tree.\n// <p>\n// Since tokens on hidden channels (e.g. whitespace or comments) are not\n// added to the parse trees, they will not appear in the output of this\n// method.\n// /\nRuleContext.prototype.getText = function() {\n\tif (this.getChildCount() === 0) {\n\t\treturn \"\";\n\t} else {\n\t\treturn this.children.map(function(child) {\n\t\t\treturn child.getText();\n\t\t}).join(\"\");\n\t}\n};\n\n// For rule associated with this parse tree internal node, return\n// the outer alternative number used to match the input. Default\n// implementation does not compute nor store this alt num. Create\n// a subclass of ParserRuleContext with backing field and set\n// option contextSuperClass.\n// to set it.\nRuleContext.prototype.getAltNumber = function() { return INVALID_ALT_NUMBER; }\n\n// Set the outer alternative number for this context node. Default\n// implementation does nothing to avoid backing field overhead for\n// trees that don't need it.  Create\n// a subclass of ParserRuleContext with backing field and set\n// option contextSuperClass.\nRuleContext.prototype.setAltNumber = function(altNumber) { }\n\nRuleContext.prototype.getChild = function(i) {\n\treturn null;\n};\n\nRuleContext.prototype.getChildCount = function() {\n\treturn 0;\n};\n\nRuleContext.prototype.accept = function(visitor) {\n\treturn visitor.visitChildren(this);\n};\n\n//need to manage circular dependencies, so export now\nexports.RuleContext = RuleContext;\nvar Trees = require('./tree/Trees').Trees;\n\n\n// Print out a whole tree, not just a node, in LISP format\n// (root child1 .. childN). Print just a node if this is a leaf.\n//\n\nRuleContext.prototype.toStringTree = function(ruleNames, recog) {\n\treturn Trees.toStringTree(this, ruleNames, recog);\n};\n\nRuleContext.prototype.toString = function(ruleNames, stop) {\n\truleNames = ruleNames || null;\n\tstop = stop || null;\n\tvar p = this;\n\tvar s = \"[\";\n\twhile (p !== null && p !== stop) {\n\t\tif (ruleNames === null) {\n\t\t\tif (!p.isEmpty()) {\n\t\t\t\ts += p.invokingState;\n\t\t\t}\n\t\t} else {\n\t\t\tvar ri = p.ruleIndex;\n\t\t\tvar ruleName = (ri >= 0 && ri < ruleNames.length) ? ruleNames[ri]\n\t\t\t\t\t: \"\" + ri;\n\t\t\ts += ruleName;\n\t\t}\n\t\tif (p.parentCtx !== null && (ruleNames !== null || !p.parentCtx.isEmpty())) {\n\t\t\ts += \" \";\n\t\t}\n\t\tp = p.parentCtx;\n\t}\n\ts += \"]\";\n\treturn s;\n};\n\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/RuleContext.js\n ** module id = 16\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\n// The basic notion of a tree has a parent, a payload, and a list of children.\n//  It is the most abstract interface for all the trees used by ANTLR.\n///\n\nvar Token = require('./../Token').Token;\nvar Interval = require('./../IntervalSet').Interval;\nvar INVALID_INTERVAL = new Interval(-1, -2);\nvar Utils = require('../Utils.js');\n\n\nfunction Tree() {\n\treturn this;\n}\n\nfunction SyntaxTree() {\n\tTree.call(this);\n\treturn this;\n}\n\nSyntaxTree.prototype = Object.create(Tree.prototype);\nSyntaxTree.prototype.constructor = SyntaxTree;\n\nfunction ParseTree() {\n\tSyntaxTree.call(this);\n\treturn this;\n}\n\nParseTree.prototype = Object.create(SyntaxTree.prototype);\nParseTree.prototype.constructor = ParseTree;\n\nfunction RuleNode() {\n\tParseTree.call(this);\n\treturn this;\n}\n\nRuleNode.prototype = Object.create(ParseTree.prototype);\nRuleNode.prototype.constructor = RuleNode;\n\nfunction TerminalNode() {\n\tParseTree.call(this);\n\treturn this;\n}\n\nTerminalNode.prototype = Object.create(ParseTree.prototype);\nTerminalNode.prototype.constructor = TerminalNode;\n\nfunction ErrorNode() {\n\tTerminalNode.call(this);\n\treturn this;\n}\n\nErrorNode.prototype = Object.create(TerminalNode.prototype);\nErrorNode.prototype.constructor = ErrorNode;\n\nfunction ParseTreeVisitor() {\n\treturn this;\n}\n\nParseTreeVisitor.prototype.visit = function(ctx) {\n\tif (Utils.isArray(ctx)) {\n\t\tvar self = this;\n\t\treturn ctx.map(function(child) { return visitAtom(self, child)});\n\t} else {\n\t\treturn visitAtom(this, ctx);\n\t}\n};\n\nParseTreeVisitor.prototype.visitTerminal = function(node) {\n};\n\nParseTreeVisitor.prototype.visitErrorNode = function(node) {\n};\n\n\nvar visitAtom = function(visitor, ctx) {\n\tif (ctx.parser === undefined) { //is terminal\n\t\treturn;\n\t}\n\n\tvar name = ctx.parser.ruleNames[ctx.ruleIndex];\n\tvar funcName = \"visit\" + Utils.titleCase(name);\n\n\treturn visitor[funcName](ctx);\n};\n\nfunction ParseTreeListener() {\n\treturn this;\n}\n\nParseTreeListener.prototype.visitTerminal = function(node) {\n};\n\nParseTreeListener.prototype.visitErrorNode = function(node) {\n};\n\nParseTreeListener.prototype.enterEveryRule = function(node) {\n};\n\nParseTreeListener.prototype.exitEveryRule = function(node) {\n};\n\nfunction TerminalNodeImpl(symbol) {\n\tTerminalNode.call(this);\n\tthis.parentCtx = null;\n\tthis.symbol = symbol;\n\treturn this;\n}\n\nTerminalNodeImpl.prototype = Object.create(TerminalNode.prototype);\nTerminalNodeImpl.prototype.constructor = TerminalNodeImpl;\n\nTerminalNodeImpl.prototype.getChild = function(i) {\n\treturn null;\n};\n\nTerminalNodeImpl.prototype.getSymbol = function() {\n\treturn this.symbol;\n};\n\nTerminalNodeImpl.prototype.getParent = function() {\n\treturn this.parentCtx;\n};\n\nTerminalNodeImpl.prototype.getPayload = function() {\n\treturn this.symbol;\n};\n\nTerminalNodeImpl.prototype.getSourceInterval = function() {\n\tif (this.symbol === null) {\n\t\treturn INVALID_INTERVAL;\n\t}\n\tvar tokenIndex = this.symbol.tokenIndex;\n\treturn new Interval(tokenIndex, tokenIndex);\n};\n\nTerminalNodeImpl.prototype.getChildCount = function() {\n\treturn 0;\n};\n\nTerminalNodeImpl.prototype.accept = function(visitor) {\n\treturn visitor.visitTerminal(this);\n};\n\nTerminalNodeImpl.prototype.getText = function() {\n\treturn this.symbol.text;\n};\n\nTerminalNodeImpl.prototype.toString = function() {\n\tif (this.symbol.type === Token.EOF) {\n\t\treturn \"<EOF>\";\n\t} else {\n\t\treturn this.symbol.text;\n\t}\n};\n\n// Represents a token that was consumed during resynchronization\n// rather than during a valid match operation. For example,\n// we will create this kind of a node during single token insertion\n// and deletion as well as during \"consume until error recovery set\"\n// upon no viable alternative exceptions.\n\nfunction ErrorNodeImpl(token) {\n\tTerminalNodeImpl.call(this, token);\n\treturn this;\n}\n\nErrorNodeImpl.prototype = Object.create(TerminalNodeImpl.prototype);\nErrorNodeImpl.prototype.constructor = ErrorNodeImpl;\n\nErrorNodeImpl.prototype.isErrorNode = function() {\n\treturn true;\n};\n\nErrorNodeImpl.prototype.accept = function(visitor) {\n\treturn visitor.visitErrorNode(this);\n};\n\nfunction ParseTreeWalker() {\n\treturn this;\n}\n\nParseTreeWalker.prototype.walk = function(listener, t) {\n\tvar errorNode = t instanceof ErrorNode ||\n\t\t\t(t.isErrorNode !== undefined && t.isErrorNode());\n\tif (errorNode) {\n\t\tlistener.visitErrorNode(t);\n\t} else if (t instanceof TerminalNode) {\n\t\tlistener.visitTerminal(t);\n\t} else {\n\t\tthis.enterRule(listener, t);\n\t\tfor (var i = 0; i < t.getChildCount(); i++) {\n\t\t\tvar child = t.getChild(i);\n\t\t\tthis.walk(listener, child);\n\t\t}\n\t\tthis.exitRule(listener, t);\n\t}\n};\n//\n// The discovery of a rule node, involves sending two events: the generic\n// {@link ParseTreeListener//enterEveryRule} and a\n// {@link RuleContext}-specific event. First we trigger the generic and then\n// the rule specific. We to them in reverse order upon finishing the node.\n//\nParseTreeWalker.prototype.enterRule = function(listener, r) {\n\tvar ctx = r.getRuleContext();\n\tlistener.enterEveryRule(ctx);\n\tctx.enterRule(listener);\n};\n\nParseTreeWalker.prototype.exitRule = function(listener, r) {\n\tvar ctx = r.getRuleContext();\n\tctx.exitRule(listener);\n\tlistener.exitEveryRule(ctx);\n};\n\nParseTreeWalker.DEFAULT = new ParseTreeWalker();\n\nexports.RuleNode = RuleNode;\nexports.ErrorNode = ErrorNode;\nexports.TerminalNode = TerminalNode;\nexports.ErrorNodeImpl = ErrorNodeImpl;\nexports.TerminalNodeImpl = TerminalNodeImpl;\nexports.ParseTreeListener = ParseTreeListener;\nexports.ParseTreeVisitor = ParseTreeVisitor;\nexports.ParseTreeWalker = ParseTreeWalker;\nexports.INVALID_INTERVAL = INVALID_INTERVAL;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/tree/Tree.js\n ** module id = 17\n ** module chunks = 0\n **/","/*\n * [The \"BSD license\"]\n *  Copyright (c) 2012 Terence Parr\n *  Copyright (c) 2012 Sam Harwell\n *  All rights reserved.\n *\n *  Redistribution and use in source and binary forms, with or without\n *  modification, are permitted provided that the following conditions\n *  are met:\n *\n *  1. Redistributions of source code must retain the above copyright\n *     notice, this list of conditions and the following disclaimer.\n *  2. Redistributions in binary form must reproduce the above copyright\n *     notice, this list of conditions and the following disclaimer in the\n *     documentation and/or other materials provided with the distribution.\n *  3. The name of the author may not be used to endorse or promote products\n *     derived from this software without specific prior written permission.\n *\n *  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n *  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n *  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n *  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n *  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n *  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n *  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\nvar Utils = require('./../Utils');\nvar Token = require('./../Token').Token;\nvar RuleNode = require('./Tree').RuleNode;\nvar ErrorNode = require('./Tree').ErrorNode;\nvar TerminalNode = require('./Tree').TerminalNode;\nvar ParserRuleContext = require('./../ParserRuleContext').ParserRuleContext;\nvar RuleContext = require('./../RuleContext').RuleContext;\nvar INVALID_ALT_NUMBER = require('./../atn/ATN').INVALID_ALT_NUMBER;\n\n\n/** A set of utility routines useful for all kinds of ANTLR trees. */\nfunction Trees() {\n}\n\n// Print out a whole tree in LISP form. {@link //getNodeText} is used on the\n//  node payloads to get the text for the nodes.  Detect\n//  parse trees and extract data appropriately.\nTrees.toStringTree = function(tree, ruleNames, recog) {\n\truleNames = ruleNames || null;\n\trecog = recog || null;\n    if(recog!==null) {\n       ruleNames = recog.ruleNames;\n    }\n    var s = Trees.getNodeText(tree, ruleNames);\n    s = Utils.escapeWhitespace(s, false);\n    var c = tree.getChildCount();\n    if(c===0) {\n        return s;\n    }\n    var res = \"(\" + s + ' ';\n    if(c>0) {\n        s = Trees.toStringTree(tree.getChild(0), ruleNames);\n        res = res.concat(s);\n    }\n    for(var i=1;i<c;i++) {\n        s = Trees.toStringTree(tree.getChild(i), ruleNames);\n        res = res.concat(' ' + s);\n    }\n    res = res.concat(\")\");\n    return res;\n};\n\nTrees.getNodeText = function(t, ruleNames, recog) {\n\truleNames = ruleNames || null;\n\trecog = recog || null;\n    if(recog!==null) {\n        ruleNames = recog.ruleNames;\n    }\n    if(ruleNames!==null) {\n       if (t instanceof RuleContext) {\n           var altNumber = t.getAltNumber();\n           if ( altNumber!=INVALID_ALT_NUMBER ) {\n               return ruleNames[t.ruleIndex]+\":\"+altNumber;\n           }\n           return ruleNames[t.ruleIndex];\n       } else if ( t instanceof ErrorNode) {\n           return t.toString();\n       } else if(t instanceof TerminalNode) {\n           if(t.symbol!==null) {\n               return t.symbol.text;\n           }\n       }\n    }\n    // no recog for rule names\n    var payload = t.getPayload();\n    if (payload instanceof Token ) {\n       return payload.text;\n    }\n    return t.getPayload().toString();\n};\n\n\n// Return ordered list of all children of this node\nTrees.getChildren = function(t) {\n\tvar list = [];\n\tfor(var i=0;i<t.getChildCount();i++) {\n\t\tlist.push(t.getChild(i));\n\t}\n\treturn list;\n};\n\n// Return a list of all ancestors of this node.  The first node of\n//  list is the root and the last is the parent of this node.\n//\nTrees.getAncestors = function(t) {\n    var ancestors = [];\n    t = t.getParent();\n    while(t!==null) {\n        ancestors = [t].concat(ancestors);\n        t = t.getParent();\n    }\n    return ancestors;\n};\n\nTrees.findAllTokenNodes = function(t, ttype) {\n    return Trees.findAllNodes(t, ttype, true);\n};\n\nTrees.findAllRuleNodes = function(t, ruleIndex) {\n\treturn Trees.findAllNodes(t, ruleIndex, false);\n};\n\nTrees.findAllNodes = function(t, index, findTokens) {\n\tvar nodes = [];\n\tTrees._findAllNodes(t, index, findTokens, nodes);\n\treturn nodes;\n};\n\nTrees._findAllNodes = function(t, index, findTokens, nodes) {\n\t// check this node (the root) first\n\tif(findTokens && (t instanceof TerminalNode)) {\n\t\tif(t.symbol.type===index) {\n\t\t\tnodes.push(t);\n\t\t}\n\t} else if(!findTokens && (t instanceof ParserRuleContext)) {\n\t\tif(t.ruleIndex===index) {\n\t\t\tnodes.push(t);\n\t\t}\n\t}\n\t// check children\n\tfor(var i=0;i<t.getChildCount();i++) {\n\t\tTrees._findAllNodes(t.getChild(i), index, findTokens, nodes);\n\t}\n};\n\nTrees.descendants = function(t) {\n\tvar nodes = [t];\n    for(var i=0;i<t.getChildCount();i++) {\n        nodes = nodes.concat(Trees.descendants(t.getChild(i)));\n    }\n    return nodes;\n};\n\n\nexports.Trees = Trees;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/tree/Trees.js\n ** module id = 18\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n//* A rule invocation record for parsing.\n//\n//  Contains all of the information about the current rule not stored in the\n//  RuleContext. It handles parse tree children list, Any ATN state\n//  tracing, and the default values available for rule indications:\n//  start, stop, rule index, current alt number, current\n//  ATN state.\n//\n//  Subclasses made for each rule and grammar track the parameters,\n//  return values, locals, and labels specific to that rule. These\n//  are the objects that are returned from rules.\n//\n//  Note text is not an actual field of a rule return value; it is computed\n//  from start and stop using the input stream's toString() method.  I\n//  could add a ctor to this so that we can pass in and store the input\n//  stream, but I'm not sure we want to do that.  It would seem to be undefined\n//  to get the .text property anyway if the rule matches tokens from multiple\n//  input streams.\n//\n//  I do not use getters for fields of objects that are used simply to\n//  group values such as this aggregate.  The getters/setters are there to\n//  satisfy the superclass interface.\n\nvar RuleContext = require('./RuleContext').RuleContext;\nvar Tree = require('./tree/Tree');\nvar INVALID_INTERVAL = Tree.INVALID_INTERVAL;\nvar TerminalNode = Tree.TerminalNode;\nvar TerminalNodeImpl = Tree.TerminalNodeImpl;\nvar ErrorNodeImpl = Tree.ErrorNodeImpl;\nvar Interval = require(\"./IntervalSet\").Interval;\n\nfunction ParserRuleContext(parent, invokingStateNumber) {\n\tparent = parent || null;\n\tinvokingStateNumber = invokingStateNumber || null;\n\tRuleContext.call(this, parent, invokingStateNumber);\n\tthis.ruleIndex = -1;\n    // * If we are debugging or building a parse tree for a visitor,\n    // we need to track all of the tokens and rule invocations associated\n    // with this rule's context. This is empty for parsing w/o tree constr.\n    // operation because we don't the need to track the details about\n    // how we parse this rule.\n    // /\n    this.children = null;\n    this.start = null;\n    this.stop = null;\n    // The exception that forced this rule to return. If the rule successfully\n    // completed, this is {@code null}.\n    this.exception = null;\n}\n\nParserRuleContext.prototype = Object.create(RuleContext.prototype);\nParserRuleContext.prototype.constructor = ParserRuleContext;\n\n// * COPY a ctx (I'm deliberately not using copy constructor)///\nParserRuleContext.prototype.copyFrom = function(ctx) {\n    // from RuleContext\n    this.parentCtx = ctx.parentCtx;\n    this.invokingState = ctx.invokingState;\n    this.children = null;\n    this.start = ctx.start;\n    this.stop = ctx.stop;\n};\n\n// Double dispatch methods for listeners\nParserRuleContext.prototype.enterRule = function(listener) {\n};\n\nParserRuleContext.prototype.exitRule = function(listener) {\n};\n\n// * Does not set parent link; other add methods do that///\nParserRuleContext.prototype.addChild = function(child) {\n    if (this.children === null) {\n        this.children = [];\n    }\n    this.children.push(child);\n    return child;\n};\n\n// * Used by enterOuterAlt to toss out a RuleContext previously added as\n// we entered a rule. If we have // label, we will need to remove\n// generic ruleContext object.\n// /\nParserRuleContext.prototype.removeLastChild = function() {\n    if (this.children !== null) {\n        this.children.pop();\n    }\n};\n\nParserRuleContext.prototype.addTokenNode = function(token) {\n    var node = new TerminalNodeImpl(token);\n    this.addChild(node);\n    node.parentCtx = this;\n    return node;\n};\n\nParserRuleContext.prototype.addErrorNode = function(badToken) {\n    var node = new ErrorNodeImpl(badToken);\n    this.addChild(node);\n    node.parentCtx = this;\n    return node;\n};\n\nParserRuleContext.prototype.getChild = function(i, type) {\n\ttype = type || null;\n\tif (type === null) {\n\t\treturn this.children.length>=i ? this.children[i] : null;\n\t} else {\n\t\tfor(var j=0; j<this.children.length; j++) {\n\t\t\tvar child = this.children[j];\n\t\t\tif(child instanceof type) {\n\t\t\t\tif(i===0) {\n\t\t\t\t\treturn child;\n\t\t\t\t} else {\n\t\t\t\t\ti -= 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n    }\n};\n\n\nParserRuleContext.prototype.getToken = function(ttype, i) {\n\tfor(var j=0; j<this.children.length; j++) {\n\t\tvar child = this.children[j];\n\t\tif (child instanceof TerminalNode) {\n\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\tif(i===0) {\n\t\t\t\t\treturn child;\n\t\t\t\t} else {\n\t\t\t\t\ti -= 1;\n\t\t\t\t}\n\t\t\t}\n        }\n\t}\n    return null;\n};\n\nParserRuleContext.prototype.getTokens = function(ttype ) {\n    if (this.children=== null) {\n        return [];\n    } else {\n\t\tvar tokens = [];\n\t\tfor(var j=0; j<this.children.length; j++) {\n\t\t\tvar child = this.children[j];\n\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\ttokens.push(child);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn tokens;\n    }\n};\n\nParserRuleContext.prototype.getTypedRuleContext = function(ctxType, i) {\n    return this.getChild(i, ctxType);\n};\n\nParserRuleContext.prototype.getTypedRuleContexts = function(ctxType) {\n    if (this.children=== null) {\n        return [];\n    } else {\n\t\tvar contexts = [];\n\t\tfor(var j=0; j<this.children.length; j++) {\n\t\t\tvar child = this.children[j];\n\t\t\tif (child instanceof ctxType) {\n\t\t\t\tcontexts.push(child);\n\t\t\t}\n\t\t}\n\t\treturn contexts;\n\t}\n};\n\nParserRuleContext.prototype.getChildCount = function() {\n\tif (this.children=== null) {\n\t\treturn 0;\n\t} else {\n\t\treturn this.children.length;\n\t}\n};\n\nParserRuleContext.prototype.getSourceInterval = function() {\n    if( this.start === null || this.stop === null) {\n        return INVALID_INTERVAL;\n    } else {\n        return new Interval(this.start.tokenIndex, this.stop.tokenIndex);\n    }\n};\n\nRuleContext.EMPTY = new ParserRuleContext();\n\nfunction InterpreterRuleContext(parent, invokingStateNumber, ruleIndex) {\n\tParserRuleContext.call(parent, invokingStateNumber);\n    this.ruleIndex = ruleIndex;\n    return this;\n}\n\nInterpreterRuleContext.prototype = Object.create(ParserRuleContext.prototype);\nInterpreterRuleContext.prototype.constructor = InterpreterRuleContext;\n\nexports.ParserRuleContext = ParserRuleContext;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/ParserRuleContext.js\n ** module id = 19\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2013 Terence Parr\n//  Copyright (c) 2013 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nvar Token = require('./../Token').Token;\nvar ATN = require('./ATN').ATN;\nvar ATNType = require('./ATNType').ATNType;\nvar ATNStates = require('./ATNState');\nvar ATNState = ATNStates.ATNState;\nvar BasicState = ATNStates.BasicState;\nvar DecisionState = ATNStates.DecisionState;\nvar BlockStartState = ATNStates.BlockStartState;\nvar BlockEndState = ATNStates.BlockEndState;\nvar LoopEndState = ATNStates.LoopEndState;\nvar RuleStartState = ATNStates.RuleStartState;\nvar RuleStopState = ATNStates.RuleStopState;\nvar TokensStartState = ATNStates.TokensStartState;\nvar PlusLoopbackState = ATNStates.PlusLoopbackState;\nvar StarLoopbackState = ATNStates.StarLoopbackState;\nvar StarLoopEntryState = ATNStates.StarLoopEntryState;\nvar PlusBlockStartState = ATNStates.PlusBlockStartState;\nvar StarBlockStartState = ATNStates.StarBlockStartState;\nvar BasicBlockStartState = ATNStates.BasicBlockStartState;\nvar Transitions = require('./Transition');\nvar Transition = Transitions.Transition;\nvar AtomTransition = Transitions.AtomTransition;\nvar SetTransition = Transitions.SetTransition;\nvar NotSetTransition = Transitions.NotSetTransition;\nvar RuleTransition = Transitions.RuleTransition;\nvar RangeTransition = Transitions.RangeTransition;\nvar ActionTransition = Transitions.ActionTransition;\nvar EpsilonTransition = Transitions.EpsilonTransition;\nvar WildcardTransition = Transitions.WildcardTransition;\nvar PredicateTransition = Transitions.PredicateTransition;\nvar PrecedencePredicateTransition = Transitions.PrecedencePredicateTransition;\nvar IntervalSet = require('./../IntervalSet').IntervalSet;\nvar Interval = require('./../IntervalSet').Interval;\nvar ATNDeserializationOptions = require('./ATNDeserializationOptions').ATNDeserializationOptions;\nvar LexerActions = require('./LexerAction');\nvar LexerActionType = LexerActions.LexerActionType;\nvar LexerSkipAction = LexerActions.LexerSkipAction;\nvar LexerChannelAction = LexerActions.LexerChannelAction;\nvar LexerCustomAction = LexerActions.LexerCustomAction;\nvar LexerMoreAction = LexerActions.LexerMoreAction;\nvar LexerTypeAction = LexerActions.LexerTypeAction;\nvar LexerPushModeAction = LexerActions.LexerPushModeAction;\nvar LexerPopModeAction = LexerActions.LexerPopModeAction;\nvar LexerModeAction = LexerActions.LexerModeAction;\n// This is the earliest supported serialized UUID.\n// stick to serialized version for now, we don't need a UUID instance\nvar BASE_SERIALIZED_UUID = \"AADB8D7E-AEEF-4415-AD2B-8204D6CF042E\";\n\n// This list contains all of the currently supported UUIDs, ordered by when\n// the feature first appeared in this branch.\nvar SUPPORTED_UUIDS = [ BASE_SERIALIZED_UUID ];\n\nvar SERIALIZED_VERSION = 3;\n\n// This is the current serialized UUID.\nvar SERIALIZED_UUID = BASE_SERIALIZED_UUID;\n\nfunction initArray( length, value) {\n\tvar tmp = [];\n\ttmp[length-1] = value;\n\treturn tmp.map(function(i) {return value;});\n}\n\nfunction ATNDeserializer (options) {\n\t\n    if ( options=== undefined || options === null ) {\n        options = ATNDeserializationOptions.defaultOptions;\n    }\n    this.deserializationOptions = options;\n    this.stateFactories = null;\n    this.actionFactories = null;\n    \n    return this;\n}\n\n// Determines if a particular serialized representation of an ATN supports\n// a particular feature, identified by the {@link UUID} used for serializing\n// the ATN at the time the feature was first introduced.\n//\n// @param feature The {@link UUID} marking the first time the feature was\n// supported in the serialized ATN.\n// @param actualUuid The {@link UUID} of the actual serialized ATN which is\n// currently being deserialized.\n// @return {@code true} if the {@code actualUuid} value represents a\n// serialized ATN at or after the feature identified by {@code feature} was\n// introduced; otherwise, {@code false}.\n\nATNDeserializer.prototype.isFeatureSupported = function(feature, actualUuid) {\n    var idx1 = SUPPORTED_UUIDS.index(feature);\n    if (idx1<0) {\n        return false;\n    }\n    var idx2 = SUPPORTED_UUIDS.index(actualUuid);\n    return idx2 >= idx1;\n};\n\nATNDeserializer.prototype.deserialize = function(data) {\n    this.reset(data);\n    this.checkVersion();\n    this.checkUUID();\n    var atn = this.readATN();\n    this.readStates(atn);\n    this.readRules(atn);\n    this.readModes(atn);\n    var sets = this.readSets(atn);\n    this.readEdges(atn, sets);\n    this.readDecisions(atn);\n    this.readLexerActions(atn);\n    this.markPrecedenceDecisions(atn);\n    this.verifyATN(atn);\n    if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATNType.PARSER ) {\n        this.generateRuleBypassTransitions(atn);\n        // re-verify after modification\n        this.verifyATN(atn);\n    }\n    return atn;\n};\n\nATNDeserializer.prototype.reset = function(data) {\n\tvar adjust = function(c) {\n        var v = c.charCodeAt(0);\n        return v>1  ? v-2 : -1;\n\t};\n    var temp = data.split(\"\").map(adjust);\n    // don't adjust the first value since that's the version number\n    temp[0] = data.charCodeAt(0);\n    this.data = temp;\n    this.pos = 0;\n};\n\nATNDeserializer.prototype.checkVersion = function() {\n    var version = this.readInt();\n    if ( version !== SERIALIZED_VERSION ) {\n        throw (\"Could not deserialize ATN with version \" + version + \" (expected \" + SERIALIZED_VERSION + \").\");\n    }\n};\n\nATNDeserializer.prototype.checkUUID = function() {\n    var uuid = this.readUUID();\n    if (SUPPORTED_UUIDS.indexOf(uuid)<0) {\n        throw (\"Could not deserialize ATN with UUID: \" + uuid +\n                        \" (expected \" + SERIALIZED_UUID + \" or a legacy UUID).\", uuid, SERIALIZED_UUID);\n    }\n    this.uuid = uuid;\n};\n\nATNDeserializer.prototype.readATN = function() {\n    var grammarType = this.readInt();\n    var maxTokenType = this.readInt();\n    return new ATN(grammarType, maxTokenType);\n};\n\nATNDeserializer.prototype.readStates = function(atn) {\n\tvar j, pair, stateNumber;\n    var loopBackStateNumbers = [];\n    var endStateNumbers = [];\n    var nstates = this.readInt();\n    for(var i=0; i<nstates; i++) {\n        var stype = this.readInt();\n        // ignore bad type of states\n        if (stype===ATNState.INVALID_TYPE) {\n            atn.addState(null);\n            continue;\n        }\n        var ruleIndex = this.readInt();\n        if (ruleIndex === 0xFFFF) {\n            ruleIndex = -1;\n        }\n        var s = this.stateFactory(stype, ruleIndex);\n        if (stype === ATNState.LOOP_END) { // special case\n            var loopBackStateNumber = this.readInt();\n            loopBackStateNumbers.push([s, loopBackStateNumber]);\n        } else if(s instanceof BlockStartState) {\n            var endStateNumber = this.readInt();\n            endStateNumbers.push([s, endStateNumber]);\n        }\n        atn.addState(s);\n    }\n    // delay the assignment of loop back and end states until we know all the\n\t// state instances have been initialized\n    for (j=0; j<loopBackStateNumbers.length; j++) {\n        pair = loopBackStateNumbers[j];\n        pair[0].loopBackState = atn.states[pair[1]];\n    }\n\n    for (j=0; j<endStateNumbers.length; j++) {\n        pair = endStateNumbers[j];\n        pair[0].endState = atn.states[pair[1]];\n    }\n    \n    var numNonGreedyStates = this.readInt();\n    for (j=0; j<numNonGreedyStates; j++) {\n        stateNumber = this.readInt();\n        atn.states[stateNumber].nonGreedy = true;\n    }\n\n    var numPrecedenceStates = this.readInt();\n    for (j=0; j<numPrecedenceStates; j++) {\n        stateNumber = this.readInt();\n        atn.states[stateNumber].isPrecedenceRule = true;\n    }\n};\n\nATNDeserializer.prototype.readRules = function(atn) {\n    var i;\n    var nrules = this.readInt();\n    if (atn.grammarType === ATNType.LEXER ) {\n        atn.ruleToTokenType = initArray(nrules, 0);\n    }\n    atn.ruleToStartState = initArray(nrules, 0);\n    for (i=0; i<nrules; i++) {\n        var s = this.readInt();\n        var startState = atn.states[s];\n        atn.ruleToStartState[i] = startState;\n        if ( atn.grammarType === ATNType.LEXER ) {\n            var tokenType = this.readInt();\n            if (tokenType === 0xFFFF) {\n                tokenType = Token.EOF;\n            }\n            atn.ruleToTokenType[i] = tokenType;\n        }\n    }\n    atn.ruleToStopState = initArray(nrules, 0);\n    for (i=0; i<atn.states.length; i++) {\n        var state = atn.states[i];\n        if (!(state instanceof RuleStopState)) {\n            continue;\n        }\n        atn.ruleToStopState[state.ruleIndex] = state;\n        atn.ruleToStartState[state.ruleIndex].stopState = state;\n    }\n};\n\nATNDeserializer.prototype.readModes = function(atn) {\n    var nmodes = this.readInt();\n    for (var i=0; i<nmodes; i++) {\n        var s = this.readInt();\n        atn.modeToStartState.push(atn.states[s]);\n    }\n};\n\nATNDeserializer.prototype.readSets = function(atn) {\n    var sets = [];\n    var m = this.readInt();\n    for (var i=0; i<m; i++) {\n        var iset = new IntervalSet();\n        sets.push(iset);\n        var n = this.readInt();\n        var containsEof = this.readInt();\n        if (containsEof!==0) {\n            iset.addOne(-1);\n        }\n        for (var j=0; j<n; j++) {\n            var i1 = this.readInt();\n            var i2 = this.readInt();\n            iset.addRange(i1, i2);\n        }\n    }\n    return sets;\n};\n\nATNDeserializer.prototype.readEdges = function(atn, sets) {\n\tvar i, j, state, trans, target;\n    var nedges = this.readInt();\n    for (i=0; i<nedges; i++) {\n        var src = this.readInt();\n        var trg = this.readInt();\n        var ttype = this.readInt();\n        var arg1 = this.readInt();\n        var arg2 = this.readInt();\n        var arg3 = this.readInt();\n        trans = this.edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);\n        var srcState = atn.states[src];\n        srcState.addTransition(trans);\n    }\n    // edges for rule stop states can be derived, so they aren't serialized\n    for (i=0; i<atn.states.length; i++) {\n        state = atn.states[i];\n        for (j=0; j<state.transitions.length; j++) {\n            var t = state.transitions[j];\n            if (!(t instanceof RuleTransition)) {\n                continue;\n            }\n\t\t\tvar outermostPrecedenceReturn = -1;\n\t\t\tif (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {\n\t\t\t\tif (t.precedence === 0) {\n\t\t\t\t\toutermostPrecedenceReturn = t.target.ruleIndex;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ttrans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);\n            atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);\n        }\n    }\n\n    for (i=0; i<atn.states.length; i++) {\n        state = atn.states[i];\n        if (state instanceof BlockStartState) {\n            // we need to know the end state to set its start state\n            if (state.endState === null) {\n                throw (\"IllegalState\");\n            }\n            // block end states can only be associated to a single block start\n\t\t\t// state\n            if ( state.endState.startState !== null) {\n                throw (\"IllegalState\");\n            }\n            state.endState.startState = state;\n        }\n        if (state instanceof PlusLoopbackState) {\n            for (j=0; j<state.transitions.length; j++) {\n                target = state.transitions[j].target;\n                if (target instanceof PlusBlockStartState) {\n                    target.loopBackState = state;\n                }\n            }\n        } else if (state instanceof StarLoopbackState) {\n            for (j=0; j<state.transitions.length; j++) {\n                target = state.transitions[j].target;\n                if (target instanceof StarLoopEntryState) {\n                    target.loopBackState = state;\n                }\n            }\n        }\n    }\n};\n\nATNDeserializer.prototype.readDecisions = function(atn) {\n    var ndecisions = this.readInt();\n    for (var i=0; i<ndecisions; i++) {\n        var s = this.readInt();\n        var decState = atn.states[s];\n        atn.decisionToState.push(decState);\n        decState.decision = i;\n    }\n};\n\nATNDeserializer.prototype.readLexerActions = function(atn) {\n    if (atn.grammarType === ATNType.LEXER) {\n        var count = this.readInt();\n        atn.lexerActions = initArray(count, null);\n        for (var i=0; i<count; i++) {\n            var actionType = this.readInt();\n            var data1 = this.readInt();\n            if (data1 === 0xFFFF) {\n                data1 = -1;\n            }\n            var data2 = this.readInt();\n            if (data2 === 0xFFFF) {\n                data2 = -1;\n            }\n            var lexerAction = this.lexerActionFactory(actionType, data1, data2);\n            atn.lexerActions[i] = lexerAction;\n        }\n    }\n};\n\nATNDeserializer.prototype.generateRuleBypassTransitions = function(atn) {\n\tvar i;\n    var count = atn.ruleToStartState.length;\n    for(i=0; i<count; i++) {\n        atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;\n    }\n    for(i=0; i<count; i++) {\n        this.generateRuleBypassTransition(atn, i);\n    }\n};\n\nATNDeserializer.prototype.generateRuleBypassTransition = function(atn, idx) {\n\tvar i, state;\n    var bypassStart = new BasicBlockStartState();\n    bypassStart.ruleIndex = idx;\n    atn.addState(bypassStart);\n\n    var bypassStop = new BlockEndState();\n    bypassStop.ruleIndex = idx;\n    atn.addState(bypassStop);\n\n    bypassStart.endState = bypassStop;\n    atn.defineDecisionState(bypassStart);\n\n    bypassStop.startState = bypassStart;\n\n    var excludeTransition = null;\n    var endState = null;\n    \n    if (atn.ruleToStartState[idx].isPrecedenceRule) {\n        // wrap from the beginning of the rule to the StarLoopEntryState\n        endState = null;\n        for(i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            if (this.stateIsEndStateFor(state, idx)) {\n                endState = state;\n                excludeTransition = state.loopBackState.transitions[0];\n                break;\n            }\n        }\n        if (excludeTransition === null) {\n            throw (\"Couldn't identify final state of the precedence rule prefix section.\");\n        }\n    } else {\n        endState = atn.ruleToStopState[idx];\n    }\n    \n    // all non-excluded transitions that currently target end state need to\n\t// target blockEnd instead\n    for(i=0; i<atn.states.length; i++) {\n        state = atn.states[i];\n        for(var j=0; j<state.transitions.length; j++) {\n            var transition = state.transitions[j];\n            if (transition === excludeTransition) {\n                continue;\n            }\n            if (transition.target === endState) {\n                transition.target = bypassStop;\n            }\n        }\n    }\n\n    // all transitions leaving the rule start state need to leave blockStart\n\t// instead\n    var ruleToStartState = atn.ruleToStartState[idx];\n    var count = ruleToStartState.transitions.length;\n    while ( count > 0) {\n        bypassStart.addTransition(ruleToStartState.transitions[count-1]);\n        ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);\n    }\n    // link the new states\n    atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));\n    bypassStop.addTransition(new EpsilonTransition(endState));\n\n    var matchState = new BasicState();\n    atn.addState(matchState);\n    matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));\n    bypassStart.addTransition(new EpsilonTransition(matchState));\n};\n\nATNDeserializer.prototype.stateIsEndStateFor = function(state, idx) {\n    if ( state.ruleIndex !== idx) {\n        return null;\n    }\n    if (!( state instanceof StarLoopEntryState)) {\n        return null;\n    }\n    var maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n    if (!( maybeLoopEndState instanceof LoopEndState)) {\n        return null;\n    }\n    if (maybeLoopEndState.epsilonOnlyTransitions &&\n        (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n        return state;\n    } else {\n        return null;\n    }\n};\n\n//\n// Analyze the {@link StarLoopEntryState} states in the specified ATN to set\n// the {@link StarLoopEntryState//precedenceRuleDecision} field to the\n// correct value.\n//\n// @param atn The ATN.\n//\nATNDeserializer.prototype.markPrecedenceDecisions = function(atn) {\n\tfor(var i=0; i<atn.states.length; i++) {\n\t\tvar state = atn.states[i];\n\t\tif (!( state instanceof StarLoopEntryState)) {\n            continue;\n        }\n        // We analyze the ATN to determine if this ATN decision state is the\n        // decision for the closure block that determines whether a\n        // precedence rule should continue or complete.\n        //\n        if ( atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {\n            var maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n            if (maybeLoopEndState instanceof LoopEndState) {\n                if ( maybeLoopEndState.epsilonOnlyTransitions &&\n                        (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n                    state.precedenceRuleDecision = true;\n                }\n            }\n        }\n\t}\n};\n\nATNDeserializer.prototype.verifyATN = function(atn) {\n    if (!this.deserializationOptions.verifyATN) {\n        return;\n    }\n    // verify assumptions\n\tfor(var i=0; i<atn.states.length; i++) {\n        var state = atn.states[i];\n        if (state === null) {\n            continue;\n        }\n        this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);\n        if (state instanceof PlusBlockStartState) {\n            this.checkCondition(state.loopBackState !== null);\n        } else  if (state instanceof StarLoopEntryState) {\n            this.checkCondition(state.loopBackState !== null);\n            this.checkCondition(state.transitions.length === 2);\n            if (state.transitions[0].target instanceof StarBlockStartState) {\n                this.checkCondition(state.transitions[1].target instanceof LoopEndState);\n                this.checkCondition(!state.nonGreedy);\n            } else if (state.transitions[0].target instanceof LoopEndState) {\n                this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);\n                this.checkCondition(state.nonGreedy);\n            } else {\n                throw(\"IllegalState\");\n            }\n        } else if (state instanceof StarLoopbackState) {\n            this.checkCondition(state.transitions.length === 1);\n            this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);\n        } else if (state instanceof LoopEndState) {\n            this.checkCondition(state.loopBackState !== null);\n        } else if (state instanceof RuleStartState) {\n            this.checkCondition(state.stopState !== null);\n        } else if (state instanceof BlockStartState) {\n            this.checkCondition(state.endState !== null);\n        } else if (state instanceof BlockEndState) {\n            this.checkCondition(state.startState !== null);\n        } else if (state instanceof DecisionState) {\n            this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);\n        } else {\n            this.checkCondition(state.transitions.length <= 1 || (state instanceof RuleStopState));\n        }\n\t}\n};\n\nATNDeserializer.prototype.checkCondition = function(condition, message) {\n    if (!condition) {\n        if (message === undefined || message===null) {\n            message = \"IllegalState\";\n        }\n        throw (message);\n    }\n};\n\nATNDeserializer.prototype.readInt = function() {\n    return this.data[this.pos++];\n};\n\nATNDeserializer.prototype.readInt32 = function() {\n    var low = this.readInt();\n    var high = this.readInt();\n    return low | (high << 16);\n};\n\nATNDeserializer.prototype.readLong = function() {\n    var low = this.readInt32();\n    var high = this.readInt32();\n    return (low & 0x00000000FFFFFFFF) | (high << 32);\n};\n\nfunction createByteToHex() {\n\tvar bth = [];\n\tfor (var i = 0; i < 256; i++) {\n\t\tbth[i] = (i + 0x100).toString(16).substr(1).toUpperCase();\n\t}\n\treturn bth;\n}\n\nvar byteToHex = createByteToHex();\n\t\nATNDeserializer.prototype.readUUID = function() {\n\tvar bb = [];\n\tfor(var i=7;i>=0;i--) {\n\t\tvar int = this.readInt();\n\t\t/* jshint bitwise: false */\n\t\tbb[(2*i)+1] = int & 0xFF;\n\t\tbb[2*i] = (int >> 8) & 0xFF;\n\t}\n    return byteToHex[bb[0]] + byteToHex[bb[1]] +\n    byteToHex[bb[2]] + byteToHex[bb[3]] + '-' +\n    byteToHex[bb[4]] + byteToHex[bb[5]] + '-' +\n    byteToHex[bb[6]] + byteToHex[bb[7]] + '-' +\n    byteToHex[bb[8]] + byteToHex[bb[9]] + '-' +\n    byteToHex[bb[10]] + byteToHex[bb[11]] +\n    byteToHex[bb[12]] + byteToHex[bb[13]] +\n    byteToHex[bb[14]] + byteToHex[bb[15]];\n};\n\nATNDeserializer.prototype.edgeFactory = function(atn, type, src, trg, arg1, arg2, arg3, sets) {\n    var target = atn.states[trg];\n    switch(type) {\n    case Transition.EPSILON:\n        return new EpsilonTransition(target);\n    case Transition.RANGE:\n        return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);\n    case Transition.RULE:\n        return new RuleTransition(atn.states[arg1], arg2, arg3, target);\n    case Transition.PREDICATE:\n        return new PredicateTransition(target, arg1, arg2, arg3 !== 0);\n    case Transition.PRECEDENCE:\n        return new PrecedencePredicateTransition(target, arg1);\n    case Transition.ATOM:\n        return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);\n    case Transition.ACTION:\n        return new ActionTransition(target, arg1, arg2, arg3 !== 0);\n    case Transition.SET:\n        return new SetTransition(target, sets[arg1]);\n    case Transition.NOT_SET:\n        return new NotSetTransition(target, sets[arg1]);\n    case Transition.WILDCARD:\n        return new WildcardTransition(target);\n    default:\n        throw \"The specified transition type: \" + type + \" is not valid.\";\n    }\n};\n\nATNDeserializer.prototype.stateFactory = function(type, ruleIndex) {\n    if (this.stateFactories === null) {\n        var sf = [];\n        sf[ATNState.INVALID_TYPE] = null;\n        sf[ATNState.BASIC] = function() { return new BasicState(); };\n        sf[ATNState.RULE_START] = function() { return new RuleStartState(); };\n        sf[ATNState.BLOCK_START] = function() { return new BasicBlockStartState(); };\n        sf[ATNState.PLUS_BLOCK_START] = function() { return new PlusBlockStartState(); };\n        sf[ATNState.STAR_BLOCK_START] = function() { return new StarBlockStartState(); };\n        sf[ATNState.TOKEN_START] = function() { return new TokensStartState(); };\n        sf[ATNState.RULE_STOP] = function() { return new RuleStopState(); };\n        sf[ATNState.BLOCK_END] = function() { return new BlockEndState(); };\n        sf[ATNState.STAR_LOOP_BACK] = function() { return new StarLoopbackState(); };\n        sf[ATNState.STAR_LOOP_ENTRY] = function() { return new StarLoopEntryState(); };\n        sf[ATNState.PLUS_LOOP_BACK] = function() { return new PlusLoopbackState(); };\n        sf[ATNState.LOOP_END] = function() { return new LoopEndState(); };\n        this.stateFactories = sf;\n    }\n    if (type>this.stateFactories.length || this.stateFactories[type] === null) {\n        throw(\"The specified state type \" + type + \" is not valid.\");\n    } else {\n        var s = this.stateFactories[type]();\n        if (s!==null) {\n            s.ruleIndex = ruleIndex;\n            return s;\n        }\n    }\n};\n\nATNDeserializer.prototype.lexerActionFactory = function(type, data1, data2) {\n    if (this.actionFactories === null) {\n        var af = [];\n        af[LexerActionType.CHANNEL] = function(data1, data2) { return new LexerChannelAction(data1); };\n        af[LexerActionType.CUSTOM] = function(data1, data2) { return new LexerCustomAction(data1, data2); };\n        af[LexerActionType.MODE] = function(data1, data2) { return new LexerModeAction(data1); };\n        af[LexerActionType.MORE] = function(data1, data2) { return LexerMoreAction.INSTANCE; };\n        af[LexerActionType.POP_MODE] = function(data1, data2) { return LexerPopModeAction.INSTANCE; };\n        af[LexerActionType.PUSH_MODE] = function(data1, data2) { return new LexerPushModeAction(data1); };\n        af[LexerActionType.SKIP] = function(data1, data2) { return LexerSkipAction.INSTANCE; };\n        af[LexerActionType.TYPE] = function(data1, data2) { return new LexerTypeAction(data1); };\n        this.actionFactories = af;\n    }\n    if (type>this.actionFactories.length || this.actionFactories[type] === null) {\n        throw(\"The specified lexer action type \" + type + \" is not valid.\");\n    } else {\n        return this.actionFactories[type](data1, data2);\n    }\n};\n   \n\nexports.ATNDeserializer = ATNDeserializer;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/ATNDeserializer.js\n ** module id = 20\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2013 Terence Parr\n//  Copyright (c) 2013 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\n// Represents the type of recognizer an ATN applies to.\n\nfunction ATNType() {\n\t\n}\n\nATNType.LEXER = 0;\nATNType.PARSER = 1;\n\nexports.ATNType = ATNType;\n\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/ATNType.js\n ** module id = 21\n ** module chunks = 0\n **/","//[The \"BSD license\"]\n// Copyright (c) 2013 Terence Parr\n// Copyright (c) 2013 Sam Harwell\n// Copyright (c) 2014 Eric Vergnaud\n// All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions\n// are met:\n//\n// 1. Redistributions of source code must retain the above copyright\n//    notice, this list of conditions and the following disclaimer.\n// 2. Redistributions in binary form must reproduce the above copyright\n//    notice, this list of conditions and the following disclaimer in the\n//    documentation and/or other materials provided with the distribution.\n// 3. The name of the author may not be used to endorse or promote products\n//    derived from this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n// IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n// INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n// NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n// THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nfunction ATNDeserializationOptions(copyFrom) {\n\tif(copyFrom===undefined) {\n\t\tcopyFrom = null;\n\t}\n\tthis.readOnly = false;\n    this.verifyATN = copyFrom===null ? true : copyFrom.verifyATN;\n    this.generateRuleBypassTransitions = copyFrom===null ? false : copyFrom.generateRuleBypassTransitions;\n\n    return this;\n}\n\nATNDeserializationOptions.defaultOptions = new ATNDeserializationOptions();\nATNDeserializationOptions.defaultOptions.readOnly = true;\n\n//    def __setattr__(self, key, value):\n//        if key!=\"readOnly\" and self.readOnly:\n//            raise Exception(\"The object is read only.\")\n//        super(type(self), self).__setattr__(key,value)\n\nexports.ATNDeserializationOptions = ATNDeserializationOptions;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/ATNDeserializationOptions.js\n ** module id = 22\n ** module chunks = 0\n **/","//\n //[The \"BSD license\"]\n // Copyright (c) 2013 Terence Parr\n // Copyright (c) 2013 Sam Harwell\n // Copyright (c) 2014 Eric Vergnaud\n // All rights reserved.\n //\n // Redistribution and use in source and binary forms, with or without\n // modification, are permitted provided that the following conditions\n // are met:\n //\n // 1. Redistributions of source code must retain the above copyright\n //    notice, this list of conditions and the following disclaimer.\n // 2. Redistributions in binary form must reproduce the above copyright\n //    notice, this list of conditions and the following disclaimer in the\n //    documentation and/or other materials provided with the distribution.\n // 3. The name of the author may not be used to endorse or promote products\n //    derived from this software without specific prior written permission.\n //\n // THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n // IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n // OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n // IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n // INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n // NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n // THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n //\n\nfunction LexerActionType() {\n}\n\nLexerActionType.CHANNEL = 0;     //The type of a {@link LexerChannelAction} action.\nLexerActionType.CUSTOM = 1;      //The type of a {@link LexerCustomAction} action.\nLexerActionType.MODE = 2;        //The type of a {@link LexerModeAction} action.\nLexerActionType.MORE = 3;        //The type of a {@link LexerMoreAction} action.\nLexerActionType.POP_MODE = 4;    //The type of a {@link LexerPopModeAction} action.\nLexerActionType.PUSH_MODE = 5;   //The type of a {@link LexerPushModeAction} action.\nLexerActionType.SKIP = 6;        //The type of a {@link LexerSkipAction} action.\nLexerActionType.TYPE = 7;        //The type of a {@link LexerTypeAction} action.\n\nfunction LexerAction(action) {\n    this.actionType = action;\n    this.isPositionDependent = false;\n    return this;\n}\n\nLexerAction.prototype.hashString = function() {\n    return \"\" + this.actionType;\n};\n\nLexerAction.prototype.equals = function(other) {\n    return this === other;\n};\n\n\n\n//\n// Implements the {@code skip} lexer action by calling {@link Lexer//skip}.\n//\n// <p>The {@code skip} command does not have any parameters, so this action is\n// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\nfunction LexerSkipAction() {\n\tLexerAction.call(this, LexerActionType.SKIP);\n\treturn this;\n}\n\nLexerSkipAction.prototype = Object.create(LexerAction.prototype);\nLexerSkipAction.prototype.constructor = LexerSkipAction;\n\n// Provides a singleton instance of this parameterless lexer action.\nLexerSkipAction.INSTANCE = new LexerSkipAction();\n\nLexerSkipAction.prototype.execute = function(lexer) {\n    lexer.skip();\n};\n\nLexerSkipAction.prototype.toString = function() {\n\treturn \"skip\";\n};\n\n//  Implements the {@code type} lexer action by calling {@link Lexer//setType}\n// with the assigned type.\nfunction LexerTypeAction(type) {\n\tLexerAction.call(this, LexerActionType.TYPE);\n\tthis.type = type;\n\treturn this;\n}\n\nLexerTypeAction.prototype = Object.create(LexerAction.prototype);\nLexerTypeAction.prototype.constructor = LexerTypeAction;\n\nLexerTypeAction.prototype.execute = function(lexer) {\n    lexer.type = this.type;\n};\n\nLexerTypeAction.prototype.hashString = function() {\n\treturn \"\" + this.actionType + this.type;\n};\n\n\nLexerTypeAction.prototype.equals = function(other) {\n    if(this === other) {\n        return true;\n    } else if (! (other instanceof LexerTypeAction)) {\n        return false;\n    } else {\n        return this.type === other.type;\n    }\n};\n\nLexerTypeAction.prototype.toString = function() {\n    return \"type(\" + this.type + \")\";\n};\n\n// Implements the {@code pushMode} lexer action by calling\n// {@link Lexer//pushMode} with the assigned mode.\nfunction LexerPushModeAction(mode) {\n\tLexerAction.call(this, LexerActionType.PUSH_MODE);\n    this.mode = mode;\n    return this;\n}\n\nLexerPushModeAction.prototype = Object.create(LexerAction.prototype);\nLexerPushModeAction.prototype.constructor = LexerPushModeAction;\n\n// <p>This action is implemented by calling {@link Lexer//pushMode} with the\n// value provided by {@link //getMode}.</p>\nLexerPushModeAction.prototype.execute = function(lexer) {\n    lexer.pushMode(this.mode);\n};\n\nLexerPushModeAction.prototype.hashString = function() {\n    return \"\" + this.actionType + this.mode;\n};\n\nLexerPushModeAction.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof LexerPushModeAction)) {\n        return false;\n    } else {\n        return this.mode === other.mode;\n    }\n};\n\nLexerPushModeAction.prototype.toString = function() {\n\treturn \"pushMode(\" + this.mode + \")\";\n};\n\n\n// Implements the {@code popMode} lexer action by calling {@link Lexer//popMode}.\n//\n// <p>The {@code popMode} command does not have any parameters, so this action is\n// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\nfunction LexerPopModeAction() {\n\tLexerAction.call(this,LexerActionType.POP_MODE);\n\treturn this;\n}\n\nLexerPopModeAction.prototype = Object.create(LexerAction.prototype);\nLexerPopModeAction.prototype.constructor = LexerPopModeAction;\n\nLexerPopModeAction.INSTANCE = new LexerPopModeAction();\n\n// <p>This action is implemented by calling {@link Lexer//popMode}.</p>\nLexerPopModeAction.prototype.execute = function(lexer) {\n    lexer.popMode();\n};\n\nLexerPopModeAction.prototype.toString = function() {\n\treturn \"popMode\";\n};\n\n// Implements the {@code more} lexer action by calling {@link Lexer//more}.\n//\n// <p>The {@code more} command does not have any parameters, so this action is\n// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\nfunction LexerMoreAction() {\n\tLexerAction.call(this, LexerActionType.MORE);\n\treturn this;\n}\n\nLexerMoreAction.prototype = Object.create(LexerAction.prototype);\nLexerMoreAction.prototype.constructor = LexerMoreAction;\n\nLexerMoreAction.INSTANCE = new LexerMoreAction();\n\n// <p>This action is implemented by calling {@link Lexer//popMode}.</p>\nLexerMoreAction.prototype.execute = function(lexer) {\n    lexer.more();\n};\n\nLexerMoreAction.prototype.toString = function() {\n    return \"more\";\n};\n\n\n// Implements the {@code mode} lexer action by calling {@link Lexer//mode} with\n// the assigned mode.\nfunction LexerModeAction(mode) {\n\tLexerAction.call(this, LexerActionType.MODE);\n    this.mode = mode;\n    return this;\n}\n\nLexerModeAction.prototype = Object.create(LexerAction.prototype);\nLexerModeAction.prototype.constructor = LexerModeAction;\n\n// <p>This action is implemented by calling {@link Lexer//mode} with the\n// value provided by {@link //getMode}.</p>\nLexerModeAction.prototype.execute = function(lexer) {\n    lexer.mode(this.mode);\n};\n\nLexerModeAction.prototype.hashString = function() {\n\treturn \"\" + this.actionType + this.mode;\n};\n\nLexerModeAction.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof LexerModeAction)) {\n        return false;\n    } else {\n        return this.mode === other.mode;\n    }\n};\n\nLexerModeAction.prototype.toString = function() {\n    return \"mode(\" + this.mode + \")\";\n};\n\n// Executes a custom lexer action by calling {@link Recognizer//action} with the\n// rule and action indexes assigned to the custom action. The implementation of\n// a custom action is added to the generated code for the lexer in an override\n// of {@link Recognizer//action} when the grammar is compiled.\n//\n// <p>This class may represent embedded actions created with the <code>{...}</code>\n// syntax in ANTLR 4, as well as actions created for lexer commands where the\n// command argument could not be evaluated when the grammar was compiled.</p>\n\n\n    // Constructs a custom lexer action with the specified rule and action\n    // indexes.\n    //\n    // @param ruleIndex The rule index to use for calls to\n    // {@link Recognizer//action}.\n    // @param actionIndex The action index to use for calls to\n    // {@link Recognizer//action}.\n\nfunction LexerCustomAction(ruleIndex, actionIndex) {\n\tLexerAction.call(this, LexerActionType.CUSTOM);\n    this.ruleIndex = ruleIndex;\n    this.actionIndex = actionIndex;\n    this.isPositionDependent = true;\n    return this;\n}\n\nLexerCustomAction.prototype = Object.create(LexerAction.prototype);\nLexerCustomAction.prototype.constructor = LexerCustomAction;\n\n// <p>Custom actions are implemented by calling {@link Lexer//action} with the\n// appropriate rule and action indexes.</p>\nLexerCustomAction.prototype.execute = function(lexer) {\n    lexer.action(null, this.ruleIndex, this.actionIndex);\n};\n\nLexerCustomAction.prototype.hashString = function() {\n    return \"\" + this.actionType + this.ruleIndex + this.actionIndex;\n};\n\nLexerCustomAction.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof LexerCustomAction)) {\n        return false;\n    } else {\n        return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;\n    }\n};\n\n// Implements the {@code channel} lexer action by calling\n// {@link Lexer//setChannel} with the assigned channel.\n// Constructs a new {@code channel} action with the specified channel value.\n// @param channel The channel value to pass to {@link Lexer//setChannel}.\nfunction LexerChannelAction(channel) {\n\tLexerAction.call(this, LexerActionType.CHANNEL);\n    this.channel = channel;\n    return this;\n}\n\nLexerChannelAction.prototype = Object.create(LexerAction.prototype);\nLexerChannelAction.prototype.constructor = LexerChannelAction;\n\n// <p>This action is implemented by calling {@link Lexer//setChannel} with the\n// value provided by {@link //getChannel}.</p>\nLexerChannelAction.prototype.execute = function(lexer) {\n    lexer._channel = this.channel;\n};\n\nLexerChannelAction.prototype.hashString = function() {\n    return \"\" + this.actionType + this.channel;\n};\n\nLexerChannelAction.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof LexerChannelAction)) {\n        return false;\n    } else {\n        return this.channel === other.channel;\n    }\n};\n\nLexerChannelAction.prototype.toString = function() {\n    return \"channel(\" + this.channel + \")\";\n};\n\n// This implementation of {@link LexerAction} is used for tracking input offsets\n// for position-dependent actions within a {@link LexerActionExecutor}.\n//\n// <p>This action is not serialized as part of the ATN, and is only required for\n// position-dependent lexer actions which appear at a location other than the\n// end of a rule. For more information about DFA optimizations employed for\n// lexer actions, see {@link LexerActionExecutor//append} and\n// {@link LexerActionExecutor//fixOffsetBeforeMatch}.</p>\n\n// Constructs a new indexed custom action by associating a character offset\n// with a {@link LexerAction}.\n//\n// <p>Note: This class is only required for lexer actions for which\n// {@link LexerAction//isPositionDependent} returns {@code true}.</p>\n//\n// @param offset The offset into the input {@link CharStream}, relative to\n// the token start index, at which the specified lexer action should be\n// executed.\n// @param action The lexer action to execute at a particular offset in the\n// input {@link CharStream}.\nfunction LexerIndexedCustomAction(offset, action) {\n\tLexerAction.call(this, action.actionType);\n    this.offset = offset;\n    this.action = action;\n    this.isPositionDependent = true;\n    return this;\n}\n\nLexerIndexedCustomAction.prototype = Object.create(LexerAction.prototype);\nLexerIndexedCustomAction.prototype.constructor = LexerIndexedCustomAction;\n\n// <p>This method calls {@link //execute} on the result of {@link //getAction}\n// using the provided {@code lexer}.</p>\nLexerIndexedCustomAction.prototype.execute = function(lexer) {\n    // assume the input stream position was properly set by the calling code\n    this.action.execute(lexer);\n};\n\nLexerIndexedCustomAction.prototype.hashString = function() {\n    return \"\" + this.actionType + this.offset + this.action;\n};\n\nLexerIndexedCustomAction.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof LexerIndexedCustomAction)) {\n        return false;\n    } else {\n        return this.offset === other.offset && this.action === other.action;\n    }\n};\n\n\nexports.LexerActionType = LexerActionType;\nexports.LexerSkipAction = LexerSkipAction;\nexports.LexerChannelAction = LexerChannelAction;\nexports.LexerCustomAction = LexerCustomAction;\nexports.LexerIndexedCustomAction = LexerIndexedCustomAction;\nexports.LexerMoreAction = LexerMoreAction;\nexports.LexerTypeAction = LexerTypeAction;\nexports.LexerPushModeAction = LexerPushModeAction;\nexports.LexerPopModeAction = LexerPopModeAction;\nexports.LexerModeAction = LexerModeAction;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/LexerAction.js\n ** module id = 23\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\n// When we hit an accept state in either the DFA or the ATN, we\n//  have to notify the character stream to start buffering characters\n//  via {@link IntStream//mark} and record the current state. The current sim state\n//  includes the current index into the input, the current line,\n//  and current character position in that line. Note that the Lexer is\n//  tracking the starting line and characterization of the token. These\n//  variables track the \"state\" of the simulator when it hits an accept state.\n//\n//  <p>We track these variables separately for the DFA and ATN simulation\n//  because the DFA simulation often has to fail over to the ATN\n//  simulation. If the ATN simulation fails, we need the DFA to fall\n//  back to its previously accepted state, if any. If the ATN succeeds,\n//  then the ATN does the accept and the DFA simulator that invoked it\n//  can simply return the predicted token type.</p>\n///\n\nvar Token = require('./../Token').Token;\nvar Lexer = require('./../Lexer').Lexer;\nvar ATN = require('./ATN').ATN;\nvar ATNSimulator = require('./ATNSimulator').ATNSimulator;\nvar DFAState = require('./../dfa/DFAState').DFAState;\nvar ATNConfigSet = require('./ATNConfigSet').ATNConfigSet;\nvar OrderedATNConfigSet = require('./ATNConfigSet').OrderedATNConfigSet;\nvar PredictionContext = require('./../PredictionContext').PredictionContext;\nvar SingletonPredictionContext = require('./../PredictionContext').SingletonPredictionContext;\nvar RuleStopState = require('./ATNState').RuleStopState;\nvar LexerATNConfig = require('./ATNConfig').LexerATNConfig;\nvar Transition = require('./Transition').Transition;\nvar LexerActionExecutor = require('./LexerActionExecutor').LexerActionExecutor;\nvar LexerNoViableAltException = require('./../error/Errors').LexerNoViableAltException;\n\nfunction resetSimState(sim) {\n\tsim.index = -1;\n\tsim.line = 0;\n\tsim.column = -1;\n\tsim.dfaState = null;\n}\n\nfunction SimState() {\n\tresetSimState(this);\n\treturn this;\n}\n\nSimState.prototype.reset = function() {\n\tresetSimState(this);\n};\n\nfunction LexerATNSimulator(recog, atn, decisionToDFA, sharedContextCache) {\n\tATNSimulator.call(this, atn, sharedContextCache);\n\tthis.decisionToDFA = decisionToDFA;\n\tthis.recog = recog;\n\t// The current token's starting index into the character stream.\n\t// Shared across DFA to ATN simulation in case the ATN fails and the\n\t// DFA did not have a previous accept state. In this case, we use the\n\t// ATN-generated exception object.\n\tthis.startIndex = -1;\n\t// line number 1..n within the input///\n\tthis.line = 1;\n\t// The index of the character relative to the beginning of the line\n\t// 0..n-1///\n\tthis.column = 0;\n\tthis.mode = Lexer.DEFAULT_MODE;\n\t// Used during DFA/ATN exec to record the most recent accept configuration\n\t// info\n\tthis.prevAccept = new SimState();\n\t// done\n\treturn this;\n}\n\nLexerATNSimulator.prototype = Object.create(ATNSimulator.prototype);\nLexerATNSimulator.prototype.constructor = LexerATNSimulator;\n\nLexerATNSimulator.debug = false;\nLexerATNSimulator.dfa_debug = false;\n\nLexerATNSimulator.MIN_DFA_EDGE = 0;\nLexerATNSimulator.MAX_DFA_EDGE = 127; // forces unicode to stay in ATN\n\nLexerATNSimulator.match_calls = 0;\n\nLexerATNSimulator.prototype.copyState = function(simulator) {\n\tthis.column = simulator.column;\n\tthis.line = simulator.line;\n\tthis.mode = simulator.mode;\n\tthis.startIndex = simulator.startIndex;\n};\n\nLexerATNSimulator.prototype.match = function(input, mode) {\n\tthis.match_calls += 1;\n\tthis.mode = mode;\n\tvar mark = input.mark();\n\ttry {\n\t\tthis.startIndex = input.index;\n\t\tthis.prevAccept.reset();\n\t\tvar dfa = this.decisionToDFA[mode];\n\t\tif (dfa.s0 === null) {\n\t\t\treturn this.matchATN(input);\n\t\t} else {\n\t\t\treturn this.execATN(input, dfa.s0);\n\t\t}\n\t} finally {\n\t\tinput.release(mark);\n\t}\n};\n\nLexerATNSimulator.prototype.reset = function() {\n\tthis.prevAccept.reset();\n\tthis.startIndex = -1;\n\tthis.line = 1;\n\tthis.column = 0;\n\tthis.mode = Lexer.DEFAULT_MODE;\n};\n\nLexerATNSimulator.prototype.matchATN = function(input) {\n\tvar startState = this.atn.modeToStartState[this.mode];\n\n\tif (this.debug) {\n\t\tconsole.log(\"matchATN mode \" + this.mode + \" start: \" + startState);\n\t}\n\tvar old_mode = this.mode;\n\tvar s0_closure = this.computeStartState(input, startState);\n\tvar suppressEdge = s0_closure.hasSemanticContext;\n\ts0_closure.hasSemanticContext = false;\n\n\tvar next = this.addDFAState(s0_closure);\n\tif (!suppressEdge) {\n\t\tthis.decisionToDFA[this.mode].s0 = next;\n\t}\n\n\tvar predict = this.execATN(input, next);\n\n\tif (this.debug) {\n\t\tconsole.log(\"DFA after matchATN: \" + this.decisionToDFA[old_mode].toLexerString());\n\t}\n\treturn predict;\n};\n\nLexerATNSimulator.prototype.execATN = function(input, ds0) {\n\tif (this.debug) {\n\t\tconsole.log(\"start state closure=\" + ds0.configs);\n\t}\n\tif (ds0.isAcceptState) {\n\t\t// allow zero-length tokens\n\t\tthis.captureSimState(this.prevAccept, input, ds0);\n\t}\n\tvar t = input.LA(1);\n\tvar s = ds0; // s is current/from DFA state\n\n\twhile (true) { // while more work\n\t\tif (this.debug) {\n\t\t\tconsole.log(\"execATN loop starting closure: \" + s.configs);\n\t\t}\n\n\t\t// As we move src->trg, src->trg, we keep track of the previous trg to\n\t\t// avoid looking up the DFA state again, which is expensive.\n\t\t// If the previous target was already part of the DFA, we might\n\t\t// be able to avoid doing a reach operation upon t. If s!=null,\n\t\t// it means that semantic predicates didn't prevent us from\n\t\t// creating a DFA state. Once we know s!=null, we check to see if\n\t\t// the DFA state has an edge already for t. If so, we can just reuse\n\t\t// it's configuration set; there's no point in re-computing it.\n\t\t// This is kind of like doing DFA simulation within the ATN\n\t\t// simulation because DFA simulation is really just a way to avoid\n\t\t// computing reach/closure sets. Technically, once we know that\n\t\t// we have a previously added DFA state, we could jump over to\n\t\t// the DFA simulator. But, that would mean popping back and forth\n\t\t// a lot and making things more complicated algorithmically.\n\t\t// This optimization makes a lot of sense for loops within DFA.\n\t\t// A character will take us back to an existing DFA state\n\t\t// that already has lots of edges out of it. e.g., .* in comments.\n\t\t// print(\"Target for:\" + str(s) + \" and:\" + str(t))\n\t\tvar target = this.getExistingTargetState(s, t);\n\t\t// print(\"Existing:\" + str(target))\n\t\tif (target === null) {\n\t\t\ttarget = this.computeTargetState(input, s, t);\n\t\t\t// print(\"Computed:\" + str(target))\n\t\t}\n\t\tif (target === ATNSimulator.ERROR) {\n\t\t\tbreak;\n\t\t}\n\t\t// If this is a consumable input element, make sure to consume before\n\t\t// capturing the accept state so the input index, line, and char\n\t\t// position accurately reflect the state of the interpreter at the\n\t\t// end of the token.\n\t\tif (t !== Token.EOF) {\n\t\t\tthis.consume(input);\n\t\t}\n\t\tif (target.isAcceptState) {\n\t\t\tthis.captureSimState(this.prevAccept, input, target);\n\t\t\tif (t === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tt = input.LA(1);\n\t\ts = target; // flip; current DFA target becomes new src/from state\n\t}\n\treturn this.failOrAccept(this.prevAccept, input, s.configs, t);\n};\n\n// Get an existing target state for an edge in the DFA. If the target state\n// for the edge has not yet been computed or is otherwise not available,\n// this method returns {@code null}.\n//\n// @param s The current DFA state\n// @param t The next input symbol\n// @return The existing target DFA state for the given input symbol\n// {@code t}, or {@code null} if the target state for this edge is not\n// already cached\nLexerATNSimulator.prototype.getExistingTargetState = function(s, t) {\n\tif (s.edges === null || t < LexerATNSimulator.MIN_DFA_EDGE || t > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\treturn null;\n\t}\n\n\tvar target = s.edges[t - LexerATNSimulator.MIN_DFA_EDGE];\n\tif(target===undefined) {\n\t\ttarget = null;\n\t}\n\tif (this.debug && target !== null) {\n\t\tconsole.log(\"reuse state \" + s.stateNumber + \" edge to \" + target.stateNumber);\n\t}\n\treturn target;\n};\n\n// Compute a target state for an edge in the DFA, and attempt to add the\n// computed state and corresponding edge to the DFA.\n//\n// @param input The input stream\n// @param s The current DFA state\n// @param t The next input symbol\n//\n// @return The computed target DFA state for the given input symbol\n// {@code t}. If {@code t} does not lead to a valid DFA state, this method\n// returns {@link //ERROR}.\nLexerATNSimulator.prototype.computeTargetState = function(input, s, t) {\n\tvar reach = new OrderedATNConfigSet();\n\t// if we don't find an existing DFA state\n\t// Fill reach starting from closure, following t transitions\n\tthis.getReachableConfigSet(input, s.configs, reach, t);\n\n\tif (reach.items.length === 0) { // we got nowhere on t from s\n\t\tif (!reach.hasSemanticContext) {\n\t\t\t// we got nowhere on t, don't throw out this knowledge; it'd\n\t\t\t// cause a failover from DFA later.\n\t\t\tthis.addDFAEdge(s, t, ATNSimulator.ERROR);\n\t\t}\n\t\t// stop when we can't match any more char\n\t\treturn ATNSimulator.ERROR;\n\t}\n\t// Add an edge from s to target DFA found/created for reach\n\treturn this.addDFAEdge(s, t, null, reach);\n};\n\nLexerATNSimulator.prototype.failOrAccept = function(prevAccept, input, reach, t) {\n\tif (this.prevAccept.dfaState !== null) {\n\t\tvar lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;\n\t\tthis.accept(input, lexerActionExecutor, this.startIndex,\n\t\t\t\tprevAccept.index, prevAccept.line, prevAccept.column);\n\t\treturn prevAccept.dfaState.prediction;\n\t} else {\n\t\t// if no accept and EOF is first char, return EOF\n\t\tif (t === Token.EOF && input.index === this.startIndex) {\n\t\t\treturn Token.EOF;\n\t\t}\n\t\tthrow new LexerNoViableAltException(this.recog, input, this.startIndex, reach);\n\t}\n};\n\n// Given a starting configuration set, figure out all ATN configurations\n// we can reach upon input {@code t}. Parameter {@code reach} is a return\n// parameter.\nLexerATNSimulator.prototype.getReachableConfigSet = function(input, closure,\n\t\treach, t) {\n\t// this is used to skip processing for configs which have a lower priority\n\t// than a config that already reached an accept state for the same rule\n\tvar skipAlt = ATN.INVALID_ALT_NUMBER;\n\tfor (var i = 0; i < closure.items.length; i++) {\n\t\tvar cfg = closure.items[i];\n\t\tvar currentAltReachedAcceptState = (cfg.alt === skipAlt);\n\t\tif (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {\n\t\t\tcontinue;\n\t\t}\n\t\tif (this.debug) {\n\t\t\tconsole.log(\"testing %s at %s\\n\", this.getTokenName(t), cfg\n\t\t\t\t\t.toString(this.recog, true));\n\t\t}\n\t\tfor (var j = 0; j < cfg.state.transitions.length; j++) {\n\t\t\tvar trans = cfg.state.transitions[j]; // for each transition\n\t\t\tvar target = this.getReachableTarget(trans, t);\n\t\t\tif (target !== null) {\n\t\t\t\tvar lexerActionExecutor = cfg.lexerActionExecutor;\n\t\t\t\tif (lexerActionExecutor !== null) {\n\t\t\t\t\tlexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);\n\t\t\t\t}\n\t\t\t\tvar treatEofAsEpsilon = (t === Token.EOF);\n\t\t\t\tvar config = new LexerATNConfig({state:target, lexerActionExecutor:lexerActionExecutor}, cfg);\n\t\t\t\tif (this.closure(input, config, reach,\n\t\t\t\t\t\tcurrentAltReachedAcceptState, true, treatEofAsEpsilon)) {\n\t\t\t\t\t// any remaining configs for this alt have a lower priority\n\t\t\t\t\t// than the one that just reached an accept state.\n\t\t\t\t\tskipAlt = cfg.alt;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n};\n\nLexerATNSimulator.prototype.accept = function(input, lexerActionExecutor,\n\t\tstartIndex, index, line, charPos) {\n\tif (this.debug) {\n\t\tconsole.log(\"ACTION %s\\n\", lexerActionExecutor);\n\t}\n\t// seek to after last char in token\n\tinput.seek(index);\n\tthis.line = line;\n\tthis.column = charPos;\n\tif (lexerActionExecutor !== null && this.recog !== null) {\n\t\tlexerActionExecutor.execute(this.recog, input, startIndex);\n\t}\n};\n\nLexerATNSimulator.prototype.getReachableTarget = function(trans, t) {\n\tif (trans.matches(t, 0, 0xFFFE)) {\n\t\treturn trans.target;\n\t} else {\n\t\treturn null;\n\t}\n};\n\nLexerATNSimulator.prototype.computeStartState = function(input, p) {\n\tvar initialContext = PredictionContext.EMPTY;\n\tvar configs = new OrderedATNConfigSet();\n\tfor (var i = 0; i < p.transitions.length; i++) {\n\t\tvar target = p.transitions[i].target;\n        var cfg = new LexerATNConfig({state:target, alt:i+1, context:initialContext}, null);\n\t\tthis.closure(input, cfg, configs, false, false, false);\n\t}\n\treturn configs;\n};\n\n// Since the alternatives within any lexer decision are ordered by\n// preference, this method stops pursuing the closure as soon as an accept\n// state is reached. After the first accept state is reached by depth-first\n// search from {@code config}, all other (potentially reachable) states for\n// this rule would have a lower priority.\n//\n// @return {@code true} if an accept state is reached, otherwise\n// {@code false}.\nLexerATNSimulator.prototype.closure = function(input, config, configs,\n\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon) {\n\tvar cfg = null;\n\tif (this.debug) {\n\t\tconsole.log(\"closure(\" + config.toString(this.recog, true) + \")\");\n\t}\n\tif (config.state instanceof RuleStopState) {\n\t\tif (this.debug) {\n\t\t\tif (this.recog !== null) {\n\t\t\t\tconsole.log(\"closure at %s rule stop %s\\n\", this.recog.getRuleNames()[config.state.ruleIndex], config);\n\t\t\t} else {\n\t\t\t\tconsole.log(\"closure at rule stop %s\\n\", config);\n\t\t\t}\n\t\t}\n\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\tif (config.context === null || config.context.isEmpty()) {\n\t\t\t\tconfigs.add(config);\n\t\t\t\treturn true;\n\t\t\t} else {\n\t\t\t\tconfigs.add(new LexerATNConfig({ state:config.state, context:PredictionContext.EMPTY}, config));\n\t\t\t\tcurrentAltReachedAcceptState = true;\n\t\t\t}\n\t\t}\n\t\tif (config.context !== null && !config.context.isEmpty()) {\n\t\t\tfor (var i = 0; i < config.context.length; i++) {\n\t\t\t\tif (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\tvar newContext = config.context.getParent(i); // \"pop\" return state\n\t\t\t\t\tvar returnState = this.atn.states[config.context.getReturnState(i)];\n\t\t\t\t\tcfg = new LexerATNConfig({ state:returnState, context:newContext }, config);\n\t\t\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg,\n\t\t\t\t\t\t\tconfigs, currentAltReachedAcceptState, speculative,\n\t\t\t\t\t\t\ttreatEofAsEpsilon);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn currentAltReachedAcceptState;\n\t}\n\t// optimization\n\tif (!config.state.epsilonOnlyTransitions) {\n\t\tif (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {\n\t\t\tconfigs.add(config);\n\t\t}\n\t}\n\tfor (var j = 0; j < config.state.transitions.length; j++) {\n\t\tvar trans = config.state.transitions[j];\n\t\tcfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);\n\t\tif (cfg !== null) {\n\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg, configs,\n\t\t\t\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon);\n\t\t}\n\t}\n\treturn currentAltReachedAcceptState;\n};\n\n// side-effect: can alter configs.hasSemanticContext\nLexerATNSimulator.prototype.getEpsilonTarget = function(input, config, trans,\n\t\tconfigs, speculative, treatEofAsEpsilon) {\n\tvar cfg = null;\n\tif (trans.serializationType === Transition.RULE) {\n\t\tvar newContext = SingletonPredictionContext.create(config.context, trans.followState.stateNumber);\n\t\tcfg = new LexerATNConfig( { state:trans.target, context:newContext}, config);\n\t} else if (trans.serializationType === Transition.PRECEDENCE) {\n\t\tthrow \"Precedence predicates are not supported in lexers.\";\n\t} else if (trans.serializationType === Transition.PREDICATE) {\n\t\t// Track traversing semantic predicates. If we traverse,\n\t\t// we cannot add a DFA state for this \"reach\" computation\n\t\t// because the DFA would not test the predicate again in the\n\t\t// future. Rather than creating collections of semantic predicates\n\t\t// like v3 and testing them on prediction, v4 will test them on the\n\t\t// fly all the time using the ATN not the DFA. This is slower but\n\t\t// semantically it's not used that often. One of the key elements to\n\t\t// this predicate mechanism is not adding DFA states that see\n\t\t// predicates immediately afterwards in the ATN. For example,\n\n\t\t// a : ID {p1}? | ID {p2}? ;\n\n\t\t// should create the start state for rule 'a' (to save start state\n\t\t// competition), but should not create target of ID state. The\n\t\t// collection of ATN states the following ID references includes\n\t\t// states reached by traversing predicates. Since this is when we\n\t\t// test them, we cannot cash the DFA state target of ID.\n\n\t\tif (this.debug) {\n\t\t\tconsole.log(\"EVAL rule \" + trans.ruleIndex + \":\" + trans.predIndex);\n\t\t}\n\t\tconfigs.hasSemanticContext = true;\n\t\tif (this.evaluatePredicate(input, trans.ruleIndex, trans.predIndex, speculative)) {\n\t\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t\t}\n\t} else if (trans.serializationType === Transition.ACTION) {\n\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\t// execute actions anywhere in the start rule for a token.\n\t\t\t//\n\t\t\t// TODO: if the entry rule is invoked recursively, some\n\t\t\t// actions may be executed during the recursive call. The\n\t\t\t// problem can appear when hasEmptyPath() is true but\n\t\t\t// isEmpty() is false. In this case, the config needs to be\n\t\t\t// split into two contexts - one with just the empty path\n\t\t\t// and another with everything but the empty path.\n\t\t\t// Unfortunately, the current algorithm does not allow\n\t\t\t// getEpsilonTarget to return two configurations, so\n\t\t\t// additional modifications are needed before we can support\n\t\t\t// the split operation.\n\t\t\tvar lexerActionExecutor = LexerActionExecutor.append(config.lexerActionExecutor,\n\t\t\t\t\tthis.atn.lexerActions[trans.actionIndex]);\n\t\t\tcfg = new LexerATNConfig({ state:trans.target, lexerActionExecutor:lexerActionExecutor }, config);\n\t\t} else {\n\t\t\t// ignore actions in referenced rules\n\t\t\tcfg = new LexerATNConfig( { state:trans.target}, config);\n\t\t}\n\t} else if (trans.serializationType === Transition.EPSILON) {\n\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t} else if (trans.serializationType === Transition.ATOM ||\n\t\t\t\ttrans.serializationType === Transition.RANGE ||\n\t\t\t\ttrans.serializationType === Transition.SET) {\n\t\tif (treatEofAsEpsilon) {\n\t\t\tif (trans.matches(Token.EOF, 0, 0xFFFF)) {\n\t\t\t\tcfg = new LexerATNConfig( { state:trans.target }, config);\n\t\t\t}\n\t\t}\n\t}\n\treturn cfg;\n};\n\n// Evaluate a predicate specified in the lexer.\n//\n// <p>If {@code speculative} is {@code true}, this method was called before\n// {@link //consume} for the matched character. This method should call\n// {@link //consume} before evaluating the predicate to ensure position\n// sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},\n// and {@link Lexer//getcolumn}, properly reflect the current\n// lexer state. This method should restore {@code input} and the simulator\n// to the original state before returning (i.e. undo the actions made by the\n// call to {@link //consume}.</p>\n//\n// @param input The input stream.\n// @param ruleIndex The rule containing the predicate.\n// @param predIndex The index of the predicate within the rule.\n// @param speculative {@code true} if the current index in {@code input} is\n// one character before the predicate's location.\n//\n// @return {@code true} if the specified predicate evaluates to\n// {@code true}.\n// /\nLexerATNSimulator.prototype.evaluatePredicate = function(input, ruleIndex,\n\t\tpredIndex, speculative) {\n\t// assume true if no recognizer was provided\n\tif (this.recog === null) {\n\t\treturn true;\n\t}\n\tif (!speculative) {\n\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t}\n\tvar savedcolumn = this.column;\n\tvar savedLine = this.line;\n\tvar index = input.index;\n\tvar marker = input.mark();\n\ttry {\n\t\tthis.consume(input);\n\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t} finally {\n\t\tthis.column = savedcolumn;\n\t\tthis.line = savedLine;\n\t\tinput.seek(index);\n\t\tinput.release(marker);\n\t}\n};\n\nLexerATNSimulator.prototype.captureSimState = function(settings, input, dfaState) {\n\tsettings.index = input.index;\n\tsettings.line = this.line;\n\tsettings.column = this.column;\n\tsettings.dfaState = dfaState;\n};\n\nLexerATNSimulator.prototype.addDFAEdge = function(from_, tk, to, cfgs) {\n\tif (to === undefined) {\n\t\tto = null;\n\t}\n\tif (cfgs === undefined) {\n\t\tcfgs = null;\n\t}\n\tif (to === null && cfgs !== null) {\n\t\t// leading to this call, ATNConfigSet.hasSemanticContext is used as a\n\t\t// marker indicating dynamic predicate evaluation makes this edge\n\t\t// dependent on the specific input sequence, so the static edge in the\n\t\t// DFA should be omitted. The target DFAState is still created since\n\t\t// execATN has the ability to resynchronize with the DFA state cache\n\t\t// following the predicate evaluation step.\n\t\t//\n\t\t// TJP notes: next time through the DFA, we see a pred again and eval.\n\t\t// If that gets us to a previously created (but dangling) DFA\n\t\t// state, we can continue in pure DFA mode from there.\n\t\t// /\n\t\tvar suppressEdge = cfgs.hasSemanticContext;\n\t\tcfgs.hasSemanticContext = false;\n\n\t\tto = this.addDFAState(cfgs);\n\n\t\tif (suppressEdge) {\n\t\t\treturn to;\n\t\t}\n\t}\n\t// add the edge\n\tif (tk < LexerATNSimulator.MIN_DFA_EDGE || tk > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\t// Only track edges within the DFA bounds\n\t\treturn to;\n\t}\n\tif (this.debug) {\n\t\tconsole.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + tk);\n\t}\n\tif (from_.edges === null) {\n\t\t// make room for tokens 1..n and -1 masquerading as index 0\n\t\tfrom_.edges = [];\n\t}\n\tfrom_.edges[tk - LexerATNSimulator.MIN_DFA_EDGE] = to; // connect\n\n\treturn to;\n};\n\n// Add a new DFA state if there isn't one with this set of\n// configurations already. This method also detects the first\n// configuration containing an ATN rule stop state. Later, when\n// traversing the DFA, we will know which rule to accept.\nLexerATNSimulator.prototype.addDFAState = function(configs) {\n\tvar proposed = new DFAState(null, configs);\n\tvar firstConfigWithRuleStopState = null;\n\tfor (var i = 0; i < configs.items.length; i++) {\n\t\tvar cfg = configs.items[i];\n\t\tif (cfg.state instanceof RuleStopState) {\n\t\t\tfirstConfigWithRuleStopState = cfg;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (firstConfigWithRuleStopState !== null) {\n\t\tproposed.isAcceptState = true;\n\t\tproposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;\n\t\tproposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];\n\t}\n\tvar hash = proposed.hashString();\n\tvar dfa = this.decisionToDFA[this.mode];\n\tvar existing = dfa.states[hash] || null;\n\tif (existing!==null) {\n\t\treturn existing;\n\t}\n\tvar newState = proposed;\n\tnewState.stateNumber = dfa.states.length;\n\tconfigs.setReadonly(true);\n\tnewState.configs = configs;\n\tdfa.states[hash] = newState;\n\treturn newState;\n};\n\nLexerATNSimulator.prototype.getDFA = function(mode) {\n\treturn this.decisionToDFA[mode];\n};\n\n// Get the text matched so far for the current token.\nLexerATNSimulator.prototype.getText = function(input) {\n\t// index is first lookahead char, don't include.\n\treturn input.getText(this.startIndex, input.index - 1);\n};\n\nLexerATNSimulator.prototype.consume = function(input) {\n\tvar curChar = input.LA(1);\n\tif (curChar === \"\\n\".charCodeAt(0)) {\n\t\tthis.line += 1;\n\t\tthis.column = 0;\n\t} else {\n\t\tthis.column += 1;\n\t}\n\tinput.consume();\n};\n\nLexerATNSimulator.prototype.getTokenName = function(tt) {\n\tif (tt === -1) {\n\t\treturn \"EOF\";\n\t} else {\n\t\treturn \"'\" + String.fromCharCode(tt) + \"'\";\n\t}\n};\n\nexports.LexerATNSimulator = LexerATNSimulator;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/LexerATNSimulator.js\n ** module id = 24\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  this SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  this SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\n// A lexer is recognizer that draws input symbols from a character stream.\n//  lexer grammars result in a subclass of this object. A Lexer object\n//  uses simplified match() and error recovery mechanisms in the interest\n//  of speed.\n///\n\nvar Token = require('./Token').Token;\nvar Recognizer = require('./Recognizer').Recognizer;\nvar CommonTokenFactory = require('./CommonTokenFactory').CommonTokenFactory;\nvar LexerNoViableAltException = require('./error/Errors').LexerNoViableAltException;\n\nfunction TokenSource() {\n\treturn this;\n}\n\nfunction Lexer(input) {\n\tRecognizer.call(this);\n\tthis._input = input;\n\tthis._factory = CommonTokenFactory.DEFAULT;\n\tthis._tokenFactorySourcePair = [ this, input ];\n\n\tthis._interp = null; // child classes must populate this\n\n\t// The goal of all lexer rules/methods is to create a token object.\n\t// this is an instance variable as multiple rules may collaborate to\n\t// create a single token. nextToken will return this object after\n\t// matching lexer rule(s). If you subclass to allow multiple token\n\t// emissions, then set this to the last token to be matched or\n\t// something nonnull so that the auto token emit mechanism will not\n\t// emit another token.\n\tthis._token = null;\n\n\t// What character index in the stream did the current token start at?\n\t// Needed, for example, to get the text for current token. Set at\n\t// the start of nextToken.\n\tthis._tokenStartCharIndex = -1;\n\n\t// The line on which the first character of the token resides///\n\tthis._tokenStartLine = -1;\n\n\t// The character position of first character within the line///\n\tthis._tokenStartColumn = -1;\n\n\t// Once we see EOF on char stream, next token will be EOF.\n\t// If you have DONE : EOF ; then you see DONE EOF.\n\tthis._hitEOF = false;\n\n\t// The channel number for the current token///\n\tthis._channel = Token.DEFAULT_CHANNEL;\n\n\t// The token type for the current token///\n\tthis._type = Token.INVALID_TYPE;\n\n\tthis._modeStack = [];\n\tthis._mode = Lexer.DEFAULT_MODE;\n\n\t// You can set the text for the current token to override what is in\n\t// the input char buffer. Use setText() or can set this instance var.\n\t// /\n\tthis._text = null;\n\n\treturn this;\n}\n\nLexer.prototype = Object.create(Recognizer.prototype);\nLexer.prototype.constructor = Lexer;\n\nLexer.DEFAULT_MODE = 0;\nLexer.MORE = -2;\nLexer.SKIP = -3;\n\nLexer.DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\nLexer.HIDDEN = Token.HIDDEN_CHANNEL;\nLexer.MIN_CHAR_VALUE = '\\u0000';\nLexer.MAX_CHAR_VALUE = '\\uFFFE';\n\nLexer.prototype.reset = function() {\n\t// wack Lexer state variables\n\tif (this._input !== null) {\n\t\tthis._input.seek(0); // rewind the input\n\t}\n\tthis._token = null;\n\tthis._type = Token.INVALID_TYPE;\n\tthis._channel = Token.DEFAULT_CHANNEL;\n\tthis._tokenStartCharIndex = -1;\n\tthis._tokenStartColumn = -1;\n\tthis._tokenStartLine = -1;\n\tthis._text = null;\n\n\tthis._hitEOF = false;\n\tthis._mode = Lexer.DEFAULT_MODE;\n\tthis._modeStack = [];\n\n\tthis._interp.reset();\n};\n\n// Return a token from this source; i.e., match a token on the char stream.\nLexer.prototype.nextToken = function() {\n\tif (this._input === null) {\n\t\tthrow \"nextToken requires a non-null input stream.\";\n\t}\n\n\t// Mark start location in char stream so unbuffered streams are\n\t// guaranteed at least have text of current token\n\tvar tokenStartMarker = this._input.mark();\n\ttry {\n\t\twhile (true) {\n\t\t\tif (this._hitEOF) {\n\t\t\t\tthis.emitEOF();\n\t\t\t\treturn this._token;\n\t\t\t}\n\t\t\tthis._token = null;\n\t\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\t\tthis._tokenStartCharIndex = this._input.index;\n\t\t\tthis._tokenStartColumn = this._interp.column;\n\t\t\tthis._tokenStartLine = this._interp.line;\n\t\t\tthis._text = null;\n\t\t\tvar continueOuter = false;\n\t\t\twhile (true) {\n\t\t\t\tthis._type = Token.INVALID_TYPE;\n\t\t\t\tvar ttype = Lexer.SKIP;\n\t\t\t\ttry {\n\t\t\t\t\tttype = this._interp.match(this._input, this._mode);\n\t\t\t\t} catch (e) {\n\t\t\t\t\tthis.notifyListeners(e); // report error\n\t\t\t\t\tthis.recover(e);\n\t\t\t\t}\n\t\t\t\tif (this._input.LA(1) === Token.EOF) {\n\t\t\t\t\tthis._hitEOF = true;\n\t\t\t\t}\n\t\t\t\tif (this._type === Token.INVALID_TYPE) {\n\t\t\t\t\tthis._type = ttype;\n\t\t\t\t}\n\t\t\t\tif (this._type === Lexer.SKIP) {\n\t\t\t\t\tcontinueOuter = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (this._type !== Lexer.MORE) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (continueOuter) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (this._token === null) {\n\t\t\t\tthis.emit();\n\t\t\t}\n\t\t\treturn this._token;\n\t\t}\n\t} finally {\n\t\t// make sure we release marker after match or\n\t\t// unbuffered char stream will keep buffering\n\t\tthis._input.release(tokenStartMarker);\n\t}\n};\n\n// Instruct the lexer to skip creating a token for current lexer rule\n// and look for another token. nextToken() knows to keep looking when\n// a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n// if token==null at end of any token rule, it creates one for you\n// and emits it.\n// /\nLexer.prototype.skip = function() {\n\tthis._type = Lexer.SKIP;\n};\n\nLexer.prototype.more = function() {\n\tthis._type = Lexer.MORE;\n};\n\nLexer.prototype.mode = function(m) {\n\tthis._mode = m;\n};\n\nLexer.prototype.pushMode = function(m) {\n\tif (this._interp.debug) {\n\t\tconsole.log(\"pushMode \" + m);\n\t}\n\tthis._modeStack.push(this._mode);\n\tthis.mode(m);\n};\n\nLexer.prototype.popMode = function() {\n\tif (this._modeStack.length === 0) {\n\t\tthrow \"Empty Stack\";\n\t}\n\tif (this._interp.debug) {\n\t\tconsole.log(\"popMode back to \" + this._modeStack.slice(0, -1));\n\t}\n\tthis.mode(this._modeStack.pop());\n\treturn this._mode;\n};\n\n// Set the char stream and reset the lexer\nObject.defineProperty(Lexer.prototype, \"inputStream\", {\n\tget : function() {\n\t\treturn this._input;\n\t},\n\tset : function(input) {\n\t\tthis._input = null;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t\tthis.reset();\n\t\tthis._input = input;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t}\n});\n\nObject.defineProperty(Lexer.prototype, \"sourceName\", {\n\tget : function sourceName() {\n\t\treturn this._input.sourceName;\n\t}\n});\n\n// By default does not support multiple emits per nextToken invocation\n// for efficiency reasons. Subclass and override this method, nextToken,\n// and getToken (to push tokens into a list and pull from that list\n// rather than a single variable as this implementation does).\n// /\nLexer.prototype.emitToken = function(token) {\n\tthis._token = token;\n};\n\n// The standard method called to automatically emit a token at the\n// outermost lexical rule. The token object should point into the\n// char buffer start..stop. If there is a text override in 'text',\n// use that to set the token's text. Override this method to emit\n// custom Token objects or provide a new factory.\n// /\nLexer.prototype.emit = function() {\n\tvar t = this._factory.create(this._tokenFactorySourcePair, this._type,\n\t\t\tthis._text, this._channel, this._tokenStartCharIndex, this\n\t\t\t\t\t.getCharIndex() - 1, this._tokenStartLine,\n\t\t\tthis._tokenStartColumn);\n\tthis.emitToken(t);\n\treturn t;\n};\n\nLexer.prototype.emitEOF = function() {\n\tvar cpos = this.column;\n\tvar lpos = this.line;\n\tvar eof = this._factory.create(this._tokenFactorySourcePair, Token.EOF,\n\t\t\tnull, Token.DEFAULT_CHANNEL, this._input.index,\n\t\t\tthis._input.index - 1, lpos, cpos);\n\tthis.emitToken(eof);\n\treturn eof;\n};\n\nObject.defineProperty(Lexer.prototype, \"type\", {\n\tget : function() {\n\t\treturn this.type;\n\t},\n\tset : function(type) {\n\t\tthis._type = type;\n\t}\n});\n\nObject.defineProperty(Lexer.prototype, \"line\", {\n\tget : function() {\n\t\treturn this._interp.line;\n\t},\n\tset : function(line) {\n\t\tthis._interp.line = line;\n\t}\n});\n\nObject.defineProperty(Lexer.prototype, \"column\", {\n\tget : function() {\n\t\treturn this._interp.column;\n\t},\n\tset : function(column) {\n\t\tthis._interp.column = column;\n\t}\n});\n\n\n// What is the index of the current character of lookahead?///\nLexer.prototype.getCharIndex = function() {\n\treturn this._input.index;\n};\n\n// Return the text matched so far for the current token or any text override.\n//Set the complete text of this token; it wipes any previous changes to the text.\nObject.defineProperty(Lexer.prototype, \"text\", {\n\tget : function() {\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t} else {\n\t\t\treturn this._interp.getText(this._input);\n\t\t}\n\t},\n\tset : function(text) {\n\t\tthis._text = text;\n\t}\n});\n// Return a list of all Token objects in input char stream.\n// Forces load of all tokens. Does not include EOF token.\n// /\nLexer.prototype.getAllTokens = function() {\n\tvar tokens = [];\n\tvar t = this.nextToken();\n\twhile (t.type !== Token.EOF) {\n\t\ttokens.push(t);\n\t\tt = this.nextToken();\n\t}\n\treturn tokens;\n};\n\nLexer.prototype.notifyListeners = function(e) {\n\tvar start = this._tokenStartCharIndex;\n\tvar stop = this._input.index;\n\tvar text = this._input.getText(start, stop);\n\tvar msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n\tvar listener = this.getErrorListenerDispatch();\n\tlistener.syntaxError(this, null, this._tokenStartLine,\n\t\t\tthis._tokenStartColumn, msg, e);\n};\n\nLexer.prototype.getErrorDisplay = function(s) {\n\tvar d = [];\n\tfor (var i = 0; i < s.length; i++) {\n\t\td.push(s[i]);\n\t}\n\treturn d.join('');\n};\n\nLexer.prototype.getErrorDisplayForChar = function(c) {\n\tif (c.charCodeAt(0) === Token.EOF) {\n\t\treturn \"<EOF>\";\n\t} else if (c === '\\n') {\n\t\treturn \"\\\\n\";\n\t} else if (c === '\\t') {\n\t\treturn \"\\\\t\";\n\t} else if (c === '\\r') {\n\t\treturn \"\\\\r\";\n\t} else {\n\t\treturn c;\n\t}\n};\n\nLexer.prototype.getCharErrorDisplay = function(c) {\n\treturn \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n};\n\n// Lexers can normally match any char in it's vocabulary after matching\n// a token, so do the easy thing and just kill a character and hope\n// it all works out. You can instead use the rule invocation stack\n// to do sophisticated error recovery if you are in a fragment rule.\n// /\nLexer.prototype.recover = function(re) {\n\tif (this._input.LA(1) !== Token.EOF) {\n\t\tif (re instanceof LexerNoViableAltException) {\n\t\t\t// skip a char and try again\n\t\t\tthis._interp.consume(this._input);\n\t\t} else {\n\t\t\t// TODO: Do we lose character or line position information?\n\t\t\tthis._input.consume();\n\t\t}\n\t}\n};\n\nexports.Lexer = Lexer;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/Lexer.js\n ** module id = 25\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n\nvar Token = require('./Token').Token;\nvar ConsoleErrorListener = require('./error/ErrorListener').ConsoleErrorListener;\nvar ProxyErrorListener = require('./error/ErrorListener').ProxyErrorListener;\n\nfunction Recognizer() {\n    this._listeners = [ ConsoleErrorListener.INSTANCE ];\n    this._interp = null;\n    this._stateNumber = -1;\n    return this;\n}\n\nRecognizer.tokenTypeMapCache = {};\nRecognizer.ruleIndexMapCache = {};\n\n\nRecognizer.prototype.checkVersion = function(toolVersion) {\n    var runtimeVersion = \"4.5.3\";\n    if (runtimeVersion!==toolVersion) {\n        console.log(\"ANTLR runtime and generated code versions disagree: \"+runtimeVersion+\"!=\"+toolVersion);\n    }\n};\n\nRecognizer.prototype.addErrorListener = function(listener) {\n    this._listeners.push(listener);\n};\n\nRecognizer.prototype.removeErrorListeners = function() {\n    this._listeners = [];\n};\n\nRecognizer.prototype.getTokenTypeMap = function() {\n    var tokenNames = this.getTokenNames();\n    if (tokenNames===null) {\n        throw(\"The current recognizer does not provide a list of token names.\");\n    }\n    var result = this.tokenTypeMapCache[tokenNames];\n    if(result===undefined) {\n        result = tokenNames.reduce(function(o, k, i) { o[k] = i; });\n        result.EOF = Token.EOF;\n        this.tokenTypeMapCache[tokenNames] = result;\n    }\n    return result;\n};\n\n// Get a map from rule names to rule indexes.\n//\n// <p>Used for XPath and tree pattern compilation.</p>\n//\nRecognizer.prototype.getRuleIndexMap = function() {\n    var ruleNames = this.getRuleNames();\n    if (ruleNames===null) {\n        throw(\"The current recognizer does not provide a list of rule names.\");\n    }\n    var result = this.ruleIndexMapCache[ruleNames];\n    if(result===undefined) {\n        result = ruleNames.reduce(function(o, k, i) { o[k] = i; });\n        this.ruleIndexMapCache[ruleNames] = result;\n    }\n    return result;\n};\n\nRecognizer.prototype.getTokenType = function(tokenName) {\n    var ttype = this.getTokenTypeMap()[tokenName];\n    if (ttype !==undefined) {\n        return ttype;\n    } else {\n        return Token.INVALID_TYPE;\n    }\n};\n\n\n// What is the error header, normally line/character position information?//\nRecognizer.prototype.getErrorHeader = function(e) {\n    var line = e.getOffendingToken().line;\n    var column = e.getOffendingToken().column;\n    return \"line \" + line + \":\" + column;\n};\n\n\n// How should a token be displayed in an error message? The default\n//  is to display just the text, but during development you might\n//  want to have a lot of information spit out.  Override in that case\n//  to use t.toString() (which, for CommonToken, dumps everything about\n//  the token). This is better than forcing you to override a method in\n//  your token objects because you don't have to go modify your lexer\n//  so that it creates a new Java type.\n//\n// @deprecated This method is not called by the ANTLR 4 Runtime. Specific\n// implementations of {@link ANTLRErrorStrategy} may provide a similar\n// feature when necessary. For example, see\n// {@link DefaultErrorStrategy//getTokenErrorDisplay}.\n//\nRecognizer.prototype.getTokenErrorDisplay = function(t) {\n    if (t===null) {\n        return \"<no token>\";\n    }\n    var s = t.text;\n    if (s===null) {\n        if (t.type===Token.EOF) {\n            s = \"<EOF>\";\n        } else {\n            s = \"<\" + t.type + \">\";\n        }\n    }\n    s = s.replace(\"\\n\",\"\\\\n\").replace(\"\\r\",\"\\\\r\").replace(\"\\t\",\"\\\\t\");\n    return \"'\" + s + \"'\";\n};\n\nRecognizer.prototype.getErrorListenerDispatch = function() {\n    return new ProxyErrorListener(this._listeners);\n};\n\n// subclass needs to override these if there are sempreds or actions\n// that the ATN interp needs to execute\nRecognizer.prototype.sempred = function(localctx, ruleIndex, actionIndex) {\n    return true;\n};\n\nRecognizer.prototype.precpred = function(localctx , precedence) {\n    return true;\n};\n\n//Indicate that the recognizer has changed internal state that is\n//consistent with the ATN state passed in.  This way we always know\n//where we are in the ATN as the parser goes along. The rule\n//context objects form a stack that lets us see the stack of\n//invoking rules. Combine this and we have complete ATN\n//configuration information.\n\nObject.defineProperty(Recognizer.prototype, \"state\", {\n\tget : function() {\n\t\treturn this._stateNumber;\n\t},\n\tset : function(state) {\n\t\tthis._stateNumber = state;\n\t}\n});\n\n\nexports.Recognizer = Recognizer;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/Recognizer.js\n ** module id = 26\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n// Provides an empty default implementation of {@link ANTLRErrorListener}. The\n// default implementation of each method does nothing, but can be overridden as\n// necessary.\n\nfunction ErrorListener() {\n\treturn this;\n}\n\nErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {\n};\n\nErrorListener.prototype.reportAmbiguity = function(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n};\n\nErrorListener.prototype.reportAttemptingFullContext = function(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n};\n\nErrorListener.prototype.reportContextSensitivity = function(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n};\n\nfunction ConsoleErrorListener() {\n\tErrorListener.call(this);\n\treturn this;\n}\n\nConsoleErrorListener.prototype = Object.create(ErrorListener.prototype);\nConsoleErrorListener.prototype.constructor = ConsoleErrorListener;\n\n//\n// Provides a default instance of {@link ConsoleErrorListener}.\n//\nConsoleErrorListener.INSTANCE = new ConsoleErrorListener();\n\n//\n// {@inheritDoc}\n//\n// <p>\n// This implementation prints messages to {@link System//err} containing the\n// values of {@code line}, {@code charPositionInLine}, and {@code msg} using\n// the following format.</p>\n//\n// <pre>\n// line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>\n// </pre>\n//\nConsoleErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {\n    console.error(\"line \" + line + \":\" + column + \" \" + msg);\n};\n\nfunction ProxyErrorListener(delegates) {\n\tErrorListener.call(this);\n    if (delegates===null) {\n        throw \"delegates\";\n    }\n    this.delegates = delegates;\n\treturn this;\n}\n\nProxyErrorListener.prototype = Object.create(ErrorListener.prototype);\nProxyErrorListener.prototype.constructor = ProxyErrorListener;\n\nProxyErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {\n    this.delegates.map(function(d) { d.syntaxError(recognizer, offendingSymbol, line, column, msg, e); });\n};\n\nProxyErrorListener.prototype.reportAmbiguity = function(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n    this.delegates.map(function(d) { d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs); });\n};\n\nProxyErrorListener.prototype.reportAttemptingFullContext = function(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\tthis.delegates.map(function(d) { d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs); });\n};\n\nProxyErrorListener.prototype.reportContextSensitivity = function(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\tthis.delegates.map(function(d) { d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs); });\n};\n\nexports.ErrorListener = ErrorListener;\nexports.ConsoleErrorListener = ConsoleErrorListener;\nexports.ProxyErrorListener = ProxyErrorListener;\n\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/error/ErrorListener.js\n ** module id = 27\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n\n//\n// This default implementation of {@link TokenFactory} creates\n// {@link CommonToken} objects.\n//\n\nvar CommonToken = require('./Token').CommonToken;\n\nfunction TokenFactory() {\n\treturn this;\n}\n\nfunction CommonTokenFactory(copyText) {\n\tTokenFactory.call(this);\n    // Indicates whether {@link CommonToken//setText} should be called after\n    // constructing tokens to explicitly set the text. This is useful for cases\n    // where the input stream might not be able to provide arbitrary substrings\n    // of text from the input after the lexer creates a token (e.g. the\n    // implementation of {@link CharStream//getText} in\n    // {@link UnbufferedCharStream} throws an\n    // {@link UnsupportedOperationException}). Explicitly setting the token text\n    // allows {@link Token//getText} to be called at any time regardless of the\n    // input stream implementation.\n    //\n    // <p>\n    // The default value is {@code false} to avoid the performance and memory\n    // overhead of copying text for every token unless explicitly requested.</p>\n    //\n    this.copyText = copyText===undefined ? false : copyText;\n\treturn this;\n}\n\nCommonTokenFactory.prototype = Object.create(TokenFactory.prototype);\nCommonTokenFactory.prototype.constructor = CommonTokenFactory;\n\n//\n// The default {@link CommonTokenFactory} instance.\n//\n// <p>\n// This token factory does not explicitly copy token text when constructing\n// tokens.</p>\n//\nCommonTokenFactory.DEFAULT = new CommonTokenFactory();\n\nCommonTokenFactory.prototype.create = function(source, type, text, channel, start, stop, line, column) {\n    var t = new CommonToken(source, type, channel, start, stop);\n    t.line = line;\n    t.column = column;\n    if (text !==null) {\n        t.text = text;\n    } else if (this.copyText && source[1] !==null) {\n        t.text = source[1].getText(start,stop);\n    }\n    return t;\n};\n\nCommonTokenFactory.prototype.createThin = function(type, text) {\n    var t = new CommonToken(null, type);\n    t.text = text;\n    return t;\n};\n\nexports.CommonTokenFactory = CommonTokenFactory;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/CommonTokenFactory.js\n ** module id = 28\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n// The root of the ANTLR exception hierarchy. In general, ANTLR tracks just\n//  3 kinds of errors: prediction errors, failed predicate errors, and\n//  mismatched input errors. In each case, the parser knows where it is\n//  in the input, where it is in the ATN, the rule invocation stack,\n//  and what kind of problem occurred.\n\nvar PredicateTransition = require('./../atn/Transition').PredicateTransition;\n\nfunction RecognitionException(params) {\n\tError.call(this);\n\tif (!!Error.captureStackTrace) {\n        Error.captureStackTrace(this, RecognitionException);\n\t} else {\n\t\tvar stack = new Error().stack;\n\t}\n\tthis.message = params.message;\n    this.recognizer = params.recognizer;\n    this.input = params.input;\n    this.ctx = params.ctx;\n    // The current {@link Token} when an error occurred. Since not all streams\n    // support accessing symbols by index, we have to track the {@link Token}\n    // instance itself.\n    this.offendingToken = null;\n    // Get the ATN state number the parser was in at the time the error\n    // occurred. For {@link NoViableAltException} and\n    // {@link LexerNoViableAltException} exceptions, this is the\n    // {@link DecisionState} number. For others, it is the state whose outgoing\n    // edge we couldn't match.\n    this.offendingState = -1;\n    if (this.recognizer!==null) {\n        this.offendingState = this.recognizer.state;\n    }\n    return this;\n}\n\nRecognitionException.prototype = Object.create(Error.prototype);\nRecognitionException.prototype.constructor = RecognitionException;\n\n// <p>If the state number is not known, this method returns -1.</p>\n\n//\n// Gets the set of input symbols which could potentially follow the\n// previously matched symbol at the time this exception was thrown.\n//\n// <p>If the set of expected tokens is not known and could not be computed,\n// this method returns {@code null}.</p>\n//\n// @return The set of token types that could potentially follow the current\n// state in the ATN, or {@code null} if the information is not available.\n// /\nRecognitionException.prototype.getExpectedTokens = function() {\n    if (this.recognizer!==null) {\n        return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);\n    } else {\n        return null;\n    }\n};\n\nRecognitionException.prototype.toString = function() {\n    return this.message;\n};\n\nfunction LexerNoViableAltException(lexer, input, startIndex, deadEndConfigs) {\n\tRecognitionException.call(this, {message:\"\", recognizer:lexer, input:input, ctx:null});\n    this.startIndex = startIndex;\n    this.deadEndConfigs = deadEndConfigs;\n    return this;\n}\n\nLexerNoViableAltException.prototype = Object.create(RecognitionException.prototype);\nLexerNoViableAltException.prototype.constructor = LexerNoViableAltException;\n\nLexerNoViableAltException.prototype.toString = function() {\n    var symbol = \"\";\n    if (this.startIndex >= 0 && this.startIndex < this.input.size) {\n        symbol = this.input.getText((this.startIndex,this.startIndex));\n    }\n    return \"LexerNoViableAltException\" + symbol;\n};\n\n// Indicates that the parser could not decide which of two or more paths\n// to take based upon the remaining input. It tracks the starting token\n// of the offending input and also knows where the parser was\n// in the various paths when the error. Reported by reportNoViableAlternative()\n//\nfunction NoViableAltException(recognizer, input, startToken, offendingToken, deadEndConfigs, ctx) {\n\tctx = ctx || recognizer._ctx;\n\toffendingToken = offendingToken || recognizer.getCurrentToken();\n\tstartToken = startToken || recognizer.getCurrentToken();\n\tinput = input || recognizer.getInputStream();\n\tRecognitionException.call(this, {message:\"\", recognizer:recognizer, input:input, ctx:ctx});\n    // Which configurations did we try at input.index() that couldn't match\n\t// input.LT(1)?//\n    this.deadEndConfigs = deadEndConfigs;\n    // The token object at the start index; the input stream might\n    // not be buffering tokens so get a reference to it. (At the\n    // time the error occurred, of course the stream needs to keep a\n    // buffer all of the tokens but later we might not have access to those.)\n    this.startToken = startToken;\n    this.offendingToken = offendingToken;\n}\n\nNoViableAltException.prototype = Object.create(RecognitionException.prototype);\nNoViableAltException.prototype.constructor = NoViableAltException;\n\n// This signifies any kind of mismatched input exceptions such as\n// when the current input does not match the expected token.\n//\nfunction InputMismatchException(recognizer) {\n\tRecognitionException.call(this, {message:\"\", recognizer:recognizer, input:recognizer.getInputStream(), ctx:recognizer._ctx});\n    this.offendingToken = recognizer.getCurrentToken();\n}\n\nInputMismatchException.prototype = Object.create(RecognitionException.prototype);\nInputMismatchException.prototype.constructor = InputMismatchException;\n\n// A semantic predicate failed during validation. Validation of predicates\n// occurs when normally parsing the alternative just like matching a token.\n// Disambiguating predicate evaluation occurs when we test a predicate during\n// prediction.\n\nfunction FailedPredicateException(recognizer, predicate, message) {\n\tRecognitionException.call(this, {message:this.formatMessage(predicate,message || null), recognizer:recognizer,\n                         input:recognizer.getInputStream(), ctx:recognizer._ctx});\n    var s = recognizer._interp.atn.states[recognizer.state];\n    var trans = s.transitions[0];\n    if (trans instanceof PredicateTransition) {\n        this.ruleIndex = trans.ruleIndex;\n        this.predicateIndex = trans.predIndex;\n    } else {\n        this.ruleIndex = 0;\n        this.predicateIndex = 0;\n    }\n    this.predicate = predicate;\n    this.offendingToken = recognizer.getCurrentToken();\n    return this;\n}\n\nFailedPredicateException.prototype = Object.create(RecognitionException.prototype);\nFailedPredicateException.prototype.constructor = FailedPredicateException;\n\nFailedPredicateException.prototype.formatMessage = function(predicate, message) {\n    if (message !==null) {\n        return message;\n    } else {\n        return \"failed predicate: {\" + predicate + \"}?\";\n    }\n};\n\nfunction ParseCancellationException() {\n\tError.call(this);\n\tError.captureStackTrace(this, ParseCancellationException);\n\treturn this;\n}\n\nParseCancellationException.prototype = Object.create(Error.prototype);\nParseCancellationException.prototype.constructor = ParseCancellationException;\n\nexports.RecognitionException = RecognitionException;\nexports.NoViableAltException = NoViableAltException;\nexports.LexerNoViableAltException = LexerNoViableAltException;\nexports.InputMismatchException = InputMismatchException;\nexports.FailedPredicateException = FailedPredicateException;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/error/Errors.js\n ** module id = 29\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2013 Terence Parr\n//  Copyright (c) 2013 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\nvar DFAState = require('./../dfa/DFAState').DFAState;\nvar ATNConfigSet = require('./ATNConfigSet').ATNConfigSet;\nvar getCachedPredictionContext = require('./../PredictionContext').getCachedPredictionContext;\n\nfunction ATNSimulator(atn, sharedContextCache) {\n\t\n    // The context cache maps all PredictionContext objects that are ==\n    //  to a single cached copy. This cache is shared across all contexts\n    //  in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet\n    //  to use only cached nodes/graphs in addDFAState(). We don't want to\n    //  fill this during closure() since there are lots of contexts that\n    //  pop up but are not used ever again. It also greatly slows down closure().\n    //\n    //  <p>This cache makes a huge difference in memory and a little bit in speed.\n    //  For the Java grammar on java.*, it dropped the memory requirements\n    //  at the end from 25M to 16M. We don't store any of the full context\n    //  graphs in the DFA because they are limited to local context only,\n    //  but apparently there's a lot of repetition there as well. We optimize\n    //  the config contexts before storing the config set in the DFA states\n    //  by literally rebuilding them with cached subgraphs only.</p>\n    //\n    //  <p>I tried a cache for use during closure operations, that was\n    //  whacked after each adaptivePredict(). It cost a little bit\n    //  more time I think and doesn't save on the overall footprint\n    //  so it's not worth the complexity.</p>\n    ///\n    this.atn = atn;\n    this.sharedContextCache = sharedContextCache;\n    return this;\n}\n\n// Must distinguish between missing edge and edge we know leads nowhere///\nATNSimulator.ERROR = new DFAState(0x7FFFFFFF, new ATNConfigSet());\n\n\nATNSimulator.prototype.getCachedContext = function(context) {\n    if (this.sharedContextCache ===null) {\n        return context;\n    }\n    var visited = {};\n    return getCachedPredictionContext(context, this.sharedContextCache, visited);\n};\n\nexports.ATNSimulator = ATNSimulator;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/ATNSimulator.js\n ** module id = 30\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\nvar ATNConfigSet = require('./../atn/ATNConfigSet').ATNConfigSet;\nvar Utils = require('./../Utils');\nvar Set = Utils.Set;\n\n// Map a predicate to a predicted alternative.///\n\nfunction PredPrediction(pred, alt) {\n\tthis.alt = alt;\n\tthis.pred = pred;\n\treturn this;\n}\n\nPredPrediction.prototype.toString = function() {\n\treturn \"(\" + this.pred + \", \" + this.alt + \")\";\n};\n\n// A DFA state represents a set of possible ATN configurations.\n// As Aho, Sethi, Ullman p. 117 says \"The DFA uses its state\n// to keep track of all possible states the ATN can be in after\n// reading each input symbol. That is to say, after reading\n// input a1a2..an, the DFA is in a state that represents the\n// subset T of the states of the ATN that are reachable from the\n// ATN's start state along some path labeled a1a2..an.\"\n// In conventional NFA&rarr;DFA conversion, therefore, the subset T\n// would be a bitset representing the set of states the\n// ATN could be in. We need to track the alt predicted by each\n// state as well, however. More importantly, we need to maintain\n// a stack of states, tracking the closure operations as they\n// jump from rule to rule, emulating rule invocations (method calls).\n// I have to add a stack to simulate the proper lookahead sequences for\n// the underlying LL grammar from which the ATN was derived.\n//\n// <p>I use a set of ATNConfig objects not simple states. An ATNConfig\n// is both a state (ala normal conversion) and a RuleContext describing\n// the chain of rules (if any) followed to arrive at that state.</p>\n//\n// <p>A DFA state may have multiple references to a particular state,\n// but with different ATN contexts (with same or different alts)\n// meaning that state was reached via a different set of rule invocations.</p>\n// /\n\nfunction DFAState(stateNumber, configs) {\n\tif (stateNumber === null) {\n\t\tstateNumber = -1;\n\t}\n\tif (configs === null) {\n\t\tconfigs = new ATNConfigSet();\n\t}\n\tthis.stateNumber = stateNumber;\n\tthis.configs = configs;\n\t// {@code edges[symbol]} points to target of symbol. Shift up by 1 so (-1)\n\t// {@link Token//EOF} maps to {@code edges[0]}.\n\tthis.edges = null;\n\tthis.isAcceptState = false;\n\t// if accept state, what ttype do we match or alt do we predict?\n\t// This is set to {@link ATN//INVALID_ALT_NUMBER} when {@link\n\t// //predicates}{@code !=null} or\n\t// {@link //requiresFullContext}.\n\tthis.prediction = 0;\n\tthis.lexerActionExecutor = null;\n\t// Indicates that this state was created during SLL prediction that\n\t// discovered a conflict between the configurations in the state. Future\n\t// {@link ParserATNSimulator//execATN} invocations immediately jumped doing\n\t// full context prediction if this field is true.\n\tthis.requiresFullContext = false;\n\t// During SLL parsing, this is a list of predicates associated with the\n\t// ATN configurations of the DFA state. When we have predicates,\n\t// {@link //requiresFullContext} is {@code false} since full context\n\t// prediction evaluates predicates\n\t// on-the-fly. If this is not null, then {@link //prediction} is\n\t// {@link ATN//INVALID_ALT_NUMBER}.\n\t//\n\t// <p>We only use these for non-{@link //requiresFullContext} but\n\t// conflicting states. That\n\t// means we know from the context (it's $ or we don't dip into outer\n\t// context) that it's an ambiguity not a conflict.</p>\n\t//\n\t// <p>This list is computed by {@link\n\t// ParserATNSimulator//predicateDFAState}.</p>\n\tthis.predicates = null;\n\treturn this;\n}\n\n// Get the set of all alts mentioned by all ATN configurations in this\n// DFA state.\nDFAState.prototype.getAltSet = function() {\n\tvar alts = new Set();\n\tif (this.configs !== null) {\n\t\tfor (var i = 0; i < this.configs.length; i++) {\n\t\t\tvar c = this.configs[i];\n\t\t\talts.add(c.alt);\n\t\t}\n\t}\n\tif (alts.length === 0) {\n\t\treturn null;\n\t} else {\n\t\treturn alts;\n\t}\n};\n\n// Two {@link DFAState} instances are equal if their ATN configuration sets\n// are the same. This method is used to see if a state already exists.\n//\n// <p>Because the number of alternatives and number of ATN configurations are\n// finite, there is a finite number of DFA states that can be processed.\n// This is necessary to show that the algorithm terminates.</p>\n//\n// <p>Cannot test the DFA state numbers here because in\n// {@link ParserATNSimulator//addDFAState} we need to know if any other state\n// exists that has this exact set of ATN configurations. The\n// {@link //stateNumber} is irrelevant.</p>\nDFAState.prototype.equals = function(other) {\n\t// compare set of ATN configurations in this set with other\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof DFAState)) {\n\t\treturn false;\n\t} else {\n\t\treturn this.configs.equals(other.configs);\n\t}\n};\n\nDFAState.prototype.toString = function() {\n\treturn \"\" + this.stateNumber + \":\" + this.hashString();\n};\n\nDFAState.prototype.hashString = function() {\n\treturn \"\" +  this.configs +\n\t\t\t(this.isAcceptState ?\n\t\t\t\t\t\"=>\" + (this.predicates !== null ?\n\t\t\t\t\t\t\t\tthis.predicates :\n\t\t\t\t\t\t\t\tthis.prediction) :\n\t\t\t\t\t\"\");\n};\n\nexports.DFAState = DFAState;\nexports.PredPrediction = PredPrediction;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/dfa/DFAState.js\n ** module id = 31\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n//\n// Specialized {@link Set}{@code <}{@link ATNConfig}{@code >} that can track\n// info about the set, with support for combining similar configurations using a\n// graph-structured stack.\n///\n\nvar ATN = require('./ATN').ATN;\nvar Utils = require('./../Utils');\nvar Set = Utils.Set;\nvar SemanticContext = require('./SemanticContext').SemanticContext;\nvar merge = require('./../PredictionContext').merge;\n\nfunction hashATNConfig(c) {\n\treturn c.shortHashString();\n}\n\nfunction equalATNConfigs(a, b) {\n\tif ( a===b ) {\n\t\treturn true;\n\t}\n\tif ( a===null || b===null ) {\n\t\treturn false;\n\t}\n\treturn a.state.stateNumber===b.state.stateNumber &&\n\t\ta.alt===b.alt && a.semanticContext.equals(b.semanticContext);\n}\n\n\nfunction ATNConfigSet(fullCtx) {\n\t//\n\t// The reason that we need this is because we don't want the hash map to use\n\t// the standard hash code and equals. We need all configurations with the\n\t// same\n\t// {@code (s,i,_,semctx)} to be equal. Unfortunately, this key effectively\n\t// doubles\n\t// the number of objects associated with ATNConfigs. The other solution is\n\t// to\n\t// use a hash table that lets us specify the equals/hashcode operation.\n\t// All configs but hashed by (s, i, _, pi) not including context. Wiped out\n\t// when we go readonly as this set becomes a DFA state.\n\tthis.configLookup = new Set(hashATNConfig, equalATNConfigs);\n\t// Indicates that this configuration set is part of a full context\n\t// LL prediction. It will be used to determine how to merge $. With SLL\n\t// it's a wildcard whereas it is not for LL context merge.\n\tthis.fullCtx = fullCtx === undefined ? true : fullCtx;\n\t// Indicates that the set of configurations is read-only. Do not\n\t// allow any code to manipulate the set; DFA states will point at\n\t// the sets and they must not change. This does not protect the other\n\t// fields; in particular, conflictingAlts is set after\n\t// we've made this readonly.\n\tthis.readOnly = false;\n\t// Track the elements as they are added to the set; supports get(i)///\n\tthis.configs = [];\n\n\t// TODO: these fields make me pretty uncomfortable but nice to pack up info\n\t// together, saves recomputation\n\t// TODO: can we track conflicts as they are added to save scanning configs\n\t// later?\n\tthis.uniqueAlt = 0;\n\tthis.conflictingAlts = null;\n\n\t// Used in parser and lexer. In lexer, it indicates we hit a pred\n\t// while computing a closure operation. Don't make a DFA state from this.\n\tthis.hasSemanticContext = false;\n\tthis.dipsIntoOuterContext = false;\n\n\tthis.cachedHashString = \"-1\";\n\n\treturn this;\n}\n\n// Adding a new config means merging contexts with existing configs for\n// {@code (s, i, pi, _)}, where {@code s} is the\n// {@link ATNConfig//state}, {@code i} is the {@link ATNConfig//alt}, and\n// {@code pi} is the {@link ATNConfig//semanticContext}. We use\n// {@code (s,i,pi)} as key.\n//\n// <p>This method updates {@link //dipsIntoOuterContext} and\n// {@link //hasSemanticContext} when necessary.</p>\n// /\nATNConfigSet.prototype.add = function(config, mergeCache) {\n\tif (mergeCache === undefined) {\n\t\tmergeCache = null;\n\t}\n\tif (this.readOnly) {\n\t\tthrow \"This set is readonly\";\n\t}\n\tif (config.semanticContext !== SemanticContext.NONE) {\n\t\tthis.hasSemanticContext = true;\n\t}\n\tif (config.reachesIntoOuterContext > 0) {\n\t\tthis.dipsIntoOuterContext = true;\n\t}\n\tvar existing = this.configLookup.add(config);\n\tif (existing === config) {\n\t\tthis.cachedHashString = \"-1\";\n\t\tthis.configs.push(config); // track order here\n\t\treturn true;\n\t}\n\t// a previous (s,i,pi,_), merge with it and save result\n\tvar rootIsWildcard = !this.fullCtx;\n\tvar merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);\n\t// no need to check for existing.context, config.context in cache\n\t// since only way to create new graphs is \"call rule\" and here. We\n\t// cache at both places.\n\texisting.reachesIntoOuterContext = Math.max( existing.reachesIntoOuterContext, config.reachesIntoOuterContext);\n\t// make sure to preserve the precedence filter suppression during the merge\n\tif (config.precedenceFilterSuppressed) {\n\t\texisting.precedenceFilterSuppressed = true;\n\t}\n\texisting.context = merged; // replace context; no need to alt mapping\n\treturn true;\n};\n\nATNConfigSet.prototype.getStates = function() {\n\tvar states = new Set();\n\tfor (var i = 0; i < this.configs.length; i++) {\n\t\tstates.add(this.configs[i].state);\n\t}\n\treturn states;\n};\n\nATNConfigSet.prototype.getPredicates = function() {\n\tvar preds = [];\n\tfor (var i = 0; i < this.configs.length; i++) {\n\t\tvar c = this.configs[i].semanticContext;\n\t\tif (c !== SemanticContext.NONE) {\n\t\t\tpreds.push(c.semanticContext);\n\t\t}\n\t}\n\treturn preds;\n};\n\nObject.defineProperty(ATNConfigSet.prototype, \"items\", {\n\tget : function() {\n\t\treturn this.configs;\n\t}\n});\n\nATNConfigSet.prototype.optimizeConfigs = function(interpreter) {\n\tif (this.readOnly) {\n\t\tthrow \"This set is readonly\";\n\t}\n\tif (this.configLookup.length === 0) {\n\t\treturn;\n\t}\n\tfor (var i = 0; i < this.configs.length; i++) {\n\t\tvar config = this.configs[i];\n\t\tconfig.context = interpreter.getCachedContext(config.context);\n\t}\n};\n\nATNConfigSet.prototype.addAll = function(coll) {\n\tfor (var i = 0; i < coll.length; i++) {\n\t\tthis.add(coll[i]);\n\t}\n\treturn false;\n};\n\nATNConfigSet.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof ATNConfigSet)) {\n\t\treturn false;\n\t}\n\treturn this.configs !== null && this.configs.equals(other.configs) &&\n\t\t\tthis.fullCtx === other.fullCtx &&\n\t\t\tthis.uniqueAlt === other.uniqueAlt &&\n\t\t\tthis.conflictingAlts === other.conflictingAlts &&\n\t\t\tthis.hasSemanticContext === other.hasSemanticContext &&\n\t\t\tthis.dipsIntoOuterContext === other.dipsIntoOuterContext;\n};\n\nATNConfigSet.prototype.hashString = function() {\n\tif (this.readOnly) {\n\t\tif (this.cachedHashString === \"-1\") {\n\t\t\tthis.cachedHashString = this.hashConfigs();\n\t\t}\n\t\treturn this.cachedHashString;\n\t} else {\n\t\treturn this.hashConfigs();\n\t}\n};\n\nATNConfigSet.prototype.hashConfigs = function() {\n\tvar s = \"\";\n\tthis.configs.map(function(c) {\n\t\ts += c.toString();\n\t});\n\treturn s;\n};\n\nObject.defineProperty(ATNConfigSet.prototype, \"length\", {\n\tget : function() {\n\t\treturn this.configs.length;\n\t}\n});\n\nATNConfigSet.prototype.isEmpty = function() {\n\treturn this.configs.length === 0;\n};\n\nATNConfigSet.prototype.contains = function(item) {\n\tif (this.configLookup === null) {\n\t\tthrow \"This method is not implemented for readonly sets.\";\n\t}\n\treturn this.configLookup.contains(item);\n};\n\nATNConfigSet.prototype.containsFast = function(item) {\n\tif (this.configLookup === null) {\n\t\tthrow \"This method is not implemented for readonly sets.\";\n\t}\n\treturn this.configLookup.containsFast(item);\n};\n\nATNConfigSet.prototype.clear = function() {\n\tif (this.readOnly) {\n\t\tthrow \"This set is readonly\";\n\t}\n\tthis.configs = [];\n\tthis.cachedHashString = \"-1\";\n\tthis.configLookup = new Set();\n};\n\nATNConfigSet.prototype.setReadonly = function(readOnly) {\n\tthis.readOnly = readOnly;\n\tif (readOnly) {\n\t\tthis.configLookup = null; // can't mod, no need for lookup cache\n\t}\n};\n\nATNConfigSet.prototype.toString = function() {\n\treturn Utils.arrayToString(this.configs) +\n\t\t(this.hasSemanticContext ? \",hasSemanticContext=\" + this.hasSemanticContext : \"\") +\n\t\t(this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? \",uniqueAlt=\" + this.uniqueAlt : \"\") +\n\t\t(this.conflictingAlts !== null ? \",conflictingAlts=\" + this.conflictingAlts : \"\") +\n\t\t(this.dipsIntoOuterContext ? \",dipsIntoOuterContext\" : \"\");\n};\n\nfunction OrderedATNConfigSet() {\n\tATNConfigSet.call(this);\n\tthis.configLookup = new Set();\n\treturn this;\n}\n\nOrderedATNConfigSet.prototype = Object.create(ATNConfigSet.prototype);\nOrderedATNConfigSet.prototype.constructor = OrderedATNConfigSet;\n\nexports.ATNConfigSet = ATNConfigSet;\nexports.OrderedATNConfigSet = OrderedATNConfigSet;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/ATNConfigSet.js\n ** module id = 32\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2013 Terence Parr\n//  Copyright (c) 2013 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\n// Represents an executor for a sequence of lexer actions which traversed during\n// the matching operation of a lexer rule (token).\n//\n// <p>The executor tracks position information for position-dependent lexer actions\n// efficiently, ensuring that actions appearing only at the end of the rule do\n// not cause bloating of the {@link DFA} created for the lexer.</p>\n\nvar LexerIndexedCustomAction = require('./LexerAction').LexerIndexedCustomAction;\n\nfunction LexerActionExecutor(lexerActions) {\n\tthis.lexerActions = lexerActions === null ? [] : lexerActions;\n\t// Caches the result of {@link //hashCode} since the hash code is an element\n\t// of the performance-critical {@link LexerATNConfig//hashCode} operation.\n\tthis._hashString = lexerActions.toString(); // \"\".join([str(la) for la in\n\t// lexerActions]))\n\treturn this;\n}\n\n// Creates a {@link LexerActionExecutor} which executes the actions for\n// the input {@code lexerActionExecutor} followed by a specified\n// {@code lexerAction}.\n//\n// @param lexerActionExecutor The executor for actions already traversed by\n// the lexer while matching a token within a particular\n// {@link LexerATNConfig}. If this is {@code null}, the method behaves as\n// though it were an empty executor.\n// @param lexerAction The lexer action to execute after the actions\n// specified in {@code lexerActionExecutor}.\n//\n// @return A {@link LexerActionExecutor} for executing the combine actions\n// of {@code lexerActionExecutor} and {@code lexerAction}.\nLexerActionExecutor.append = function(lexerActionExecutor, lexerAction) {\n\tif (lexerActionExecutor === null) {\n\t\treturn new LexerActionExecutor([ lexerAction ]);\n\t}\n\tvar lexerActions = lexerActionExecutor.lexerActions.concat([ lexerAction ]);\n\treturn new LexerActionExecutor(lexerActions);\n};\n\n// Creates a {@link LexerActionExecutor} which encodes the current offset\n// for position-dependent lexer actions.\n//\n// <p>Normally, when the executor encounters lexer actions where\n// {@link LexerAction//isPositionDependent} returns {@code true}, it calls\n// {@link IntStream//seek} on the input {@link CharStream} to set the input\n// position to the <em>end</em> of the current token. This behavior provides\n// for efficient DFA representation of lexer actions which appear at the end\n// of a lexer rule, even when the lexer rule matches a variable number of\n// characters.</p>\n//\n// <p>Prior to traversing a match transition in the ATN, the current offset\n// from the token start index is assigned to all position-dependent lexer\n// actions which have not already been assigned a fixed offset. By storing\n// the offsets relative to the token start index, the DFA representation of\n// lexer actions which appear in the middle of tokens remains efficient due\n// to sharing among tokens of the same length, regardless of their absolute\n// position in the input stream.</p>\n//\n// <p>If the current executor already has offsets assigned to all\n// position-dependent lexer actions, the method returns {@code this}.</p>\n//\n// @param offset The current offset to assign to all position-dependent\n// lexer actions which do not already have offsets assigned.\n//\n// @return A {@link LexerActionExecutor} which stores input stream offsets\n// for all position-dependent lexer actions.\n// /\nLexerActionExecutor.prototype.fixOffsetBeforeMatch = function(offset) {\n\tvar updatedLexerActions = null;\n\tfor (var i = 0; i < this.lexerActions.length; i++) {\n\t\tif (this.lexerActions[i].isPositionDependent &&\n\t\t\t\t!(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {\n\t\t\tif (updatedLexerActions === null) {\n\t\t\t\tupdatedLexerActions = this.lexerActions.concat([]);\n\t\t\t}\n\t\t\tupdatedLexerActions[i] = new LexerIndexedCustomAction(offset,\n\t\t\t\t\tthis.lexerActions[i]);\n\t\t}\n\t}\n\tif (updatedLexerActions === null) {\n\t\treturn this;\n\t} else {\n\t\treturn new LexerActionExecutor(updatedLexerActions);\n\t}\n};\n\n// Execute the actions encapsulated by this executor within the context of a\n// particular {@link Lexer}.\n//\n// <p>This method calls {@link IntStream//seek} to set the position of the\n// {@code input} {@link CharStream} prior to calling\n// {@link LexerAction//execute} on a position-dependent action. Before the\n// method returns, the input position will be restored to the same position\n// it was in when the method was invoked.</p>\n//\n// @param lexer The lexer instance.\n// @param input The input stream which is the source for the current token.\n// When this method is called, the current {@link IntStream//index} for\n// {@code input} should be the start of the following token, i.e. 1\n// character past the end of the current token.\n// @param startIndex The token start index. This value may be passed to\n// {@link IntStream//seek} to set the {@code input} position to the beginning\n// of the token.\n// /\nLexerActionExecutor.prototype.execute = function(lexer, input, startIndex) {\n\tvar requiresSeek = false;\n\tvar stopIndex = input.index;\n\ttry {\n\t\tfor (var i = 0; i < this.lexerActions.length; i++) {\n\t\t\tvar lexerAction = this.lexerActions[i];\n\t\t\tif (lexerAction instanceof LexerIndexedCustomAction) {\n\t\t\t\tvar offset = lexerAction.offset;\n\t\t\t\tinput.seek(startIndex + offset);\n\t\t\t\tlexerAction = lexerAction.action;\n\t\t\t\trequiresSeek = (startIndex + offset) !== stopIndex;\n\t\t\t} else if (lexerAction.isPositionDependent) {\n\t\t\t\tinput.seek(stopIndex);\n\t\t\t\trequiresSeek = false;\n\t\t\t}\n\t\t\tlexerAction.execute(lexer);\n\t\t}\n\t} finally {\n\t\tif (requiresSeek) {\n\t\t\tinput.seek(stopIndex);\n\t\t}\n\t}\n};\n\nLexerActionExecutor.prototype.hashString = function() {\n\treturn this._hashString;\n};\n\nLexerActionExecutor.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof LexerActionExecutor)) {\n\t\treturn false;\n\t} else if (this._hashString != other._hashString) {\n\t\treturn false;\n\t} else if (this.lexerActions.length != other.lexerActions.length) {\n\t\treturn false;\n\t} else {\n\t\tvar numActions = this.lexerActions.length\n\t\tfor (var idx = 0; idx < numActions; ++idx) {\n\t\t\tif (!this.lexerActions[idx].equals(other.lexerActions[idx])) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}\n};\n\nexports.LexerActionExecutor = LexerActionExecutor;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/LexerActionExecutor.js\n ** module id = 33\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n\n//\n// The embodiment of the adaptive LL(*), ALL(*), parsing strategy.\n//\n// <p>\n// The basic complexity of the adaptive strategy makes it harder to understand.\n// We begin with ATN simulation to build paths in a DFA. Subsequent prediction\n// requests go through the DFA first. If they reach a state without an edge for\n// the current symbol, the algorithm fails over to the ATN simulation to\n// complete the DFA path for the current input (until it finds a conflict state\n// or uniquely predicting state).</p>\n//\n// <p>\n// All of that is done without using the outer context because we want to create\n// a DFA that is not dependent upon the rule invocation stack when we do a\n// prediction. One DFA works in all contexts. We avoid using context not\n// necessarily because it's slower, although it can be, but because of the DFA\n// caching problem. The closure routine only considers the rule invocation stack\n// created during prediction beginning in the decision rule. For example, if\n// prediction occurs without invoking another rule's ATN, there are no context\n// stacks in the configurations. When lack of context leads to a conflict, we\n// don't know if it's an ambiguity or a weakness in the strong LL(*) parsing\n// strategy (versus full LL(*)).</p>\n//\n// <p>\n// When SLL yields a configuration set with conflict, we rewind the input and\n// retry the ATN simulation, this time using full outer context without adding\n// to the DFA. Configuration context stacks will be the full invocation stacks\n// from the start rule. If we get a conflict using full context, then we can\n// definitively say we have a true ambiguity for that input sequence. If we\n// don't get a conflict, it implies that the decision is sensitive to the outer\n// context. (It is not context-sensitive in the sense of context-sensitive\n// grammars.)</p>\n//\n// <p>\n// The next time we reach this DFA state with an SLL conflict, through DFA\n// simulation, we will again retry the ATN simulation using full context mode.\n// This is slow because we can't save the results and have to \"interpret\" the\n// ATN each time we get that input.</p>\n//\n// <p>\n// <strong>CACHING FULL CONTEXT PREDICTIONS</strong></p>\n//\n// <p>\n// We could cache results from full context to predicted alternative easily and\n// that saves a lot of time but doesn't work in presence of predicates. The set\n// of visible predicates from the ATN start state changes depending on the\n// context, because closure can fall off the end of a rule. I tried to cache\n// tuples (stack context, semantic context, predicted alt) but it was slower\n// than interpreting and much more complicated. Also required a huge amount of\n// memory. The goal is not to create the world's fastest parser anyway. I'd like\n// to keep this algorithm simple. By launching multiple threads, we can improve\n// the speed of parsing across a large number of files.</p>\n//\n// <p>\n// There is no strict ordering between the amount of input used by SLL vs LL,\n// which makes it really hard to build a cache for full context. Let's say that\n// we have input A B C that leads to an SLL conflict with full context X. That\n// implies that using X we might only use A B but we could also use A B C D to\n// resolve conflict. Input A B C D could predict alternative 1 in one position\n// in the input and A B C E could predict alternative 2 in another position in\n// input. The conflicting SLL configurations could still be non-unique in the\n// full context prediction, which would lead us to requiring more input than the\n// original A B C.\tTo make a\tprediction cache work, we have to track\tthe exact\n// input\tused during the previous prediction. That amounts to a cache that maps\n// X to a specific DFA for that context.</p>\n//\n// <p>\n// Something should be done for left-recursive expression predictions. They are\n// likely LL(1) + pred eval. Easier to do the whole SLL unless error and retry\n// with full LL thing Sam does.</p>\n//\n// <p>\n// <strong>AVOIDING FULL CONTEXT PREDICTION</strong></p>\n//\n// <p>\n// We avoid doing full context retry when the outer context is empty, we did not\n// dip into the outer context by falling off the end of the decision state rule,\n// or when we force SLL mode.</p>\n//\n// <p>\n// As an example of the not dip into outer context case, consider as super\n// constructor calls versus function calls. One grammar might look like\n// this:</p>\n//\n// <pre>\n// ctorBody\n//   : '{' superCall? stat* '}'\n//   ;\n// </pre>\n//\n// <p>\n// Or, you might see something like</p>\n//\n// <pre>\n// stat\n//   : superCall ';'\n//   | expression ';'\n//   | ...\n//   ;\n// </pre>\n//\n// <p>\n// In both cases I believe that no closure operations will dip into the outer\n// context. In the first case ctorBody in the worst case will stop at the '}'.\n// In the 2nd case it should stop at the ';'. Both cases should stay within the\n// entry rule and not dip into the outer context.</p>\n//\n// <p>\n// <strong>PREDICATES</strong></p>\n//\n// <p>\n// Predicates are always evaluated if present in either SLL or LL both. SLL and\n// LL simulation deals with predicates differently. SLL collects predicates as\n// it performs closure operations like ANTLR v3 did. It delays predicate\n// evaluation until it reaches and accept state. This allows us to cache the SLL\n// ATN simulation whereas, if we had evaluated predicates on-the-fly during\n// closure, the DFA state configuration sets would be different and we couldn't\n// build up a suitable DFA.</p>\n//\n// <p>\n// When building a DFA accept state during ATN simulation, we evaluate any\n// predicates and return the sole semantically valid alternative. If there is\n// more than 1 alternative, we report an ambiguity. If there are 0 alternatives,\n// we throw an exception. Alternatives without predicates act like they have\n// true predicates. The simple way to think about it is to strip away all\n// alternatives with false predicates and choose the minimum alternative that\n// remains.</p>\n//\n// <p>\n// When we start in the DFA and reach an accept state that's predicated, we test\n// those and return the minimum semantically viable alternative. If no\n// alternatives are viable, we throw an exception.</p>\n//\n// <p>\n// During full LL ATN simulation, closure always evaluates predicates and\n// on-the-fly. This is crucial to reducing the configuration set size during\n// closure. It hits a landmine when parsing with the Java grammar, for example,\n// without this on-the-fly evaluation.</p>\n//\n// <p>\n// <strong>SHARING DFA</strong></p>\n//\n// <p>\n// All instances of the same parser share the same decision DFAs through a\n// static field. Each instance gets its own ATN simulator but they share the\n// same {@link //decisionToDFA} field. They also share a\n// {@link PredictionContextCache} object that makes sure that all\n// {@link PredictionContext} objects are shared among the DFA states. This makes\n// a big size difference.</p>\n//\n// <p>\n// <strong>THREAD SAFETY</strong></p>\n//\n// <p>\n// The {@link ParserATNSimulator} locks on the {@link //decisionToDFA} field when\n// it adds a new DFA object to that array. {@link //addDFAEdge}\n// locks on the DFA for the current decision when setting the\n// {@link DFAState//edges} field. {@link //addDFAState} locks on\n// the DFA for the current decision when looking up a DFA state to see if it\n// already exists. We must make sure that all requests to add DFA states that\n// are equivalent result in the same shared DFA object. This is because lots of\n// threads will be trying to update the DFA at once. The\n// {@link //addDFAState} method also locks inside the DFA lock\n// but this time on the shared context cache when it rebuilds the\n// configurations' {@link PredictionContext} objects using cached\n// subgraphs/nodes. No other locking occurs, even during DFA simulation. This is\n// safe as long as we can guarantee that all threads referencing\n// {@code s.edge[t]} get the same physical target {@link DFAState}, or\n// {@code null}. Once into the DFA, the DFA simulation does not reference the\n// {@link DFA//states} map. It follows the {@link DFAState//edges} field to new\n// targets. The DFA simulator will either find {@link DFAState//edges} to be\n// {@code null}, to be non-{@code null} and {@code dfa.edges[t]} null, or\n// {@code dfa.edges[t]} to be non-null. The\n// {@link //addDFAEdge} method could be racing to set the field\n// but in either case the DFA simulator works; if {@code null}, and requests ATN\n// simulation. It could also race trying to get {@code dfa.edges[t]}, but either\n// way it will work because it's not doing a test and set operation.</p>\n//\n// <p>\n// <strong>Starting with SLL then failing to combined SLL/LL (Two-Stage\n// Parsing)</strong></p>\n//\n// <p>\n// Sam pointed out that if SLL does not give a syntax error, then there is no\n// point in doing full LL, which is slower. We only have to try LL if we get a\n// syntax error. For maximum speed, Sam starts the parser set to pure SLL\n// mode with the {@link BailErrorStrategy}:</p>\n//\n// <pre>\n// parser.{@link Parser//getInterpreter() getInterpreter()}.{@link //setPredictionMode setPredictionMode}{@code (}{@link PredictionMode//SLL}{@code )};\n// parser.{@link Parser//setErrorHandler setErrorHandler}(new {@link BailErrorStrategy}());\n// </pre>\n//\n// <p>\n// If it does not get a syntax error, then we're done. If it does get a syntax\n// error, we need to retry with the combined SLL/LL strategy.</p>\n//\n// <p>\n// The reason this works is as follows. If there are no SLL conflicts, then the\n// grammar is SLL (at least for that input set). If there is an SLL conflict,\n// the full LL analysis must yield a set of viable alternatives which is a\n// subset of the alternatives reported by SLL. If the LL set is a singleton,\n// then the grammar is LL but not SLL. If the LL set is the same size as the SLL\n// set, the decision is SLL. If the LL set has size &gt; 1, then that decision\n// is truly ambiguous on the current input. If the LL set is smaller, then the\n// SLL conflict resolution might choose an alternative that the full LL would\n// rule out as a possibility based upon better context information. If that's\n// the case, then the SLL parse will definitely get an error because the full LL\n// analysis says it's not viable. If SLL conflict resolution chooses an\n// alternative within the LL set, them both SLL and LL would choose the same\n// alternative because they both choose the minimum of multiple conflicting\n// alternatives.</p>\n//\n// <p>\n// Let's say we have a set of SLL conflicting alternatives {@code {1, 2, 3}} and\n// a smaller LL set called <em>s</em>. If <em>s</em> is {@code {2, 3}}, then SLL\n// parsing will get an error because SLL will pursue alternative 1. If\n// <em>s</em> is {@code {1, 2}} or {@code {1, 3}} then both SLL and LL will\n// choose the same alternative because alternative one is the minimum of either\n// set. If <em>s</em> is {@code {2}} or {@code {3}} then SLL will get a syntax\n// error. If <em>s</em> is {@code {1}} then SLL will succeed.</p>\n//\n// <p>\n// Of course, if the input is invalid, then we will get an error for sure in\n// both SLL and LL parsing. Erroneous input will therefore require 2 passes over\n// the input.</p>\n//\n\nvar Utils = require('./../Utils');\nvar Set = Utils.Set;\nvar BitSet = Utils.BitSet;\nvar DoubleDict = Utils.DoubleDict;\nvar ATN = require('./ATN').ATN;\nvar ATNConfig = require('./ATNConfig').ATNConfig;\nvar ATNConfigSet = require('./ATNConfigSet').ATNConfigSet;\nvar Token = require('./../Token').Token;\nvar DFAState = require('./../dfa/DFAState').DFAState;\nvar PredPrediction = require('./../dfa/DFAState').PredPrediction;\nvar ATNSimulator = require('./ATNSimulator').ATNSimulator;\nvar PredictionMode = require('./PredictionMode').PredictionMode;\nvar RuleContext = require('./../RuleContext').RuleContext;\nvar ParserRuleContext = require('./../ParserRuleContext').ParserRuleContext;\nvar SemanticContext = require('./SemanticContext').SemanticContext;\nvar StarLoopEntryState = require('./ATNState').StarLoopEntryState;\nvar RuleStopState = require('./ATNState').RuleStopState;\nvar PredictionContext = require('./../PredictionContext').PredictionContext;\nvar Interval = require('./../IntervalSet').Interval;\nvar Transitions = require('./Transition');\nvar Transition = Transitions.Transition;\nvar SetTransition = Transitions.SetTransition;\nvar NotSetTransition = Transitions.NotSetTransition;\nvar RuleTransition = Transitions.RuleTransition;\nvar ActionTransition = Transitions.ActionTransition;\nvar NoViableAltException = require('./../error/Errors').NoViableAltException;\n\nvar SingletonPredictionContext = require('./../PredictionContext').SingletonPredictionContext;\nvar predictionContextFromRuleContext = require('./../PredictionContext').predictionContextFromRuleContext;\n\nfunction ParserATNSimulator(parser, atn, decisionToDFA, sharedContextCache) {\n\tATNSimulator.call(this, atn, sharedContextCache);\n    this.parser = parser;\n    this.decisionToDFA = decisionToDFA;\n    // SLL, LL, or LL + exact ambig detection?//\n    this.predictionMode = PredictionMode.LL;\n    // LAME globals to avoid parameters!!!!! I need these down deep in predTransition\n    this._input = null;\n    this._startIndex = 0;\n    this._outerContext = null;\n    this._dfa = null;\n    // Each prediction operation uses a cache for merge of prediction contexts.\n    //  Don't keep around as it wastes huge amounts of memory. DoubleKeyMap\n    //  isn't synchronized but we're ok since two threads shouldn't reuse same\n    //  parser/atnsim object because it can only handle one input at a time.\n    //  This maps graphs a and b to merged result c. (a,b)&rarr;c. We can avoid\n    //  the merge if we ever see a and b again.  Note that (b,a)&rarr;c should\n    //  also be examined during cache lookup.\n    //\n    this.mergeCache = null;\n    return this;\n}\n\nParserATNSimulator.prototype = Object.create(ATNSimulator.prototype);\nParserATNSimulator.prototype.constructor = ParserATNSimulator;\n\nParserATNSimulator.prototype.debug = false;\nParserATNSimulator.prototype.debug_list_atn_decisions = false;\nParserATNSimulator.prototype.dfa_debug = false;\nParserATNSimulator.prototype.retry_debug = false;\n\n\nParserATNSimulator.prototype.reset = function() {\n};\n\nParserATNSimulator.prototype.adaptivePredict = function(input, decision, outerContext) {\n    if (this.debug || this.debug_list_atn_decisions) {\n        console.log(\"adaptivePredict decision \" + decision +\n                               \" exec LA(1)==\" + this.getLookaheadName(input) +\n                               \" line \" + input.LT(1).line + \":\" +\n                               input.LT(1).column);\n    }\n    this._input = input;\n    this._startIndex = input.index;\n    this._outerContext = outerContext;\n    \n    var dfa = this.decisionToDFA[decision];\n    this._dfa = dfa;\n    var m = input.mark();\n    var index = input.index;\n\n    // Now we are certain to have a specific decision's DFA\n    // But, do we still need an initial state?\n    try {\n        var s0;\n        if (dfa.precedenceDfa) {\n            // the start state for a precedence DFA depends on the current\n            // parser precedence, and is provided by a DFA method.\n            s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());\n        } else {\n            // the start state for a \"regular\" DFA is just s0\n            s0 = dfa.s0;\n        }\n        if (s0===null) {\n            if (outerContext===null) {\n                outerContext = RuleContext.EMPTY;\n            }\n            if (this.debug || this.debug_list_atn_decisions) {\n                console.log(\"predictATN decision \" + dfa.decision +\n                                   \" exec LA(1)==\" + this.getLookaheadName(input) +\n                                   \", outerContext=\" + outerContext.toString(this.parser.ruleNames));\n            }\n            // If this is not a precedence DFA, we check the ATN start state\n            // to determine if this ATN start state is the decision for the\n            // closure block that determines whether a precedence rule\n            // should continue or complete.\n            //\n            if (!dfa.precedenceDfa && (dfa.atnStartState instanceof StarLoopEntryState)) {\n                if (dfa.atnStartState.precedenceRuleDecision) {\n                    dfa.setPrecedenceDfa(true);\n                }\n            }\n            var fullCtx = false;\n            var s0_closure = this.computeStartState(dfa.atnStartState, RuleContext.EMPTY, fullCtx);\n\n            if( dfa.precedenceDfa) {\n                // If this is a precedence DFA, we use applyPrecedenceFilter\n                // to convert the computed start state to a precedence start\n                // state. We then use DFA.setPrecedenceStartState to set the\n                // appropriate start state for the precedence level rather\n                // than simply setting DFA.s0.\n                //\n                s0_closure = this.applyPrecedenceFilter(s0_closure);\n                s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);\n            } else {\n                s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                dfa.s0 = s0;\n            }\n        }\n        var alt = this.execATN(dfa, s0, input, index, outerContext);\n        if (this.debug) {\n            console.log(\"DFA after predictATN: \" + dfa.toString(this.parser.literalNames));\n        }\n        return alt;\n    } finally {\n        this._dfa = null;\n        this.mergeCache = null; // wack cache after each prediction\n        input.seek(index);\n        input.release(m);\n    }\n};\n// Performs ATN simulation to compute a predicted alternative based\n//  upon the remaining input, but also updates the DFA cache to avoid\n//  having to traverse the ATN again for the same input sequence.\n\n// There are some key conditions we're looking for after computing a new\n// set of ATN configs (proposed DFA state):\n      // if the set is empty, there is no viable alternative for current symbol\n      // does the state uniquely predict an alternative?\n      // does the state have a conflict that would prevent us from\n      //   putting it on the work list?\n\n// We also have some key operations to do:\n      // add an edge from previous DFA state to potentially new DFA state, D,\n      //   upon current symbol but only if adding to work list, which means in all\n      //   cases except no viable alternative (and possibly non-greedy decisions?)\n      // collecting predicates and adding semantic context to DFA accept states\n      // adding rule context to context-sensitive DFA accept states\n      // consuming an input symbol\n      // reporting a conflict\n      // reporting an ambiguity\n      // reporting a context sensitivity\n      // reporting insufficient predicates\n\n// cover these cases:\n//    dead end\n//    single alt\n//    single alt + preds\n//    conflict\n//    conflict + preds\n//\nParserATNSimulator.prototype.execATN = function(dfa, s0, input, startIndex, outerContext ) {\n    if (this.debug || this.debug_list_atn_decisions) {\n        console.log(\"execATN decision \" + dfa.decision +\n                \" exec LA(1)==\" + this.getLookaheadName(input) +\n                \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n    }\n    var alt;\n    var previousD = s0;\n\n    if (this.debug) {\n        console.log(\"s0 = \" + s0);\n    }\n    var t = input.LA(1);\n    while(true) { // while more work\n        var D = this.getExistingTargetState(previousD, t);\n        if(D===null) {\n            D = this.computeTargetState(dfa, previousD, t);\n        }\n        if(D===ATNSimulator.ERROR) {\n            // if any configs in previous dipped into outer context, that\n            // means that input up to t actually finished entry rule\n            // at least for SLL decision. Full LL doesn't dip into outer\n            // so don't need special case.\n            // We will get an error no matter what so delay until after\n            // decision; better error message. Also, no reachable target\n            // ATN states in SLL implies LL will also get nowhere.\n            // If conflict in states that dip out, choose min since we\n            // will get error no matter what.\n            var e = this.noViableAlt(input, outerContext, previousD.configs, startIndex);\n            input.seek(startIndex);\n            alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);\n            if(alt!==ATN.INVALID_ALT_NUMBER) {\n                return alt;\n            } else {\n                throw e;\n            }\n        }\n        if(D.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {\n            // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)\n            var conflictingAlts = null;\n            if (D.predicates!==null) {\n                if (this.debug) {\n                    console.log(\"DFA state has preds in DFA sim LL failover\");\n                }\n                var conflictIndex = input.index;\n                if(conflictIndex !== startIndex) {\n                    input.seek(startIndex);\n                }\n                conflictingAlts = this.evalSemanticContext(D.predicates, outerContext, true);\n                if (conflictingAlts.length===1) {\n                    if(this.debug) {\n                        console.log(\"Full LL avoided\");\n                    }\n                    return conflictingAlts.minValue();\n                }\n                if (conflictIndex !== startIndex) {\n                    // restore the index so reporting the fallback to full\n                    // context occurs with the index at the correct spot\n                    input.seek(conflictIndex);\n                }\n            }\n            if (this.dfa_debug) {\n                console.log(\"ctx sensitive state \" + outerContext +\" in \" + D);\n            }\n            var fullCtx = true;\n            var s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);\n            this.reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index);\n            alt = this.execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);\n            return alt;\n        }\n        if (D.isAcceptState) {\n            if (D.predicates===null) {\n                return D.prediction;\n            }\n            var stopIndex = input.index;\n            input.seek(startIndex);\n            var alts = this.evalSemanticContext(D.predicates, outerContext, true);\n            if (alts.length===0) {\n                throw this.noViableAlt(input, outerContext, D.configs, startIndex);\n            } else if (alts.length===1) {\n                return alts.minValue();\n            } else {\n                // report ambiguity after predicate evaluation to make sure the correct set of ambig alts is reported.\n                this.reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);\n                return alts.minValue();\n            }\n        }\n        previousD = D;\n\n        if (t !== Token.EOF) {\n            input.consume();\n            t = input.LA(1);\n        }\n    }\n};\n//\n// Get an existing target state for an edge in the DFA. If the target state\n// for the edge has not yet been computed or is otherwise not available,\n// this method returns {@code null}.\n//\n// @param previousD The current DFA state\n// @param t The next input symbol\n// @return The existing target DFA state for the given input symbol\n// {@code t}, or {@code null} if the target state for this edge is not\n// already cached\n//\nParserATNSimulator.prototype.getExistingTargetState = function(previousD, t) {\n    var edges = previousD.edges;\n    if (edges===null) {\n        return null;\n    } else {\n        return edges[t + 1] || null;\n    }\n};\n//\n// Compute a target state for an edge in the DFA, and attempt to add the\n// computed state and corresponding edge to the DFA.\n//\n// @param dfa The DFA\n// @param previousD The current DFA state\n// @param t The next input symbol\n//\n// @return The computed target DFA state for the given input symbol\n// {@code t}. If {@code t} does not lead to a valid DFA state, this method\n// returns {@link //ERROR}.\n//\nParserATNSimulator.prototype.computeTargetState = function(dfa, previousD, t) {\n   var reach = this.computeReachSet(previousD.configs, t, false);\n    if(reach===null) {\n        this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);\n        return ATNSimulator.ERROR;\n    }\n    // create new target state; we'll add to DFA after it's complete\n    var D = new DFAState(null, reach);\n\n    var predictedAlt = this.getUniqueAlt(reach);\n\n    if (this.debug) {\n        var altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n        console.log(\"SLL altSubSets=\" + Utils.arrayToString(altSubSets) +\n                    \", previous=\" + previousD.configs +\n                    \", configs=\" + reach +\n                    \", predict=\" + predictedAlt +\n                    \", allSubsetsConflict=\" +\n                    PredictionMode.allSubsetsConflict(altSubSets) + \", conflictingAlts=\" +\n                    this.getConflictingAlts(reach));\n    }\n    if (predictedAlt!==ATN.INVALID_ALT_NUMBER) {\n        // NO CONFLICT, UNIQUELY PREDICTED ALT\n        D.isAcceptState = true;\n        D.configs.uniqueAlt = predictedAlt;\n        D.prediction = predictedAlt;\n    } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {\n        // MORE THAN ONE VIABLE ALTERNATIVE\n        D.configs.conflictingAlts = this.getConflictingAlts(reach);\n        D.requiresFullContext = true;\n        // in SLL-only mode, we will stop at this state and return the minimum alt\n        D.isAcceptState = true;\n        D.prediction = D.configs.conflictingAlts.minValue();\n    }\n    if (D.isAcceptState && D.configs.hasSemanticContext) {\n        this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));\n        if( D.predicates!==null) {\n            D.prediction = ATN.INVALID_ALT_NUMBER;\n        }\n    }\n    // all adds to dfa are done after we've created full D state\n    D = this.addDFAEdge(dfa, previousD, t, D);\n    return D;\n};\n\nParserATNSimulator.prototype.predicateDFAState = function(dfaState, decisionState) {\n    // We need to test all predicates, even in DFA states that\n    // uniquely predict alternative.\n    var nalts = decisionState.transitions.length;\n    // Update DFA so reach becomes accept state with (predicate,alt)\n    // pairs if preds found for conflicting alts\n    var altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);\n    var altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);\n    if (altToPred!==null) {\n        dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);\n        dfaState.prediction = ATN.INVALID_ALT_NUMBER; // make sure we use preds\n    } else {\n        // There are preds in configs but they might go away\n        // when OR'd together like {p}? || NONE == NONE. If neither\n        // alt has preds, resolve to min alt\n        dfaState.prediction = altsToCollectPredsFrom.minValue();\n    }\n};\n\n// comes back with reach.uniqueAlt set to a valid alt\nParserATNSimulator.prototype.execATNWithFullContext = function(dfa, D, // how far we got before failing over\n                                     s0,\n                                     input,\n                                     startIndex,\n                                     outerContext) {\n    if (this.debug || this.debug_list_atn_decisions) {\n        console.log(\"execATNWithFullContext \"+s0);\n    }\n    var fullCtx = true;\n    var foundExactAmbig = false;\n    var reach = null;\n    var previous = s0;\n    input.seek(startIndex);\n    var t = input.LA(1);\n    var predictedAlt = -1;\n    while (true) { // while more work\n        reach = this.computeReachSet(previous, t, fullCtx);\n        if (reach===null) {\n            // if any configs in previous dipped into outer context, that\n            // means that input up to t actually finished entry rule\n            // at least for LL decision. Full LL doesn't dip into outer\n            // so don't need special case.\n            // We will get an error no matter what so delay until after\n            // decision; better error message. Also, no reachable target\n            // ATN states in SLL implies LL will also get nowhere.\n            // If conflict in states that dip out, choose min since we\n            // will get error no matter what.\n            var e = this.noViableAlt(input, outerContext, previous, startIndex);\n            input.seek(startIndex);\n            var alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);\n            if(alt!==ATN.INVALID_ALT_NUMBER) {\n                return alt;\n            } else {\n                throw e;\n            }\n        }\n        var altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n        if(this.debug) {\n            console.log(\"LL altSubSets=\" + altSubSets + \", predict=\" +\n                  PredictionMode.getUniqueAlt(altSubSets) + \", resolvesToJustOneViableAlt=\" +\n                  PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n        }\n        reach.uniqueAlt = this.getUniqueAlt(reach);\n        // unique prediction?\n        if(reach.uniqueAlt!==ATN.INVALID_ALT_NUMBER) {\n            predictedAlt = reach.uniqueAlt;\n            break;\n        } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {\n            predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n            if(predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n                break;\n            }\n        } else {\n            // In exact ambiguity mode, we never try to terminate early.\n            // Just keeps scarfing until we know what the conflict is\n            if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {\n                foundExactAmbig = true;\n                predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n                break;\n            }\n            // else there are multiple non-conflicting subsets or\n            // we're not sure what the ambiguity is yet.\n            // So, keep going.\n        }\n        previous = reach;\n        if( t !== Token.EOF) {\n            input.consume();\n            t = input.LA(1);\n        }\n    }\n    // If the configuration set uniquely predicts an alternative,\n    // without conflict, then we know that it's a full LL decision\n    // not SLL.\n    if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER ) {\n        this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);\n        return predictedAlt;\n    }\n    // We do not check predicates here because we have checked them\n    // on-the-fly when doing full context prediction.\n\n    //\n    // In non-exact ambiguity detection mode, we might\tactually be able to\n    // detect an exact ambiguity, but I'm not going to spend the cycles\n    // needed to check. We only emit ambiguity warnings in exact ambiguity\n    // mode.\n    //\n    // For example, we might know that we have conflicting configurations.\n    // But, that does not mean that there is no way forward without a\n    // conflict. It's possible to have nonconflicting alt subsets as in:\n\n    // altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]\n\n    // from\n    //\n    //    [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),\n    //     (13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]\n    //\n    // In this case, (17,1,[5 $]) indicates there is some next sequence that\n    // would resolve this without conflict to alternative 1. Any other viable\n    // next sequence, however, is associated with a conflict.  We stop\n    // looking for input because no amount of further lookahead will alter\n    // the fact that we should predict alternative 1.  We just can't say for\n    // sure that there is an ambiguity without looking further.\n\n    this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, null, reach);\n\n    return predictedAlt;\n};\n\nParserATNSimulator.prototype.computeReachSet = function(closure, t, fullCtx) {\n    if (this.debug) {\n        console.log(\"in computeReachSet, starting closure: \" + closure);\n    }\n    if( this.mergeCache===null) {\n        this.mergeCache = new DoubleDict();\n    }\n    var intermediate = new ATNConfigSet(fullCtx);\n\n    // Configurations already in a rule stop state indicate reaching the end\n    // of the decision rule (local context) or end of the start rule (full\n    // context). Once reached, these configurations are never updated by a\n    // closure operation, so they are handled separately for the performance\n    // advantage of having a smaller intermediate set when calling closure.\n    //\n    // For full-context reach operations, separate handling is required to\n    // ensure that the alternative matching the longest overall sequence is\n    // chosen when multiple such configurations can match the input.\n    \n    var skippedStopStates = null;\n\n    // First figure out where we can reach on input t\n    for (var i=0; i<closure.items.length;i++) {\n        var c = closure.items[i];\n        if(this.debug) {\n            console.log(\"testing \" + this.getTokenName(t) + \" at \" + c);\n        }\n        if (c.state instanceof RuleStopState) {\n            if (fullCtx || t === Token.EOF) {\n                if (skippedStopStates===null) {\n                    skippedStopStates = [];\n                }\n                skippedStopStates.push(c);\n                if(this.debug) {\n                    console.log(\"added \" + c + \" to skippedStopStates\");\n                }\n            }\n            continue;\n        }\n        for(var j=0;j<c.state.transitions.length;j++) {\n            var trans = c.state.transitions[j];\n            var target = this.getReachableTarget(trans, t);\n            if (target!==null) {\n                var cfg = new ATNConfig({state:target}, c);\n                intermediate.add(cfg, this.mergeCache);\n                if(this.debug) {\n                    console.log(\"added \" + cfg + \" to intermediate\");\n                }\n            }\n        }\n    }\n    // Now figure out where the reach operation can take us...\n    var reach = null;\n\n    // This block optimizes the reach operation for intermediate sets which\n    // trivially indicate a termination state for the overall\n    // adaptivePredict operation.\n    //\n    // The conditions assume that intermediate\n    // contains all configurations relevant to the reach set, but this\n    // condition is not true when one or more configurations have been\n    // withheld in skippedStopStates, or when the current symbol is EOF.\n    //\n    if (skippedStopStates===null && t!==Token.EOF) {\n        if (intermediate.items.length===1) {\n            // Don't pursue the closure if there is just one state.\n            // It can only have one alternative; just add to result\n            // Also don't pursue the closure if there is unique alternative\n            // among the configurations.\n            reach = intermediate;\n        } else if (this.getUniqueAlt(intermediate)!==ATN.INVALID_ALT_NUMBER) {\n            // Also don't pursue the closure if there is unique alternative\n            // among the configurations.\n            reach = intermediate;\n        }\n    }\n    // If the reach set could not be trivially determined, perform a closure\n    // operation on the intermediate set to compute its initial value.\n    //\n    if (reach===null) {\n        reach = new ATNConfigSet(fullCtx);\n        var closureBusy = new Set();\n        var treatEofAsEpsilon = t === Token.EOF;\n        for (var k=0; k<intermediate.items.length;k++) {\n            this.closure(intermediate.items[k], reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n        }\n    }\n    if (t === Token.EOF) {\n        // After consuming EOF no additional input is possible, so we are\n        // only interested in configurations which reached the end of the\n        // decision rule (local context) or end of the start rule (full\n        // context). Update reach to contain only these configurations. This\n        // handles both explicit EOF transitions in the grammar and implicit\n        // EOF transitions following the end of the decision or start rule.\n        //\n        // When reach==intermediate, no closure operation was performed. In\n        // this case, removeAllConfigsNotInRuleStopState needs to check for\n        // reachable rule stop states as well as configurations already in\n        // a rule stop state.\n        //\n        // This is handled before the configurations in skippedStopStates,\n        // because any configurations potentially added from that list are\n        // already guaranteed to meet this condition whether or not it's\n        // required.\n        //\n        reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);\n    }\n    // If skippedStopStates!==null, then it contains at least one\n    // configuration. For full-context reach operations, these\n    // configurations reached the end of the start rule, in which case we\n    // only add them back to reach if no configuration during the current\n    // closure operation reached such a state. This ensures adaptivePredict\n    // chooses an alternative matching the longest overall sequence when\n    // multiple alternatives are viable.\n    //\n    if (skippedStopStates!==null && ( (! fullCtx) || (! PredictionMode.hasConfigInRuleStopState(reach)))) {\n        for (var l=0; l<skippedStopStates.length;l++) {\n            reach.add(skippedStopStates[l], this.mergeCache);\n        }\n    }\n    if (reach.items.length===0) {\n        return null;\n    } else {\n        return reach;\n    }\n};\n//\n// Return a configuration set containing only the configurations from\n// {@code configs} which are in a {@link RuleStopState}. If all\n// configurations in {@code configs} are already in a rule stop state, this\n// method simply returns {@code configs}.\n//\n// <p>When {@code lookToEndOfRule} is true, this method uses\n// {@link ATN//nextTokens} for each configuration in {@code configs} which is\n// not already in a rule stop state to see if a rule stop state is reachable\n// from the configuration via epsilon-only transitions.</p>\n//\n// @param configs the configuration set to update\n// @param lookToEndOfRule when true, this method checks for rule stop states\n// reachable by epsilon-only transitions from each configuration in\n// {@code configs}.\n//\n// @return {@code configs} if all configurations in {@code configs} are in a\n// rule stop state, otherwise return a new configuration set containing only\n// the configurations from {@code configs} which are in a rule stop state\n//\nParserATNSimulator.prototype.removeAllConfigsNotInRuleStopState = function(configs, lookToEndOfRule) {\n    if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n        return configs;\n    }\n    var result = new ATNConfigSet(configs.fullCtx);\n    for(var i=0; i<configs.items.length;i++) {\n        var config = configs.items[i];\n        if (config.state instanceof RuleStopState) {\n            result.add(config, this.mergeCache);\n            continue;\n        }\n        if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {\n            var nextTokens = this.atn.nextTokens(config.state);\n            if (nextTokens.contains(Token.EPSILON)) {\n                var endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];\n                result.add(new ATNConfig({state:endOfRuleState}, config), this.mergeCache);\n            }\n        }\n    }\n    return result;\n};\n\nParserATNSimulator.prototype.computeStartState = function(p, ctx, fullCtx) {\n    // always at least the implicit call to start rule\n    var initialContext = predictionContextFromRuleContext(this.atn, ctx);\n    var configs = new ATNConfigSet(fullCtx);\n    for(var i=0;i<p.transitions.length;i++) {\n        var target = p.transitions[i].target;\n        var c = new ATNConfig({ state:target, alt:i+1, context:initialContext }, null);\n        var closureBusy = new Set();\n        this.closure(c, configs, closureBusy, true, fullCtx, false);\n    }\n    return configs;\n};\n\n//\n// This method transforms the start state computed by\n// {@link //computeStartState} to the special start state used by a\n// precedence DFA for a particular precedence value. The transformation\n// process applies the following changes to the start state's configuration\n// set.\n//\n// <ol>\n// <li>Evaluate the precedence predicates for each configuration using\n// {@link SemanticContext//evalPrecedence}.</li>\n// <li>Remove all configurations which predict an alternative greater than\n// 1, for which another configuration that predicts alternative 1 is in the\n// same ATN state with the same prediction context. This transformation is\n// valid for the following reasons:\n// <ul>\n// <li>The closure block cannot contain any epsilon transitions which bypass\n// the body of the closure, so all states reachable via alternative 1 are\n// part of the precedence alternatives of the transformed left-recursive\n// rule.</li>\n// <li>The \"primary\" portion of a left recursive rule cannot contain an\n// epsilon transition, so the only way an alternative other than 1 can exist\n// in a state that is also reachable via alternative 1 is by nesting calls\n// to the left-recursive rule, with the outer calls not being at the\n// preferred precedence level.</li>\n// </ul>\n// </li>\n// </ol>\n//\n// <p>\n// The prediction context must be considered by this filter to address\n// situations like the following.\n// </p>\n// <code>\n// <pre>\n// grammar TA;\n// prog: statement* EOF;\n// statement: letterA | statement letterA 'b' ;\n// letterA: 'a';\n// </pre>\n// </code>\n// <p>\n// If the above grammar, the ATN state immediately before the token\n// reference {@code 'a'} in {@code letterA} is reachable from the left edge\n// of both the primary and closure blocks of the left-recursive rule\n// {@code statement}. The prediction context associated with each of these\n// configurations distinguishes between them, and prevents the alternative\n// which stepped out to {@code prog} (and then back in to {@code statement}\n// from being eliminated by the filter.\n// </p>\n//\n// @param configs The configuration set computed by\n// {@link //computeStartState} as the start state for the DFA.\n// @return The transformed configuration set representing the start state\n// for a precedence DFA at a particular precedence level (determined by\n// calling {@link Parser//getPrecedence}).\n//\nParserATNSimulator.prototype.applyPrecedenceFilter = function(configs) {\n\tvar config;\n\tvar statesFromAlt1 = [];\n    var configSet = new ATNConfigSet(configs.fullCtx);\n    for(var i=0; i<configs.items.length; i++) {\n        config = configs.items[i];\n        // handle alt 1 first\n        if (config.alt !== 1) {\n            continue;\n        }\n        var updatedContext = config.semanticContext.evalPrecedence(this.parser, this._outerContext);\n        if (updatedContext===null) {\n            // the configuration was eliminated\n            continue;\n        }\n        statesFromAlt1[config.state.stateNumber] = config.context;\n        if (updatedContext !== config.semanticContext) {\n            configSet.add(new ATNConfig({semanticContext:updatedContext}, config), this.mergeCache);\n        } else {\n            configSet.add(config, this.mergeCache);\n        }\n    }\n    for(i=0; i<configs.items.length; i++) {\n        config = configs.items[i];\n        if (config.alt === 1) {\n            // already handled\n            continue;\n        }\n        // In the future, this elimination step could be updated to also\n        // filter the prediction context for alternatives predicting alt>1\n        // (basically a graph subtraction algorithm).\n\t\tif (!config.precedenceFilterSuppressed) {\n            var context = statesFromAlt1[config.state.stateNumber] || null;\n            if (context!==null && context.equals(config.context)) {\n                // eliminated\n                continue;\n            }\n\t\t}\n        configSet.add(config, this.mergeCache);\n    }\n    return configSet;\n};\n\nParserATNSimulator.prototype.getReachableTarget = function(trans, ttype) {\n    if (trans.matches(ttype, 0, this.atn.maxTokenType)) {\n        return trans.target;\n    } else {\n        return null;\n    }\n};\n\nParserATNSimulator.prototype.getPredsForAmbigAlts = function(ambigAlts, configs, nalts) {\n    // REACH=[1|1|[]|0:0, 1|2|[]|0:1]\n    // altToPred starts as an array of all null contexts. The entry at index i\n    // corresponds to alternative i. altToPred[i] may have one of three values:\n    //   1. null: no ATNConfig c is found such that c.alt==i\n    //   2. SemanticContext.NONE: At least one ATNConfig c exists such that\n    //      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,\n    //      alt i has at least one unpredicated config.\n    //   3. Non-NONE Semantic Context: There exists at least one, and for all\n    //      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.\n    //\n    // From this, it is clear that NONE||anything==NONE.\n    //\n    var altToPred = [];\n    for(var i=0;i<configs.items.length;i++) {\n        var c = configs.items[i];\n        if(ambigAlts.contains( c.alt )) {\n            altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] || null, c.semanticContext);\n        }\n    }\n    var nPredAlts = 0;\n    for (i =1;i< nalts+1;i++) {\n        var pred = altToPred[i] || null;\n        if (pred===null) {\n            altToPred[i] = SemanticContext.NONE;\n        } else if (pred !== SemanticContext.NONE) {\n            nPredAlts += 1;\n        }\n    }\n    // nonambig alts are null in altToPred\n    if (nPredAlts===0) {\n        altToPred = null;\n    }\n    if (this.debug) {\n        console.log(\"getPredsForAmbigAlts result \" + Utils.arrayToString(altToPred));\n    }\n    return altToPred;\n};\n\nParserATNSimulator.prototype.getPredicatePredictions = function(ambigAlts, altToPred) {\n    var pairs = [];\n    var containsPredicate = false;\n    for (var i=1; i<altToPred.length;i++) {\n        var pred = altToPred[i];\n        // unpredicated is indicated by SemanticContext.NONE\n        if( ambigAlts!==null && ambigAlts.contains( i )) {\n            pairs.push(new PredPrediction(pred, i));\n        }\n        if (pred !== SemanticContext.NONE) {\n            containsPredicate = true;\n        }\n    }\n    if (! containsPredicate) {\n        return null;\n    }\n    return pairs;\n};\n\n//\n// This method is used to improve the localization of error messages by\n// choosing an alternative rather than throwing a\n// {@link NoViableAltException} in particular prediction scenarios where the\n// {@link //ERROR} state was reached during ATN simulation.\n//\n// <p>\n// The default implementation of this method uses the following\n// algorithm to identify an ATN configuration which successfully parsed the\n// decision entry rule. Choosing such an alternative ensures that the\n// {@link ParserRuleContext} returned by the calling rule will be complete\n// and valid, and the syntax error will be reported later at a more\n// localized location.</p>\n//\n// <ul>\n// <li>If a syntactically valid path or paths reach the end of the decision rule and\n// they are semantically valid if predicated, return the min associated alt.</li>\n// <li>Else, if a semantically invalid but syntactically valid path exist\n// or paths exist, return the minimum associated alt.\n// </li>\n// <li>Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.</li>\n// </ul>\n//\n// <p>\n// In some scenarios, the algorithm described above could predict an\n// alternative which will result in a {@link FailedPredicateException} in\n// the parser. Specifically, this could occur if the <em>only</em> configuration\n// capable of successfully parsing to the end of the decision rule is\n// blocked by a semantic predicate. By choosing this alternative within\n// {@link //adaptivePredict} instead of throwing a\n// {@link NoViableAltException}, the resulting\n// {@link FailedPredicateException} in the parser will identify the specific\n// predicate which is preventing the parser from successfully parsing the\n// decision rule, which helps developers identify and correct logic errors\n// in semantic predicates.\n// </p>\n//\n// @param configs The ATN configurations which were valid immediately before\n// the {@link //ERROR} state was reached\n// @param outerContext The is the \\gamma_0 initial parser context from the paper\n// or the parser stack at the instant before prediction commences.\n//\n// @return The value to return from {@link //adaptivePredict}, or\n// {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not\n// identified and {@link //adaptivePredict} should report an error instead.\n//\nParserATNSimulator.prototype.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule = function(configs, outerContext) {\n    var cfgs = this.splitAccordingToSemanticValidity(configs, outerContext);\n    var semValidConfigs = cfgs[0];\n    var semInvalidConfigs = cfgs[1];\n    var alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);\n    if (alt!==ATN.INVALID_ALT_NUMBER) { // semantically/syntactically viable path exists\n        return alt;\n    }\n    // Is there a syntactically valid path with a failed pred?\n    if (semInvalidConfigs.items.length>0) {\n        alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);\n        if (alt!==ATN.INVALID_ALT_NUMBER) { // syntactically viable path exists\n            return alt;\n        }\n    }\n    return ATN.INVALID_ALT_NUMBER;\n};\n    \nParserATNSimulator.prototype.getAltThatFinishedDecisionEntryRule = function(configs) {\n    var alts = [];\n    for(var i=0;i<configs.items.length; i++) {\n        var c = configs.items[i];\n        if (c.reachesIntoOuterContext>0 || ((c.state instanceof RuleStopState) && c.context.hasEmptyPath())) {\n            if(alts.indexOf(c.alt)<0) {\n                alts.push(c.alt);\n            }\n        }\n    }\n    if (alts.length===0) {\n        return ATN.INVALID_ALT_NUMBER;\n    } else {\n        return Math.min.apply(null, alts);\n    }\n};\n// Walk the list of configurations and split them according to\n//  those that have preds evaluating to true/false.  If no pred, assume\n//  true pred and include in succeeded set.  Returns Pair of sets.\n//\n//  Create a new set so as not to alter the incoming parameter.\n//\n//  Assumption: the input stream has been restored to the starting point\n//  prediction, which is where predicates need to evaluate.\n//\nParserATNSimulator.prototype.splitAccordingToSemanticValidity = function( configs, outerContext) {\n    var succeeded = new ATNConfigSet(configs.fullCtx);\n    var failed = new ATNConfigSet(configs.fullCtx);\n    for(var i=0;i<configs.items.length; i++) {\n        var c = configs.items[i];\n        if (c.semanticContext !== SemanticContext.NONE) {\n            var predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);\n            if (predicateEvaluationResult) {\n                succeeded.add(c);\n            } else {\n                failed.add(c);\n            }\n        } else {\n            succeeded.add(c);\n        }\n    }\n    return [succeeded, failed];\n};\n\n// Look through a list of predicate/alt pairs, returning alts for the\n//  pairs that win. A {@code NONE} predicate indicates an alt containing an\n//  unpredicated config which behaves as \"always true.\" If !complete\n//  then we stop at the first predicate that evaluates to true. This\n//  includes pairs with null predicates.\n//\nParserATNSimulator.prototype.evalSemanticContext = function(predPredictions, outerContext, complete) {\n    var predictions = new BitSet();\n    for(var i=0;i<predPredictions.length;i++) {\n    \tvar pair = predPredictions[i];\n        if (pair.pred === SemanticContext.NONE) {\n            predictions.add(pair.alt);\n            if (! complete) {\n                break;\n            }\n            continue;\n        }\n        var predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);\n        if (this.debug || this.dfa_debug) {\n            console.log(\"eval pred \" + pair + \"=\" + predicateEvaluationResult);\n        }\n        if (predicateEvaluationResult) {\n            if (this.debug || this.dfa_debug) {\n                console.log(\"PREDICT \" + pair.alt);\n            }\n            predictions.add(pair.alt);\n            if (! complete) {\n                break;\n            }\n        }\n    }\n    return predictions;\n};\n\n// TODO: If we are doing predicates, there is no point in pursuing\n//     closure operations if we reach a DFA state that uniquely predicts\n//     alternative. We will not be caching that DFA state and it is a\n//     waste to pursue the closure. Might have to advance when we do\n//     ambig detection thought :(\n//\n\nParserATNSimulator.prototype.closure = function(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {\n    var initialDepth = 0;\n    this.closureCheckingStopState(config, configs, closureBusy, collectPredicates,\n                             fullCtx, initialDepth, treatEofAsEpsilon);\n};\n\n\nParserATNSimulator.prototype.closureCheckingStopState = function(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n    if (this.debug) {\n        console.log(\"closure(\" + config.toString(this.parser,true) + \")\");\n        console.log(\"configs(\" + configs.toString() + \")\");\n        if(config.reachesIntoOuterContext>50) {\n            throw \"problem\";\n        }\n    }\n    if (config.state instanceof RuleStopState) {\n        // We hit rule end. If we have context info, use it\n        // run thru all possible stack tops in ctx\n        if (! config.context.isEmpty()) {\n            for ( var i =0; i<config.context.length; i++) {\n                if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {\n                    if (fullCtx) {\n                        configs.add(new ATNConfig({state:config.state, context:PredictionContext.EMPTY}, config), this.mergeCache);\n                        continue;\n                    } else {\n                        // we have no context info, just chase follow links (if greedy)\n                        if (this.debug) {\n                            console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n                        }\n                        this.closure_(config, configs, closureBusy, collectPredicates,\n                                 fullCtx, depth, treatEofAsEpsilon);\n                    }\n                    continue;\n                }\n                var returnState = this.atn.states[config.context.getReturnState(i)];\n                var newContext = config.context.getParent(i); // \"pop\" return state\n                var parms = {state:returnState, alt:config.alt, context:newContext, semanticContext:config.semanticContext};\n                var c = new ATNConfig(parms, null);\n                // While we have context to pop back from, we may have\n                // gotten that context AFTER having falling off a rule.\n                // Make sure we track that we are now out of context.\n                c.reachesIntoOuterContext = config.reachesIntoOuterContext;\n                this.closureCheckingStopState(c, configs, closureBusy, collectPredicates, fullCtx, depth - 1, treatEofAsEpsilon);\n            }\n            return;\n        } else if( fullCtx) {\n            // reached end of start rule\n            configs.add(config, this.mergeCache);\n            return;\n        } else {\n            // else if we have no context info, just chase follow links (if greedy)\n            if (this.debug) {\n                console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n            }\n        }\n    }\n    this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n};\n\n// Do the actual work of walking epsilon edges//\nParserATNSimulator.prototype.closure_ = function(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n    var p = config.state;\n    // optimization\n    if (! p.epsilonOnlyTransitions) {\n        configs.add(config, this.mergeCache);\n        // make sure to not return here, because EOF transitions can act as\n        // both epsilon transitions and non-epsilon transitions.\n    }\n    for(var i = 0;i<p.transitions.length; i++) {\n        var t = p.transitions[i];\n        var continueCollecting = collectPredicates && !(t instanceof ActionTransition);\n        var c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);\n        if (c!==null) {\n\t\t\tif (!t.isEpsilon && closureBusy.add(c)!==c){\n\t\t\t\t// avoid infinite recursion for EOF* and EOF+\n\t\t\t\tcontinue;\n\t\t\t}\n            var newDepth = depth;\n            if ( config.state instanceof RuleStopState) {\n                // target fell off end of rule; mark resulting c as having dipped into outer context\n                // We can't get here if incoming config was rule stop and we had context\n                // track how far we dip into outer context.  Might\n                // come in handy and we avoid evaluating context dependent\n                // preds if this is > 0.\n\n                if (closureBusy.add(c)!==c) {\n                    // avoid infinite recursion for right-recursive rules\n                    continue;\n                }\n\n\t\t\t\tif (this._dfa !== null && this._dfa.precedenceDfa) {\n\t\t\t\t\tif (t.outermostPrecedenceReturn === this._dfa.atnStartState.ruleIndex) {\n\t\t\t\t\t\tc.precedenceFilterSuppressed = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\n                c.reachesIntoOuterContext += 1;\n                configs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n                newDepth -= 1;\n                if (this.debug) {\n                    console.log(\"dips into outer ctx: \" + c);\n                }\n            } else if (t instanceof RuleTransition) {\n                // latch when newDepth goes negative - once we step out of the entry context we can't return\n                if (newDepth >= 0) {\n                    newDepth += 1;\n                }\n            }\n            this.closureCheckingStopState(c, configs, closureBusy, continueCollecting, fullCtx, newDepth, treatEofAsEpsilon);\n        }\n    }\n};\n\nParserATNSimulator.prototype.getRuleName = function( index) {\n    if (this.parser!==null && index>=0) {\n        return this.parser.ruleNames[index];\n    } else {\n        return \"<rule \" + index + \">\";\n    }\n};\n\nParserATNSimulator.prototype.getEpsilonTarget = function(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {\n    switch(t.serializationType) {\n    case Transition.RULE:\n        return this.ruleTransition(config, t);\n    case Transition.PRECEDENCE:\n        return this.precedenceTransition(config, t, collectPredicates, inContext, fullCtx);\n    case Transition.PREDICATE:\n        return this.predTransition(config, t, collectPredicates, inContext, fullCtx);\n    case Transition.ACTION:\n        return this.actionTransition(config, t);\n    case Transition.EPSILON:\n        return new ATNConfig({state:t.target}, config);\n    case Transition.ATOM:\n    case Transition.RANGE:\n    case Transition.SET:\n        // EOF transitions act like epsilon transitions after the first EOF\n        // transition is traversed\n        if (treatEofAsEpsilon) {\n            if (t.matches(Token.EOF, 0, 1)) {\n                return new ATNConfig({state: t.target}, config);\n            }\n        }\n        return null;\n    default:\n    \treturn null;\n    }\n};\n\nParserATNSimulator.prototype.actionTransition = function(config, t) {\n    if (this.debug) {\n        console.log(\"ACTION edge \" + t.ruleIndex + \":\" + t.actionIndex);\n    }\n    return new ATNConfig({state:t.target}, config);\n};\n\nParserATNSimulator.prototype.precedenceTransition = function(config, pt,  collectPredicates, inContext, fullCtx) {\n    if (this.debug) {\n        console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" +\n                pt.precedence + \">=_p, ctx dependent=true\");\n        if (this.parser!==null) {\n        \tconsole.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n        }\n    }\n    var c = null;\n    if (collectPredicates && inContext) {\n        if (fullCtx) {\n            // In full context mode, we can evaluate predicates on-the-fly\n            // during closure, which dramatically reduces the size of\n            // the config sets. It also obviates the need to test predicates\n            // later during conflict resolution.\n            var currentPosition = this._input.index;\n            this._input.seek(this._startIndex);\n            var predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n            this._input.seek(currentPosition);\n            if (predSucceeds) {\n                c = new ATNConfig({state:pt.target}, config); // no pred context\n            }\n        } else {\n            newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n            c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n        }\n    } else {\n        c = new ATNConfig({state:pt.target}, config);\n    }\n    if (this.debug) {\n        console.log(\"config from pred transition=\" + c);\n    }\n    return c;\n};\n\nParserATNSimulator.prototype.predTransition = function(config, pt, collectPredicates, inContext, fullCtx) {\n    if (this.debug) {\n        console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.ruleIndex +\n                \":\" + pt.predIndex + \", ctx dependent=\" + pt.isCtxDependent);\n        if (this.parser!==null) {\n            console.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n        }\n    }\n    var c = null;\n    if (collectPredicates && ((pt.isCtxDependent && inContext) || ! pt.isCtxDependent)) {\n        if (fullCtx) {\n            // In full context mode, we can evaluate predicates on-the-fly\n            // during closure, which dramatically reduces the size of\n            // the config sets. It also obviates the need to test predicates\n            // later during conflict resolution.\n            var currentPosition = this._input.index;\n            this._input.seek(this._startIndex);\n            var predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n            this._input.seek(currentPosition);\n            if (predSucceeds) {\n                c = new ATNConfig({state:pt.target}, config); // no pred context\n            }\n        } else {\n            var newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n            c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n        }\n    } else {\n        c = new ATNConfig({state:pt.target}, config);\n    }\n    if (this.debug) {\n        console.log(\"config from pred transition=\" + c);\n    }\n    return c;\n};\n\nParserATNSimulator.prototype.ruleTransition = function(config, t) {\n    if (this.debug) {\n        console.log(\"CALL rule \" + this.getRuleName(t.target.ruleIndex) + \", ctx=\" + config.context);\n    }\n    var returnState = t.followState;\n    var newContext = SingletonPredictionContext.create(config.context, returnState.stateNumber);\n    return new ATNConfig({state:t.target, context:newContext}, config );\n};\n\nParserATNSimulator.prototype.getConflictingAlts = function(configs) {\n    var altsets = PredictionMode.getConflictingAltSubsets(configs);\n    return PredictionMode.getAlts(altsets);\n};\n\n // Sam pointed out a problem with the previous definition, v3, of\n // ambiguous states. If we have another state associated with conflicting\n // alternatives, we should keep going. For example, the following grammar\n //\n // s : (ID | ID ID?) ';' ;\n //\n // When the ATN simulation reaches the state before ';', it has a DFA\n // state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally\n // 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node\n // because alternative to has another way to continue, via [6|2|[]].\n // The key is that we have a single state that has config's only associated\n // with a single alternative, 2, and crucially the state transitions\n // among the configurations are all non-epsilon transitions. That means\n // we don't consider any conflicts that include alternative 2. So, we\n // ignore the conflict between alts 1 and 2. We ignore a set of\n // conflicting alts when there is an intersection with an alternative\n // associated with a single alt state in the state&rarr;config-list map.\n //\n // It's also the case that we might have two conflicting configurations but\n // also a 3rd nonconflicting configuration for a different alternative:\n // [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:\n //\n // a : A | A | A B ;\n //\n // After matching input A, we reach the stop state for rule A, state 1.\n // State 8 is the state right before B. Clearly alternatives 1 and 2\n // conflict and no amount of further lookahead will separate the two.\n // However, alternative 3 will be able to continue and so we do not\n // stop working on this state. In the previous example, we're concerned\n // with states associated with the conflicting alternatives. Here alt\n // 3 is not associated with the conflicting configs, but since we can continue\n // looking for input reasonably, I don't declare the state done. We\n // ignore a set of conflicting alts when we have an alternative\n // that we still need to pursue.\n//\n\nParserATNSimulator.prototype.getConflictingAltsOrUniqueAlt = function(configs) {\n    var conflictingAlts = null;\n    if (configs.uniqueAlt!== ATN.INVALID_ALT_NUMBER) {\n        conflictingAlts = new BitSet();\n        conflictingAlts.add(configs.uniqueAlt);\n    } else {\n        conflictingAlts = configs.conflictingAlts;\n    }\n    return conflictingAlts;\n};\n\nParserATNSimulator.prototype.getTokenName = function( t) {\n    if (t===Token.EOF) {\n        return \"EOF\";\n    }\n    if( this.parser!==null && this.parser.literalNames!==null) {\n        if (t >= this.parser.literalNames.length) {\n            console.log(\"\" + t + \" ttype out of range: \" + this.parser.literalNames);\n            console.log(\"\" + this.parser.getInputStream().getTokens());\n        } else {\n            return this.parser.literalNames[t] + \"<\" + t + \">\";\n        }\n    }\n    return \"\" + t;\n};\n\nParserATNSimulator.prototype.getLookaheadName = function(input) {\n    return this.getTokenName(input.LA(1));\n};\n\n// Used for debugging in adaptivePredict around execATN but I cut\n//  it out for clarity now that alg. works well. We can leave this\n//  \"dead\" code for a bit.\n//\nParserATNSimulator.prototype.dumpDeadEndConfigs = function(nvae) {\n    console.log(\"dead end configs: \");\n    var decs = nvae.getDeadEndConfigs();\n    for(var i=0; i<decs.length; i++) {\n    \tvar c = decs[i];\n        var trans = \"no edges\";\n        if (c.state.transitions.length>0) {\n            var t = c.state.transitions[0];\n            if (t instanceof AtomTransition) {\n                trans = \"Atom \"+ this.getTokenName(t.label);\n            } else if (t instanceof SetTransition) {\n                var neg = (t instanceof NotSetTransition);\n                trans = (neg ? \"~\" : \"\") + \"Set \" + t.set;\n            }\n        }\n        console.error(c.toString(this.parser, true) + \":\" + trans);\n    }\n};\n\nParserATNSimulator.prototype.noViableAlt = function(input, outerContext, configs, startIndex) {\n    return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);\n};\n\nParserATNSimulator.prototype.getUniqueAlt = function(configs) {\n    var alt = ATN.INVALID_ALT_NUMBER;\n    for(var i=0;i<configs.items.length;i++) {\n    \tvar c = configs.items[i];\n        if (alt === ATN.INVALID_ALT_NUMBER) {\n            alt = c.alt // found first alt\n        } else if( c.alt!==alt) {\n            return ATN.INVALID_ALT_NUMBER;\n        }\n    }\n    return alt;\n};\n\n//\n// Add an edge to the DFA, if possible. This method calls\n// {@link //addDFAState} to ensure the {@code to} state is present in the\n// DFA. If {@code from} is {@code null}, or if {@code t} is outside the\n// range of edges that can be represented in the DFA tables, this method\n// returns without adding the edge to the DFA.\n//\n// <p>If {@code to} is {@code null}, this method returns {@code null}.\n// Otherwise, this method returns the {@link DFAState} returned by calling\n// {@link //addDFAState} for the {@code to} state.</p>\n//\n// @param dfa The DFA\n// @param from The source state for the edge\n// @param t The input symbol\n// @param to The target state for the edge\n//\n// @return If {@code to} is {@code null}, this method returns {@code null};\n// otherwise this method returns the result of calling {@link //addDFAState}\n// on {@code to}\n//\nParserATNSimulator.prototype.addDFAEdge = function(dfa, from_, t, to) {\n    if( this.debug) {\n        console.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + this.getTokenName(t));\n    }\n    if (to===null) {\n        return null;\n    }\n    to = this.addDFAState(dfa, to); // used existing if possible not incoming\n    if (from_===null || t < -1 || t > this.atn.maxTokenType) {\n        return to;\n    }\n    if (from_.edges===null) {\n        from_.edges = [];\n    }\n    from_.edges[t+1] = to; // connect\n\n    if (this.debug) {\n        var names = this.parser===null ? null : this.parser.literalNames;\n        console.log(\"DFA=\\n\" + dfa.toString(names));\n    }\n    return to;\n};\n//\n// Add state {@code D} to the DFA if it is not already present, and return\n// the actual instance stored in the DFA. If a state equivalent to {@code D}\n// is already in the DFA, the existing state is returned. Otherwise this\n// method returns {@code D} after adding it to the DFA.\n//\n// <p>If {@code D} is {@link //ERROR}, this method returns {@link //ERROR} and\n// does not change the DFA.</p>\n//\n// @param dfa The dfa\n// @param D The DFA state to add\n// @return The state stored in the DFA. This will be either the existing\n// state if {@code D} is already in the DFA, or {@code D} itself if the\n// state was not already present.\n//\nParserATNSimulator.prototype.addDFAState = function(dfa, D) {\n    if (D == ATNSimulator.ERROR) {\n        return D;\n    }\n    var hash = D.hashString();\n    var existing = dfa.states[hash] || null;\n    if(existing!==null) {\n        return existing;\n    }\n    D.stateNumber = dfa.states.length;\n    if (! D.configs.readOnly) {\n        D.configs.optimizeConfigs(this);\n        D.configs.setReadonly(true);\n    }\n    dfa.states[hash] = D;\n    if (this.debug) {\n        console.log(\"adding new DFA state: \" + D);\n    }\n    return D;\n};\n\nParserATNSimulator.prototype.reportAttemptingFullContext = function(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n    if (this.debug || this.retry_debug) {\n        var interval = new Interval(startIndex, stopIndex + 1);\n        console.log(\"reportAttemptingFullContext decision=\" + dfa.decision + \":\" + configs +\n                           \", input=\" + this.parser.getTokenStream().getText(interval));\n    }\n    if (this.parser!==null) {\n        this.parser.getErrorListenerDispatch().reportAttemptingFullContext(this.parser, dfa, startIndex, stopIndex, conflictingAlts, configs);\n    }\n};\n\nParserATNSimulator.prototype.reportContextSensitivity = function(dfa, prediction, configs, startIndex, stopIndex) {\n    if (this.debug || this.retry_debug) {\n        var interval = new Interval(startIndex, stopIndex + 1);\n        console.log(\"reportContextSensitivity decision=\" + dfa.decision + \":\" + configs +\n                           \", input=\" + this.parser.getTokenStream().getText(interval));\n    }\n    if (this.parser!==null) {\n        this.parser.getErrorListenerDispatch().reportContextSensitivity(this.parser, dfa, startIndex, stopIndex, prediction, configs);\n    }\n};\n    \n// If context sensitive parsing, we know it's ambiguity not conflict//\nParserATNSimulator.prototype.reportAmbiguity = function(dfa, D, startIndex, stopIndex,\n                               exact, ambigAlts, configs ) {\n    if (this.debug || this.retry_debug) {\n        var interval = new Interval(startIndex, stopIndex + 1);\n        console.log(\"reportAmbiguity \" + ambigAlts + \":\" + configs +\n                           \", input=\" + this.parser.getTokenStream().getText(interval));\n    }\n    if (this.parser!==null) {\n        this.parser.getErrorListenerDispatch().reportAmbiguity(this.parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);\n    }\n};\n            \nexports.ParserATNSimulator = ParserATNSimulator;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/ParserATNSimulator.js\n ** module id = 34\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n//\n// This enumeration defines the prediction modes available in ANTLR 4 along with\n// utility methods for analyzing configuration sets for conflicts and/or\n// ambiguities.\n\nvar Set = require('./../Utils').Set;\nvar BitSet = require('./../Utils').BitSet;\nvar AltDict = require('./../Utils').AltDict;\nvar ATN = require('./ATN').ATN;\nvar RuleStopState = require('./ATNState').RuleStopState;\nvar ATNConfigSet = require('./ATNConfigSet').ATNConfigSet;\nvar ATNConfig = require('./ATNConfig').ATNConfig;\nvar SemanticContext = require('./SemanticContext').SemanticContext;\n\nfunction PredictionMode() {\n\treturn this;\n}\n\n//\n// The SLL(*) prediction mode. This prediction mode ignores the current\n// parser context when making predictions. This is the fastest prediction\n// mode, and provides correct results for many grammars. This prediction\n// mode is more powerful than the prediction mode provided by ANTLR 3, but\n// may result in syntax errors for grammar and input combinations which are\n// not SLL.\n//\n// <p>\n// When using this prediction mode, the parser will either return a correct\n// parse tree (i.e. the same parse tree that would be returned with the\n// {@link //LL} prediction mode), or it will report a syntax error. If a\n// syntax error is encountered when using the {@link //SLL} prediction mode,\n// it may be due to either an actual syntax error in the input or indicate\n// that the particular combination of grammar and input requires the more\n// powerful {@link //LL} prediction abilities to complete successfully.</p>\n//\n// <p>\n// This prediction mode does not provide any guarantees for prediction\n// behavior for syntactically-incorrect inputs.</p>\n//\nPredictionMode.SLL = 0;\n//\n// The LL(*) prediction mode. This prediction mode allows the current parser\n// context to be used for resolving SLL conflicts that occur during\n// prediction. This is the fastest prediction mode that guarantees correct\n// parse results for all combinations of grammars with syntactically correct\n// inputs.\n//\n// <p>\n// When using this prediction mode, the parser will make correct decisions\n// for all syntactically-correct grammar and input combinations. However, in\n// cases where the grammar is truly ambiguous this prediction mode might not\n// report a precise answer for <em>exactly which</em> alternatives are\n// ambiguous.</p>\n//\n// <p>\n// This prediction mode does not provide any guarantees for prediction\n// behavior for syntactically-incorrect inputs.</p>\n//\nPredictionMode.LL = 1;\n//\n// The LL(*) prediction mode with exact ambiguity detection. In addition to\n// the correctness guarantees provided by the {@link //LL} prediction mode,\n// this prediction mode instructs the prediction algorithm to determine the\n// complete and exact set of ambiguous alternatives for every ambiguous\n// decision encountered while parsing.\n//\n// <p>\n// This prediction mode may be used for diagnosing ambiguities during\n// grammar development. Due to the performance overhead of calculating sets\n// of ambiguous alternatives, this prediction mode should be avoided when\n// the exact results are not necessary.</p>\n//\n// <p>\n// This prediction mode does not provide any guarantees for prediction\n// behavior for syntactically-incorrect inputs.</p>\n//\nPredictionMode.LL_EXACT_AMBIG_DETECTION = 2;\n\n\n//\n// Computes the SLL prediction termination condition.\n//\n// <p>\n// This method computes the SLL prediction termination condition for both of\n// the following cases.</p>\n//\n// <ul>\n// <li>The usual SLL+LL fallback upon SLL conflict</li>\n// <li>Pure SLL without LL fallback</li>\n// </ul>\n//\n// <p><strong>COMBINED SLL+LL PARSING</strong></p>\n//\n// <p>When LL-fallback is enabled upon SLL conflict, correct predictions are\n// ensured regardless of how the termination condition is computed by this\n// method. Due to the substantially higher cost of LL prediction, the\n// prediction should only fall back to LL when the additional lookahead\n// cannot lead to a unique SLL prediction.</p>\n//\n// <p>Assuming combined SLL+LL parsing, an SLL configuration set with only\n// conflicting subsets should fall back to full LL, even if the\n// configuration sets don't resolve to the same alternative (e.g.\n// {@code {1,2}} and {@code {3,4}}. If there is at least one non-conflicting\n// configuration, SLL could continue with the hopes that more lookahead will\n// resolve via one of those non-conflicting configurations.</p>\n//\n// <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing)\n// stops when it sees only conflicting configuration subsets. In contrast,\n// full LL keeps going when there is uncertainty.</p>\n//\n// <p><strong>HEURISTIC</strong></p>\n//\n// <p>As a heuristic, we stop prediction when we see any conflicting subset\n// unless we see a state that only has one alternative associated with it.\n// The single-alt-state thing lets prediction continue upon rules like\n// (otherwise, it would admit defeat too soon):</p>\n//\n// <p>{@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}</p>\n//\n// <p>When the ATN simulation reaches the state before {@code ';'}, it has a\n// DFA state that looks like: {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally\n// {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stop\n// processing this node because alternative to has another way to continue,\n// via {@code [6|2|[]]}.</p>\n//\n// <p>It also let's us continue for this rule:</p>\n//\n// <p>{@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}</p>\n//\n// <p>After matching input A, we reach the stop state for rule A, state 1.\n// State 8 is the state right before B. Clearly alternatives 1 and 2\n// conflict and no amount of further lookahead will separate the two.\n// However, alternative 3 will be able to continue and so we do not stop\n// working on this state. In the previous example, we're concerned with\n// states associated with the conflicting alternatives. Here alt 3 is not\n// associated with the conflicting configs, but since we can continue\n// looking for input reasonably, don't declare the state done.</p>\n//\n// <p><strong>PURE SLL PARSING</strong></p>\n//\n// <p>To handle pure SLL parsing, all we have to do is make sure that we\n// combine stack contexts for configurations that differ only by semantic\n// predicate. From there, we can do the usual SLL termination heuristic.</p>\n//\n// <p><strong>PREDICATES IN SLL+LL PARSING</strong></p>\n//\n// <p>SLL decisions don't evaluate predicates until after they reach DFA stop\n// states because they need to create the DFA cache that works in all\n// semantic situations. In contrast, full LL evaluates predicates collected\n// during start state computation so it can ignore predicates thereafter.\n// This means that SLL termination detection can totally ignore semantic\n// predicates.</p>\n//\n// <p>Implementation-wise, {@link ATNConfigSet} combines stack contexts but not\n// semantic predicate contexts so we might see two configurations like the\n// following.</p>\n//\n// <p>{@code (s, 1, x, {}), (s, 1, x', {p})}</p>\n//\n// <p>Before testing these configurations against others, we have to merge\n// {@code x} and {@code x'} (without modifying the existing configurations).\n// For example, we test {@code (x+x')==x''} when looking for conflicts in\n// the following configurations.</p>\n//\n// <p>{@code (s, 1, x, {}), (s, 1, x', {p}), (s, 2, x'', {})}</p>\n//\n// <p>If the configuration set has predicates (as indicated by\n// {@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of\n// the configurations to strip out all of the predicates so that a standard\n// {@link ATNConfigSet} will merge everything ignoring predicates.</p>\n//\nPredictionMode.hasSLLConflictTerminatingPrediction = function( mode, configs) {\n    // Configs in rule stop states indicate reaching the end of the decision\n    // rule (local context) or end of start rule (full context). If all\n    // configs meet this condition, then none of the configurations is able\n    // to match additional input so we terminate prediction.\n    //\n    if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n        return true;\n    }\n    // pure SLL mode parsing\n    if (mode === PredictionMode.SLL) {\n        // Don't bother with combining configs from different semantic\n        // contexts if we can fail over to full LL; costs more time\n        // since we'll often fail over anyway.\n        if (configs.hasSemanticContext) {\n            // dup configs, tossing out semantic predicates\n            var dup = new ATNConfigSet();\n            for(var i=0;i<configs.items.length;i++) {\n            \tvar c = configs.items[i];\n                c = new ATNConfig({semanticContext:SemanticContext.NONE}, c);\n                dup.add(c);\n            }\n            configs = dup;\n        }\n        // now we have combined contexts for configs with dissimilar preds\n    }\n    // pure SLL or combined SLL+LL mode parsing\n    var altsets = PredictionMode.getConflictingAltSubsets(configs);\n    return PredictionMode.hasConflictingAltSet(altsets) && !PredictionMode.hasStateAssociatedWithOneAlt(configs);\n};\n\n// Checks if any configuration in {@code configs} is in a\n// {@link RuleStopState}. Configurations meeting this condition have reached\n// the end of the decision rule (local context) or end of start rule (full\n// context).\n//\n// @param configs the configuration set to test\n// @return {@code true} if any configuration in {@code configs} is in a\n// {@link RuleStopState}, otherwise {@code false}\nPredictionMode.hasConfigInRuleStopState = function(configs) {\n\tfor(var i=0;i<configs.items.length;i++) {\n\t\tvar c = configs.items[i];\n        if (c.state instanceof RuleStopState) {\n            return true;\n        }\n\t}\n    return false;\n};\n\n// Checks if all configurations in {@code configs} are in a\n// {@link RuleStopState}. Configurations meeting this condition have reached\n// the end of the decision rule (local context) or end of start rule (full\n// context).\n//\n// @param configs the configuration set to test\n// @return {@code true} if all configurations in {@code configs} are in a\n// {@link RuleStopState}, otherwise {@code false}\nPredictionMode.allConfigsInRuleStopStates = function(configs) {\n\tfor(var i=0;i<configs.items.length;i++) {\n\t\tvar c = configs.items[i];\n        if (!(c.state instanceof RuleStopState)) {\n            return false;\n        }\n\t}\n    return true;\n};\n\n//\n// Full LL prediction termination.\n//\n// <p>Can we stop looking ahead during ATN simulation or is there some\n// uncertainty as to which alternative we will ultimately pick, after\n// consuming more input? Even if there are partial conflicts, we might know\n// that everything is going to resolve to the same minimum alternative. That\n// means we can stop since no more lookahead will change that fact. On the\n// other hand, there might be multiple conflicts that resolve to different\n// minimums. That means we need more look ahead to decide which of those\n// alternatives we should predict.</p>\n//\n// <p>The basic idea is to split the set of configurations {@code C}, into\n// conflicting subsets {@code (s, _, ctx, _)} and singleton subsets with\n// non-conflicting configurations. Two configurations conflict if they have\n// identical {@link ATNConfig//state} and {@link ATNConfig//context} values\n// but different {@link ATNConfig//alt} value, e.g. {@code (s, i, ctx, _)}\n// and {@code (s, j, ctx, _)} for {@code i!=j}.</p>\n//\n// <p>Reduce these configuration subsets to the set of possible alternatives.\n// You can compute the alternative subsets in one pass as follows:</p>\n//\n// <p>{@code A_s,ctx = {i | (s, i, ctx, _)}} for each configuration in\n// {@code C} holding {@code s} and {@code ctx} fixed.</p>\n//\n// <p>Or in pseudo-code, for each configuration {@code c} in {@code C}:</p>\n//\n// <pre>\n// map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n// alt and not pred\n// </pre>\n//\n// <p>The values in {@code map} are the set of {@code A_s,ctx} sets.</p>\n//\n// <p>If {@code |A_s,ctx|=1} then there is no conflict associated with\n// {@code s} and {@code ctx}.</p>\n//\n// <p>Reduce the subsets to singletons by choosing a minimum of each subset. If\n// the union of these alternative subsets is a singleton, then no amount of\n// more lookahead will help us. We will always pick that alternative. If,\n// however, there is more than one alternative, then we are uncertain which\n// alternative to predict and must continue looking for resolution. We may\n// or may not discover an ambiguity in the future, even if there are no\n// conflicting subsets this round.</p>\n//\n// <p>The biggest sin is to terminate early because it means we've made a\n// decision but were uncertain as to the eventual outcome. We haven't used\n// enough lookahead. On the other hand, announcing a conflict too late is no\n// big deal; you will still have the conflict. It's just inefficient. It\n// might even look until the end of file.</p>\n//\n// <p>No special consideration for semantic predicates is required because\n// predicates are evaluated on-the-fly for full LL prediction, ensuring that\n// no configuration contains a semantic context during the termination\n// check.</p>\n//\n// <p><strong>CONFLICTING CONFIGS</strong></p>\n//\n// <p>Two configurations {@code (s, i, x)} and {@code (s, j, x')}, conflict\n// when {@code i!=j} but {@code x=x'}. Because we merge all\n// {@code (s, i, _)} configurations together, that means that there are at\n// most {@code n} configurations associated with state {@code s} for\n// {@code n} possible alternatives in the decision. The merged stacks\n// complicate the comparison of configuration contexts {@code x} and\n// {@code x'}. Sam checks to see if one is a subset of the other by calling\n// merge and checking to see if the merged result is either {@code x} or\n// {@code x'}. If the {@code x} associated with lowest alternative {@code i}\n// is the superset, then {@code i} is the only possible prediction since the\n// others resolve to {@code min(i)} as well. However, if {@code x} is\n// associated with {@code j>i} then at least one stack configuration for\n// {@code j} is not in conflict with alternative {@code i}. The algorithm\n// should keep going, looking for more lookahead due to the uncertainty.</p>\n//\n// <p>For simplicity, I'm doing a equality check between {@code x} and\n// {@code x'} that lets the algorithm continue to consume lookahead longer\n// than necessary. The reason I like the equality is of course the\n// simplicity but also because that is the test you need to detect the\n// alternatives that are actually in conflict.</p>\n//\n// <p><strong>CONTINUE/STOP RULE</strong></p>\n//\n// <p>Continue if union of resolved alternative sets from non-conflicting and\n// conflicting alternative subsets has more than one alternative. We are\n// uncertain about which alternative to predict.</p>\n//\n// <p>The complete set of alternatives, {@code [i for (_,i,_)]}, tells us which\n// alternatives are still in the running for the amount of input we've\n// consumed at this point. The conflicting sets let us to strip away\n// configurations that won't lead to more states because we resolve\n// conflicts to the configuration with a minimum alternate for the\n// conflicting set.</p>\n//\n// <p><strong>CASES</strong></p>\n//\n// <ul>\n//\n// <li>no conflicts and more than 1 alternative in set =&gt; continue</li>\n//\n// <li> {@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s, 3, z)},\n// {@code (s', 1, y)}, {@code (s', 2, y)} yields non-conflicting set\n// {@code {3}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n// {@code {1,3}} =&gt; continue\n// </li>\n//\n// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n// {@code (s', 2, y)}, {@code (s'', 1, z)} yields non-conflicting set\n// {@code {1}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n// {@code {1}} =&gt; stop and predict 1</li>\n//\n// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n// {@code (s', 2, y)} yields conflicting, reduced sets {@code {1}} U\n// {@code {1}} = {@code {1}} =&gt; stop and predict 1, can announce\n// ambiguity {@code {1,2}}</li>\n//\n// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 2, y)},\n// {@code (s', 3, y)} yields conflicting, reduced sets {@code {1}} U\n// {@code {2}} = {@code {1,2}} =&gt; continue</li>\n//\n// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 3, y)},\n// {@code (s', 4, y)} yields conflicting, reduced sets {@code {1}} U\n// {@code {3}} = {@code {1,3}} =&gt; continue</li>\n//\n// </ul>\n//\n// <p><strong>EXACT AMBIGUITY DETECTION</strong></p>\n//\n// <p>If all states report the same conflicting set of alternatives, then we\n// know we have the exact ambiguity set.</p>\n//\n// <p><code>|A_<em>i</em>|&gt;1</code> and\n// <code>A_<em>i</em> = A_<em>j</em></code> for all <em>i</em>, <em>j</em>.</p>\n//\n// <p>In other words, we continue examining lookahead until all {@code A_i}\n// have more than one alternative and all {@code A_i} are the same. If\n// {@code A={{1,2}, {1,3}}}, then regular LL prediction would terminate\n// because the resolved set is {@code {1}}. To determine what the real\n// ambiguity is, we have to know whether the ambiguity is between one and\n// two or one and three so we keep going. We can only stop prediction when\n// we need exact ambiguity detection when the sets look like\n// {@code A={{1,2}}} or {@code {{1,2},{1,2}}}, etc...</p>\n//\nPredictionMode.resolvesToJustOneViableAlt = function(altsets) {\n    return PredictionMode.getSingleViableAlt(altsets);\n};\n\n//\n// Determines if every alternative subset in {@code altsets} contains more\n// than one alternative.\n//\n// @param altsets a collection of alternative subsets\n// @return {@code true} if every {@link BitSet} in {@code altsets} has\n// {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n//\nPredictionMode.allSubsetsConflict = function(altsets) {\n    return ! PredictionMode.hasNonConflictingAltSet(altsets);\n};\n//\n// Determines if any single alternative subset in {@code altsets} contains\n// exactly one alternative.\n//\n// @param altsets a collection of alternative subsets\n// @return {@code true} if {@code altsets} contains a {@link BitSet} with\n// {@link BitSet//cardinality cardinality} 1, otherwise {@code false}\n//\nPredictionMode.hasNonConflictingAltSet = function(altsets) {\n\tfor(var i=0;i<altsets.length;i++) {\n\t\tvar alts = altsets[i];\n        if (alts.length===1) {\n            return true;\n        }\n\t}\n    return false;\n};\n\n//\n// Determines if any single alternative subset in {@code altsets} contains\n// more than one alternative.\n//\n// @param altsets a collection of alternative subsets\n// @return {@code true} if {@code altsets} contains a {@link BitSet} with\n// {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n//\nPredictionMode.hasConflictingAltSet = function(altsets) {\n\tfor(var i=0;i<altsets.length;i++) {\n\t\tvar alts = altsets[i];\n        if (alts.length>1) {\n            return true;\n        }\n\t}\n    return false;\n};\n\n//\n// Determines if every alternative subset in {@code altsets} is equivalent.\n//\n// @param altsets a collection of alternative subsets\n// @return {@code true} if every member of {@code altsets} is equal to the\n// others, otherwise {@code false}\n//\nPredictionMode.allSubsetsEqual = function(altsets) {\n    var first = null;\n\tfor(var i=0;i<altsets.length;i++) {\n\t\tvar alts = altsets[i];\n        if (first === null) {\n            first = alts;\n        } else if (alts!==first) {\n            return false;\n        }\n\t}\n    return true;\n};\n\n//\n// Returns the unique alternative predicted by all alternative subsets in\n// {@code altsets}. If no such alternative exists, this method returns\n// {@link ATN//INVALID_ALT_NUMBER}.\n//\n// @param altsets a collection of alternative subsets\n//\nPredictionMode.getUniqueAlt = function(altsets) {\n    var all = PredictionMode.getAlts(altsets);\n    if (all.length===1) {\n        return all.minValue();\n    } else {\n        return ATN.INVALID_ALT_NUMBER;\n    }\n};\n\n// Gets the complete set of represented alternatives for a collection of\n// alternative subsets. This method returns the union of each {@link BitSet}\n// in {@code altsets}.\n//\n// @param altsets a collection of alternative subsets\n// @return the set of represented alternatives in {@code altsets}\n//\nPredictionMode.getAlts = function(altsets) {\n    var all = new BitSet();\n    altsets.map( function(alts) { all.or(alts); });\n    return all;\n};\n\n//\n// This function gets the conflicting alt subsets from a configuration set.\n// For each configuration {@code c} in {@code configs}:\n//\n// <pre>\n// map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n// alt and not pred\n// </pre>\n//\nPredictionMode.getConflictingAltSubsets = function(configs) {\n    var configToAlts = {};\n\tfor(var i=0;i<configs.items.length;i++) {\n\t\tvar c = configs.items[i];\n        var key = \"key_\" + c.state.stateNumber + \"/\" + c.context;\n        var alts = configToAlts[key] || null;\n        if (alts === null) {\n            alts = new BitSet();\n            configToAlts[key] = alts;\n        }\n        alts.add(c.alt);\n\t}\n\tvar values = [];\n\tfor(var k in configToAlts) {\n\t\tif(k.indexOf(\"key_\")!==0) {\n\t\t\tcontinue;\n\t\t}\n\t\tvalues.push(configToAlts[k]);\n\t}\n    return values;\n};\n\n//\n// Get a map from state to alt subset from a configuration set. For each\n// configuration {@code c} in {@code configs}:\n//\n// <pre>\n// map[c.{@link ATNConfig//state state}] U= c.{@link ATNConfig//alt alt}\n// </pre>\n//\nPredictionMode.getStateToAltMap = function(configs) {\n    var m = new AltDict();\n    configs.items.map(function(c) {\n        var alts = m.get(c.state);\n        if (alts === null) {\n            alts = new BitSet();\n            m.put(c.state, alts);\n        }\n        alts.add(c.alt);\n    });\n    return m;\n};\n\nPredictionMode.hasStateAssociatedWithOneAlt = function(configs) {\n    var values = PredictionMode.getStateToAltMap(configs).values();\n    for(var i=0;i<values.length;i++) {\n        if (values[i].length===1) {\n            return true;\n        }\n    }\n    return false;\n};\n\nPredictionMode.getSingleViableAlt = function(altsets) {\n    var result = null;\n\tfor(var i=0;i<altsets.length;i++) {\n\t\tvar alts = altsets[i];\n        var minAlt = alts.minValue();\n        if(result===null) {\n            result = minAlt;\n        } else if(result!==minAlt) { // more than 1 viable alt\n            return ATN.INVALID_ALT_NUMBER;\n        }\n\t}\n    return result;\n};\n\nexports.PredictionMode = PredictionMode;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/atn/PredictionMode.js\n ** module id = 35\n ** module chunks = 0\n **/","exports.DFA = require('./DFA').DFA;\nexports.DFASerializer = require('./DFASerializer').DFASerializer;\nexports.LexerDFASerializer = require('./DFASerializer').LexerDFASerializer;\nexports.PredPrediction = require('./DFAState').PredPrediction;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/dfa/index.js\n ** module id = 36\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nvar DFAState = require('./DFAState').DFAState;\nvar ATNConfigSet = require('./../atn/ATNConfigSet').ATNConfigSet;\nvar DFASerializer = require('./DFASerializer').DFASerializer;\nvar LexerDFASerializer = require('./DFASerializer').LexerDFASerializer;\n\nfunction DFAStatesSet() {\n\treturn this;\n}\n\nObject.defineProperty(DFAStatesSet.prototype, \"length\", {\n\tget : function() {\n\t\treturn Object.keys(this).length;\n\t}\n});\n\nfunction DFA(atnStartState, decision) {\n\tif (decision === undefined) {\n\t\tdecision = 0;\n\t}\n\t// From which ATN state did we create this DFA?\n\tthis.atnStartState = atnStartState;\n\tthis.decision = decision;\n\t// A set of all DFA states. Use {@link Map} so we can get old state back\n\t// ({@link Set} only allows you to see if it's there).\n\tthis._states = new DFAStatesSet();\n\tthis.s0 = null;\n\t// {@code true} if this DFA is for a precedence decision; otherwise,\n\t// {@code false}. This is the backing field for {@link //isPrecedenceDfa},\n\t// {@link //setPrecedenceDfa}.\n\tthis.precedenceDfa = false;\n\treturn this;\n}\n\n// Get the start state for a specific precedence value.\n//\n// @param precedence The current precedence.\n// @return The start state corresponding to the specified precedence, or\n// {@code null} if no start state exists for the specified precedence.\n//\n// @throws IllegalStateException if this is not a precedence DFA.\n// @see //isPrecedenceDfa()\n\nDFA.prototype.getPrecedenceStartState = function(precedence) {\n\tif (!(this.precedenceDfa)) {\n\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t}\n\t// s0.edges is never null for a precedence DFA\n\tif (precedence < 0 || precedence >= this.s0.edges.length) {\n\t\treturn null;\n\t}\n\treturn this.s0.edges[precedence] || null;\n};\n\n// Set the start state for a specific precedence value.\n//\n// @param precedence The current precedence.\n// @param startState The start state corresponding to the specified\n// precedence.\n//\n// @throws IllegalStateException if this is not a precedence DFA.\n// @see //isPrecedenceDfa()\n//\nDFA.prototype.setPrecedenceStartState = function(precedence, startState) {\n\tif (!(this.precedenceDfa)) {\n\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t}\n\tif (precedence < 0) {\n\t\treturn;\n\t}\n\n\t// synchronization on s0 here is ok. when the DFA is turned into a\n\t// precedence DFA, s0 will be initialized once and not updated again\n\t// s0.edges is never null for a precedence DFA\n\tthis.s0.edges[precedence] = startState;\n};\n\n//\n// Sets whether this is a precedence DFA. If the specified value differs\n// from the current DFA configuration, the following actions are taken;\n// otherwise no changes are made to the current DFA.\n//\n// <ul>\n// <li>The {@link //states} map is cleared</li>\n// <li>If {@code precedenceDfa} is {@code false}, the initial state\n// {@link //s0} is set to {@code null}; otherwise, it is initialized to a new\n// {@link DFAState} with an empty outgoing {@link DFAState//edges} array to\n// store the start states for individual precedence values.</li>\n// <li>The {@link //precedenceDfa} field is updated</li>\n// </ul>\n//\n// @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,\n// {@code false}\n\nDFA.prototype.setPrecedenceDfa = function(precedenceDfa) {\n\tif (this.precedenceDfa!==precedenceDfa) {\n\t\tthis._states = new DFAStatesSet();\n\t\tif (precedenceDfa) {\n\t\t\tvar precedenceState = new DFAState(new ATNConfigSet());\n\t\t\tprecedenceState.edges = [];\n\t\t\tprecedenceState.isAcceptState = false;\n\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\tthis.s0 = precedenceState;\n\t\t} else {\n\t\t\tthis.s0 = null;\n\t\t}\n\t\tthis.precedenceDfa = precedenceDfa;\n\t}\n};\n\nObject.defineProperty(DFA.prototype, \"states\", {\n\tget : function() {\n\t\treturn this._states;\n\t}\n});\n\n// Return a list of all states in this DFA, ordered by state number.\nDFA.prototype.sortedStates = function() {\n\t// states_ is a map of state/state, where key=value\n\tvar keys = Object.keys(this._states);\n\tvar list = [];\n\tfor(var i=0;i<keys.length;i++) {\n\t\tlist.push(this._states[keys[i]]);\n\t}\n\treturn list.sort(function(a, b) {\n\t\treturn a.stateNumber - b.stateNumber;\n\t});\n};\n\nDFA.prototype.toString = function(literalNames, symbolicNames) {\n\tliteralNames = literalNames || null;\n\tsymbolicNames = symbolicNames || null;\n\tif (this.s0 === null) {\n\t\treturn \"\";\n\t}\n\tvar serializer = new DFASerializer(this, literalNames, symbolicNames);\n\treturn serializer.toString();\n};\n\nDFA.prototype.toLexerString = function() {\n\tif (this.s0 === null) {\n\t\treturn \"\";\n\t}\n\tvar serializer = new LexerDFASerializer(this);\n\treturn serializer.toString();\n};\n\nexports.DFA = DFA;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/dfa/DFA.js\n ** module id = 37\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n// A DFA walker that knows how to dump them to serialized strings.#/\n\n\nfunction DFASerializer(dfa, literalNames, symbolicNames) {\n\tthis.dfa = dfa;\n\tthis.literalNames = literalNames || [];\n\tthis.symbolicNames = symbolicNames || [];\n\treturn this;\n}\n\nDFASerializer.prototype.toString = function() {\n   if(this.dfa.s0 === null) {\n       return null;\n   }\n   var buf = \"\";\n   var states = this.dfa.sortedStates();\n   for(var i=0;i<states.length;i++) {\n       var s = states[i];\n       if(s.edges!==null) {\n            var n = s.edges.length;\n            for(var j=0;j<n;j++) {\n                var t = s.edges[j] || null;\n                if(t!==null && t.stateNumber !== 0x7FFFFFFF) {\n                    buf = buf.concat(this.getStateString(s));\n                    buf = buf.concat(\"-\");\n                    buf = buf.concat(this.getEdgeLabel(j));\n                    buf = buf.concat(\"->\");\n                    buf = buf.concat(this.getStateString(t));\n                    buf = buf.concat('\\n');\n                }\n            }\n       }\n   }\n   return buf.length===0 ? null : buf;\n};\n\nDFASerializer.prototype.getEdgeLabel = function(i) {\n    if (i===0) {\n        return \"EOF\";\n    } else if(this.literalNames !==null || this.symbolicNames!==null) {\n        return this.literalNames[i-1] || this.symbolicNames[i-1];\n    } else {\n        return String.fromCharCode(i-1);\n    }\n};\n\nDFASerializer.prototype.getStateString = function(s) {\n    var baseStateStr = ( s.isAcceptState ? \":\" : \"\") + \"s\" + s.stateNumber + ( s.requiresFullContext ? \"^\" : \"\");\n    if(s.isAcceptState) {\n        if (s.predicates !== null) {\n            return baseStateStr + \"=>\" + s.predicates.toString();\n        } else {\n            return baseStateStr + \"=>\" + s.prediction.toString();\n        }\n    } else {\n        return baseStateStr;\n    }\n};\n\nfunction LexerDFASerializer(dfa) {\n\tDFASerializer.call(this, dfa, null);\n\treturn this;\n}\n\nLexerDFASerializer.prototype = Object.create(DFASerializer.prototype);\nLexerDFASerializer.prototype.constructor = LexerDFASerializer;\n\nLexerDFASerializer.prototype.getEdgeLabel = function(i) {\n\treturn \"'\" + String.fromCharCode(i) + \"'\";\n};\n\nexports.DFASerializer = DFASerializer;\nexports.LexerDFASerializer = LexerDFASerializer;\n\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/dfa/DFASerializer.js\n ** module id = 38\n ** module chunks = 0\n **/","var Tree = require('./Tree');\nexports.Trees = require('./Trees').Trees;\nexports.RuleNode = Tree.RuleNode;\nexports.ParseTreeListener = Tree.ParseTreeListener;\nexports.ParseTreeVisitor = Tree.ParseTreeVisitor;\nexports.ParseTreeWalker = Tree.ParseTreeWalker;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/tree/index.js\n ** module id = 39\n ** module chunks = 0\n **/","exports.RecognitionException = require('./Errors').RecognitionException;\nexports.NoViableAltException = require('./Errors').NoViableAltException;\nexports.LexerNoViableAltException = require('./Errors').LexerNoViableAltException;\nexports.InputMismatchException = require('./Errors').InputMismatchException;\nexports.FailedPredicateException = require('./Errors').FailedPredicateException;\nexports.DiagnosticErrorListener = require('./DiagnosticErrorListener').DiagnosticErrorListener;\nexports.BailErrorStrategy = require('./ErrorStrategy').BailErrorStrategy;\nexports.ErrorListener = require('./ErrorListener').ErrorListener;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/error/index.js\n ** module id = 40\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n\n//\n// This implementation of {@link ANTLRErrorListener} can be used to identify\n// certain potential correctness and performance problems in grammars. \"Reports\"\n// are made by calling {@link Parser//notifyErrorListeners} with the appropriate\n// message.\n//\n// <ul>\n// <li><b>Ambiguities</b>: These are cases where more than one path through the\n// grammar can match the input.</li>\n// <li><b>Weak context sensitivity</b>: These are cases where full-context\n// prediction resolved an SLL conflict to a unique alternative which equaled the\n// minimum alternative of the SLL conflict.</li>\n// <li><b>Strong (forced) context sensitivity</b>: These are cases where the\n// full-context prediction resolved an SLL conflict to a unique alternative,\n// <em>and</em> the minimum alternative of the SLL conflict was found to not be\n// a truly viable alternative. Two-stage parsing cannot be used for inputs where\n// this situation occurs.</li>\n// </ul>\n\nvar BitSet = require('./../Utils').BitSet;\nvar ErrorListener = require('./ErrorListener').ErrorListener;\nvar Interval = require('./../IntervalSet').Interval;\n\nfunction DiagnosticErrorListener(exactOnly) {\n\tErrorListener.call(this);\n\texactOnly = exactOnly || true;\n\t// whether all ambiguities or only exact ambiguities are reported.\n\tthis.exactOnly = exactOnly;\n\treturn this;\n}\n\nDiagnosticErrorListener.prototype = Object.create(ErrorListener.prototype);\nDiagnosticErrorListener.prototype.constructor = DiagnosticErrorListener;\n\nDiagnosticErrorListener.prototype.reportAmbiguity = function(recognizer, dfa,\n\t\tstartIndex, stopIndex, exact, ambigAlts, configs) {\n\tif (this.exactOnly && !exact) {\n\t\treturn;\n\t}\n\tvar msg = \"reportAmbiguity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\": ambigAlts=\" +\n\t\t\tthis.getConflictingAlts(ambigAlts, configs) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\";\n\trecognizer.notifyErrorListeners(msg);\n};\n\nDiagnosticErrorListener.prototype.reportAttemptingFullContext = function(\n\t\trecognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\tvar msg = \"reportAttemptingFullContext d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\";\n\trecognizer.notifyErrorListeners(msg);\n};\n\nDiagnosticErrorListener.prototype.reportContextSensitivity = function(\n\t\trecognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\tvar msg = \"reportContextSensitivity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\";\n\trecognizer.notifyErrorListeners(msg);\n};\n\nDiagnosticErrorListener.prototype.getDecisionDescription = function(recognizer, dfa) {\n\tvar decision = dfa.decision;\n\tvar ruleIndex = dfa.atnStartState.ruleIndex;\n\n\tvar ruleNames = recognizer.ruleNames;\n\tif (ruleIndex < 0 || ruleIndex >= ruleNames.length) {\n\t\treturn \"\" + decision;\n\t}\n\tvar ruleName = ruleNames[ruleIndex] || null;\n\tif (ruleName === null || ruleName.length === 0) {\n\t\treturn \"\" + decision;\n\t}\n\treturn \"\" + decision + \" (\" + ruleName + \")\";\n};\n\n//\n// Computes the set of conflicting or ambiguous alternatives from a\n// configuration set, if that information was not already provided by the\n// parser.\n//\n// @param reportedAlts The set of conflicting or ambiguous alternatives, as\n// reported by the parser.\n// @param configs The conflicting or ambiguous configuration set.\n// @return Returns {@code reportedAlts} if it is not {@code null}, otherwise\n// returns the set of alternatives represented in {@code configs}.\n//\nDiagnosticErrorListener.prototype.getConflictingAlts = function(reportedAlts, configs) {\n\tif (reportedAlts !== null) {\n\t\treturn reportedAlts;\n\t}\n\tvar result = new BitSet();\n\tfor (var i = 0; i < configs.items.length; i++) {\n\t\tresult.add(configs.items[i].alt);\n\t}\n\treturn \"{\" + result.values().join(\", \") + \"}\";\n};\n\nexports.DiagnosticErrorListener = DiagnosticErrorListener;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/error/DiagnosticErrorListener.js\n ** module id = 41\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n\nvar Token = require('./../Token').Token;\nvar Errors = require('./Errors');\nvar NoViableAltException = Errors.NoViableAltException;\nvar InputMismatchException = Errors.InputMismatchException;\nvar FailedPredicateException = Errors.FailedPredicateException;\nvar ParseCancellationException = Errors.ParseCancellationException;\nvar ATNState = require('./../atn/ATNState').ATNState;\nvar Interval = require('./../IntervalSet').Interval;\nvar IntervalSet = require('./../IntervalSet').IntervalSet;\n\nfunction ErrorStrategy() {\n\t\n}\n\nErrorStrategy.prototype.reset = function(recognizer){\n};\n\nErrorStrategy.prototype.recoverInline = function(recognizer){\n};\n\nErrorStrategy.prototype.recover = function(recognizer, e){\n};\n\nErrorStrategy.prototype.sync = function(recognizer){\n};\n\nErrorStrategy.prototype.inErrorRecoveryMode = function(recognizer){\n};\n\nErrorStrategy.prototype.reportError = function(recognizer){\n};\n\n\n\n// This is the default implementation of {@link ANTLRErrorStrategy} used for\n// error reporting and recovery in ANTLR parsers.\n//\nfunction DefaultErrorStrategy() {\n\tErrorStrategy.call(this);\n    // Indicates whether the error strategy is currently \"recovering from an\n    // error\". This is used to suppress reporting multiple error messages while\n    // attempting to recover from a detected syntax error.\n    //\n    // @see //inErrorRecoveryMode\n    //\n    this.errorRecoveryMode = false;\n\n    // The index into the input stream where the last error occurred.\n    // This is used to prevent infinite loops where an error is found\n    // but no token is consumed during recovery...another error is found,\n    // ad nauseum. This is a failsafe mechanism to guarantee that at least\n    // one token/tree node is consumed for two errors.\n    //\n    this.lastErrorIndex = -1;\n    this.lastErrorStates = null;\n    return this;\n}\n\nDefaultErrorStrategy.prototype = Object.create(ErrorStrategy.prototype);\nDefaultErrorStrategy.prototype.constructor = DefaultErrorStrategy;\n\n// <p>The default implementation simply calls {@link //endErrorCondition} to\n// ensure that the handler is not in error recovery mode.</p>\nDefaultErrorStrategy.prototype.reset = function(recognizer) {\n    this.endErrorCondition(recognizer);\n};\n\n//\n// This method is called to enter error recovery mode when a recognition\n// exception is reported.\n//\n// @param recognizer the parser instance\n//\nDefaultErrorStrategy.prototype.beginErrorCondition = function(recognizer) {\n    this.errorRecoveryMode = true;\n};\n\nDefaultErrorStrategy.prototype.inErrorRecoveryMode = function(recognizer) {\n    return this.errorRecoveryMode;\n};\n\n//\n// This method is called to leave error recovery mode after recovering from\n// a recognition exception.\n//\n// @param recognizer\n//\nDefaultErrorStrategy.prototype.endErrorCondition = function(recognizer) {\n    this.errorRecoveryMode = false;\n    this.lastErrorStates = null;\n    this.lastErrorIndex = -1;\n};\n\n//\n// {@inheritDoc}\n//\n// <p>The default implementation simply calls {@link //endErrorCondition}.</p>\n//\nDefaultErrorStrategy.prototype.reportMatch = function(recognizer) {\n    this.endErrorCondition(recognizer);\n};\n\n//\n// {@inheritDoc}\n//\n// <p>The default implementation returns immediately if the handler is already\n// in error recovery mode. Otherwise, it calls {@link //beginErrorCondition}\n// and dispatches the reporting task based on the runtime type of {@code e}\n// according to the following table.</p>\n//\n// <ul>\n// <li>{@link NoViableAltException}: Dispatches the call to\n// {@link //reportNoViableAlternative}</li>\n// <li>{@link InputMismatchException}: Dispatches the call to\n// {@link //reportInputMismatch}</li>\n// <li>{@link FailedPredicateException}: Dispatches the call to\n// {@link //reportFailedPredicate}</li>\n// <li>All other types: calls {@link Parser//notifyErrorListeners} to report\n// the exception</li>\n// </ul>\n//\nDefaultErrorStrategy.prototype.reportError = function(recognizer, e) {\n   // if we've already reported an error and have not matched a token\n   // yet successfully, don't report any errors.\n    if(this.inErrorRecoveryMode(recognizer)) {\n        return; // don't report spurious errors\n    }\n    this.beginErrorCondition(recognizer);\n    if ( e instanceof NoViableAltException ) {\n        this.reportNoViableAlternative(recognizer, e);\n    } else if ( e instanceof InputMismatchException ) {\n        this.reportInputMismatch(recognizer, e);\n    } else if ( e instanceof FailedPredicateException ) {\n        this.reportFailedPredicate(recognizer, e);\n    } else {\n        console.log(\"unknown recognition error type: \" + e.constructor.name);\n        console.log(e.stack);\n        recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);\n    }\n};\n//\n// {@inheritDoc}\n//\n// <p>The default implementation resynchronizes the parser by consuming tokens\n// until we find one in the resynchronization set--loosely the set of tokens\n// that can follow the current rule.</p>\n//\nDefaultErrorStrategy.prototype.recover = function(recognizer, e) {\n    if (this.lastErrorIndex===recognizer.getInputStream().index &&\n        this.lastErrorStates !== null && this.lastErrorStates.indexOf(recognizer.state)>=0) {\n\t\t// uh oh, another error at same token index and previously-visited\n\t\t// state in ATN; must be a case where LT(1) is in the recovery\n\t\t// token set so nothing got consumed. Consume a single token\n\t\t// at least to prevent an infinite loop; this is a failsafe.\n\t\trecognizer.consume();\n    }\n    this.lastErrorIndex = recognizer._input.index;\n    if (this.lastErrorStates === null) {\n        this.lastErrorStates = [];\n    }\n    this.lastErrorStates.push(recognizer.state);\n    var followSet = this.getErrorRecoverySet(recognizer);\n    this.consumeUntil(recognizer, followSet);\n};\n\n// The default implementation of {@link ANTLRErrorStrategy//sync} makes sure\n// that the current lookahead symbol is consistent with what were expecting\n// at this point in the ATN. You can call this anytime but ANTLR only\n// generates code to check before subrules/loops and each iteration.\n//\n// <p>Implements Jim Idle's magic sync mechanism in closures and optional\n// subrules. E.g.,</p>\n//\n// <pre>\n// a : sync ( stuff sync )* ;\n// sync : {consume to what can follow sync} ;\n// </pre>\n//\n// At the start of a sub rule upon error, {@link //sync} performs single\n// token deletion, if possible. If it can't do that, it bails on the current\n// rule and uses the default error recovery, which consumes until the\n// resynchronization set of the current rule.\n//\n// <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block\n// with an empty alternative), then the expected set includes what follows\n// the subrule.</p>\n//\n// <p>During loop iteration, it consumes until it sees a token that can start a\n// sub rule or what follows loop. Yes, that is pretty aggressive. We opt to\n// stay in the loop as long as possible.</p>\n//\n// <p><strong>ORIGINS</strong></p>\n//\n// <p>Previous versions of ANTLR did a poor job of their recovery within loops.\n// A single mismatch token or missing token would force the parser to bail\n// out of the entire rules surrounding the loop. So, for rule</p>\n//\n// <pre>\n// classDef : 'class' ID '{' member* '}'\n// </pre>\n//\n// input with an extra token between members would force the parser to\n// consume until it found the next class definition rather than the next\n// member definition of the current class.\n//\n// <p>This functionality cost a little bit of effort because the parser has to\n// compare token set at the start of the loop and at each iteration. If for\n// some reason speed is suffering for you, you can turn off this\n// functionality by simply overriding this method as a blank { }.</p>\n//\nDefaultErrorStrategy.prototype.sync = function(recognizer) {\n    // If already recovering, don't try to sync\n    if (this.inErrorRecoveryMode(recognizer)) {\n        return;\n    }\n    var s = recognizer._interp.atn.states[recognizer.state];\n    var la = recognizer.getTokenStream().LA(1);\n    // try cheaper subset first; might get lucky. seems to shave a wee bit off\n    if (la===Token.EOF || recognizer.atn.nextTokens(s).contains(la)) {\n        return;\n    }\n    // Return but don't end recovery. only do that upon valid token match\n    if(recognizer.isExpectedToken(la)) {\n        return;\n    }\n    switch (s.stateType) {\n    case ATNState.BLOCK_START:\n    case ATNState.STAR_BLOCK_START:\n    case ATNState.PLUS_BLOCK_START:\n    case ATNState.STAR_LOOP_ENTRY:\n       // report error and recover if possible\n        if( this.singleTokenDeletion(recognizer) !== null) {\n            return;\n        } else {\n            throw new InputMismatchException(recognizer);\n        }\n        break;\n    case ATNState.PLUS_LOOP_BACK:\n    case ATNState.STAR_LOOP_BACK:\n        this.reportUnwantedToken(recognizer);\n        var expecting = new IntervalSet();\n        expecting.addSet(recognizer.getExpectedTokens());\n        var whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer));\n        this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);\n        break;\n    default:\n        // do nothing if we can't identify the exact kind of ATN state\n    }\n};\n\n// This is called by {@link //reportError} when the exception is a\n// {@link NoViableAltException}.\n//\n// @see //reportError\n//\n// @param recognizer the parser instance\n// @param e the recognition exception\n//\nDefaultErrorStrategy.prototype.reportNoViableAlternative = function(recognizer, e) {\n    var tokens = recognizer.getTokenStream();\n    var input;\n    if(tokens !== null) {\n        if (e.startToken.type===Token.EOF) {\n            input = \"<EOF>\";\n        } else {\n            input = tokens.getText(new Interval(e.startToken, e.offendingToken));\n        }\n    } else {\n        input = \"<unknown input>\";\n    }\n    var msg = \"no viable alternative at input \" + this.escapeWSAndQuote(input);\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n};\n\n//\n// This is called by {@link //reportError} when the exception is an\n// {@link InputMismatchException}.\n//\n// @see //reportError\n//\n// @param recognizer the parser instance\n// @param e the recognition exception\n//\nDefaultErrorStrategy.prototype.reportInputMismatch = function(recognizer, e) {\n    var msg = \"mismatched input \" + this.getTokenErrorDisplay(e.offendingToken) +\n          \" expecting \" + e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames);\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n};\n\n//\n// This is called by {@link //reportError} when the exception is a\n// {@link FailedPredicateException}.\n//\n// @see //reportError\n//\n// @param recognizer the parser instance\n// @param e the recognition exception\n//\nDefaultErrorStrategy.prototype.reportFailedPredicate = function(recognizer, e) {\n    var ruleName = recognizer.ruleNames[recognizer._ctx.ruleIndex];\n    var msg = \"rule \" + ruleName + \" \" + e.message;\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n};\n\n// This method is called to report a syntax error which requires the removal\n// of a token from the input stream. At the time this method is called, the\n// erroneous symbol is current {@code LT(1)} symbol and has not yet been\n// removed from the input stream. When this method returns,\n// {@code recognizer} is in error recovery mode.\n//\n// <p>This method is called when {@link //singleTokenDeletion} identifies\n// single-token deletion as a viable recovery strategy for a mismatched\n// input error.</p>\n//\n// <p>The default implementation simply returns if the handler is already in\n// error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n// enter error recovery mode, followed by calling\n// {@link Parser//notifyErrorListeners}.</p>\n//\n// @param recognizer the parser instance\n//\nDefaultErrorStrategy.prototype.reportUnwantedToken = function(recognizer) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n        return;\n    }\n    this.beginErrorCondition(recognizer);\n    var t = recognizer.getCurrentToken();\n    var tokenName = this.getTokenErrorDisplay(t);\n    var expecting = this.getExpectedTokens(recognizer);\n    var msg = \"extraneous input \" + tokenName + \" expecting \" +\n        expecting.toString(recognizer.literalNames, recognizer.symbolicNames);\n    recognizer.notifyErrorListeners(msg, t, null);\n};\n// This method is called to report a syntax error which requires the\n// insertion of a missing token into the input stream. At the time this\n// method is called, the missing token has not yet been inserted. When this\n// method returns, {@code recognizer} is in error recovery mode.\n//\n// <p>This method is called when {@link //singleTokenInsertion} identifies\n// single-token insertion as a viable recovery strategy for a mismatched\n// input error.</p>\n//\n// <p>The default implementation simply returns if the handler is already in\n// error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n// enter error recovery mode, followed by calling\n// {@link Parser//notifyErrorListeners}.</p>\n//\n// @param recognizer the parser instance\n//\nDefaultErrorStrategy.prototype.reportMissingToken = function(recognizer) {\n    if ( this.inErrorRecoveryMode(recognizer)) {\n        return;\n    }\n    this.beginErrorCondition(recognizer);\n    var t = recognizer.getCurrentToken();\n    var expecting = this.getExpectedTokens(recognizer);\n    var msg = \"missing \" + expecting.toString(recognizer.literalNames, recognizer.symbolicNames) +\n          \" at \" + this.getTokenErrorDisplay(t);\n    recognizer.notifyErrorListeners(msg, t, null);\n};\n\n// <p>The default implementation attempts to recover from the mismatched input\n// by using single token insertion and deletion as described below. If the\n// recovery attempt fails, this method throws an\n// {@link InputMismatchException}.</p>\n//\n// <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>\n//\n// <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the\n// right token, however, then assume {@code LA(1)} is some extra spurious\n// token and delete it. Then consume and return the next token (which was\n// the {@code LA(2)} token) as the successful result of the match operation.</p>\n//\n// <p>This recovery strategy is implemented by {@link\n// //singleTokenDeletion}.</p>\n//\n// <p><strong>MISSING TOKEN</strong> (single token insertion)</p>\n//\n// <p>If current token (at {@code LA(1)}) is consistent with what could come\n// after the expected {@code LA(1)} token, then assume the token is missing\n// and use the parser's {@link TokenFactory} to create it on the fly. The\n// \"insertion\" is performed by returning the created token as the successful\n// result of the match operation.</p>\n//\n// <p>This recovery strategy is implemented by {@link\n// //singleTokenInsertion}.</p>\n//\n// <p><strong>EXAMPLE</strong></p>\n//\n// <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When\n// the parser returns from the nested call to {@code expr}, it will have\n// call chain:</p>\n//\n// <pre>\n// stat &rarr; expr &rarr; atom\n// </pre>\n//\n// and it will be trying to match the {@code ')'} at this point in the\n// derivation:\n//\n// <pre>\n// =&gt; ID '=' '(' INT ')' ('+' atom)* ';'\n// ^\n// </pre>\n//\n// The attempt to match {@code ')'} will fail when it sees {@code ';'} and\n// call {@link //recoverInline}. To recover, it sees that {@code LA(1)==';'}\n// is in the set of tokens that can follow the {@code ')'} token reference\n// in rule {@code atom}. It can assume that you forgot the {@code ')'}.\n//\nDefaultErrorStrategy.prototype.recoverInline = function(recognizer) {\n    // SINGLE TOKEN DELETION\n    var matchedSymbol = this.singleTokenDeletion(recognizer);\n    if (matchedSymbol !== null) {\n        // we have deleted the extra token.\n        // now, move past ttype token as if all were ok\n        recognizer.consume();\n        return matchedSymbol;\n    }\n    // SINGLE TOKEN INSERTION\n    if (this.singleTokenInsertion(recognizer)) {\n        return this.getMissingSymbol(recognizer);\n    }\n    // even that didn't work; must throw the exception\n    throw new InputMismatchException(recognizer);\n};\n\n//\n// This method implements the single-token insertion inline error recovery\n// strategy. It is called by {@link //recoverInline} if the single-token\n// deletion strategy fails to recover from the mismatched input. If this\n// method returns {@code true}, {@code recognizer} will be in error recovery\n// mode.\n//\n// <p>This method determines whether or not single-token insertion is viable by\n// checking if the {@code LA(1)} input symbol could be successfully matched\n// if it were instead the {@code LA(2)} symbol. If this method returns\n// {@code true}, the caller is responsible for creating and inserting a\n// token with the correct type to produce this behavior.</p>\n//\n// @param recognizer the parser instance\n// @return {@code true} if single-token insertion is a viable recovery\n// strategy for the current mismatched input, otherwise {@code false}\n//\nDefaultErrorStrategy.prototype.singleTokenInsertion = function(recognizer) {\n    var currentSymbolType = recognizer.getTokenStream().LA(1);\n    // if current token is consistent with what could come after current\n    // ATN state, then we know we're missing a token; error recovery\n    // is free to conjure up and insert the missing token\n    var atn = recognizer._interp.atn;\n    var currentState = atn.states[recognizer.state];\n    var next = currentState.transitions[0].target;\n    var expectingAtLL2 = atn.nextTokens(next, recognizer._ctx);\n    if (expectingAtLL2.contains(currentSymbolType) ){\n        this.reportMissingToken(recognizer);\n        return true;\n    } else {\n        return false;\n    }\n};\n\n// This method implements the single-token deletion inline error recovery\n// strategy. It is called by {@link //recoverInline} to attempt to recover\n// from mismatched input. If this method returns null, the parser and error\n// handler state will not have changed. If this method returns non-null,\n// {@code recognizer} will <em>not</em> be in error recovery mode since the\n// returned token was a successful match.\n//\n// <p>If the single-token deletion is successful, this method calls\n// {@link //reportUnwantedToken} to report the error, followed by\n// {@link Parser//consume} to actually \"delete\" the extraneous token. Then,\n// before returning {@link //reportMatch} is called to signal a successful\n// match.</p>\n//\n// @param recognizer the parser instance\n// @return the successfully matched {@link Token} instance if single-token\n// deletion successfully recovers from the mismatched input, otherwise\n// {@code null}\n//\nDefaultErrorStrategy.prototype.singleTokenDeletion = function(recognizer) {\n    var nextTokenType = recognizer.getTokenStream().LA(2);\n    var expecting = this.getExpectedTokens(recognizer);\n    if (expecting.contains(nextTokenType)) {\n        this.reportUnwantedToken(recognizer);\n        // print(\"recoverFromMismatchedToken deleting \" \\\n        // + str(recognizer.getTokenStream().LT(1)) \\\n        // + \" since \" + str(recognizer.getTokenStream().LT(2)) \\\n        // + \" is what we want\", file=sys.stderr)\n        recognizer.consume(); // simply delete extra token\n        // we want to return the token we're actually matching\n        var matchedSymbol = recognizer.getCurrentToken();\n        this.reportMatch(recognizer); // we know current token is correct\n        return matchedSymbol;\n    } else {\n        return null;\n    }\n};\n\n// Conjure up a missing token during error recovery.\n//\n// The recognizer attempts to recover from single missing\n// symbols. But, actions might refer to that missing symbol.\n// For example, x=ID {f($x);}. The action clearly assumes\n// that there has been an identifier matched previously and that\n// $x points at that token. If that token is missing, but\n// the next token in the stream is what we want we assume that\n// this token is missing and we keep going. Because we\n// have to return some token to replace the missing token,\n// we have to conjure one up. This method gives the user control\n// over the tokens returned for missing tokens. Mostly,\n// you will want to create something special for identifier\n// tokens. For literals such as '{' and ',', the default\n// action in the parser or tree parser works. It simply creates\n// a CommonToken of the appropriate type. The text will be the token.\n// If you change what tokens must be created by the lexer,\n// override this method to create the appropriate tokens.\n//\nDefaultErrorStrategy.prototype.getMissingSymbol = function(recognizer) {\n    var currentSymbol = recognizer.getCurrentToken();\n    var expecting = this.getExpectedTokens(recognizer);\n    var expectedTokenType = expecting.first(); // get any element\n    var tokenText;\n    if (expectedTokenType===Token.EOF) {\n        tokenText = \"<missing EOF>\";\n    } else {\n        tokenText = \"<missing \" + recognizer.literalNames[expectedTokenType] + \">\";\n    }\n    var current = currentSymbol;\n    var lookback = recognizer.getTokenStream().LT(-1);\n    if (current.type===Token.EOF && lookback !== null) {\n        current = lookback;\n    }\n    return recognizer.getTokenFactory().create(current.source,\n        expectedTokenType, tokenText, Token.DEFAULT_CHANNEL,\n        -1, -1, current.line, current.column);\n};\n\nDefaultErrorStrategy.prototype.getExpectedTokens = function(recognizer) {\n    return recognizer.getExpectedTokens();\n};\n\n// How should a token be displayed in an error message? The default\n// is to display just the text, but during development you might\n// want to have a lot of information spit out. Override in that case\n// to use t.toString() (which, for CommonToken, dumps everything about\n// the token). This is better than forcing you to override a method in\n// your token objects because you don't have to go modify your lexer\n// so that it creates a new Java type.\n//\nDefaultErrorStrategy.prototype.getTokenErrorDisplay = function(t) {\n    if (t === null) {\n        return \"<no token>\";\n    }\n    var s = t.text;\n    if (s === null) {\n        if (t.type===Token.EOF) {\n            s = \"<EOF>\";\n        } else {\n            s = \"<\" + t.type + \">\";\n        }\n    }\n    return this.escapeWSAndQuote(s);\n};\n\nDefaultErrorStrategy.prototype.escapeWSAndQuote = function(s) {\n    s = s.replace(/\\n/g,\"\\\\n\");\n    s = s.replace(/\\r/g,\"\\\\r\");\n    s = s.replace(/\\t/g,\"\\\\t\");\n    return \"'\" + s + \"'\";\n};\n\n// Compute the error recovery set for the current rule. During\n// rule invocation, the parser pushes the set of tokens that can\n// follow that rule reference on the stack; this amounts to\n// computing FIRST of what follows the rule reference in the\n// enclosing rule. See LinearApproximator.FIRST().\n// This local follow set only includes tokens\n// from within the rule; i.e., the FIRST computation done by\n// ANTLR stops at the end of a rule.\n//\n// EXAMPLE\n//\n// When you find a \"no viable alt exception\", the input is not\n// consistent with any of the alternatives for rule r. The best\n// thing to do is to consume tokens until you see something that\n// can legally follow a call to r//or* any rule that called r.\n// You don't want the exact set of viable next tokens because the\n// input might just be missing a token--you might consume the\n// rest of the input looking for one of the missing tokens.\n//\n// Consider grammar:\n//\n// a : '[' b ']'\n// | '(' b ')'\n// ;\n// b : c '^' INT ;\n// c : ID\n// | INT\n// ;\n//\n// At each rule invocation, the set of tokens that could follow\n// that rule is pushed on a stack. Here are the various\n// context-sensitive follow sets:\n//\n// FOLLOW(b1_in_a) = FIRST(']') = ']'\n// FOLLOW(b2_in_a) = FIRST(')') = ')'\n// FOLLOW(c_in_b) = FIRST('^') = '^'\n//\n// Upon erroneous input \"[]\", the call chain is\n//\n// a -> b -> c\n//\n// and, hence, the follow context stack is:\n//\n// depth follow set start of rule execution\n// 0 <EOF> a (from main())\n// 1 ']' b\n// 2 '^' c\n//\n// Notice that ')' is not included, because b would have to have\n// been called from a different context in rule a for ')' to be\n// included.\n//\n// For error recovery, we cannot consider FOLLOW(c)\n// (context-sensitive or otherwise). We need the combined set of\n// all context-sensitive FOLLOW sets--the set of all tokens that\n// could follow any reference in the call chain. We need to\n// resync to one of those tokens. Note that FOLLOW(c)='^' and if\n// we resync'd to that token, we'd consume until EOF. We need to\n// sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.\n// In this case, for input \"[]\", LA(1) is ']' and in the set, so we would\n// not consume anything. After printing an error, rule c would\n// return normally. Rule b would not find the required '^' though.\n// At this point, it gets a mismatched token error and throws an\n// exception (since LA(1) is not in the viable following token\n// set). The rule exception handler tries to recover, but finds\n// the same recovery set and doesn't consume anything. Rule b\n// exits normally returning to rule a. Now it finds the ']' (and\n// with the successful match exits errorRecovery mode).\n//\n// So, you can see that the parser walks up the call chain looking\n// for the token that was a member of the recovery set.\n//\n// Errors are not generated in errorRecovery mode.\n//\n// ANTLR's error recovery mechanism is based upon original ideas:\n//\n// \"Algorithms + Data Structures = Programs\" by Niklaus Wirth\n//\n// and\n//\n// \"A note on error recovery in recursive descent parsers\":\n// http://portal.acm.org/citation.cfm?id=947902.947905\n//\n// Later, Josef Grosch had some good ideas:\n//\n// \"Efficient and Comfortable Error Recovery in Recursive Descent\n// Parsers\":\n// ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip\n//\n// Like Grosch I implement context-sensitive FOLLOW sets that are combined\n// at run-time upon error to avoid overhead during parsing.\n//\nDefaultErrorStrategy.prototype.getErrorRecoverySet = function(recognizer) {\n    var atn = recognizer._interp.atn;\n    var ctx = recognizer._ctx;\n    var recoverSet = new IntervalSet();\n    while (ctx !== null && ctx.invokingState>=0) {\n        // compute what follows who invoked us\n        var invokingState = atn.states[ctx.invokingState];\n        var rt = invokingState.transitions[0];\n        var follow = atn.nextTokens(rt.followState);\n        recoverSet.addSet(follow);\n        ctx = ctx.parentCtx;\n    }\n    recoverSet.removeOne(Token.EPSILON);\n    return recoverSet;\n};\n\n// Consume tokens until one matches the given token set.//\nDefaultErrorStrategy.prototype.consumeUntil = function(recognizer, set) {\n    var ttype = recognizer.getTokenStream().LA(1);\n    while( ttype !== Token.EOF && !set.contains(ttype)) {\n        recognizer.consume();\n        ttype = recognizer.getTokenStream().LA(1);\n    }\n};\n\n//\n// This implementation of {@link ANTLRErrorStrategy} responds to syntax errors\n// by immediately canceling the parse operation with a\n// {@link ParseCancellationException}. The implementation ensures that the\n// {@link ParserRuleContext//exception} field is set for all parse tree nodes\n// that were not completed prior to encountering the error.\n//\n// <p>\n// This error strategy is useful in the following scenarios.</p>\n//\n// <ul>\n// <li><strong>Two-stage parsing:</strong> This error strategy allows the first\n// stage of two-stage parsing to immediately terminate if an error is\n// encountered, and immediately fall back to the second stage. In addition to\n// avoiding wasted work by attempting to recover from errors here, the empty\n// implementation of {@link BailErrorStrategy//sync} improves the performance of\n// the first stage.</li>\n// <li><strong>Silent validation:</strong> When syntax errors are not being\n// reported or logged, and the parse result is simply ignored if errors occur,\n// the {@link BailErrorStrategy} avoids wasting work on recovering from errors\n// when the result will be ignored either way.</li>\n// </ul>\n//\n// <p>\n// {@code myparser.setErrorHandler(new BailErrorStrategy());}</p>\n//\n// @see Parser//setErrorHandler(ANTLRErrorStrategy)\n//\nfunction BailErrorStrategy() {\n\tDefaultErrorStrategy.call(this);\n\treturn this;\n}\n\nBailErrorStrategy.prototype = Object.create(DefaultErrorStrategy.prototype);\nBailErrorStrategy.prototype.constructor = BailErrorStrategy;\n\n// Instead of recovering from exception {@code e}, re-throw it wrapped\n// in a {@link ParseCancellationException} so it is not caught by the\n// rule function catches. Use {@link Exception//getCause()} to get the\n// original {@link RecognitionException}.\n//\nBailErrorStrategy.prototype.recover = function(recognizer, e) {\n    var context = recognizer._ctx;\n    while (context !== null) {\n        context.exception = e;\n        context = context.parentCtx;\n    }\n    throw new ParseCancellationException(e);\n};\n    \n// Make sure we don't attempt to recover inline; if the parser\n// successfully recovers, it won't throw an exception.\n//\nBailErrorStrategy.prototype.recoverInline = function(recognizer) {\n    this.recover(recognizer, new InputMismatchException(recognizer));\n};\n\n// Make sure we don't attempt to recover from problems in subrules.//\nBailErrorStrategy.prototype.sync = function(recognizer) {\n    // pass\n};\n\nexports.BailErrorStrategy = BailErrorStrategy;\nexports.DefaultErrorStrategy = DefaultErrorStrategy;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/error/ErrorStrategy.js\n ** module id = 42\n ** module chunks = 0\n **/","// \n//  [The \"BSD license\"]\n//   Copyright (c) 2012 Terence Parr\n//   Copyright (c) 2012 Sam Harwell\n//   Copyright (c) 2014 Eric Vergnaud\n//   All rights reserved.\n// \n//   Redistribution and use in source and binary forms, with or without\n//   modification, are permitted provided that the following conditions\n//   are met:\n// \n//   1. Redistributions of source code must retain the above copyright\n//      notice, this list of conditions and the following disclaimer.\n//   2. Redistributions in binary form must reproduce the above copyright\n//      notice, this list of conditions and the following disclaimer in the\n//      documentation and/or other materials provided with the distribution.\n//   3. The name of the author may not be used to endorse or promote products\n//      derived from this software without specific prior written permission.\n// \n//   THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//   IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//   OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//   IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//   INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//   NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//   THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n// \n\nvar Token = require('./Token').Token;\n\n// Vacuum all input from a string and then treat it like a buffer.\n\nfunction _loadString(stream) {\n\tstream._index = 0;\n\tstream.data = [];\n\tfor (var i = 0; i < stream.strdata.length; i++) {\n\t\tstream.data.push(stream.strdata.charCodeAt(i));\n\t}\n\tstream._size = stream.data.length;\n}\n\nfunction InputStream(data) {\n\tthis.name = \"<empty>\";\n\tthis.strdata = data;\n\t_loadString(this);\n\treturn this;\n}\n\nObject.defineProperty(InputStream.prototype, \"index\", {\n\tget : function() {\n\t\treturn this._index;\n\t}\n});\n\nObject.defineProperty(InputStream.prototype, \"size\", {\n\tget : function() {\n\t\treturn this._size;\n\t}\n});\n\n// Reset the stream so that it's in the same state it was\n// when the object was created *except* the data array is not\n// touched.\n//\nInputStream.prototype.reset = function() {\n\tthis._index = 0;\n};\n\nInputStream.prototype.consume = function() {\n\tif (this._index >= this._size) {\n\t\t// assert this.LA(1) == Token.EOF\n\t\tthrow (\"cannot consume EOF\");\n\t}\n\tthis._index += 1;\n};\n\nInputStream.prototype.LA = function(offset) {\n\tif (offset === 0) {\n\t\treturn 0; // undefined\n\t}\n\tif (offset < 0) {\n\t\toffset += 1; // e.g., translate LA(-1) to use offset=0\n\t}\n\tvar pos = this._index + offset - 1;\n\tif (pos < 0 || pos >= this._size) { // invalid\n\t\treturn Token.EOF;\n\t}\n\treturn this.data[pos];\n};\n\nInputStream.prototype.LT = function(offset) {\n\treturn this.LA(offset);\n};\n\n// mark/release do nothing; we have entire buffer\nInputStream.prototype.mark = function() {\n\treturn -1;\n};\n\nInputStream.prototype.release = function(marker) {\n};\n\n// consume() ahead until p==_index; can't just set p=_index as we must\n// update line and column. If we seek backwards, just set p\n//\nInputStream.prototype.seek = function(_index) {\n\tif (_index <= this._index) {\n\t\tthis._index = _index; // just jump; don't update stream state (line,\n\t\t\t\t\t\t\t\t// ...)\n\t\treturn;\n\t}\n\t// seek forward\n\tthis._index = Math.min(_index, this._size);\n};\n\nInputStream.prototype.getText = function(start, stop) {\n\tif (stop >= this._size) {\n\t\tstop = this._size - 1;\n\t}\n\tif (start >= this._size) {\n\t\treturn \"\";\n\t} else {\n\t\treturn this.strdata.slice(start, stop + 1);\n\t}\n};\n\nInputStream.prototype.toString = function() {\n\treturn this.strdata;\n};\n\nexports.InputStream = InputStream;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/InputStream.js\n ** module id = 43\n ** module chunks = 0\n **/","//\n//  [The \"BSD license\"]\n//   Copyright (c) 2012 Terence Parr\n//   Copyright (c) 2012 Sam Harwell\n//   Copyright (c) 2014 Eric Vergnaud\n//   All rights reserved.\n// \n//   Redistribution and use in source and binary forms, with or without\n//   modification, are permitted provided that the following conditions\n//   are met:\n// \n//   1. Redistributions of source code must retain the above copyright\n//      notice, this list of conditions and the following disclaimer.\n//   2. Redistributions in binary form must reproduce the above copyright\n//      notice, this list of conditions and the following disclaimer in the\n//      documentation and/or other materials provided with the distribution.\n//   3. The name of the author may not be used to endorse or promote products\n//      derived from this software without specific prior written permission.\n// \n//   THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//   IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//   OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//   IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//   INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//   NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//   THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n// \n\n//\n//  This is an InputStream that is loaded from a file all at once\n//  when you construct the object.\n// \nvar InputStream = require('./InputStream').InputStream;\nvar isNodeJs = typeof window === 'undefined' && typeof importScripts === 'undefined';\nvar fs = isNodeJs ? require(\"fs\") : null;\n\nfunction FileStream(fileName) {\n\tvar data = fs.readFileSync(fileName, \"utf8\");\n\tInputStream.call(this, data);\n\tthis.fileName = fileName;\n\treturn this;\n}\n\nFileStream.prototype = Object.create(InputStream.prototype);\nFileStream.prototype.constructor = FileStream;\n\nexports.FileStream = FileStream;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/FileStream.js\n ** module id = 44\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n///\n\n//\n// This class extends {@link BufferedTokenStream} with functionality to filter\n// token streams to tokens on a particular channel (tokens where\n// {@link Token//getChannel} returns a particular value).\n//\n// <p>\n// This token stream provides access to all tokens by index or when calling\n// methods like {@link //getText}. The channel filtering is only used for code\n// accessing tokens via the lookahead methods {@link //LA}, {@link //LT}, and\n// {@link //LB}.</p>\n//\n// <p>\n// By default, tokens are placed on the default channel\n// ({@link Token//DEFAULT_CHANNEL}), but may be reassigned by using the\n// {@code ->channel(HIDDEN)} lexer command, or by using an embedded action to\n// call {@link Lexer//setChannel}.\n// </p>\n//\n// <p>\n// Note: lexer rules which use the {@code ->skip} lexer command or call\n// {@link Lexer//skip} do not produce tokens at all, so input text matched by\n// such a rule will not be available as part of the token stream, regardless of\n// channel.</p>\n///\n\nvar Token = require('./Token').Token;\nvar BufferedTokenStream = require('./BufferedTokenStream').BufferedTokenStream;\n\nfunction CommonTokenStream(lexer, channel) {\n\tBufferedTokenStream.call(this, lexer);\n    this.channel = channel===undefined ? Token.DEFAULT_CHANNEL : channel;\n    return this;\n}\n\nCommonTokenStream.prototype = Object.create(BufferedTokenStream.prototype);\nCommonTokenStream.prototype.constructor = CommonTokenStream;\n\nCommonTokenStream.prototype.adjustSeekIndex = function(i) {\n    return this.nextTokenOnChannel(i, this.channel);\n};\n\nCommonTokenStream.prototype.LB = function(k) {\n    if (k===0 || this.index-k<0) {\n        return null;\n    }\n    var i = this.index;\n    var n = 1;\n    // find k good tokens looking backwards\n    while (n <= k) {\n        // skip off-channel tokens\n        i = this.previousTokenOnChannel(i - 1, this.channel);\n        n += 1;\n    }\n    if (i < 0) {\n        return null;\n    }\n    return this.tokens[i];\n};\n\nCommonTokenStream.prototype.LT = function(k) {\n    this.lazyInit();\n    if (k === 0) {\n        return null;\n    }\n    if (k < 0) {\n        return this.LB(-k);\n    }\n    var i = this.index;\n    var n = 1; // we know tokens[pos] is a good one\n    // find k good tokens\n    while (n < k) {\n        // skip off-channel tokens, but make sure to not look past EOF\n        if (this.sync(i + 1)) {\n            i = this.nextTokenOnChannel(i + 1, this.channel);\n        }\n        n += 1;\n    }\n    return this.tokens[i];\n};\n\n// Count EOF just once.///\nCommonTokenStream.prototype.getNumberOfOnChannelTokens = function() {\n    var n = 0;\n    this.fill();\n    for (var i =0; i< this.tokens.length;i++) {\n        var t = this.tokens[i];\n        if( t.channel===this.channel) {\n            n += 1;\n        }\n        if( t.type===Token.EOF) {\n            break;\n        }\n    }\n    return n;\n};\n\nexports.CommonTokenStream = CommonTokenStream;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/CommonTokenStream.js\n ** module id = 46\n ** module chunks = 0\n **/","//\n// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n// This implementation of {@link TokenStream} loads tokens from a\n// {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n// access to any previous token by index.\n//\n// <p>\n// This token stream ignores the value of {@link Token//getChannel}. If your\n// parser requires the token stream filter tokens to only those on a particular\n// channel, such as {@link Token//DEFAULT_CHANNEL} or\n// {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n// {@link CommonTokenStream}.</p>\n\nvar Token = require('./Token').Token;\nvar Lexer = require('./Lexer').Lexer;\nvar Interval = require('./IntervalSet').Interval;\n\n// this is just to keep meaningful parameter types to Parser\nfunction TokenStream() {\n\treturn this;\n}\n\nfunction BufferedTokenStream(tokenSource) {\n\n\tTokenStream.call(this);\n\t// The {@link TokenSource} from which tokens for this stream are fetched.\n\tthis.tokenSource = tokenSource;\n\n\t// A collection of all tokens fetched from the token source. The list is\n\t// considered a complete view of the input once {@link //fetchedEOF} is set\n\t// to {@code true}.\n\tthis.tokens = [];\n\n\t// The index into {@link //tokens} of the current token (next token to\n\t// {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n\t// be\n\t// {@link //LT LT(1)}.\n\t//\n\t// <p>This field is set to -1 when the stream is first constructed or when\n\t// {@link //setTokenSource} is called, indicating that the first token has\n\t// not yet been fetched from the token source. For additional information,\n\t// see the documentation of {@link IntStream} for a description of\n\t// Initializing Methods.</p>\n\tthis.index = -1;\n\n\t// Indicates whether the {@link Token//EOF} token has been fetched from\n\t// {@link //tokenSource} and added to {@link //tokens}. This field improves\n\t// performance for the following cases:\n\t//\n\t// <ul>\n\t// <li>{@link //consume}: The lookahead check in {@link //consume} to\n\t// prevent\n\t// consuming the EOF symbol is optimized by checking the values of\n\t// {@link //fetchedEOF} and {@link //p} instead of calling {@link\n\t// //LA}.</li>\n\t// <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n\t// into\n\t// {@link //tokens} is trivial with this field.</li>\n\t// <ul>\n\tthis.fetchedEOF = false;\n\treturn this;\n}\n\nBufferedTokenStream.prototype = Object.create(TokenStream.prototype);\nBufferedTokenStream.prototype.constructor = BufferedTokenStream;\n\nBufferedTokenStream.prototype.mark = function() {\n\treturn 0;\n};\n\nBufferedTokenStream.prototype.release = function(marker) {\n\t// no resources to release\n};\n\nBufferedTokenStream.prototype.reset = function() {\n\tthis.seek(0);\n};\n\nBufferedTokenStream.prototype.seek = function(index) {\n\tthis.lazyInit();\n\tthis.index = this.adjustSeekIndex(index);\n};\n\nBufferedTokenStream.prototype.get = function(index) {\n\tthis.lazyInit();\n\treturn this.tokens[index];\n};\n\nBufferedTokenStream.prototype.consume = function() {\n\tvar skipEofCheck = false;\n\tif (this.index >= 0) {\n\t\tif (this.fetchedEOF) {\n\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t// fetched token except the last.\n\t\t\tskipEofCheck = this.index < this.tokens.length - 1;\n\t\t} else {\n\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\tskipEofCheck = this.index < this.tokens.length;\n\t\t}\n\t} else {\n\t\t// not yet initialized\n\t\tskipEofCheck = false;\n\t}\n\tif (!skipEofCheck && this.LA(1) === Token.EOF) {\n\t\tthrow \"cannot consume EOF\";\n\t}\n\tif (this.sync(this.index + 1)) {\n\t\tthis.index = this.adjustSeekIndex(this.index + 1);\n\t}\n};\n\n// Make sure index {@code i} in tokens has a token.\n//\n// @return {@code true} if a token is located at index {@code i}, otherwise\n// {@code false}.\n// @see //get(int i)\n// /\nBufferedTokenStream.prototype.sync = function(i) {\n\tvar n = i - this.tokens.length + 1; // how many more elements we need?\n\tif (n > 0) {\n\t\tvar fetched = this.fetch(n);\n\t\treturn fetched >= n;\n\t}\n\treturn true;\n};\n\n// Add {@code n} elements to buffer.\n//\n// @return The actual number of elements added to the buffer.\n// /\nBufferedTokenStream.prototype.fetch = function(n) {\n\tif (this.fetchedEOF) {\n\t\treturn 0;\n\t}\n\tfor (var i = 0; i < n; i++) {\n\t\tvar t = this.tokenSource.nextToken();\n\t\tt.tokenIndex = this.tokens.length;\n\t\tthis.tokens.push(t);\n\t\tif (t.type === Token.EOF) {\n\t\t\tthis.fetchedEOF = true;\n\t\t\treturn i + 1;\n\t\t}\n\t}\n\treturn n;\n};\n\n// Get all tokens from start..stop inclusively///\nBufferedTokenStream.prototype.getTokens = function(start, stop, types) {\n\tif (types === undefined) {\n\t\ttypes = null;\n\t}\n\tif (start < 0 || stop < 0) {\n\t\treturn null;\n\t}\n\tthis.lazyInit();\n\tvar subset = [];\n\tif (stop >= this.tokens.length) {\n\t\tstop = this.tokens.length - 1;\n\t}\n\tfor (var i = start; i < stop; i++) {\n\t\tvar t = this.tokens[i];\n\t\tif (t.type === Token.EOF) {\n\t\t\tbreak;\n\t\t}\n\t\tif (types === null || types.contains(t.type)) {\n\t\t\tsubset.push(t);\n\t\t}\n\t}\n\treturn subset;\n};\n\nBufferedTokenStream.prototype.LA = function(i) {\n\treturn this.LT(i).type;\n};\n\nBufferedTokenStream.prototype.LB = function(k) {\n\tif (this.index - k < 0) {\n\t\treturn null;\n\t}\n\treturn this.tokens[this.index - k];\n};\n\nBufferedTokenStream.prototype.LT = function(k) {\n\tthis.lazyInit();\n\tif (k === 0) {\n\t\treturn null;\n\t}\n\tif (k < 0) {\n\t\treturn this.LB(-k);\n\t}\n\tvar i = this.index + k - 1;\n\tthis.sync(i);\n\tif (i >= this.tokens.length) { // return EOF token\n\t\t// EOF must be last token\n\t\treturn this.tokens[this.tokens.length - 1];\n\t}\n\treturn this.tokens[i];\n};\n\n// Allowed derived classes to modify the behavior of operations which change\n// the current stream position by adjusting the target token index of a seek\n// operation. The default implementation simply returns {@code i}. If an\n// exception is thrown in this method, the current stream index should not be\n// changed.\n//\n// <p>For example, {@link CommonTokenStream} overrides this method to ensure\n// that\n// the seek target is always an on-channel token.</p>\n//\n// @param i The target token index.\n// @return The adjusted target token index.\n\nBufferedTokenStream.prototype.adjustSeekIndex = function(i) {\n\treturn i;\n};\n\nBufferedTokenStream.prototype.lazyInit = function() {\n\tif (this.index === -1) {\n\t\tthis.setup();\n\t}\n};\n\nBufferedTokenStream.prototype.setup = function() {\n\tthis.sync(0);\n\tthis.index = this.adjustSeekIndex(0);\n};\n\n// Reset this token stream by setting its token source.///\nBufferedTokenStream.prototype.setTokenSource = function(tokenSource) {\n\tthis.tokenSource = tokenSource;\n\tthis.tokens = [];\n\tthis.index = -1;\n};\n\n\n// Given a starting index, return the index of the next token on channel.\n// Return i if tokens[i] is on channel. Return -1 if there are no tokens\n// on channel between i and EOF.\n// /\nBufferedTokenStream.prototype.nextTokenOnChannel = function(i, channel) {\n\tthis.sync(i);\n\tif (i >= this.tokens.length) {\n\t\treturn -1;\n\t}\n\tvar token = this.tokens[i];\n\twhile (token.channel !== this.channel) {\n\t\tif (token.type === Token.EOF) {\n\t\t\treturn -1;\n\t\t}\n\t\ti += 1;\n\t\tthis.sync(i);\n\t\ttoken = this.tokens[i];\n\t}\n\treturn i;\n};\n\n// Given a starting index, return the index of the previous token on channel.\n// Return i if tokens[i] is on channel. Return -1 if there are no tokens\n// on channel between i and 0.\nBufferedTokenStream.prototype.previousTokenOnChannel = function(i, channel) {\n\twhile (i >= 0 && this.tokens[i].channel !== channel) {\n\t\ti -= 1;\n\t}\n\treturn i;\n};\n\n// Collect all tokens on specified channel to the right of\n// the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n// EOF. If channel is -1, find any non default channel token.\nBufferedTokenStream.prototype.getHiddenTokensToRight = function(tokenIndex,\n\t\tchannel) {\n\tif (channel === undefined) {\n\t\tchannel = -1;\n\t}\n\tthis.lazyInit();\n\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t}\n\tvar nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1,\n\t\t\tLexer.DEFAULT_TOKEN_CHANNEL);\n\tvar from_ = tokenIndex + 1;\n\t// if none onchannel to right, nextOnChannel=-1 so set to = last token\n\tvar to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n\treturn this.filterForChannel(from_, to, channel);\n};\n\n// Collect all tokens on specified channel to the left of\n// the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n// If channel is -1, find any non default channel token.\nBufferedTokenStream.prototype.getHiddenTokensToLeft = function(tokenIndex,\n\t\tchannel) {\n\tif (channel === undefined) {\n\t\tchannel = -1;\n\t}\n\tthis.lazyInit();\n\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t}\n\tvar prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1,\n\t\t\tLexer.DEFAULT_TOKEN_CHANNEL);\n\tif (prevOnChannel === tokenIndex - 1) {\n\t\treturn null;\n\t}\n\t// if none on channel to left, prevOnChannel=-1 then from=0\n\tvar from_ = prevOnChannel + 1;\n\tvar to = tokenIndex - 1;\n\treturn this.filterForChannel(from_, to, channel);\n};\n\nBufferedTokenStream.prototype.filterForChannel = function(left, right, channel) {\n\tvar hidden = [];\n\tfor (var i = left; i < right + 1; i++) {\n\t\tvar t = this.tokens[i];\n\t\tif (channel === -1) {\n\t\t\tif (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n\t\t\t\thidden.push(t);\n\t\t\t}\n\t\t} else if (t.channel === channel) {\n\t\t\thidden.push(t);\n\t\t}\n\t}\n\tif (hidden.length === 0) {\n\t\treturn null;\n\t}\n\treturn hidden;\n};\n\nBufferedTokenStream.prototype.getSourceName = function() {\n\treturn this.tokenSource.getSourceName();\n};\n\n// Get the text of all tokens in this buffer.///\nBufferedTokenStream.prototype.getText = function(interval) {\n\tthis.lazyInit();\n\tthis.fill();\n\tif (interval === undefined || interval === null) {\n\t\tinterval = new Interval(0, this.tokens.length - 1);\n\t}\n\tvar start = interval.start;\n\tif (start instanceof Token) {\n\t\tstart = start.tokenIndex;\n\t}\n\tvar stop = interval.stop;\n\tif (stop instanceof Token) {\n\t\tstop = stop.tokenIndex;\n\t}\n\tif (start === null || stop === null || start < 0 || stop < 0) {\n\t\treturn \"\";\n\t}\n\tif (stop >= this.tokens.length) {\n\t\tstop = this.tokens.length - 1;\n\t}\n\tvar s = \"\";\n\tfor (var i = start; i < stop + 1; i++) {\n\t\tvar t = this.tokens[i];\n\t\tif (t.type === Token.EOF) {\n\t\t\tbreak;\n\t\t}\n\t\ts = s + t.text;\n\t}\n\treturn s;\n};\n\n// Get all tokens from lexer until EOF///\nBufferedTokenStream.prototype.fill = function() {\n\tthis.lazyInit();\n\twhile (this.fetch(1000) === 1000) {\n\t\tcontinue;\n\t}\n};\n\nexports.BufferedTokenStream = BufferedTokenStream;\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/BufferedTokenStream.js\n ** module id = 47\n ** module chunks = 0\n **/","// [The \"BSD license\"]\n//  Copyright (c) 2012 Terence Parr\n//  Copyright (c) 2012 Sam Harwell\n//  Copyright (c) 2014 Eric Vergnaud\n//  All rights reserved.\n//\n//  Redistribution and use in source and binary forms, with or without\n//  modification, are permitted provided that the following conditions\n//  are met:\n//\n//  1. Redistributions of source code must retain the above copyright\n//     notice, this list of conditions and the following disclaimer.\n//  2. Redistributions in binary form must reproduce the above copyright\n//     notice, this list of conditions and the following disclaimer in the\n//     documentation and/or other materials provided with the distribution.\n//  3. The name of the author may not be used to endorse or promote products\n//     derived from this software without specific prior written permission.\n//\n//  this SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n//  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n//  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n//  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n//  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n//  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n//  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n//  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n//  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n//  this SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nvar Token = require('./Token').Token;\nvar ParseTreeListener = require('./tree/Tree').ParseTreeListener;\nvar Recognizer = require('./Recognizer').Recognizer;\nvar DefaultErrorStrategy = require('./error/ErrorStrategy').DefaultErrorStrategy;\nvar ATNDeserializer = require('./atn/ATNDeserializer').ATNDeserializer;\nvar ATNDeserializationOptions = require('./atn/ATNDeserializationOptions').ATNDeserializationOptions;\n\nfunction TraceListener(parser) {\n\tParseTreeListener.call(this);\n    this.parser = parser;\n\treturn this;\n}\n\nTraceListener.prototype = Object.create(ParseTreeListener);\nTraceListener.prototype.constructor = TraceListener;\n\nTraceListener.prototype.enterEveryRule = function(ctx) {\n\tconsole.log(\"enter   \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n};\n\nTraceListener.prototype.visitTerminal = function( node) {\n\tconsole.log(\"consume \" + node.symbol + \" rule \" + this.parser.ruleNames[this.parser._ctx.ruleIndex]);\n};\n\nTraceListener.prototype.exitEveryRule = function(ctx) {\n\tconsole.log(\"exit    \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n};\n\n// this is all the parsing support code essentially; most of it is error\n// recovery stuff.//\nfunction Parser(input) {\n\tRecognizer.call(this);\n\t// The input stream.\n\tthis._input = null;\n\t// The error handling strategy for the parser. The default value is a new\n\t// instance of {@link DefaultErrorStrategy}.\n\tthis._errHandler = new DefaultErrorStrategy();\n\tthis._precedenceStack = [];\n\tthis._precedenceStack.push(0);\n\t// The {@link ParserRuleContext} object for the currently executing rule.\n\t// this is always non-null during the parsing process.\n\tthis._ctx = null;\n\t// Specifies whether or not the parser should construct a parse tree during\n\t// the parsing process. The default value is {@code true}.\n\tthis.buildParseTrees = true;\n\t// When {@link //setTrace}{@code (true)} is called, a reference to the\n\t// {@link TraceListener} is stored here so it can be easily removed in a\n\t// later call to {@link //setTrace}{@code (false)}. The listener itself is\n\t// implemented as a parser listener so this field is not directly used by\n\t// other parser methods.\n\tthis._tracer = null;\n\t// The list of {@link ParseTreeListener} listeners registered to receive\n\t// events during the parse.\n\tthis._parseListeners = null;\n\t// The number of syntax errors reported during parsing. this value is\n\t// incremented each time {@link //notifyErrorListeners} is called.\n\tthis._syntaxErrors = 0;\n\tthis.setInputStream(input);\n\treturn this;\n}\n\nParser.prototype = Object.create(Recognizer.prototype);\nParser.prototype.contructor = Parser;\n\n// this field maps from the serialized ATN string to the deserialized {@link\n// ATN} with\n// bypass alternatives.\n//\n// @see ATNDeserializationOptions//isGenerateRuleBypassTransitions()\n//\nParser.bypassAltsAtnCache = {};\n\n// reset the parser's state//\nParser.prototype.reset = function() {\n\tif (this._input !== null) {\n\t\tthis._input.seek(0);\n\t}\n\tthis._errHandler.reset(this);\n\tthis._ctx = null;\n\tthis._syntaxErrors = 0;\n\tthis.setTrace(false);\n\tthis._precedenceStack = [];\n\tthis._precedenceStack.push(0);\n\tif (this._interp !== null) {\n\t\tthis._interp.reset();\n\t}\n};\n\n// Match current input symbol against {@code ttype}. If the symbol type\n// matches, {@link ANTLRErrorStrategy//reportMatch} and {@link //consume} are\n// called to complete the match process.\n//\n// <p>If the symbol type does not match,\n// {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n// strategy to attempt recovery. If {@link //getBuildParseTree} is\n// {@code true} and the token index of the symbol returned by\n// {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n// the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n//\n// @param ttype the token type to match\n// @return the matched symbol\n// @throws RecognitionException if the current input symbol did not match\n// {@code ttype} and the error strategy could not recover from the\n// mismatched symbol\n\nParser.prototype.match = function(ttype) {\n\tvar t = this.getCurrentToken();\n\tif (t.type === ttype) {\n\t\tthis._errHandler.reportMatch(this);\n\t\tthis.consume();\n\t} else {\n\t\tt = this._errHandler.recoverInline(this);\n\t\tif (this.buildParseTrees && t.tokenIndex === -1) {\n\t\t\t// we must have conjured up a new token during single token\n\t\t\t// insertion\n\t\t\t// if it's not the current symbol\n\t\t\tthis._ctx.addErrorNode(t);\n\t\t}\n\t}\n\treturn t;\n};\n// Match current input symbol as a wildcard. If the symbol type matches\n// (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}\n// and {@link //consume} are called to complete the match process.\n//\n// <p>If the symbol type does not match,\n// {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n// strategy to attempt recovery. If {@link //getBuildParseTree} is\n// {@code true} and the token index of the symbol returned by\n// {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n// the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n//\n// @return the matched symbol\n// @throws RecognitionException if the current input symbol did not match\n// a wildcard and the error strategy could not recover from the mismatched\n// symbol\n\nParser.prototype.matchWildcard = function() {\n\tvar t = this.getCurrentToken();\n\tif (t.type > 0) {\n\t\tthis._errHandler.reportMatch(this);\n\t\tthis.consume();\n\t} else {\n\t\tt = this._errHandler.recoverInline(this);\n\t\tif (this._buildParseTrees && t.tokenIndex === -1) {\n\t\t\t// we must have conjured up a new token during single token\n\t\t\t// insertion\n\t\t\t// if it's not the current symbol\n\t\t\tthis._ctx.addErrorNode(t);\n\t\t}\n\t}\n\treturn t;\n};\n\nParser.prototype.getParseListeners = function() {\n\treturn this._parseListeners || [];\n};\n\n// Registers {@code listener} to receive events during the parsing process.\n//\n// <p>To support output-preserving grammar transformations (including but not\n// limited to left-recursion removal, automated left-factoring, and\n// optimized code generation), calls to listener methods during the parse\n// may differ substantially from calls made by\n// {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In\n// particular, rule entry and exit events may occur in a different order\n// during the parse than after the parser. In addition, calls to certain\n// rule entry methods may be omitted.</p>\n//\n// <p>With the following specific exceptions, calls to listener events are\n// <em>deterministic</em>, i.e. for identical input the calls to listener\n// methods will be the same.</p>\n//\n// <ul>\n// <li>Alterations to the grammar used to generate code may change the\n// behavior of the listener calls.</li>\n// <li>Alterations to the command line options passed to ANTLR 4 when\n// generating the parser may change the behavior of the listener calls.</li>\n// <li>Changing the version of the ANTLR Tool used to generate the parser\n// may change the behavior of the listener calls.</li>\n// </ul>\n//\n// @param listener the listener to add\n//\n// @throws NullPointerException if {@code} listener is {@code null}\n//\nParser.prototype.addParseListener = function(listener) {\n\tif (listener === null) {\n\t\tthrow \"listener\";\n\t}\n\tif (this._parseListeners === null) {\n\t\tthis._parseListeners = [];\n\t}\n\tthis._parseListeners.push(listener);\n};\n\n//\n// Remove {@code listener} from the list of parse listeners.\n//\n// <p>If {@code listener} is {@code null} or has not been added as a parse\n// listener, this method does nothing.</p>\n// @param listener the listener to remove\n//\nParser.prototype.removeParseListener = function(listener) {\n\tif (this._parseListeners !== null) {\n\t\tvar idx = this._parseListeners.indexOf(listener);\n\t\tif (idx >= 0) {\n\t\t\tthis._parseListeners.splice(idx, 1);\n\t\t}\n\t\tif (this._parseListeners.length === 0) {\n\t\t\tthis._parseListeners = null;\n\t\t}\n\t}\n};\n\n// Remove all parse listeners.\nParser.prototype.removeParseListeners = function() {\n\tthis._parseListeners = null;\n};\n\n// Notify any parse listeners of an enter rule event.\nParser.prototype.triggerEnterRuleEvent = function() {\n\tif (this._parseListeners !== null) {\n        var ctx = this._ctx;\n\t\tthis._parseListeners.map(function(listener) {\n\t\t\tlistener.enterEveryRule(ctx);\n\t\t\tctx.enterRule(listener);\n\t\t});\n\t}\n};\n\n//\n// Notify any parse listeners of an exit rule event.\n//\n// @see //addParseListener\n//\nParser.prototype.triggerExitRuleEvent = function() {\n\tif (this._parseListeners !== null) {\n\t\t// reverse order walk of listeners\n        var ctx = this._ctx;\n\t\tthis._parseListeners.slice(0).reverse().map(function(listener) {\n\t\t\tctx.exitRule(listener);\n\t\t\tlistener.exitEveryRule(ctx);\n\t\t});\n\t}\n};\n\nParser.prototype.getTokenFactory = function() {\n\treturn this._input.tokenSource._factory;\n};\n\n// Tell our token source and error strategy about a new way to create tokens.//\nParser.prototype.setTokenFactory = function(factory) {\n\tthis._input.tokenSource._factory = factory;\n};\n\n// The ATN with bypass alternatives is expensive to create so we create it\n// lazily.\n//\n// @throws UnsupportedOperationException if the current parser does not\n// implement the {@link //getSerializedATN()} method.\n//\nParser.prototype.getATNWithBypassAlts = function() {\n\tvar serializedAtn = this.getSerializedATN();\n\tif (serializedAtn === null) {\n\t\tthrow \"The current parser does not support an ATN with bypass alternatives.\";\n\t}\n\tvar result = this.bypassAltsAtnCache[serializedAtn];\n\tif (result === null) {\n\t\tvar deserializationOptions = new ATNDeserializationOptions();\n\t\tdeserializationOptions.generateRuleBypassTransitions = true;\n\t\tresult = new ATNDeserializer(deserializationOptions)\n\t\t\t\t.deserialize(serializedAtn);\n\t\tthis.bypassAltsAtnCache[serializedAtn] = result;\n\t}\n\treturn result;\n};\n\n// The preferred method of getting a tree pattern. For example, here's a\n// sample use:\n//\n// <pre>\n// ParseTree t = parser.expr();\n// ParseTreePattern p = parser.compileParseTreePattern(\"&lt;ID&gt;+0\",\n// MyParser.RULE_expr);\n// ParseTreeMatch m = p.match(t);\n// String id = m.get(\"ID\");\n// </pre>\n\nvar Lexer = require('./Lexer').Lexer;\n\nParser.prototype.compileParseTreePattern = function(pattern, patternRuleIndex, lexer) {\n\tlexer = lexer || null;\n\tif (lexer === null) {\n\t\tif (this.getTokenStream() !== null) {\n\t\t\tvar tokenSource = this.getTokenStream().tokenSource;\n\t\t\tif (tokenSource instanceof Lexer) {\n\t\t\t\tlexer = tokenSource;\n\t\t\t}\n\t\t}\n\t}\n\tif (lexer === null) {\n\t\tthrow \"Parser can't discover a lexer to use\";\n\t}\n\tvar m = new ParseTreePatternMatcher(lexer, this);\n\treturn m.compile(pattern, patternRuleIndex);\n};\n\nParser.prototype.getInputStream = function() {\n\treturn this.getTokenStream();\n};\n\nParser.prototype.setInputStream = function(input) {\n\tthis.setTokenStream(input);\n};\n\nParser.prototype.getTokenStream = function() {\n\treturn this._input;\n};\n\n// Set the token stream and reset the parser.//\nParser.prototype.setTokenStream = function(input) {\n\tthis._input = null;\n\tthis.reset();\n\tthis._input = input;\n};\n\n// Match needs to return the current input symbol, which gets put\n// into the label for the associated token ref; e.g., x=ID.\n//\nParser.prototype.getCurrentToken = function() {\n\treturn this._input.LT(1);\n};\n\nParser.prototype.notifyErrorListeners = function(msg, offendingToken, err) {\n\toffendingToken = offendingToken || null;\n\terr = err || null;\n\tif (offendingToken === null) {\n\t\toffendingToken = this.getCurrentToken();\n\t}\n\tthis._syntaxErrors += 1;\n\tvar line = offendingToken.line;\n\tvar column = offendingToken.column;\n\tvar listener = this.getErrorListenerDispatch();\n\tlistener.syntaxError(this, offendingToken, line, column, msg, err);\n};\n\n//\n// Consume and return the {@linkplain //getCurrentToken current symbol}.\n//\n// <p>E.g., given the following input with {@code A} being the current\n// lookahead symbol, this function moves the cursor to {@code B} and returns\n// {@code A}.</p>\n//\n// <pre>\n// A B\n// ^\n// </pre>\n//\n// If the parser is not in error recovery mode, the consumed symbol is added\n// to the parse tree using {@link ParserRuleContext//addChild(Token)}, and\n// {@link ParseTreeListener//visitTerminal} is called on any parse listeners.\n// If the parser <em>is</em> in error recovery mode, the consumed symbol is\n// added to the parse tree using\n// {@link ParserRuleContext//addErrorNode(Token)}, and\n// {@link ParseTreeListener//visitErrorNode} is called on any parse\n// listeners.\n//\nParser.prototype.consume = function() {\n\tvar o = this.getCurrentToken();\n\tif (o.type !== Token.EOF) {\n\t\tthis.getInputStream().consume();\n\t}\n\tvar hasListener = this._parseListeners !== null && this._parseListeners.length > 0;\n\tif (this.buildParseTrees || hasListener) {\n\t\tvar node;\n\t\tif (this._errHandler.inErrorRecoveryMode(this)) {\n\t\t\tnode = this._ctx.addErrorNode(o);\n\t\t} else {\n\t\t\tnode = this._ctx.addTokenNode(o);\n\t\t}\n        node.invokingState = this.state;\n\t\tif (hasListener) {\n\t\t\tthis._parseListeners.map(function(listener) {\n\t\t\t\tlistener.visitTerminal(node);\n\t\t\t});\n\t\t}\n\t}\n\treturn o;\n};\n\nParser.prototype.addContextToParseTree = function() {\n\t// add current context to parent if we have a parent\n\tif (this._ctx.parentCtx !== null) {\n\t\tthis._ctx.parentCtx.addChild(this._ctx);\n\t}\n};\n\n// Always called by generated parsers upon entry to a rule. Access field\n// {@link //_ctx} get the current context.\n\nParser.prototype.enterRule = function(localctx, state, ruleIndex) {\n\tthis.state = state;\n\tthis._ctx = localctx;\n\tthis._ctx.start = this._input.LT(1);\n\tif (this.buildParseTrees) {\n\t\tthis.addContextToParseTree();\n\t}\n\tif (this._parseListeners !== null) {\n\t\tthis.triggerEnterRuleEvent();\n\t}\n};\n\nParser.prototype.exitRule = function() {\n\tthis._ctx.stop = this._input.LT(-1);\n\t// trigger event on _ctx, before it reverts to parent\n\tif (this._parseListeners !== null) {\n\t\tthis.triggerExitRuleEvent();\n\t}\n\tthis.state = this._ctx.invokingState;\n\tthis._ctx = this._ctx.parentCtx;\n};\n\nParser.prototype.enterOuterAlt = function(localctx, altNum) {\n   \tlocalctx.setAltNumber(altNum);\n\t// if we have new localctx, make sure we replace existing ctx\n\t// that is previous child of parse tree\n\tif (this.buildParseTrees && this._ctx !== localctx) {\n\t\tif (this._ctx.parentCtx !== null) {\n\t\t\tthis._ctx.parentCtx.removeLastChild();\n\t\t\tthis._ctx.parentCtx.addChild(localctx);\n\t\t}\n\t}\n\tthis._ctx = localctx;\n};\n\n// Get the precedence level for the top-most precedence rule.\n//\n// @return The precedence level for the top-most precedence rule, or -1 if\n// the parser context is not nested within a precedence rule.\n\nParser.prototype.getPrecedence = function() {\n\tif (this._precedenceStack.length === 0) {\n\t\treturn -1;\n\t} else {\n\t\treturn this._precedenceStack[this._precedenceStack.length-1];\n\t}\n};\n\nParser.prototype.enterRecursionRule = function(localctx, state, ruleIndex,\n\t\tprecedence) {\n\tthis.state = state;\n\tthis._precedenceStack.push(precedence);\n\tthis._ctx = localctx;\n\tthis._ctx.start = this._input.LT(1);\n\tif (this._parseListeners !== null) {\n\t\tthis.triggerEnterRuleEvent(); // simulates rule entry for\n\t\t\t\t\t\t\t\t\t\t// left-recursive rules\n\t}\n};\n\n//\n// Like {@link //enterRule} but for recursive rules.\n\nParser.prototype.pushNewRecursionContext = function(localctx, state, ruleIndex) {\n\tvar previous = this._ctx;\n\tprevious.parentCtx = localctx;\n\tprevious.invokingState = state;\n\tprevious.stop = this._input.LT(-1);\n\n\tthis._ctx = localctx;\n\tthis._ctx.start = previous.start;\n\tif (this.buildParseTrees) {\n\t\tthis._ctx.addChild(previous);\n\t}\n\tif (this._parseListeners !== null) {\n\t\tthis.triggerEnterRuleEvent(); // simulates rule entry for\n\t\t\t\t\t\t\t\t\t\t// left-recursive rules\n\t}\n};\n\nParser.prototype.unrollRecursionContexts = function(parentCtx) {\n\tthis._precedenceStack.pop();\n\tthis._ctx.stop = this._input.LT(-1);\n\tvar retCtx = this._ctx; // save current ctx (return value)\n\t// unroll so _ctx is as it was before call to recursive method\n\tif (this._parseListeners !== null) {\n\t\twhile (this._ctx !== parentCtx) {\n\t\t\tthis.triggerExitRuleEvent();\n\t\t\tthis._ctx = this._ctx.parentCtx;\n\t\t}\n\t} else {\n\t\tthis._ctx = parentCtx;\n\t}\n\t// hook into tree\n\tretCtx.parentCtx = parentCtx;\n\tif (this.buildParseTrees && parentCtx !== null) {\n\t\t// add return ctx into invoking rule's tree\n\t\tparentCtx.addChild(retCtx);\n\t}\n};\n\nParser.prototype.getInvokingContext = function(ruleIndex) {\n\tvar ctx = this._ctx;\n\twhile (ctx !== null) {\n\t\tif (ctx.ruleIndex === ruleIndex) {\n\t\t\treturn ctx;\n\t\t}\n\t\tctx = ctx.parentCtx;\n\t}\n\treturn null;\n};\n\nParser.prototype.precpred = function(localctx, precedence) {\n\treturn precedence >= this._precedenceStack[this._precedenceStack.length-1];\n};\n\nParser.prototype.inContext = function(context) {\n\t// TODO: useful in parser?\n\treturn false;\n};\n\n//\n// Checks whether or not {@code symbol} can follow the current state in the\n// ATN. The behavior of this method is equivalent to the following, but is\n// implemented such that the complete context-sensitive follow set does not\n// need to be explicitly constructed.\n//\n// <pre>\n// return getExpectedTokens().contains(symbol);\n// </pre>\n//\n// @param symbol the symbol type to check\n// @return {@code true} if {@code symbol} can follow the current state in\n// the ATN, otherwise {@code false}.\n\nParser.prototype.isExpectedToken = function(symbol) {\n\tvar atn = this._interp.atn;\n\tvar ctx = this._ctx;\n\tvar s = atn.states[this.state];\n\tvar following = atn.nextTokens(s);\n\tif (following.contains(symbol)) {\n\t\treturn true;\n\t}\n\tif (!following.contains(Token.EPSILON)) {\n\t\treturn false;\n\t}\n\twhile (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n\t\tvar invokingState = atn.states[ctx.invokingState];\n\t\tvar rt = invokingState.transitions[0];\n\t\tfollowing = atn.nextTokens(rt.followState);\n\t\tif (following.contains(symbol)) {\n\t\t\treturn true;\n\t\t}\n\t\tctx = ctx.parentCtx;\n\t}\n\tif (following.contains(Token.EPSILON) && symbol === Token.EOF) {\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n};\n\n// Computes the set of input symbols which could follow the current parser\n// state and context, as given by {@link //getState} and {@link //getContext},\n// respectively.\n//\n// @see ATN//getExpectedTokens(int, RuleContext)\n//\nParser.prototype.getExpectedTokens = function() {\n\treturn this._interp.atn.getExpectedTokens(this.state, this._ctx);\n};\n\nParser.prototype.getExpectedTokensWithinCurrentRule = function() {\n\tvar atn = this._interp.atn;\n\tvar s = atn.states[this.state];\n\treturn atn.nextTokens(s);\n};\n\n// Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.//\nParser.prototype.getRuleIndex = function(ruleName) {\n\tvar ruleIndex = this.getRuleIndexMap()[ruleName];\n\tif (ruleIndex !== null) {\n\t\treturn ruleIndex;\n\t} else {\n\t\treturn -1;\n\t}\n};\n\n// Return List&lt;String&gt; of the rule names in your parser instance\n// leading up to a call to the current rule. You could override if\n// you want more details such as the file/line info of where\n// in the ATN a rule is invoked.\n//\n// this is very useful for error messages.\n//\nParser.prototype.getRuleInvocationStack = function(p) {\n\tp = p || null;\n\tif (p === null) {\n\t\tp = this._ctx;\n\t}\n\tvar stack = [];\n\twhile (p !== null) {\n\t\t// compute what follows who invoked us\n\t\tvar ruleIndex = p.ruleIndex;\n\t\tif (ruleIndex < 0) {\n\t\t\tstack.push(\"n/a\");\n\t\t} else {\n\t\t\tstack.push(this.ruleNames[ruleIndex]);\n\t\t}\n\t\tp = p.parentCtx;\n\t}\n\treturn stack;\n};\n\n// For debugging and other purposes.//\nParser.prototype.getDFAStrings = function() {\n\treturn this._interp.decisionToDFA.toString();\n};\n// For debugging and other purposes.//\nParser.prototype.dumpDFA = function() {\n\tvar seenOne = false;\n\tfor (var i = 0; i < this._interp.decisionToDFA.length; i++) {\n\t\tvar dfa = this._interp.decisionToDFA[i];\n\t\tif (dfa.states.length > 0) {\n\t\t\tif (seenOne) {\n\t\t\t\tconsole.log();\n\t\t\t}\n\t\t\tthis.printer.println(\"Decision \" + dfa.decision + \":\");\n\t\t\tthis.printer.print(dfa.toString(this.literalNames, this.symbolicNames));\n\t\t\tseenOne = true;\n\t\t}\n\t}\n};\n\n/*\n\"\t\t\tprinter = function() {\\r\\n\" +\n\"\t\t\t\tthis.println = function(s) { document.getElementById('output') += s + '\\\\n'; }\\r\\n\" +\n\"\t\t\t\tthis.print = function(s) { document.getElementById('output') += s; }\\r\\n\" +\n\"\t\t\t};\\r\\n\" +\n*/\n\nParser.prototype.getSourceName = function() {\n\treturn this._input.sourceName;\n};\n\n// During a parse is sometimes useful to listen in on the rule entry and exit\n// events as well as token matches. this is for quick and dirty debugging.\n//\nParser.prototype.setTrace = function(trace) {\n\tif (!trace) {\n\t\tthis.removeParseListener(this._tracer);\n\t\tthis._tracer = null;\n\t} else {\n\t\tif (this._tracer !== null) {\n\t\t\tthis.removeParseListener(this._tracer);\n\t\t}\n\t\tthis._tracer = new TraceListener(this);\n\t\tthis.addParseListener(this._tracer);\n\t}\n};\n\nexports.Parser = Parser;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/antlr4/Parser.js\n ** module id = 48\n ** module chunks = 0\n **/","// Generated from Calculator.g4 by ANTLR 4.5.2\r\n// jshint ignore: start\r\nvar antlr4 = require('antlr4/index');\r\nvar CalculatorVisitor = require('./CalculatorVisitor').CalculatorVisitor;\r\n\r\nvar grammarFileName = \"Calculator.g4\";\r\n\r\nvar serializedATN = [\"\\u0003\\u0430\\ud6d1\\u8206\\uad2d\\u4417\\uaef1\\u8d80\\uaadd\",\r\n    \"\\u00035{\\u0004\\u0002\\t\\u0002\\u0004\\u0003\\t\\u0003\\u0004\\u0004\\t\\u0004\",\r\n    \"\\u0003\\u0002\\u0003\\u0002\\u0005\\u0002\\u000b\\n\\u0002\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0005\\u0003W\\n\\u0003\\u0003\\u0003\\u0005\\u0003Z\\n\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\",\r\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0007\\u0003\",\r\n    \"t\\n\\u0003\\f\\u0003\\u000e\\u0003w\\u000b\\u0003\\u0003\\u0004\\u0003\\u0004\\u0003\",\r\n    \"\\u0004\\u0002\\u0003\\u0004\\u0005\\u0002\\u0004\\u0006\\u0002\\u0007\\u0003\\u0002\",\r\n    \"\\u0006\\u0007\\u0004\\u0002\\b\\b\\u000f\\u000f\\u0003\\u0002\\t\\n\\u0003\\u0002\",\r\n    \"\\u0011\\u0012\\u0003\\u0002\\u0013\\u0014\\u00a0\\u0002\\b\\u0003\\u0002\\u0002\",\r\n    \"\\u0002\\u0004Y\\u0003\\u0002\\u0002\\u0002\\u0006x\\u0003\\u0002\\u0002\\u0002\",\r\n    \"\\b\\n\\u0005\\u0004\\u0003\\u0002\\t\\u000b\\u0005\\u0006\\u0004\\u0002\\n\\t\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\n\\u000b\\u0003\\u0002\\u0002\\u0002\\u000b\\u0003\\u0003\",\r\n    \"\\u0002\\u0002\\u0002\\f\\r\\b\\u0003\\u0001\\u0002\\r\\u000e\\u0007\\u001b\\u0002\",\r\n    \"\\u0002\\u000eZ\\u0005\\u0004\\u0003*\\u000f\\u0010\\u0007\\u001c\\u0002\\u0002\",\r\n    \"\\u0010Z\\u0005\\u0004\\u0003)\\u0011\\u0012\\u0007\\u001d\\u0002\\u0002\\u0012\",\r\n    \"Z\\u0005\\u0004\\u0003(\\u0013\\u0014\\u0007\\u001f\\u0002\\u0002\\u0014Z\\u0005\",\r\n    \"\\u0004\\u0003&\\u0015\\u0016\\u0007 \\u0002\\u0002\\u0016Z\\u0005\\u0004\\u0003\",\r\n    \"%\\u0017\\u0018\\u0007!\\u0002\\u0002\\u0018Z\\u0005\\u0004\\u0003$\\u0019\\u001a\",\r\n    \"\\u0007\\\"\\u0002\\u0002\\u001aZ\\u0005\\u0004\\u0003#\\u001b\\u001c\\u0007#\\u0002\",\r\n    \"\\u0002\\u001cZ\\u0005\\u0004\\u0003\\\"\\u001d\\u001e\\u0007$\\u0002\\u0002\\u001e\",\r\n    \"Z\\u0005\\u0004\\u0003!\\u001f \\u0007%\\u0002\\u0002 Z\\u0005\\u0004\\u0003 \",\r\n    \"!\\\"\\u0007&\\u0002\\u0002\\\"Z\\u0005\\u0004\\u0003\\u001f#$\\u0007\\'\\u0002\\u0002\",\r\n    \"$Z\\u0005\\u0004\\u0003\\u001e%&\\u0007(\\u0002\\u0002&Z\\u0005\\u0004\\u0003\",\r\n    \"\\u001d\\'(\\u0007)\\u0002\\u0002(Z\\u0005\\u0004\\u0003\\u001c)*\\u0007*\\u0002\",\r\n    \"\\u0002*Z\\u0005\\u0004\\u0003\\u001b+,\\u0007,\\u0002\\u0002,Z\\u0005\\u0004\",\r\n    \"\\u0003\\u0019-.\\u0007-\\u0002\\u0002.Z\\u0005\\u0004\\u0003\\u0018/0\\u0007\",\r\n    \".\\u0002\\u00020Z\\u0005\\u0004\\u0003\\u001712\\u0007/\\u0002\\u00022Z\\u0005\",\r\n    \"\\u0004\\u0003\\u001634\\u00070\\u0002\\u00024Z\\u0005\\u0004\\u0003\\u001556\",\r\n    \"\\u00071\\u0002\\u00026Z\\u0005\\u0004\\u0003\\u001478\\u00072\\u0002\\u00028\",\r\n    \"Z\\u0005\\u0004\\u0003\\u00139:\\u0007\\u0019\\u0002\\u0002:Z\\u0005\\u0004\\u0003\",\r\n    \"\\u0012;<\\u0007\\u001a\\u0002\\u0002<Z\\u0005\\u0004\\u0003\\u0011=>\\u0007\\u0014\",\r\n    \"\\u0002\\u0002>Z\\u0005\\u0004\\u0003\\u0004?@\\u0007\\u0013\\u0002\\u0002@Z\\u0005\",\r\n    \"\\u0004\\u0003\\u0003AB\\u0007\\u001e\\u0002\\u0002BC\\u0007\\u0003\\u0002\\u0002\",\r\n    \"CD\\u0005\\u0004\\u0003\\u0002DE\\u0007\\u0004\\u0002\\u0002EF\\u0005\\u0004\\u0003\",\r\n    \"\\u0002FG\\u0007\\u0005\\u0002\\u0002GZ\\u0003\\u0002\\u0002\\u0002HI\\u0007+\",\r\n    \"\\u0002\\u0002IJ\\u0007\\u0003\\u0002\\u0002JK\\u0005\\u0004\\u0003\\u0002KL\\u0007\",\r\n    \"\\u0004\\u0002\\u0002LM\\u0005\\u0004\\u0003\\u0002MN\\u0007\\u0005\\u0002\\u0002\",\r\n    \"NZ\\u0003\\u0002\\u0002\\u0002OZ\\u0007\\f\\u0002\\u0002PQ\\u0007\\u0003\\u0002\",\r\n    \"\\u0002QR\\u0005\\u0004\\u0003\\u0002RS\\u0007\\u0005\\u0002\\u0002SZ\\u0003\\u0002\",\r\n    \"\\u0002\\u0002TV\\u0007\\u0015\\u0002\\u0002UW\\u0007\\u000b\\u0002\\u0002VU\\u0003\",\r\n    \"\\u0002\\u0002\\u0002VW\\u0003\\u0002\\u0002\\u0002WZ\\u0003\\u0002\\u0002\\u0002\",\r\n    \"XZ\\u0007\\u0018\\u0002\\u0002Y\\f\\u0003\\u0002\\u0002\\u0002Y\\u000f\\u0003\\u0002\",\r\n    \"\\u0002\\u0002Y\\u0011\\u0003\\u0002\\u0002\\u0002Y\\u0013\\u0003\\u0002\\u0002\",\r\n    \"\\u0002Y\\u0015\\u0003\\u0002\\u0002\\u0002Y\\u0017\\u0003\\u0002\\u0002\\u0002\",\r\n    \"Y\\u0019\\u0003\\u0002\\u0002\\u0002Y\\u001b\\u0003\\u0002\\u0002\\u0002Y\\u001d\",\r\n    \"\\u0003\\u0002\\u0002\\u0002Y\\u001f\\u0003\\u0002\\u0002\\u0002Y!\\u0003\\u0002\",\r\n    \"\\u0002\\u0002Y#\\u0003\\u0002\\u0002\\u0002Y%\\u0003\\u0002\\u0002\\u0002Y\\'\",\r\n    \"\\u0003\\u0002\\u0002\\u0002Y)\\u0003\\u0002\\u0002\\u0002Y+\\u0003\\u0002\\u0002\",\r\n    \"\\u0002Y-\\u0003\\u0002\\u0002\\u0002Y/\\u0003\\u0002\\u0002\\u0002Y1\\u0003\\u0002\",\r\n    \"\\u0002\\u0002Y3\\u0003\\u0002\\u0002\\u0002Y5\\u0003\\u0002\\u0002\\u0002Y7\\u0003\",\r\n    \"\\u0002\\u0002\\u0002Y9\\u0003\\u0002\\u0002\\u0002Y;\\u0003\\u0002\\u0002\\u0002\",\r\n    \"Y=\\u0003\\u0002\\u0002\\u0002Y?\\u0003\\u0002\\u0002\\u0002YA\\u0003\\u0002\\u0002\",\r\n    \"\\u0002YH\\u0003\\u0002\\u0002\\u0002YO\\u0003\\u0002\\u0002\\u0002YP\\u0003\\u0002\",\r\n    \"\\u0002\\u0002YT\\u0003\\u0002\\u0002\\u0002YX\\u0003\\u0002\\u0002\\u0002Zu\\u0003\",\r\n    \"\\u0002\\u0002\\u0002[\\\\\\f\\u0010\\u0002\\u0002\\\\]\\t\\u0002\\u0002\\u0002]t\\u0005\",\r\n    \"\\u0004\\u0003\\u0011^_\\f\\u000f\\u0002\\u0002_`\\t\\u0003\\u0002\\u0002`t\\u0005\",\r\n    \"\\u0004\\u0003\\u0010ab\\f\\u000e\\u0002\\u0002bc\\u0007\\u0010\\u0002\\u0002c\",\r\n    \"t\\u0005\\u0004\\u0003\\u000fde\\f\\r\\u0002\\u0002ef\\t\\u0004\\u0002\\u0002ft\",\r\n    \"\\u0005\\u0004\\u0003\\u000egh\\f\\f\\u0002\\u0002hi\\t\\u0005\\u0002\\u0002it\\u0005\",\r\n    \"\\u0004\\u0003\\rjk\\f\\u000b\\u0002\\u0002kl\\t\\u0006\\u0002\\u0002lt\\u0005\\u0004\",\r\n    \"\\u0003\\fmn\\f\\u0007\\u0002\\u0002no\\u0007\\u0016\\u0002\\u0002ot\\u0005\\u0004\",\r\n    \"\\u0003\\bpq\\f\\u0006\\u0002\\u0002qr\\u0007\\u0017\\u0002\\u0002rt\\u0005\\u0004\",\r\n    \"\\u0003\\u0007s[\\u0003\\u0002\\u0002\\u0002s^\\u0003\\u0002\\u0002\\u0002sa\\u0003\",\r\n    \"\\u0002\\u0002\\u0002sd\\u0003\\u0002\\u0002\\u0002sg\\u0003\\u0002\\u0002\\u0002\",\r\n    \"sj\\u0003\\u0002\\u0002\\u0002sm\\u0003\\u0002\\u0002\\u0002sp\\u0003\\u0002\\u0002\",\r\n    \"\\u0002tw\\u0003\\u0002\\u0002\\u0002us\\u0003\\u0002\\u0002\\u0002uv\\u0003\\u0002\",\r\n    \"\\u0002\\u0002v\\u0005\\u0003\\u0002\\u0002\\u0002wu\\u0003\\u0002\\u0002\\u0002\",\r\n    \"xy\\u0007\\u0002\\u0002\\u0003y\\u0007\\u0003\\u0002\\u0002\\u0002\\u0007\\nVY\",\r\n    \"su\"].join(\"\");\r\n\r\n\r\nvar atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);\r\n\r\nvar decisionsToDFA = atn.decisionToState.map( function(ds, index) { return new antlr4.dfa.DFA(ds, index); });\r\n\r\nvar sharedContextCache = new antlr4.PredictionContextCache();\r\n\r\nvar literalNames = [ null, \"'('\", \"';'\", \"')'\", \"'^'\", \"'**'\", \"'%'\", \"'~'\", \r\n                     \"'//'\", \"'()'\", null, null, null, null, null, \"'*'\", \r\n                     \"'/'\", \"'+'\", \"'-'\" ];\r\n\r\nvar symbolicNames = [ null, null, null, null, null, null, null, null, null, \r\n                      null, \"NUMBER\", \"FLOAT\", \"DIGIT\", \"MOD\", \"WHOLE\", \r\n                      \"MUL\", \"DIV\", \"ADD\", \"SUB\", \"PI\", \"EXPONENT\", \"NEGEXPONENT\", \r\n                      \"EULER\", \"SQRT\", \"SQR\", \"FLOOR\", \"CEIL\", \"ABS\", \"ROUNDK\", \r\n                      \"ROUND\", \"TRUNC\", \"SIN\", \"COS\", \"TAN\", \"COT\", \"SINH\", \r\n                      \"COSH\", \"TANH\", \"ARCSIN\", \"ARCCOS\", \"ARCTAN\", \"ARCTAN2\", \r\n                      \"ARCCOT\", \"EXP\", \"LN\", \"EEX\", \"LOG\", \"RAD\", \"DEG\", \r\n                      \"WS\", \"COM\", \"INVALID\" ];\r\n\r\nvar ruleNames =  [ \"calculator\", \"expression\", \"compileUnit\" ];\r\n\r\nfunction CalculatorParser (input) {\r\n\tantlr4.Parser.call(this, input);\r\n    this._interp = new antlr4.atn.ParserATNSimulator(this, atn, decisionsToDFA, sharedContextCache);\r\n    this.ruleNames = ruleNames;\r\n    this.literalNames = literalNames;\r\n    this.symbolicNames = symbolicNames;\r\n    return this;\r\n}\r\n\r\nCalculatorParser.prototype = Object.create(antlr4.Parser.prototype);\r\nCalculatorParser.prototype.constructor = CalculatorParser;\r\n\r\nObject.defineProperty(CalculatorParser.prototype, \"atn\", {\r\n\tget : function() {\r\n\t\treturn atn;\r\n\t}\r\n});\r\n\r\nCalculatorParser.EOF = antlr4.Token.EOF;\r\nCalculatorParser.T__0 = 1;\r\nCalculatorParser.T__1 = 2;\r\nCalculatorParser.T__2 = 3;\r\nCalculatorParser.T__3 = 4;\r\nCalculatorParser.T__4 = 5;\r\nCalculatorParser.T__5 = 6;\r\nCalculatorParser.T__6 = 7;\r\nCalculatorParser.T__7 = 8;\r\nCalculatorParser.T__8 = 9;\r\nCalculatorParser.NUMBER = 10;\r\nCalculatorParser.FLOAT = 11;\r\nCalculatorParser.DIGIT = 12;\r\nCalculatorParser.MOD = 13;\r\nCalculatorParser.WHOLE = 14;\r\nCalculatorParser.MUL = 15;\r\nCalculatorParser.DIV = 16;\r\nCalculatorParser.ADD = 17;\r\nCalculatorParser.SUB = 18;\r\nCalculatorParser.PI = 19;\r\nCalculatorParser.EXPONENT = 20;\r\nCalculatorParser.NEGEXPONENT = 21;\r\nCalculatorParser.EULER = 22;\r\nCalculatorParser.SQRT = 23;\r\nCalculatorParser.SQR = 24;\r\nCalculatorParser.FLOOR = 25;\r\nCalculatorParser.CEIL = 26;\r\nCalculatorParser.ABS = 27;\r\nCalculatorParser.ROUNDK = 28;\r\nCalculatorParser.ROUND = 29;\r\nCalculatorParser.TRUNC = 30;\r\nCalculatorParser.SIN = 31;\r\nCalculatorParser.COS = 32;\r\nCalculatorParser.TAN = 33;\r\nCalculatorParser.COT = 34;\r\nCalculatorParser.SINH = 35;\r\nCalculatorParser.COSH = 36;\r\nCalculatorParser.TANH = 37;\r\nCalculatorParser.ARCSIN = 38;\r\nCalculatorParser.ARCCOS = 39;\r\nCalculatorParser.ARCTAN = 40;\r\nCalculatorParser.ARCTAN2 = 41;\r\nCalculatorParser.ARCCOT = 42;\r\nCalculatorParser.EXP = 43;\r\nCalculatorParser.LN = 44;\r\nCalculatorParser.EEX = 45;\r\nCalculatorParser.LOG = 46;\r\nCalculatorParser.RAD = 47;\r\nCalculatorParser.DEG = 48;\r\nCalculatorParser.WS = 49;\r\nCalculatorParser.COM = 50;\r\nCalculatorParser.INVALID = 51;\r\n\r\nCalculatorParser.RULE_calculator = 0;\r\nCalculatorParser.RULE_expression = 1;\r\nCalculatorParser.RULE_compileUnit = 2;\r\n\r\nfunction CalculatorContext(parser, parent, invokingState) {\r\n\tif(parent===undefined) {\r\n\t    parent = null;\r\n\t}\r\n\tif(invokingState===undefined || invokingState===null) {\r\n\t\tinvokingState = -1;\r\n\t}\r\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = CalculatorParser.RULE_calculator;\r\n    return this;\r\n}\r\n\r\nCalculatorContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\r\nCalculatorContext.prototype.constructor = CalculatorContext;\r\n\r\nCalculatorContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\n\r\nCalculatorContext.prototype.compileUnit = function() {\r\n    return this.getTypedRuleContext(CompileUnitContext,0);\r\n};\r\n\r\nCalculatorContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitCalculator(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\n\r\n\r\nCalculatorParser.CalculatorContext = CalculatorContext;\r\n\r\nCalculatorParser.prototype.calculator = function() {\r\n\r\n    var localctx = new CalculatorContext(this, this._ctx, this.state);\r\n    this.enterRule(localctx, 0, CalculatorParser.RULE_calculator);\r\n    try {\r\n        this.enterOuterAlt(localctx, 1);\r\n        this.state = 6;\r\n        this.expression(0);\r\n        this.state = 8;\r\n        this._errHandler.sync(this);\r\n        var la_ = this._interp.adaptivePredict(this._input,0,this._ctx);\r\n        if(la_===1) {\r\n            this.state = 7;\r\n            this.compileUnit();\r\n\r\n        }\r\n    } catch (re) {\r\n    \tif(re instanceof antlr4.error.RecognitionException) {\r\n\t        localctx.exception = re;\r\n\t        this._errHandler.reportError(this, re);\r\n\t        this._errHandler.recover(this, re);\r\n\t    } else {\r\n\t    \tthrow re;\r\n\t    }\r\n    } finally {\r\n        this.exitRule();\r\n    }\r\n    return localctx;\r\n};\r\n\r\nfunction ExpressionContext(parser, parent, invokingState) {\r\n\tif(parent===undefined) {\r\n\t    parent = null;\r\n\t}\r\n\tif(invokingState===undefined || invokingState===null) {\r\n\t\tinvokingState = -1;\r\n\t}\r\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = CalculatorParser.RULE_expression;\r\n    return this;\r\n}\r\n\r\nExpressionContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\r\nExpressionContext.prototype.constructor = ExpressionContext;\r\n\r\n\r\n \r\nExpressionContext.prototype.copyFrom = function(ctx) {\r\n    antlr4.ParserRuleContext.prototype.copyFrom.call(this, ctx);\r\n};\r\n\r\nfunction TanContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nTanContext.prototype = Object.create(ExpressionContext.prototype);\r\nTanContext.prototype.constructor = TanContext;\r\n\r\nCalculatorParser.TanContext = TanContext;\r\n\r\nTanContext.prototype.TAN = function() {\r\n    return this.getToken(CalculatorParser.TAN, 0);\r\n};\r\n\r\nTanContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nTanContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitTan(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction CoshContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nCoshContext.prototype = Object.create(ExpressionContext.prototype);\r\nCoshContext.prototype.constructor = CoshContext;\r\n\r\nCalculatorParser.CoshContext = CoshContext;\r\n\r\nCoshContext.prototype.COSH = function() {\r\n    return this.getToken(CalculatorParser.COSH, 0);\r\n};\r\n\r\nCoshContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nCoshContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitCosh(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction SqRootContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    this.op = null; // Token;\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nSqRootContext.prototype = Object.create(ExpressionContext.prototype);\r\nSqRootContext.prototype.constructor = SqRootContext;\r\n\r\nCalculatorParser.SqRootContext = SqRootContext;\r\n\r\nSqRootContext.prototype.expression = function(i) {\r\n    if(i===undefined) {\r\n        i = null;\r\n    }\r\n    if(i===null) {\r\n        return this.getTypedRuleContexts(ExpressionContext);\r\n    } else {\r\n        return this.getTypedRuleContext(ExpressionContext,i);\r\n    }\r\n};\r\nSqRootContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitSqRoot(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction NegExponentContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nNegExponentContext.prototype = Object.create(ExpressionContext.prototype);\r\nNegExponentContext.prototype.constructor = NegExponentContext;\r\n\r\nCalculatorParser.NegExponentContext = NegExponentContext;\r\n\r\nNegExponentContext.prototype.expression = function(i) {\r\n    if(i===undefined) {\r\n        i = null;\r\n    }\r\n    if(i===null) {\r\n        return this.getTypedRuleContexts(ExpressionContext);\r\n    } else {\r\n        return this.getTypedRuleContext(ExpressionContext,i);\r\n    }\r\n};\r\n\r\nNegExponentContext.prototype.NEGEXPONENT = function() {\r\n    return this.getToken(CalculatorParser.NEGEXPONENT, 0);\r\n};\r\nNegExponentContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitNegExponent(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction ExponentContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nExponentContext.prototype = Object.create(ExpressionContext.prototype);\r\nExponentContext.prototype.constructor = ExponentContext;\r\n\r\nCalculatorParser.ExponentContext = ExponentContext;\r\n\r\nExponentContext.prototype.expression = function(i) {\r\n    if(i===undefined) {\r\n        i = null;\r\n    }\r\n    if(i===null) {\r\n        return this.getTypedRuleContexts(ExpressionContext);\r\n    } else {\r\n        return this.getTypedRuleContext(ExpressionContext,i);\r\n    }\r\n};\r\n\r\nExponentContext.prototype.EXPONENT = function() {\r\n    return this.getToken(CalculatorParser.EXPONENT, 0);\r\n};\r\nExponentContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitExponent(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction Arctan2Context(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nArctan2Context.prototype = Object.create(ExpressionContext.prototype);\r\nArctan2Context.prototype.constructor = Arctan2Context;\r\n\r\nCalculatorParser.Arctan2Context = Arctan2Context;\r\n\r\nArctan2Context.prototype.ARCTAN2 = function() {\r\n    return this.getToken(CalculatorParser.ARCTAN2, 0);\r\n};\r\n\r\nArctan2Context.prototype.expression = function(i) {\r\n    if(i===undefined) {\r\n        i = null;\r\n    }\r\n    if(i===null) {\r\n        return this.getTypedRuleContexts(ExpressionContext);\r\n    } else {\r\n        return this.getTypedRuleContext(ExpressionContext,i);\r\n    }\r\n};\r\nArctan2Context.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitArctan2(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction MulDivContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    this.op = null; // Token;\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nMulDivContext.prototype = Object.create(ExpressionContext.prototype);\r\nMulDivContext.prototype.constructor = MulDivContext;\r\n\r\nCalculatorParser.MulDivContext = MulDivContext;\r\n\r\nMulDivContext.prototype.expression = function(i) {\r\n    if(i===undefined) {\r\n        i = null;\r\n    }\r\n    if(i===null) {\r\n        return this.getTypedRuleContexts(ExpressionContext);\r\n    } else {\r\n        return this.getTypedRuleContext(ExpressionContext,i);\r\n    }\r\n};\r\nMulDivContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitMulDiv(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction ArcsinContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nArcsinContext.prototype = Object.create(ExpressionContext.prototype);\r\nArcsinContext.prototype.constructor = ArcsinContext;\r\n\r\nCalculatorParser.ArcsinContext = ArcsinContext;\r\n\r\nArcsinContext.prototype.ARCSIN = function() {\r\n    return this.getToken(CalculatorParser.ARCSIN, 0);\r\n};\r\n\r\nArcsinContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nArcsinContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitArcsin(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction UnaryPlusContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nUnaryPlusContext.prototype = Object.create(ExpressionContext.prototype);\r\nUnaryPlusContext.prototype.constructor = UnaryPlusContext;\r\n\r\nCalculatorParser.UnaryPlusContext = UnaryPlusContext;\r\n\r\nUnaryPlusContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nUnaryPlusContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitUnaryPlus(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction ArccotContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nArccotContext.prototype = Object.create(ExpressionContext.prototype);\r\nArccotContext.prototype.constructor = ArccotContext;\r\n\r\nCalculatorParser.ArccotContext = ArccotContext;\r\n\r\nArccotContext.prototype.ARCCOT = function() {\r\n    return this.getToken(CalculatorParser.ARCCOT, 0);\r\n};\r\n\r\nArccotContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nArccotContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitArccot(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction ArccosContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nArccosContext.prototype = Object.create(ExpressionContext.prototype);\r\nArccosContext.prototype.constructor = ArccosContext;\r\n\r\nCalculatorParser.ArccosContext = ArccosContext;\r\n\r\nArccosContext.prototype.ARCCOS = function() {\r\n    return this.getToken(CalculatorParser.ARCCOS, 0);\r\n};\r\n\r\nArccosContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nArccosContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitArccos(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction EulerContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nEulerContext.prototype = Object.create(ExpressionContext.prototype);\r\nEulerContext.prototype.constructor = EulerContext;\r\n\r\nCalculatorParser.EulerContext = EulerContext;\r\n\r\nEulerContext.prototype.EULER = function() {\r\n    return this.getToken(CalculatorParser.EULER, 0);\r\n};\r\nEulerContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitEuler(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction ArctanContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nArctanContext.prototype = Object.create(ExpressionContext.prototype);\r\nArctanContext.prototype.constructor = ArctanContext;\r\n\r\nCalculatorParser.ArctanContext = ArctanContext;\r\n\r\nArctanContext.prototype.ARCTAN = function() {\r\n    return this.getToken(CalculatorParser.ARCTAN, 0);\r\n};\r\n\r\nArctanContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nArctanContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitArctan(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction ParenthesisContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nParenthesisContext.prototype = Object.create(ExpressionContext.prototype);\r\nParenthesisContext.prototype.constructor = ParenthesisContext;\r\n\r\nCalculatorParser.ParenthesisContext = ParenthesisContext;\r\n\r\nParenthesisContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nParenthesisContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitParenthesis(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction AbsContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nAbsContext.prototype = Object.create(ExpressionContext.prototype);\r\nAbsContext.prototype.constructor = AbsContext;\r\n\r\nCalculatorParser.AbsContext = AbsContext;\r\n\r\nAbsContext.prototype.ABS = function() {\r\n    return this.getToken(CalculatorParser.ABS, 0);\r\n};\r\n\r\nAbsContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nAbsContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitAbs(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction NumberContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nNumberContext.prototype = Object.create(ExpressionContext.prototype);\r\nNumberContext.prototype.constructor = NumberContext;\r\n\r\nCalculatorParser.NumberContext = NumberContext;\r\n\r\nNumberContext.prototype.NUMBER = function() {\r\n    return this.getToken(CalculatorParser.NUMBER, 0);\r\n};\r\nNumberContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitNumber(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction SinhContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nSinhContext.prototype = Object.create(ExpressionContext.prototype);\r\nSinhContext.prototype.constructor = SinhContext;\r\n\r\nCalculatorParser.SinhContext = SinhContext;\r\n\r\nSinhContext.prototype.SINH = function() {\r\n    return this.getToken(CalculatorParser.SINH, 0);\r\n};\r\n\r\nSinhContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nSinhContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitSinh(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction RoundContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nRoundContext.prototype = Object.create(ExpressionContext.prototype);\r\nRoundContext.prototype.constructor = RoundContext;\r\n\r\nCalculatorParser.RoundContext = RoundContext;\r\n\r\nRoundContext.prototype.ROUND = function() {\r\n    return this.getToken(CalculatorParser.ROUND, 0);\r\n};\r\n\r\nRoundContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nRoundContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitRound(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction TruncContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nTruncContext.prototype = Object.create(ExpressionContext.prototype);\r\nTruncContext.prototype.constructor = TruncContext;\r\n\r\nCalculatorParser.TruncContext = TruncContext;\r\n\r\nTruncContext.prototype.TRUNC = function() {\r\n    return this.getToken(CalculatorParser.TRUNC, 0);\r\n};\r\n\r\nTruncContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nTruncContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitTrunc(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction PiContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nPiContext.prototype = Object.create(ExpressionContext.prototype);\r\nPiContext.prototype.constructor = PiContext;\r\n\r\nCalculatorParser.PiContext = PiContext;\r\n\r\nPiContext.prototype.PI = function() {\r\n    return this.getToken(CalculatorParser.PI, 0);\r\n};\r\nPiContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitPi(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction TanhContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nTanhContext.prototype = Object.create(ExpressionContext.prototype);\r\nTanhContext.prototype.constructor = TanhContext;\r\n\r\nCalculatorParser.TanhContext = TanhContext;\r\n\r\nTanhContext.prototype.TANH = function() {\r\n    return this.getToken(CalculatorParser.TANH, 0);\r\n};\r\n\r\nTanhContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nTanhContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitTanh(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction FloorContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nFloorContext.prototype = Object.create(ExpressionContext.prototype);\r\nFloorContext.prototype.constructor = FloorContext;\r\n\r\nCalculatorParser.FloorContext = FloorContext;\r\n\r\nFloorContext.prototype.FLOOR = function() {\r\n    return this.getToken(CalculatorParser.FLOOR, 0);\r\n};\r\n\r\nFloorContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nFloorContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitFloor(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction LnContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nLnContext.prototype = Object.create(ExpressionContext.prototype);\r\nLnContext.prototype.constructor = LnContext;\r\n\r\nCalculatorParser.LnContext = LnContext;\r\n\r\nLnContext.prototype.LN = function() {\r\n    return this.getToken(CalculatorParser.LN, 0);\r\n};\r\n\r\nLnContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nLnContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitLn(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction ModContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nModContext.prototype = Object.create(ExpressionContext.prototype);\r\nModContext.prototype.constructor = ModContext;\r\n\r\nCalculatorParser.ModContext = ModContext;\r\n\r\nModContext.prototype.expression = function(i) {\r\n    if(i===undefined) {\r\n        i = null;\r\n    }\r\n    if(i===null) {\r\n        return this.getTypedRuleContexts(ExpressionContext);\r\n    } else {\r\n        return this.getTypedRuleContext(ExpressionContext,i);\r\n    }\r\n};\r\n\r\nModContext.prototype.MOD = function() {\r\n    return this.getToken(CalculatorParser.MOD, 0);\r\n};\r\nModContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitMod(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction LogContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nLogContext.prototype = Object.create(ExpressionContext.prototype);\r\nLogContext.prototype.constructor = LogContext;\r\n\r\nCalculatorParser.LogContext = LogContext;\r\n\r\nLogContext.prototype.LOG = function() {\r\n    return this.getToken(CalculatorParser.LOG, 0);\r\n};\r\n\r\nLogContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nLogContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitLog(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction AddSubContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    this.op = null; // Token;\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nAddSubContext.prototype = Object.create(ExpressionContext.prototype);\r\nAddSubContext.prototype.constructor = AddSubContext;\r\n\r\nCalculatorParser.AddSubContext = AddSubContext;\r\n\r\nAddSubContext.prototype.expression = function(i) {\r\n    if(i===undefined) {\r\n        i = null;\r\n    }\r\n    if(i===null) {\r\n        return this.getTypedRuleContexts(ExpressionContext);\r\n    } else {\r\n        return this.getTypedRuleContext(ExpressionContext,i);\r\n    }\r\n};\r\nAddSubContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitAddSub(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction CosContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nCosContext.prototype = Object.create(ExpressionContext.prototype);\r\nCosContext.prototype.constructor = CosContext;\r\n\r\nCalculatorParser.CosContext = CosContext;\r\n\r\nCosContext.prototype.COS = function() {\r\n    return this.getToken(CalculatorParser.COS, 0);\r\n};\r\n\r\nCosContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nCosContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitCos(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction DegContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nDegContext.prototype = Object.create(ExpressionContext.prototype);\r\nDegContext.prototype.constructor = DegContext;\r\n\r\nCalculatorParser.DegContext = DegContext;\r\n\r\nDegContext.prototype.DEG = function() {\r\n    return this.getToken(CalculatorParser.DEG, 0);\r\n};\r\n\r\nDegContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nDegContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitDeg(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction SqrtContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nSqrtContext.prototype = Object.create(ExpressionContext.prototype);\r\nSqrtContext.prototype.constructor = SqrtContext;\r\n\r\nCalculatorParser.SqrtContext = SqrtContext;\r\n\r\nSqrtContext.prototype.SQRT = function() {\r\n    return this.getToken(CalculatorParser.SQRT, 0);\r\n};\r\n\r\nSqrtContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nSqrtContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitSqrt(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction CotContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nCotContext.prototype = Object.create(ExpressionContext.prototype);\r\nCotContext.prototype.constructor = CotContext;\r\n\r\nCalculatorParser.CotContext = CotContext;\r\n\r\nCotContext.prototype.COT = function() {\r\n    return this.getToken(CalculatorParser.COT, 0);\r\n};\r\n\r\nCotContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nCotContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitCot(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction WholeContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nWholeContext.prototype = Object.create(ExpressionContext.prototype);\r\nWholeContext.prototype.constructor = WholeContext;\r\n\r\nCalculatorParser.WholeContext = WholeContext;\r\n\r\nWholeContext.prototype.expression = function(i) {\r\n    if(i===undefined) {\r\n        i = null;\r\n    }\r\n    if(i===null) {\r\n        return this.getTypedRuleContexts(ExpressionContext);\r\n    } else {\r\n        return this.getTypedRuleContext(ExpressionContext,i);\r\n    }\r\n};\r\n\r\nWholeContext.prototype.WHOLE = function() {\r\n    return this.getToken(CalculatorParser.WHOLE, 0);\r\n};\r\nWholeContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitWhole(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction UnaryContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nUnaryContext.prototype = Object.create(ExpressionContext.prototype);\r\nUnaryContext.prototype.constructor = UnaryContext;\r\n\r\nCalculatorParser.UnaryContext = UnaryContext;\r\n\r\nUnaryContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nUnaryContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitUnary(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction RadContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nRadContext.prototype = Object.create(ExpressionContext.prototype);\r\nRadContext.prototype.constructor = RadContext;\r\n\r\nCalculatorParser.RadContext = RadContext;\r\n\r\nRadContext.prototype.RAD = function() {\r\n    return this.getToken(CalculatorParser.RAD, 0);\r\n};\r\n\r\nRadContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nRadContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitRad(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction SqrContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nSqrContext.prototype = Object.create(ExpressionContext.prototype);\r\nSqrContext.prototype.constructor = SqrContext;\r\n\r\nCalculatorParser.SqrContext = SqrContext;\r\n\r\nSqrContext.prototype.SQR = function() {\r\n    return this.getToken(CalculatorParser.SQR, 0);\r\n};\r\n\r\nSqrContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nSqrContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitSqr(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction SinContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nSinContext.prototype = Object.create(ExpressionContext.prototype);\r\nSinContext.prototype.constructor = SinContext;\r\n\r\nCalculatorParser.SinContext = SinContext;\r\n\r\nSinContext.prototype.SIN = function() {\r\n    return this.getToken(CalculatorParser.SIN, 0);\r\n};\r\n\r\nSinContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nSinContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitSin(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction EexContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nEexContext.prototype = Object.create(ExpressionContext.prototype);\r\nEexContext.prototype.constructor = EexContext;\r\n\r\nCalculatorParser.EexContext = EexContext;\r\n\r\nEexContext.prototype.EEX = function() {\r\n    return this.getToken(CalculatorParser.EEX, 0);\r\n};\r\n\r\nEexContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nEexContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitEex(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction PowContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    this.op = null; // Token;\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nPowContext.prototype = Object.create(ExpressionContext.prototype);\r\nPowContext.prototype.constructor = PowContext;\r\n\r\nCalculatorParser.PowContext = PowContext;\r\n\r\nPowContext.prototype.expression = function(i) {\r\n    if(i===undefined) {\r\n        i = null;\r\n    }\r\n    if(i===null) {\r\n        return this.getTypedRuleContexts(ExpressionContext);\r\n    } else {\r\n        return this.getTypedRuleContext(ExpressionContext,i);\r\n    }\r\n};\r\nPowContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitPow(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction CeilContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nCeilContext.prototype = Object.create(ExpressionContext.prototype);\r\nCeilContext.prototype.constructor = CeilContext;\r\n\r\nCalculatorParser.CeilContext = CeilContext;\r\n\r\nCeilContext.prototype.CEIL = function() {\r\n    return this.getToken(CalculatorParser.CEIL, 0);\r\n};\r\n\r\nCeilContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nCeilContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitCeil(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction ExpContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nExpContext.prototype = Object.create(ExpressionContext.prototype);\r\nExpContext.prototype.constructor = ExpContext;\r\n\r\nCalculatorParser.ExpContext = ExpContext;\r\n\r\nExpContext.prototype.EXP = function() {\r\n    return this.getToken(CalculatorParser.EXP, 0);\r\n};\r\n\r\nExpContext.prototype.expression = function() {\r\n    return this.getTypedRuleContext(ExpressionContext,0);\r\n};\r\nExpContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitExp(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\nfunction RoundkContext(parser, ctx) {\r\n\tExpressionContext.call(this, parser);\r\n    ExpressionContext.prototype.copyFrom.call(this, ctx);\r\n    return this;\r\n}\r\n\r\nRoundkContext.prototype = Object.create(ExpressionContext.prototype);\r\nRoundkContext.prototype.constructor = RoundkContext;\r\n\r\nCalculatorParser.RoundkContext = RoundkContext;\r\n\r\nRoundkContext.prototype.ROUNDK = function() {\r\n    return this.getToken(CalculatorParser.ROUNDK, 0);\r\n};\r\n\r\nRoundkContext.prototype.expression = function(i) {\r\n    if(i===undefined) {\r\n        i = null;\r\n    }\r\n    if(i===null) {\r\n        return this.getTypedRuleContexts(ExpressionContext);\r\n    } else {\r\n        return this.getTypedRuleContext(ExpressionContext,i);\r\n    }\r\n};\r\nRoundkContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitRoundk(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\n\r\nCalculatorParser.prototype.expression = function(_p) {\r\n\tif(_p===undefined) {\r\n\t    _p = 0;\r\n\t}\r\n    var _parentctx = this._ctx;\r\n    var _parentState = this.state;\r\n    var localctx = new ExpressionContext(this, this._ctx, _parentState);\r\n    var _prevctx = localctx;\r\n    var _startState = 2;\r\n    this.enterRecursionRule(localctx, 2, CalculatorParser.RULE_expression, _p);\r\n    var _la = 0; // Token type\r\n    try {\r\n        this.enterOuterAlt(localctx, 1);\r\n        this.state = 87;\r\n        switch(this._input.LA(1)) {\r\n        case CalculatorParser.FLOOR:\r\n            localctx = new FloorContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n\r\n            this.state = 11;\r\n            this.match(CalculatorParser.FLOOR);\r\n            this.state = 12;\r\n            this.expression(40);\r\n            break;\r\n        case CalculatorParser.CEIL:\r\n            localctx = new CeilContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 13;\r\n            this.match(CalculatorParser.CEIL);\r\n            this.state = 14;\r\n            this.expression(39);\r\n            break;\r\n        case CalculatorParser.ABS:\r\n            localctx = new AbsContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 15;\r\n            this.match(CalculatorParser.ABS);\r\n            this.state = 16;\r\n            this.expression(38);\r\n            break;\r\n        case CalculatorParser.ROUND:\r\n            localctx = new RoundContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 17;\r\n            this.match(CalculatorParser.ROUND);\r\n            this.state = 18;\r\n            this.expression(36);\r\n            break;\r\n        case CalculatorParser.TRUNC:\r\n            localctx = new TruncContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 19;\r\n            this.match(CalculatorParser.TRUNC);\r\n            this.state = 20;\r\n            this.expression(35);\r\n            break;\r\n        case CalculatorParser.SIN:\r\n            localctx = new SinContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 21;\r\n            this.match(CalculatorParser.SIN);\r\n            this.state = 22;\r\n            this.expression(34);\r\n            break;\r\n        case CalculatorParser.COS:\r\n            localctx = new CosContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 23;\r\n            this.match(CalculatorParser.COS);\r\n            this.state = 24;\r\n            this.expression(33);\r\n            break;\r\n        case CalculatorParser.TAN:\r\n            localctx = new TanContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 25;\r\n            this.match(CalculatorParser.TAN);\r\n            this.state = 26;\r\n            this.expression(32);\r\n            break;\r\n        case CalculatorParser.COT:\r\n            localctx = new CotContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 27;\r\n            this.match(CalculatorParser.COT);\r\n            this.state = 28;\r\n            this.expression(31);\r\n            break;\r\n        case CalculatorParser.SINH:\r\n            localctx = new SinhContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 29;\r\n            this.match(CalculatorParser.SINH);\r\n            this.state = 30;\r\n            this.expression(30);\r\n            break;\r\n        case CalculatorParser.COSH:\r\n            localctx = new CoshContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 31;\r\n            this.match(CalculatorParser.COSH);\r\n            this.state = 32;\r\n            this.expression(29);\r\n            break;\r\n        case CalculatorParser.TANH:\r\n            localctx = new TanhContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 33;\r\n            this.match(CalculatorParser.TANH);\r\n            this.state = 34;\r\n            this.expression(28);\r\n            break;\r\n        case CalculatorParser.ARCSIN:\r\n            localctx = new ArcsinContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 35;\r\n            this.match(CalculatorParser.ARCSIN);\r\n            this.state = 36;\r\n            this.expression(27);\r\n            break;\r\n        case CalculatorParser.ARCCOS:\r\n            localctx = new ArccosContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 37;\r\n            this.match(CalculatorParser.ARCCOS);\r\n            this.state = 38;\r\n            this.expression(26);\r\n            break;\r\n        case CalculatorParser.ARCTAN:\r\n            localctx = new ArctanContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 39;\r\n            this.match(CalculatorParser.ARCTAN);\r\n            this.state = 40;\r\n            this.expression(25);\r\n            break;\r\n        case CalculatorParser.ARCCOT:\r\n            localctx = new ArccotContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 41;\r\n            this.match(CalculatorParser.ARCCOT);\r\n            this.state = 42;\r\n            this.expression(23);\r\n            break;\r\n        case CalculatorParser.EXP:\r\n            localctx = new ExpContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 43;\r\n            this.match(CalculatorParser.EXP);\r\n            this.state = 44;\r\n            this.expression(22);\r\n            break;\r\n        case CalculatorParser.LN:\r\n            localctx = new LnContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 45;\r\n            this.match(CalculatorParser.LN);\r\n            this.state = 46;\r\n            this.expression(21);\r\n            break;\r\n        case CalculatorParser.EEX:\r\n            localctx = new EexContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 47;\r\n            this.match(CalculatorParser.EEX);\r\n            this.state = 48;\r\n            this.expression(20);\r\n            break;\r\n        case CalculatorParser.LOG:\r\n            localctx = new LogContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 49;\r\n            this.match(CalculatorParser.LOG);\r\n            this.state = 50;\r\n            this.expression(19);\r\n            break;\r\n        case CalculatorParser.RAD:\r\n            localctx = new RadContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 51;\r\n            this.match(CalculatorParser.RAD);\r\n            this.state = 52;\r\n            this.expression(18);\r\n            break;\r\n        case CalculatorParser.DEG:\r\n            localctx = new DegContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 53;\r\n            this.match(CalculatorParser.DEG);\r\n            this.state = 54;\r\n            this.expression(17);\r\n            break;\r\n        case CalculatorParser.SQRT:\r\n            localctx = new SqrtContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 55;\r\n            this.match(CalculatorParser.SQRT);\r\n            this.state = 56;\r\n            this.expression(16);\r\n            break;\r\n        case CalculatorParser.SQR:\r\n            localctx = new SqrContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 57;\r\n            this.match(CalculatorParser.SQR);\r\n            this.state = 58;\r\n            this.expression(15);\r\n            break;\r\n        case CalculatorParser.SUB:\r\n            localctx = new UnaryContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 59;\r\n            this.match(CalculatorParser.SUB);\r\n            this.state = 60;\r\n            this.expression(2);\r\n            break;\r\n        case CalculatorParser.ADD:\r\n            localctx = new UnaryPlusContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 61;\r\n            this.match(CalculatorParser.ADD);\r\n            this.state = 62;\r\n            this.expression(1);\r\n            break;\r\n        case CalculatorParser.ROUNDK:\r\n            localctx = new RoundkContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 63;\r\n            this.match(CalculatorParser.ROUNDK);\r\n            this.state = 64;\r\n            this.match(CalculatorParser.T__0);\r\n            this.state = 65;\r\n            this.expression(0);\r\n            this.state = 66;\r\n            this.match(CalculatorParser.T__1);\r\n            this.state = 67;\r\n            this.expression(0);\r\n            this.state = 68;\r\n            this.match(CalculatorParser.T__2);\r\n            break;\r\n        case CalculatorParser.ARCTAN2:\r\n            localctx = new Arctan2Context(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 70;\r\n            this.match(CalculatorParser.ARCTAN2);\r\n            this.state = 71;\r\n            this.match(CalculatorParser.T__0);\r\n            this.state = 72;\r\n            this.expression(0);\r\n            this.state = 73;\r\n            this.match(CalculatorParser.T__1);\r\n            this.state = 74;\r\n            this.expression(0);\r\n            this.state = 75;\r\n            this.match(CalculatorParser.T__2);\r\n            break;\r\n        case CalculatorParser.NUMBER:\r\n            localctx = new NumberContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 77;\r\n            this.match(CalculatorParser.NUMBER);\r\n            break;\r\n        case CalculatorParser.T__0:\r\n            localctx = new ParenthesisContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 78;\r\n            this.match(CalculatorParser.T__0);\r\n            this.state = 79;\r\n            this.expression(0);\r\n            this.state = 80;\r\n            this.match(CalculatorParser.T__2);\r\n            break;\r\n        case CalculatorParser.PI:\r\n            localctx = new PiContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 82;\r\n            this.match(CalculatorParser.PI);\r\n            this.state = 84;\r\n            this._errHandler.sync(this);\r\n            var la_ = this._interp.adaptivePredict(this._input,1,this._ctx);\r\n            if(la_===1) {\r\n                this.state = 83;\r\n                this.match(CalculatorParser.T__8);\r\n\r\n            }\r\n            break;\r\n        case CalculatorParser.EULER:\r\n            localctx = new EulerContext(this, localctx);\r\n            this._ctx = localctx;\r\n            _prevctx = localctx;\r\n            this.state = 86;\r\n            this.match(CalculatorParser.EULER);\r\n            break;\r\n        default:\r\n            throw new antlr4.error.NoViableAltException(this);\r\n        }\r\n        this._ctx.stop = this._input.LT(-1);\r\n        this.state = 115;\r\n        this._errHandler.sync(this);\r\n        var _alt = this._interp.adaptivePredict(this._input,4,this._ctx)\r\n        while(_alt!=2 && _alt!=antlr4.atn.ATN.INVALID_ALT_NUMBER) {\r\n            if(_alt===1) {\r\n                if(this._parseListeners!==null) {\r\n                    this.triggerExitRuleEvent();\r\n                }\r\n                _prevctx = localctx;\r\n                this.state = 113;\r\n                this._errHandler.sync(this);\r\n                var la_ = this._interp.adaptivePredict(this._input,3,this._ctx);\r\n                switch(la_) {\r\n                case 1:\r\n                    localctx = new PowContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n                    this.state = 89;\r\n                    if (!( this.precpred(this._ctx, 14))) {\r\n                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 14)\");\r\n                    }\r\n                    this.state = 90;\r\n                    localctx.op = this._input.LT(1);\r\n                    _la = this._input.LA(1);\r\n                    if(!(_la===CalculatorParser.T__3 || _la===CalculatorParser.T__4)) {\r\n                        localctx.op = this._errHandler.recoverInline(this);\r\n                    }\r\n                    else {\r\n                        this.consume();\r\n                    }\r\n                    this.state = 91;\r\n                    this.expression(15);\r\n                    break;\r\n\r\n                case 2:\r\n                    localctx = new ModContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n                    this.state = 92;\r\n                    if (!( this.precpred(this._ctx, 13))) {\r\n                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 13)\");\r\n                    }\r\n                    this.state = 93;\r\n                    _la = this._input.LA(1);\r\n                    if(!(_la===CalculatorParser.T__5 || _la===CalculatorParser.MOD)) {\r\n                    this._errHandler.recoverInline(this);\r\n                    }\r\n                    else {\r\n                        this.consume();\r\n                    }\r\n                    this.state = 94;\r\n                    this.expression(14);\r\n                    break;\r\n\r\n                case 3:\r\n                    localctx = new WholeContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n                    this.state = 95;\r\n                    if (!( this.precpred(this._ctx, 12))) {\r\n                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 12)\");\r\n                    }\r\n                    this.state = 96;\r\n                    this.match(CalculatorParser.WHOLE);\r\n                    this.state = 97;\r\n                    this.expression(13);\r\n                    break;\r\n\r\n                case 4:\r\n                    localctx = new SqRootContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n                    this.state = 98;\r\n                    if (!( this.precpred(this._ctx, 11))) {\r\n                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 11)\");\r\n                    }\r\n                    this.state = 99;\r\n                    localctx.op = this._input.LT(1);\r\n                    _la = this._input.LA(1);\r\n                    if(!(_la===CalculatorParser.T__6 || _la===CalculatorParser.T__7)) {\r\n                        localctx.op = this._errHandler.recoverInline(this);\r\n                    }\r\n                    else {\r\n                        this.consume();\r\n                    }\r\n                    this.state = 100;\r\n                    this.expression(12);\r\n                    break;\r\n\r\n                case 5:\r\n                    localctx = new MulDivContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n                    this.state = 101;\r\n                    if (!( this.precpred(this._ctx, 10))) {\r\n                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 10)\");\r\n                    }\r\n                    this.state = 102;\r\n                    localctx.op = this._input.LT(1);\r\n                    _la = this._input.LA(1);\r\n                    if(!(_la===CalculatorParser.MUL || _la===CalculatorParser.DIV)) {\r\n                        localctx.op = this._errHandler.recoverInline(this);\r\n                    }\r\n                    else {\r\n                        this.consume();\r\n                    }\r\n                    this.state = 103;\r\n                    this.expression(11);\r\n                    break;\r\n\r\n                case 6:\r\n                    localctx = new AddSubContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n                    this.state = 104;\r\n                    if (!( this.precpred(this._ctx, 9))) {\r\n                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 9)\");\r\n                    }\r\n                    this.state = 105;\r\n                    localctx.op = this._input.LT(1);\r\n                    _la = this._input.LA(1);\r\n                    if(!(_la===CalculatorParser.ADD || _la===CalculatorParser.SUB)) {\r\n                        localctx.op = this._errHandler.recoverInline(this);\r\n                    }\r\n                    else {\r\n                        this.consume();\r\n                    }\r\n                    this.state = 106;\r\n                    this.expression(10);\r\n                    break;\r\n\r\n                case 7:\r\n                    localctx = new ExponentContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n                    this.state = 107;\r\n                    if (!( this.precpred(this._ctx, 5))) {\r\n                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 5)\");\r\n                    }\r\n                    this.state = 108;\r\n                    this.match(CalculatorParser.EXPONENT);\r\n                    this.state = 109;\r\n                    this.expression(6);\r\n                    break;\r\n\r\n                case 8:\r\n                    localctx = new NegExponentContext(this, new ExpressionContext(this, _parentctx, _parentState));\r\n                    this.pushNewRecursionContext(localctx, _startState, CalculatorParser.RULE_expression);\r\n                    this.state = 110;\r\n                    if (!( this.precpred(this._ctx, 4))) {\r\n                        throw new antlr4.error.FailedPredicateException(this, \"this.precpred(this._ctx, 4)\");\r\n                    }\r\n                    this.state = 111;\r\n                    this.match(CalculatorParser.NEGEXPONENT);\r\n                    this.state = 112;\r\n                    this.expression(5);\r\n                    break;\r\n\r\n                } \r\n            }\r\n            this.state = 117;\r\n            this._errHandler.sync(this);\r\n            _alt = this._interp.adaptivePredict(this._input,4,this._ctx);\r\n        }\r\n\r\n    } catch( error) {\r\n        if(error instanceof antlr4.error.RecognitionException) {\r\n\t        localctx.exception = error;\r\n\t        this._errHandler.reportError(this, error);\r\n\t        this._errHandler.recover(this, error);\r\n\t    } else {\r\n\t    \tthrow error;\r\n\t    }\r\n    } finally {\r\n        this.unrollRecursionContexts(_parentctx)\r\n    }\r\n    return localctx;\r\n};\r\n\r\nfunction CompileUnitContext(parser, parent, invokingState) {\r\n\tif(parent===undefined) {\r\n\t    parent = null;\r\n\t}\r\n\tif(invokingState===undefined || invokingState===null) {\r\n\t\tinvokingState = -1;\r\n\t}\r\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\r\n    this.parser = parser;\r\n    this.ruleIndex = CalculatorParser.RULE_compileUnit;\r\n    return this;\r\n}\r\n\r\nCompileUnitContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\r\nCompileUnitContext.prototype.constructor = CompileUnitContext;\r\n\r\nCompileUnitContext.prototype.EOF = function() {\r\n    return this.getToken(CalculatorParser.EOF, 0);\r\n};\r\n\r\nCompileUnitContext.prototype.accept = function(visitor) {\r\n    if ( visitor instanceof CalculatorVisitor ) {\r\n        return visitor.visitCompileUnit(this);\r\n    } else {\r\n        return visitor.visitChildren(this);\r\n    }\r\n};\r\n\r\n\r\n\r\n\r\nCalculatorParser.CompileUnitContext = CompileUnitContext;\r\n\r\nCalculatorParser.prototype.compileUnit = function() {\r\n\r\n    var localctx = new CompileUnitContext(this, this._ctx, this.state);\r\n    this.enterRule(localctx, 4, CalculatorParser.RULE_compileUnit);\r\n    try {\r\n        this.enterOuterAlt(localctx, 1);\r\n        this.state = 118;\r\n        this.match(CalculatorParser.EOF);\r\n    } catch (re) {\r\n    \tif(re instanceof antlr4.error.RecognitionException) {\r\n\t        localctx.exception = re;\r\n\t        this._errHandler.reportError(this, re);\r\n\t        this._errHandler.recover(this, re);\r\n\t    } else {\r\n\t    \tthrow re;\r\n\t    }\r\n    } finally {\r\n        this.exitRule();\r\n    }\r\n    return localctx;\r\n};\r\n\r\n\r\nCalculatorParser.prototype.sempred = function(localctx, ruleIndex, predIndex) {\r\n\tswitch(ruleIndex) {\r\n\tcase 1:\r\n\t\t\treturn this.expression_sempred(localctx, predIndex);\r\n    default:\r\n        throw \"No predicate with index:\" + ruleIndex;\r\n   }\r\n};\r\n\r\nCalculatorParser.prototype.expression_sempred = function(localctx, predIndex) {\r\n\tswitch(predIndex) {\r\n\t\tcase 0:\r\n\t\t\treturn this.precpred(this._ctx, 14);\r\n\t\tcase 1:\r\n\t\t\treturn this.precpred(this._ctx, 13);\r\n\t\tcase 2:\r\n\t\t\treturn this.precpred(this._ctx, 12);\r\n\t\tcase 3:\r\n\t\t\treturn this.precpred(this._ctx, 11);\r\n\t\tcase 4:\r\n\t\t\treturn this.precpred(this._ctx, 10);\r\n\t\tcase 5:\r\n\t\t\treturn this.precpred(this._ctx, 9);\r\n\t\tcase 6:\r\n\t\t\treturn this.precpred(this._ctx, 5);\r\n\t\tcase 7:\r\n\t\t\treturn this.precpred(this._ctx, 4);\r\n\t\tdefault:\r\n\t\t\tthrow \"No predicate with index:\" + predIndex;\r\n\t}\r\n};\r\n\r\n\r\nexports.CalculatorParser = CalculatorParser;\r\n\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./GeneratedAntlr/CalculatorParser.js\n ** module id = 49\n ** module chunks = 0\n **/","// Generated from Calculator.g4 by ANTLR 4.5.2\r\n// jshint ignore: start\r\nvar antlr4 = require('antlr4/index');\r\n\r\n// This class defines a complete generic visitor for a parse tree produced by CalculatorParser.\r\n\r\nfunction CalculatorVisitor() {\r\n\tantlr4.tree.ParseTreeVisitor.call(this);\r\n\treturn this;\r\n}\r\n\r\nCalculatorVisitor.prototype = Object.create(antlr4.tree.ParseTreeVisitor.prototype);\r\nCalculatorVisitor.prototype.constructor = CalculatorVisitor;\r\n\r\n// Visit a parse tree produced by CalculatorParser#calculator.\r\nCalculatorVisitor.prototype.visitCalculator = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Tan.\r\nCalculatorVisitor.prototype.visitTan = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Cosh.\r\nCalculatorVisitor.prototype.visitCosh = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#SqRoot.\r\nCalculatorVisitor.prototype.visitSqRoot = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#NegExponent.\r\nCalculatorVisitor.prototype.visitNegExponent = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Exponent.\r\nCalculatorVisitor.prototype.visitExponent = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Arctan2.\r\nCalculatorVisitor.prototype.visitArctan2 = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#MulDiv.\r\nCalculatorVisitor.prototype.visitMulDiv = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Arcsin.\r\nCalculatorVisitor.prototype.visitArcsin = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#UnaryPlus.\r\nCalculatorVisitor.prototype.visitUnaryPlus = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Arccot.\r\nCalculatorVisitor.prototype.visitArccot = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Arccos.\r\nCalculatorVisitor.prototype.visitArccos = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Euler.\r\nCalculatorVisitor.prototype.visitEuler = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Arctan.\r\nCalculatorVisitor.prototype.visitArctan = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Parenthesis.\r\nCalculatorVisitor.prototype.visitParenthesis = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Abs.\r\nCalculatorVisitor.prototype.visitAbs = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Number.\r\nCalculatorVisitor.prototype.visitNumber = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Sinh.\r\nCalculatorVisitor.prototype.visitSinh = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Round.\r\nCalculatorVisitor.prototype.visitRound = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Trunc.\r\nCalculatorVisitor.prototype.visitTrunc = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Pi.\r\nCalculatorVisitor.prototype.visitPi = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Tanh.\r\nCalculatorVisitor.prototype.visitTanh = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Floor.\r\nCalculatorVisitor.prototype.visitFloor = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Ln.\r\nCalculatorVisitor.prototype.visitLn = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Mod.\r\nCalculatorVisitor.prototype.visitMod = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Log.\r\nCalculatorVisitor.prototype.visitLog = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#AddSub.\r\nCalculatorVisitor.prototype.visitAddSub = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Cos.\r\nCalculatorVisitor.prototype.visitCos = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Deg.\r\nCalculatorVisitor.prototype.visitDeg = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Sqrt.\r\nCalculatorVisitor.prototype.visitSqrt = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Cot.\r\nCalculatorVisitor.prototype.visitCot = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Whole.\r\nCalculatorVisitor.prototype.visitWhole = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Unary.\r\nCalculatorVisitor.prototype.visitUnary = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Rad.\r\nCalculatorVisitor.prototype.visitRad = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Sqr.\r\nCalculatorVisitor.prototype.visitSqr = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Sin.\r\nCalculatorVisitor.prototype.visitSin = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Eex.\r\nCalculatorVisitor.prototype.visitEex = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Pow.\r\nCalculatorVisitor.prototype.visitPow = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Ceil.\r\nCalculatorVisitor.prototype.visitCeil = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Exp.\r\nCalculatorVisitor.prototype.visitExp = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#Roundk.\r\nCalculatorVisitor.prototype.visitRoundk = function(ctx) {\r\n};\r\n\r\n\r\n// Visit a parse tree produced by CalculatorParser#compileUnit.\r\nCalculatorVisitor.prototype.visitCompileUnit = function(ctx) {\r\n};\r\n\r\n\r\n\r\nexports.CalculatorVisitor = CalculatorVisitor;\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./GeneratedAntlr/CalculatorVisitor.js\n ** module id = 50\n ** module chunks = 0\n **/","export class CalculationResult {\r\n    public isValid: boolean = false;\r\n    public errorPosition: number = null;\r\n    public errorMessage: string = null;\r\n    public result: number = NaN;\r\n}\n\n\n/** WEBPACK FOOTER **\n ** ./CalculationResult.ts\n **/","export class FormulaErrorListener {\r\n\r\n    private _isValid = true;\r\n    private _errorLocation: number | null = null;\r\n    private _errorMessage: string;\r\n\r\n    public get isValid() {\r\n        return this._isValid;\r\n    }\r\n\r\n    public get errorLocation() {\r\n        return this._errorLocation;\r\n    }\r\n\r\n    public get errorMessage() {\r\n        return this._errorMessage;\r\n    }\r\n\r\n    public syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\r\n        this._isValid = false;\r\n        this._errorLocation = column;\r\n        this._errorMessage = msg;\r\n    }\r\n\r\n    /**\r\n     * Method stub - does nothing\r\n     * @param recognizer\r\n     * @param dfa\r\n     * @param startIndex\r\n     * @param stopIndex\r\n     * @param exact\r\n     * @param ambigAlts\r\n     * @param configs\r\n     */\r\n    public reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\r\n    };\r\n\r\n    /**\r\n     * Method stub - does nothing\r\n     * @param recognizer\r\n     * @param dfa\r\n     * @param startIndex\r\n     * @param stopIndex\r\n     * @param conflictingAlts\r\n     * @param configs\r\n     */\r\n    public reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\r\n    };\r\n\r\n    /**\r\n     * Method stub - does nothing\r\n     * @param recognizer\r\n     * @param dfa\r\n     * @param startIndex\r\n     * @param stopIndex\r\n     * @param prediction\r\n     * @param configs\r\n     */\r\n    public reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\r\n    };\r\n}\n\n\n/** WEBPACK FOOTER **\n ** ./FormulaErrorListener.ts\n **/"],"sourceRoot":""}